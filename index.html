<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="纸上得来终觉浅，绝知此事要躬行" />










<meta name="description" content="纸上得来终觉浅">
<meta property="og:type" content="website">
<meta property="og:title" content="cherish">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="cherish">
<meta property="og:description" content="纸上得来终觉浅">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="cherish-ls">
<meta property="article:tag" content="纸上得来终觉浅，绝知此事要躬行">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>cherish</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">cherish</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">返朴归真</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/03/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/03/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%AF%BB/" itemprop="url">文章导读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-12-03T22:56:59+08:00">
                2019-12-03
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/12/03/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%AF%BB/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/12/03/文章导读/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  533
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  2
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="JAVA"><a href="#JAVA" class="headerlink" title="JAVA"></a>JAVA</h1><ul>
<li><h2 id="JAVA-JVM"><a href="#JAVA-JVM" class="headerlink" title="JAVA  JVM"></a>JAVA  JVM</h2><ul>
<li><a href="https://cherish-ls.github.io/2019/10/17/JAVA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/" target="_blank" rel="noopener" title="JAVA内存模型">JAVA内存模型</a></li>
<li><a href="https://cherish-ls.github.io/2019/10/23/JAVA%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E5%92%8C%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/" target="_blank" rel="noopener" title="JAVA内存结构和内存管理">JAVA内存结构和内存管理</a></li>
<li><a href="https://cherish-ls.github.io/2019/11/21/JAVA%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/" target="_blank" rel="noopener" title="JAVA垃圾回收器">JAVA垃圾回收器</a></li>
<li><a href="https://cherish-ls.github.io/2019/12/03/Class%E6%96%87%E4%BB%B6%E5%92%8C%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/" target="_blank" rel="noopener" title="Class文件和类加载机制">Class文件和类加载机制</a></li>
<li><a href="https://cherish-ls.github.io/2019/11/25/JAVA%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/" target="_blank" rel="noopener" title="JAVA对象的创建和内存分配策略">JAVA对象的创建和内存分配策略</a></li>
<li><a href="https://cherish-ls.github.io/2020/05/07/JVM%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%E4%B9%8B%E3%80%8E%E4%B8%80%E4%B8%AA%E7%B1%BB%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%E3%80%8F/" target="_blank" rel="noopener" title="JVM学习总结之『一个类的前世今生』">JVM学习总结之『一个类的前世今生』</a></li>
</ul>
</li>
<li><h2 id="线程与并发控制"><a href="#线程与并发控制" class="headerlink" title="线程与并发控制"></a>线程与并发控制</h2><ul>
<li><a href="https://cherish-ls.github.io/2018/03/27/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-ThreadPoolExecutor/" target="_blank" rel="noopener" title="线程池源码分析——ThreadPoolExecutor">线程池源码分析——ThreadPoolExecutor</a></li>
<li><a href="https://cherish-ls.github.io/2019/08/29/JAVA%E4%B8%AD%E6%96%AD%E6%9C%BA%E5%88%B6/" target="_blank" rel="noopener" title="JAVA中断机制">JAVA中断机制</a></li>
<li><a href="https://cherish-ls.github.io/2019/08/23/JAVA%E5%B9%B6%E5%8F%91%E4%B9%8BAQS%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener" title="JAVA并发之AQS详解">JAVA并发之AQS详解</a></li>
<li><a href="https://cherish-ls.github.io/2019/09/26/AQS%E5%AE%9E%E7%8E%B0%E4%B9%8BCountDownLatch-Semaphore-CyclicBarrier/" target="_blank" rel="noopener" title="AQS实现之CountDownLatch/Semaphore/CyclicBarrier">AQS实现之CountDownLatch/Semaphore/CyclicBarrier</a></li>
<li><a href="https://cherish-ls.github.io/2019/10/15/synchronized%E5%8E%9F%E7%90%86%E5%92%8C%E9%94%81%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5-%E5%81%8F%E5%90%91-%E8%BD%BB%E9%87%8F%E7%BA%A7-%E9%87%8D%E9%87%8F%E7%BA%A7/" target="_blank" rel="noopener" title="synchronized原理和锁优化策略(偏向/轻量级/重量级)">synchronized原理和锁优化策略(偏向/轻量级/重量级)</a></li>
<li><a href="https://cherish-ls.github.io/2020/08/05/JAVA%E7%9A%84CAS%E5%8F%8A%E5%85%B6ABA%E9%97%AE%E9%A2%98/" target="_blank" rel="noopener" title="JAVA的CAS及其ABA问题">JAVA的CAS及其ABA问题</a></li>
<li><a href="https://cherish-ls.github.io/2020/08/07/volatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener" title="volatile关键字详解">volatile关键字详解</a></li>
</ul>
</li>
<li><h2 id="JAVA实现或特性"><a href="#JAVA实现或特性" class="headerlink" title="JAVA实现或特性"></a>JAVA实现或特性</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/07/26/JAVA%E9%9D%99%E6%80%81-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/" target="_blank" rel="noopener" title="JAVA静态/动态代理">JAVA静态/动态代理</a></li>
<li><a href="https://cherish-ls.github.io/2020/10/14/JAVA%E5%86%85%E7%BD%AE%E6%8E%92%E5%BA%8FArrays-sort%E5%AE%9E%E7%8E%B0%E7%AE%80%E8%BF%B0/" target="_blank" rel="noopener" title="JAVA内置排序Arrays.sort实现简述">JAVA内置排序Arrays.sort实现简述</a></li>
</ul>
</li>
<li><h2 id="JAVA监控和调优"><a href="#JAVA监控和调优" class="headerlink" title="JAVA监控和调优"></a>JAVA监控和调优</h2><ul>
<li><a href="https://cherish-ls.github.io/2019/08/27/dump%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%92%8C%E5%88%86%E6%9E%90%E6%9F%A5%E7%9C%8B/" target="_blank" rel="noopener" title="dump文件生成和分析查看">dump文件生成和分析查看</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="数据结构与算法"><a href="#数据结构与算法" class="headerlink" title="数据结构与算法"></a>数据结构与算法</h1><ul>
<li><h2 id="树"><a href="#树" class="headerlink" title="树"></a>树</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/04/28/B%E6%A0%91-B-%E6%A0%91%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="B树/B+树分析">B树/B+树分析</a></li>
</ul>
</li>
<li><h2 id="图"><a href="#图" class="headerlink" title="图"></a>图</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/" target="_blank" rel="noopener" title="【图论】广度/深度优先搜索算法">【图论】广度/深度优先搜索算法</a></li>
<li><a href="https://cherish-ls.github.io/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener" title="【图论】拓扑排序详解">【图论】拓扑排序详解</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="计算机协议和技术"><a href="#计算机协议和技术" class="headerlink" title="计算机协议和技术"></a>计算机协议和技术</h1><ul>
<li><h2 id="网络协议"><a href="#网络协议" class="headerlink" title="网络协议"></a>网络协议</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/03/17/TCP-IP%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%A7%88/" target="_blank" rel="noopener" title="TCP-IP协议学习导览">TCP-IP协议学习导览</a></li>
<li><a href="https://cherish-ls.github.io/2020/03/18/UDP%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="UDP协议分析">UDP协议分析</a></li>
<li><a href="https://cherish-ls.github.io/2020/04/08/TCP%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="TCP协议分析">TCP协议分析</a> </li>
</ul>
</li>
<li><h2 id="Linux相关"><a href="#Linux相关" class="headerlink" title="Linux相关"></a>Linux相关</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/08/13/%E8%AF%A6%E8%A7%A3IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%92%8C%E5%85%B6%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94select-poll-epoll/" target="_blank" rel="noopener" title="详解IO多路复用和其三种模式——select/poll/epoll">详解IO多路复用和其三种模式——select/poll/epoll</a></li>
<li><a href="https://cherish-ls.github.io/2019/07/21/%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4%E5%AF%BC%E8%88%AA/" target="_blank" rel="noopener" title="常用shell命令导航">常用shell命令导航</a></li>
<li><a href="https://cherish-ls.github.io/2019/07/17/shell-notes-tips/" target="_blank" rel="noopener" title="shell notes&amp;tips">shell notes&amp;tips</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h1><ul>
<li><h2 id="spring"><a href="#spring" class="headerlink" title="spring"></a>spring</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/05/25/Spring-IoC%E6%A6%82%E5%BF%B5%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="Spring-IoC概念分析">Spring-IoC概念分析</a></li>
<li><a href="https://cherish-ls.github.io/2020/06/29/Spring-Resource%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6%E4%BD%93%E7%B3%BB/" target="_blank" rel="noopener" title="Spring-Resource资源文件体系">Spring-Resource资源文件体系</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h1><ul>
<li><h2 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h2><ul>
<li><a href="https://cherish-ls.github.io/2019/08/20/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1zookeeper%E7%AE%80%E8%AE%BA/" target="_blank" rel="noopener" title="分布式协调服务zookeeper简论">分布式协调服务zookeeper简论</a></li>
</ul>
</li>
<li><h2 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/02/20/ElasticSearch%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E8%AF%A6%E8%A7%A3%EF%BC%88index-type-doc-node-shard-replica-segment%EF%BC%89/" target="_blank" rel="noopener" title="ElasticSearch核心概念详解（index/type/doc/node/shard/replica/segment）">ElasticSearch核心概念详解（index/type/doc/node/shard/replica/segment）</a></li>
<li><a href="https://cherish-ls.github.io/2020/02/18/ElasticSearch-Master%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6%E6%B5%85%E6%9E%90/" target="_blank" rel="noopener" title="ElasticSearch Master选举机制浅析">ElasticSearch Master选举机制浅析</a></li>
<li><a href="https://cherish-ls.github.io/2018/08/02/ElasticSearch%E5%8D%87%E7%BA%A7%E8%AE%B0%E5%BD%95-ver-1-4-5%E2%86%92ver-5-2-0/" target="_blank" rel="noopener" title="ElasticSearch升级记录 ver.1.4.5→ver.5.2.0">ElasticSearch升级记录 ver.1.4.5→ver.5.2.0</a></li>
</ul>
</li>
<li><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><ul>
<li><a href="https://cherish-ls.github.io/2019/12/19/Redis%E7%9A%845%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/" target="_blank" rel="noopener" title="Redis的5种数据类型">Redis的5种数据类型</a></li>
<li><a href="https://cherish-ls.github.io/2019/12/19/Redis%E7%9A%848%E7%A7%8D%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" target="_blank" rel="noopener" title="Redis的8种底层数据结构">Redis的8种底层数据结构</a></li>
<li><a href="https://cherish-ls.github.io/2020/01/08/Redis%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%9E%8B-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/" target="_blank" rel="noopener" title="Redis事件模型-主从复制-哨兵模型-集群模式">Redis事件模型-主从复制-哨兵模型-集群模式</a></li>
<li><a href="https://cherish-ls.github.io/2019/12/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%93%E6%9E%84-%E9%94%AE%E7%A9%BA%E9%97%B4-%E8%BF%87%E6%9C%9F%E5%AD%97%E5%85%B8-%E4%BA%8B%E5%8A%A1-%E9%94%81-%E6%8C%81%E4%B9%85%E5%8C%96/" target="_blank" rel="noopener" title="Redis数据库结构/键空间/过期字典/事务/锁/持久化">Redis数据库结构/键空间/过期字典/事务/锁/持久化</a></li>
<li><a href="https://cherish-ls.github.io/2020/04/09/Redis%E7%9A%84%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E4%BB%8B%E7%BB%8D/" target="_blank" rel="noopener" title="Redis的缓存雪崩/缓存穿透/缓存预热+布隆过滤器介绍">Redis的缓存雪崩/缓存穿透/缓存预热+布隆过滤器介绍</a></li>
<li><a href="https://cherish-ls.github.io/2020/08/04/Redis%E4%B8%ADLRU%E5%92%8CLFU%E7%AE%97%E6%B3%95%E5%92%8C%E5%AE%9E%E7%8E%B0/" target="_blank" rel="noopener" title="LRU和LFU算法以及其在Redis中的实现">LRU和LFU算法以及其在Redis中的实现</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h1><ul>
<li><h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/05/06/MySQL%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%B1%87%E6%80%BB/" target="_blank" rel="noopener" title="MySQL核心要点汇总">MySQL核心要点汇总</a></li>
<li><a href="https://cherish-ls.github.io/2020/09/30/MySQL%E6%97%A5%E5%BF%97%E4%BD%93%E7%B3%BB%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener" title="MySQL日志体系详解">MySQL日志体系详解</a></li>
<li><a href="https://cherish-ls.github.io/2020/08/31/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%80%E3%80%91%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%92%8C%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7/" target="_blank" rel="noopener" title="【InnoDB详解一】体系架构和关键特性">【InnoDB详解一】体系架构和关键特性</a></li>
<li><a href="https://cherish-ls.github.io/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/" target="_blank" rel="noopener" title="【InnoDB详解二】MySQL文件系统和InnoDB存储结构">【InnoDB详解二】MySQL文件系统和InnoDB存储结构</a></li>
<li><a href="https://cherish-ls.github.io/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/" target="_blank" rel="noopener" title="【InnoDB详解三】锁和事务">【InnoDB详解三】锁和事务</a></li>
<li><a href="https://cherish-ls.github.io/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/" target="_blank" rel="noopener" title="【InnoDB详解四】redo log和undo log">【InnoDB详解四】redo log和undo log</a></li>
</ul>
</li>
<li><h2 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/05/06/%E7%90%86%E8%A7%A3sql%E4%B8%AD%E7%9A%84group-by%E5%92%8Chaving/" target="_blank" rel="noopener" title="理解sql中的group by和having">理解sql中的group by和having</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="分布式算法-amp-理论"><a href="#分布式算法-amp-理论" class="headerlink" title="分布式算法&amp;理论"></a>分布式算法&amp;理论</h1><ul>
<li><h2 id="分布式事务和数据一致性"><a href="#分布式事务和数据一致性" class="headerlink" title="分布式事务和数据一致性"></a>分布式事务和数据一致性</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/01/21/Raft%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="Raft算法分析">Raft算法分析</a></li>
<li><a href="https://cherish-ls.github.io/2019/08/12/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%90%86%E8%AE%BA%E5%92%8Cpaxos%E7%AE%97%E6%B3%95/" target="_blank" rel="noopener" title="分布式一致性理论和paxos算法">分布式一致性理论和paxos算法</a></li>
<li><a href="https://cherish-ls.github.io/2020/07/26/ZAB%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="ZAB协议分析">ZAB协议分析</a></li>
</ul>
</li>
<li><h2 id="负载均衡算法"><a href="#负载均衡算法" class="headerlink" title="负载均衡算法"></a>负载均衡算法</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/07/26/%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95/" target="_blank" rel="noopener" title="一致性hash算法">一致性hash算法</a></li>
</ul>
</li>
</ul>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E6%A6%82%E5%BF%B5%E8%AE%BA%E8%BF%B0%E5%92%8C%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E6%A6%82%E5%BF%B5%E8%AE%BA%E8%BF%B0%E5%92%8C%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/" itemprop="url">分布式事务的概念论述和方案总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-19T21:27:25+08:00">
                2020-11-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95-%E7%90%86%E8%AE%BA/" itemprop="url" rel="index">
                    <span itemprop="name">分布式算法&理论</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95-%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%92%8C%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/" itemprop="url" rel="index">
                    <span itemprop="name">分布式事务和数据一致性</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E6%A6%82%E5%BF%B5%E8%AE%BA%E8%BF%B0%E5%92%8C%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/11/19/分布式事务的概念论述和方案总结/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  13k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  45
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-分布式事务的概念"><a href="#1-分布式事务的概念" class="headerlink" title="1 分布式事务的概念"></a>1 分布式事务的概念</h1><p>事务在分布式计算领域也得到了广泛的应用。在单机数据库中，我们很容易能够实现一套满足ACID特性的事务处理系统，但是在分布式数据库中，数据分散在各台不同的机器上，如何对这些数据进行分布式事务处理具有非常大的挑战。</p>
<p>分布式事务的分布式，是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点之上。通常一个分布式事务会涉及对多个数据源或业务系统的操作。</p>
<p>一个最典型的分布式事务场景是跨行的转账操作。该操作涉及调用两个异地的银行服务。其中一个是本地银行提供的取款服务，另一个是目标银行提供的存款服务，这两个服务本身是无状态且相互独立的，共同构成了一个完整的分布式事务。取款和存款两个步骤要么都执行，要么都不执行。否则，如果从本地银行取款成功，但是因为某种原因存款服务失败了，那么必须回滚到取款之前的状态，否则就会导致数据不一致。</p>
<p>从上面的例子可以看出，一个分布式事务可以看作是由多个分布式操作序列组成的，例如上面例子中的取款服务和存款服务，通常可以把这一系列分布式的操作序列称为<strong>子事务</strong>。由于分布式事务中，各个子事务的执行是分布式的，因此要实现一种能够保证ACID特性的分布式事务处理系统就显得格外复杂。</p>
<p>分布式事务=分布式+事务，这是分布式事务本身最直观，也最重要的标签。我们要想理解分布式事务的理论基础，就要首先从这两个角度来解读：</p>
<h2 id="1-1-分布式事务是个事务"><a href="#1-1-分布式事务是个事务" class="headerlink" title="1.1 分布式事务是个事务"></a>1.1 分布式事务是个事务</h2><p>首先，分布式事务是个事务，既然是事务，那么我们会希望它能够满足传统事务的ACID四个特性：</p>
<h3 id="1-1-1-传统事务要拥有ACID特性"><a href="#1-1-1-传统事务要拥有ACID特性" class="headerlink" title="1.1.1 传统事务要拥有ACID特性"></a>1.1.1 传统事务要拥有ACID特性</h3><ul>
<li><p>Atomic（原子性）</p>
<ul>
<li>事务的原子性是指事务必须是一个原子的操作序列单元。事务中包含的各项操作在一次执行过程中，要么全部执行，要么全部不执行。</li>
<li>任何一项操作失败都将导致整个事务失败，同时其他已经被执行的操作都将被撤销并回滚。只有所有的操作全部成功，整个事务才算是成功完成。</li>
</ul>
</li>
<li><p>Consistency（一致性）</p>
<ul>
<li>事务的一致性是指事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行前后，数据库都必须处于一致性状态。换句话说，事务的执行结果必须是使数据库从一个一致性状态转变到另一个一致性状态。</li>
<li>假设银行的转账操作就是一个事务。假设A和B原来账户都有100元。此时A转账给B50元，转账结束后，应该是A账户减去50元变成50元，B账户增加50元变成150元。A、B的账户总和还是200元。转账前后，数据库就是从一个一致性状态（A100元，B100元，A、B共200元）转变到另一个一致性状态（A50元，B150元，A、B共200元）。假设转账结束后只扣了A账户，没有增加B账户，这时数据库就处于不一致的状态。</li>
</ul>
</li>
<li><p>Isolation（隔离性）</p>
<ul>
<li><p>事务的隔离性是指在并发环境中，并发的事务是相互隔离的，事务之间互不干扰。</p>
</li>
<li><p>在标准的SQL规范中，定义的4个事务隔离级别，不同隔离级别对事务的处理不同。4个隔离级别分别是：读未提交、读已提交、可重复读和串行化。</p>
<p><img src="https://oscimg.oschina.net/oscnet/e21672a1348914a88a48ad986f9cd5457ce.jpg" alt=""></p>
</li>
<li><p>事务隔离级别越高，就越能保证数据的完整性和一致性，但同时对并发性能的影响也越大。</p>
</li>
<li><p>通常，对于绝大多数的应用来说，可以优先考虑将数据库系统的隔离级别设置为授权读取，这能够在避免脏读的同时保证较好的并发性能。尽管这种事务隔离级别会导致不可重复读、幻读和第二类丢失更新等并发问题，但较为科学的做法是在可能出现这类问题的个别场合中，由应用程序主动采用悲观锁或乐观锁来进行事务控制。</p>
</li>
</ul>
</li>
<li><p>Durability（持久性）</p>
<ul>
<li>事务的持久性又称为永久性，是指一个事务一旦提交，对数据库中对应数据的状态变更就应该是永久性的。即使发生系统崩溃或机器宕机等故障，只要数据库能够重新启动，那么一定能够将其恢复到事务成功结束时的状态。</li>
</ul>
</li>
</ul>
<h2 id="1-2-分布式事务是分布式的"><a href="#1-2-分布式事务是分布式的" class="headerlink" title="1.2 分布式事务是分布式的"></a>1.2 分布式事务是分布式的</h2><p>其次，分布式事务是分布式的，既然是分布式的系统，那么它必然无可避免的要收到CAP理论的约束：</p>
<h3 id="1-2-1-分布式系统要受CAP理论约束"><a href="#1-2-1-分布式系统要受CAP理论约束" class="headerlink" title="1.2.1 分布式系统要受CAP理论约束"></a>1.2.1 分布式系统要受CAP理论约束</h3><p>CAP理论：一个分布式系统不可能同时满足一致性（C:Consistency）、可用性（A:Availability）和分区容错性（P:Partition tolerance）这三个基本要求，最多只能满足其中的两项。</p>
<ul>
<li>一致性<ul>
<li>在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性（这点跟ACID中的一致性含义不同）。</li>
<li>对于一个将数据副本分布在不同节点上的分布式系统来说，如果对第一个节点的数据进行了更新操作并且更新成功后，却没有使得第二个节点上的数据得到相应的更新，于是在对第二个节点的数据进行读取操作时，获取的依然是更新前的数据（称为脏数据），这就是典型的分布式数据不一致情况。</li>
<li>在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都能读取到最新的值，那么这样的系统就被认为具有强一致性（或严格的一致性）。</li>
</ul>
</li>
<li>可用性<ul>
<li>可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果，如果超过了这个时间范围，那么系统就被认为是不可用的。</li>
<li>『有限的时间内』是一个在系统设计之初就设定好的运行指标，不同的系统会有很大的差别。比如对于一个在线搜索引擎来说，通常在0.5秒内需要给出用户搜索关键词对应的检索结果。而对应Hive来说，一次正常的查询时间可能在20秒到30秒之间。</li>
<li>『返回结果』是可用性的另一个非常重要的指标，它要求系统在完成对用户请求的处理后，返回一个正常的响应结果。正常的响应结果通常能够明确地反映出对请求的处理结果，及成功或失败，而不是一个让用户感到困惑的返回结果。</li>
<li>让我们再来看看上面提到的在线搜索引擎的例子，如果用户输入指定的搜索关键词后，返回的结果是一个系统错误，比如”OutOfMemoryErroe”或”System Has Crashed”等提示语，那么我们认为此时系统是不可用的。</li>
</ul>
</li>
<li>分区容错性<ul>
<li>分区容错性要求一个分布式系统需要具备如下特性：分布式系统在遇到任何网络分区故障的时候，仍然能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。</li>
<li>网络分区是指在分布式系统中，不同的节点分布在不同的子网络（机房或异地网络等）中，由于一些特殊的原因导致这些子网络之间出现网络不连通的状况，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干个孤立的区域。</li>
</ul>
</li>
</ul>
<p>需要明确的一点是：<strong>对于一个分布式系统而言，分区容错性可以说是一个最基本的要求</strong>。因为既然是一个分布式系统，那么分布式系统中的组件必然需要被部署到不同的节点，否则也就无所谓的分布式系统了，因此必然出现子网络。</p>
<p>而对于分布式系统而言，网络问题又是一个必定会出现的异常情况，因此分区容错性也就成为了一个分布式系统必然需要面对和解决的问题。<strong>因此系统架构师往往需要把精力花在如何根据业务特点在C（一致性）和A（可用性）之间寻求平衡</strong>。</p>
<p>比如Cassandra、Dynamo等中间件，他们的实现默认优先选择AP，弱化C；</p>
<p>而HBase、MongoDB等中间件，他们的实现默认优先选择CP，弱化A。</p>
<h3 id="1-2-2-一致性和可用性权衡的总结——BASE理论"><a href="#1-2-2-一致性和可用性权衡的总结——BASE理论" class="headerlink" title="1.2.2 一致性和可用性权衡的总结——BASE理论"></a>1.2.2 一致性和可用性权衡的总结——BASE理论</h3><p>BASE是Basically Available(基本可用）、Soft state(软状态）和Eventually consistent(最终一致性）三个短语的简写，由eBay架构师Dan Pritchett提出的，是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网分布式系统实践的总结，是基于CAP定律逐步演化而来。</p>
<p>BASE理论核心思想是：<strong>即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性</strong>。</p>
<ul>
<li><p>基本可用</p>
<ul>
<li>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用。比如<ul>
<li>响应时间上的损失：正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。</li>
<li>功能上的损失：正常情况下，在一个电子商务网站（比如淘宝）上购物，消费者几乎能够顺利地完成每一笔订单。但在一些节日大促购物高峰的时候（比如双十一、双十二），由于消费者的购物行为激增，为了保护系统的稳定性（或者保证一致性），部分消费者可能会被引导到一个降级页面</li>
</ul>
</li>
</ul>
</li>
<li><p>弱状态</p>
<ul>
<li>弱状态是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同的数据副本之间进行数据同步的过程存在延时。</li>
</ul>
</li>
<li><p>最终一致性</p>
<ul>
<li>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。</li>
<li>最终一致性是一种特殊的弱一致性：系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问都能够获取到最新的值。同时，在没有发生故障的前提下，数据到达一致状态的时间延迟，取决于网络延迟、系统负载和数据复制方案设计等因素。</li>
<li>在实际工程实践中，最终一致性存在以下五类主要的变种：<ul>
<li>因果一致性(Causal consistency)<ul>
<li>如果进程A通知进程B它已更新了一个数据项，那么进程B的后续访问将返回更新后的值，且一次写入将保证取代前一次写入。与进程A无因果关系的进程C的访问遵守一般的最终一致性规则。</li>
</ul>
</li>
<li>读己之所写(Read your writes)<ul>
<li>当进程A自己更新一个数据项之后，它总是访问到更新过的值，绝不会看到旧值。这是因果一致性模型的一个特例。</li>
</ul>
</li>
<li>会话一致性(Session consistency)<ul>
<li>这是上一个模型的实用版本，它把访问存储系统的进程放到会话的上下文中。只要会话还存在，系统就保证“读己之所写”一致性。如果由于某些失败情形令会话终止，就要建立新的会话，而且系统的保证不会延续到新的会话。</li>
</ul>
</li>
<li>单调读一致性(Monotonic read consistency)<ul>
<li>如果某个进程已经看到过数据对象的某个值，那么该进程任何后续访问都不会返回在那个值之前的值。</li>
</ul>
</li>
<li>单调写一致性(Monotonic write consistency)<ul>
<li>系统保证来自同一个进程的写操作顺序执行。要是系统不能保证这种程度的一致性，就非常难以编程了。<blockquote>
<p>以上就是最终一致性的五种常见的变种，在实际系统实践中，可以将其中的若干个变种互相结合起来，以构建一个具有最终一致性特性的分布式系统。<br>事实上，最终一致性并不是只有那些大型分布式系统才涉及的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中（比如MySQL和PostgreSQL），大多都会采用同步或异步方式来实现主备数据复制技术。在同步方式中，数据的复制过程通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致。而在异步方式中，备库的更新往往会存在延时，这取决于事务日志在主备数据库之间传输的时间长短。如果传输时间过长或者甚至在日志传输过程中出现异常导致无法及时将事务应用到备库上，那么很显然，从备库中读取的数据将是旧的，因此就出现了数据不一致的情况。<br>当然，无论是采用多次重试还是人为数据订正，关系型数据库还是能够保证最终数据达到一致，这就是系统提供最终一致性保证的经典案例。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="1-3-ACID和CAP妥协下的柔性事务"><a href="#1-3-ACID和CAP妥协下的柔性事务" class="headerlink" title="1.3 ACID和CAP妥协下的柔性事务"></a>1.3 ACID和CAP妥协下的柔性事务</h2><p>可以看到，ACID特性和CAP理论，在关于一致性问题上都有论述，只不过</p>
<ul>
<li>ACID中的C论述的是：一个事务在执行前后，数据库的数据都必须处于一致性状态，如转账过程，金钱总量应该保持不变。</li>
<li>CAP中的C论述的是：同一个数据在多个分布式副本之间是否能够保持一致，如某个用户的余额，在各个副本之间值应该一致。</li>
</ul>
<p>我们需要注意到他们论述的点其实是不同的。</p>
<p>同时，我们还要注意到，虽然分布式系统受限于CAP理论而时常要在A和C中做取舍，但对于分布式事务系统来说，C的重要性是高于A的，故而市面上成熟的分布式事务解决方案，都是在努力事务ACID特性的基础上，尽量在分布式的情况下（也就是满足分区容错性的情况下）达到较好的数据一致性。</p>
<p>我们一般来说，根据数据一致性的实效，以及ACID/CAP取舍的类型，可将事务分为：</p>
<ol>
<li>刚性事务：遵循ACID原则，强一致性。本地事务，基本都是刚性事务。</li>
<li>柔性事务：遵循BASE理论，最终一致性；与刚性事务不同，柔性事务允许一定时间内，不同节点的数据不一致，但要求最终一致。</li>
</ol>
<p><strong>受限于分布式的局限，分布式事务的实现目前都是柔性事务，换句话说，我们还无法实现完全满足ACID强一致性的分布式事务</strong>。</p>
<h1 id="2-分布式事务的解决方案"><a href="#2-分布式事务的解决方案" class="headerlink" title="2 分布式事务的解决方案"></a>2 分布式事务的解决方案</h1><p>经过上文的论述，我们有了一定的理论基础，明确了我们希望的分布式事务应该是什么样的。我们往往为了可用性和分区容错性，忍痛放弃强一致支持的刚性事务，转而追求最终一致性的柔性事务。</p>
<p>那么如何实现能够<strong>基本满足</strong>ACID特性和CAP理论的分布式事务呢？我们接下来介绍几种成熟的柔性事务实现。</p>
<ol>
<li><strong>XA协议</strong>：更偏向于在数据库层面解决数据库之间的分布式事务<ul>
<li>1.1 2PC（两段式提交）</li>
<li>1.2 3PC（三段式提交）</li>
</ul>
</li>
<li><strong>TCC两阶段补偿型事务</strong>：更偏向于在应用层面解决分布式系统中的补偿形分布式事务</li>
<li><strong>最大努力通知</strong>：最简单的一种柔性事务，适用于一些最终一致性时间敏感度低，且被动方处理结果<strong>不影响</strong>主动方的处理结果的业务。</li>
<li><strong>本地消息表</strong>：将分布式事务拆分成本地事务进行处理的一种思路</li>
<li>半消息/最终一致性（RocketMQ）</li>
</ol>
<p>TCC、Saga、事务消息、最大努力事务</p>
<h2 id="2-1-XA协议"><a href="#2-1-XA协议" class="headerlink" title="2.1 XA协议"></a>2.1 XA协议</h2><p>在分布式系统中，每个节点都能明确知道自身事务操作结果，但无法直接获取到其他分布式节点的操作结果。所以当一个事务要横跨多个节点时，为了保证事务处理的ACID特性而引入了协调者组件来统一调度所有分布式节点（参与者）的执行逻辑，协调者调度参与者的行为并最终决定是否把参与者的事务进行真正的提交。</p>
<p>XA协议是体现和贯彻协调者角色的一种很经典分布式事务协议，由Tuxedo提出，XA的目的是保证分布式事务的ACID特性，就像本地事务一样。</p>
<p>XA大致分为两部分：事务管理器（<strong>协调者角色</strong>）和本地资源管理器。其中本地资源管理器往往由数据库实现，比如Oracle、DB2这些商业数据库都实现了XA接口，而事务管理器作为全局的调度者，负责各个本地资源的提交和回滚。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-30f12d658476ab1e33f5927ccfd6b141604.png" alt=""></p>
<p>XA协议为了保证分布式事务能够在保持ACID特性的同时保证分布式系统之间的数据一致性，提供了两种分布式事务的实现：2PC和3PC协议。</p>
<h3 id="2-1-1-2PC"><a href="#2-1-1-2PC" class="headerlink" title="2.1.1 2PC"></a>2.1.1 2PC</h3><h4 id="2-1-1-1-简介"><a href="#2-1-1-1-简介" class="headerlink" title="2.1.1.1 简介"></a>2.1.1.1 简介</h4><ul>
<li>2PC（Two-Phase Commit 两阶段提交）：完成参与者的协调，统一决定事务的提交或回滚，使基于分布式系统架构下的所有节点在进行事务处理过程中能够保持原子性和数据一致性。</li>
<li>目前绝大部分的关系型数据库都是采用二阶段提交协议来完成分布式事务处理的。</li>
</ul>
<hr>
<h4 id="2-1-1-2-协议内容"><a href="#2-1-1-2-协议内容" class="headerlink" title="2.1.1.2 协议内容"></a>2.1.1.2 协议内容</h4><ol>
<li><p><strong>投票，尝试让协调者们提交事务</strong></p>
<ul>
<li>事务询问：协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，等待响应</li>
<li>执行事务：参与者节点执行事务操作，并记录Undo和Redo信息到事务日志</li>
<li>参与者响应：若参与者成功执行事务，则向协调者反馈Yes响应，否则反馈No响应</li>
</ul>
</li>
<li><p><strong>根据协调者反馈决定事务执行结果</strong></p>
<ol start="21">
<li>如果所有参与者的反馈都是Yes响应，那么执行事务提交<ul>
<li>发送提交请求：协调者向所有参与者发送Commit请求 </li>
<li>事务提交：参与者接受到Commit请求后执行事务提交操作并释放占用的事务资源 </li>
<li>反馈事务提交结果：参与者完成事务提交后向协调者发送Ack消息 </li>
<li>完成事务：协调者收到所有参与者的Ack响应后，完成事务提交</li>
</ul>
</li>
</ol>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/4468f39b5d7567570812b28447e0fb3346b.jpg" alt=""></li>
</ul>
<ol start="22">
<li>如果任何一个参与者返回了N响应或者协调者等待超时后就会中断事务<ul>
<li>发送回滚请求：协调者向所有参与者发送Rollback请求 </li>
<li>事务回滚：参与者受到请求后通过Undo信息执行事务回滚操作并释放占用的事务资源 </li>
<li>反馈事务回滚结果：参与者回滚事务后向协调者发送Ack消息 </li>
<li>中断事务：协调者接收到所有参与者的Ack响应后，完成事务中断</li>
</ul>
</li>
</ol>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/2d9e49af734e01cd1514beebdbf8b2c5aeb.jpg" alt=""></li>
</ul>
<hr>
<h4 id="2-1-1-3-优缺点"><a href="#2-1-1-3-优缺点" class="headerlink" title="2.1.1.3 优缺点"></a>2.1.1.3 优缺点</h4></li>
</ol>
<ul>
<li>优点<ul>
<li>原理简单，实现方便，有许多现成的实现框架</li>
</ul>
</li>
<li>缺点<ul>
<li>同步阻塞：在阶段二事务提交过程中，所有参与者的操作逻辑都处于阻塞状态，等待其他参与者响应，协调者请求</li>
<li>单点问题：一旦协调者出现问题，阶段二提交流程无法运转，并且参与者会一直处于锁定事务资源的状态，无法继续事务操作</li>
<li>太过保守：任何一个参与节点的失败使得协调者无法获取所有参与者的响应信息都会导致整个事务的失败<h3 id="2-1-2-3PC"><a href="#2-1-2-3PC" class="headerlink" title="2.1.2 3PC"></a>2.1.2 3PC</h3><h4 id="2-1-2-1-简介"><a href="#2-1-2-1-简介" class="headerlink" title="2.1.2.1 简介"></a>2.1.2.1 简介</h4></li>
</ul>
</li>
<li>3PC（Three-Phase Commit 三阶段提交）将二阶段提交的提交事务请求过程一分为二，形成CanCommit、PreCommit、doCommit三个阶段</li>
<li><img src="https://oscimg.oschina.net/oscnet/7a6cf90924d8b6ef9e4e6190be693612419.jpg" alt=""><h4 id="2-1-2-2-内容"><a href="#2-1-2-2-内容" class="headerlink" title="2.1.2.2 内容"></a>2.1.2.2 内容</h4></li>
</ul>
<ol>
<li><p>CanCommit</p>
<ul>
<li>事务询问：协调者向所有参与者发送包含事务内容的CanCommit请求，询问是否可以执行事务提交操作，等待响应 </li>
<li>参与者响应：参与者接收到CanCommit请求后判断自身能够顺利执行事务，能则返回Yes响应并进入预备状态，否则返回No响应</li>
</ul>
</li>
<li><p>PreCommit</p>
<ol start="21">
<li>如果所有参与者反馈都为Yes响应，则执行事务预提交<ul>
<li>发送预提交请求：协调者向所有参与者节点发出PreCommit请求，并进入Prepared阶段 </li>
<li>事务预提交：参与者接收到PreCommit请求后预执行事务操作（还未提交），并记录Undo和Redo信息到事务日志中 </li>
<li>参与者响应事务执行结果：若参与者成功执行事务后则返回Ack响应给协调者，等待最终命令，提交（commit）或者中断（abort）</li>
</ul>
</li>
<li>如果任何一个参与者反馈了No响应或者<strong>协调者等待所有协调者的响应超时</strong>则中断事务<ul>
<li>发送中断请求：协调者向所有参与者节点发出Abort请求 </li>
<li>中断事务：无论收到Abort请求或者等待协调者请求超时，参与者都会中断事务</li>
</ul>
</li>
</ol>
</li>
<li><p>DoCommit</p>
<ol start="31">
<li><p>执行提交</p>
<ul>
<li>发送提交请求：当协调者收到所有参与者反馈的Ack响应，向所有参与者发送DoCommit请求，从预提交状态转到提交状态 </li>
<li>事务提交：参与者接收到DoCommit请求后，正式执行事务提交操作，并释放占用的事务资源 </li>
<li>反馈事务提交结果：参与者完成事务提交后向协调者发送Ack消息</li>
<li>完成事务：协调者接受到所有参与者反馈的Ack响应后，完成事务</li>
</ul>
</li>
<li><p>中断事务</p>
<ul>
<li>发送中断请求：协调者向所有参与者节点发出Abort请求 </li>
<li>事务回滚：参与者接收到Abort请求后，利用Undo信息执行事务回滚操作，并释放占用的事务资源 </li>
<li>反馈事务回滚结果：参与者完成事务回滚后向协调者发送Ack消息 </li>
<li>中断事务：协调者接收到所有参与者反馈的Ack响应后，中断事务</li>
</ul>
<blockquote>
<p>ps1.需要注意的是，在这一阶段，可能发生两种故障，协调者工作异常，或者协调者与参与者之间网络异常。无论出现何种情况，都会导致参与者无法及时接收到协调者发送的doCommit或者Abort请求，针对这样的异常，参与者在等待超时后，继续进行事务提交。</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<h4 id="2-1-2-3-优缺点"><a href="#2-1-2-3-优缺点" class="headerlink" title="2.1.2.3 优缺点"></a>2.1.2.3 优缺点</h4><ul>
<li>优点<ul>
<li>降低参与者的阻塞范围，能够在出现单点故障后继续达成一致</li>
</ul>
</li>
<li>缺点<ul>
<li>接受者接收到PreCommit消息后，如果出现网络分区导致协调者和参与者无法正常通信，这时参与者仍会进行事务提交，造成数据的不一致</li>
</ul>
</li>
</ul>
<h3 id="2-1-3-2PC和3PC的区别总结"><a href="#2-1-3-2PC和3PC的区别总结" class="headerlink" title="2.1.3 2PC和3PC的区别总结"></a>2.1.3 2PC和3PC的区别总结</h3><ul>
<li><p>2PC图示</p>
<ul>
<li>提交成功<br><img src="https://oscimg.oschina.net/oscnet/c0085259e239f6951bd1a2ea157c3adf752.jpg" alt=""></li>
<li>中断事务<br><img src="https://oscimg.oschina.net/oscnet/6c004cf1642872088d024f6a27fd97eca93.jpg" alt=""></li>
</ul>
</li>
<li><p>3PC 图示<br><img src="https://oscimg.oschina.net/oscnet/b77e43933901bccaeef41c088534d616695.jpg" alt=""></p>
</li>
<li><p>与两阶段提交不同的是，三阶段提交有如下改动点。</p>
<ul>
<li>引入超时机制。同时在协调者和参与者中都引入超时机制。</li>
<li>在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。</li>
<li>3PC的第三阶段，参与者等待协调者反馈超时时，会默认执行。</li>
</ul>
</li>
<li><p>总结</p>
<ul>
<li>相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。</li>
<li>默认执行其实是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。</li>
</ul>
</li>
</ul>
<h2 id="2-2-TCC两阶段补偿型事务"><a href="#2-2-TCC两阶段补偿型事务" class="headerlink" title="2.2 TCC两阶段补偿型事务"></a>2.2 TCC两阶段补偿型事务</h2><h3 id="2-2-1-简介"><a href="#2-2-1-简介" class="headerlink" title="2.2.1 简介"></a>2.2.1 简介</h3><p>TCC方案是可能是目前最火的一种柔性事务方案了。关于TCC（Try-Confirm-Cancel）的概念，最早是由Pat Helland于2007年发表的一篇名为《Life beyond Distributed Transactions:an Apostate’s Opinion》的论文提出。在该论文中，TCC还是以Tentative-Confirmation-Cancellation命名。正式以Try-Confirm-Cancel作为名称的是Atomikos公司，其注册了TCC商标。</p>
<p>国内最早关于TCC的报道，应该是InfoQ上对阿里程立博士的一篇采访。经过程博士的这一次传道之后，TCC在国内逐渐被大家广为了解并接受。</p>
<p>Atomikos公司在商业版本事务管理器ExtremeTransactions中提供了TCC方案的实现，但是由于其是收费的，因此相应的很多的开源实现方案也就涌现出来，如：TCC-transaction、ByteTCC、spring-cloud-rest-tcc、ByteTCC、Himly。</p>
<h3 id="2-2-2-内容"><a href="#2-2-2-内容" class="headerlink" title="2.2.2 内容"></a>2.2.2 内容</h3><p>TCC是三个英文单词的首字母缩写而来。没错，TCC分别对应Try、Confirm和Cancel三种操作，这三种操作的业务含义如下：</p>
<ol>
<li>Try：预留业务资源</li>
<li>Confirm：确认执行业务操作</li>
<li>Cancel：取消执行业务操作</li>
</ol>
<p>我们以一个经典电商系统下的支付订单场景为例：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f40b616bc3819ac5b3843c49ca268d98f23.png" alt=""></p>
<p>那对一个订单支付之后，我们需要做下面的步骤：</p>
<ol>
<li>更改订单的状态为“已支付”</li>
<li>扣减商品库存</li>
<li>给会员增加积分</li>
<li>创建销售出库单通知仓库发货</li>
</ol>
<p>上述这几个步骤，要么一起成功，要么一起失败，必须是一个整体性的事务。</p>
<p>那么TCC如何实现呢？</p>
<h4 id="2-2-2-1-Try"><a href="#2-2-2-1-Try" class="headerlink" title="2.2.2.1 Try"></a>2.2.2.1 Try</h4><p>Try操作的核心是<strong>预留业务资源</strong>，比如</p>
<ol>
<li>别直接把订单状态修改为已支付，可以先把订单状态修改为 UPDATING，也就是修改中的意思。</li>
<li>库存服务也别直接扣减库存啊，而改为冻结掉库存。你可以把可销售的库存：100-2=98，设置为98没问题，然后在一个单独的冻结库存的字段里，设置一个2，也就是说，有2个库存是给冻结了。</li>
<li>同理，别直接给用户增加会员积分，可以先在积分表里的一个预增加积分字段加入积分。</li>
<li>销售出库单可以创建，但是也设置一个中间状态“UNKNOWN”表示未确认。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-e47473f4956006c79ea5baa78b1569cbd02.png" alt=""></p>
<h4 id="2-2-2-2-Confirm"><a href="#2-2-2-2-Confirm" class="headerlink" title="2.2.2.2 Confirm"></a>2.2.2.2 Confirm</h4><p>完成了Try操作后，接下来就分成两种情况了，第一种情况是比较理想的，那就是各个服务执行自己的Try操作都成功了，那么紧接着进入Confirm阶段。</p>
<p>订单，库存，积分，出库四个模块都感知到了try操作的成功，这是confirm操作执行：</p>
<ol>
<li>正式把订单的状态设置为“已支付”。</li>
<li>冻结库存字段的2个库存扣掉变为0。</li>
<li>将预增加字段的10个积分扣掉，然后加入实际的会员积分字段中。</li>
<li>将销售出库单的状态正式修改为“已创建”，可以供仓储管理人员查看和使用，而不是停留在之前的中间状态“UNKNOWN”了。</li>
</ol>
<blockquote>
<p>这里简单提一句，如果你要玩TCC分布式事务，必须引入一款TCC分布式事务框架，比如国内开源的 ByteTCC、Himly、TCC-transaction。否则的话，感知各个阶段的执行情况以及推进执行下一个阶段的这些事情，不太可能自己手写实现，太复杂了。</p>
</blockquote>
<p><img src="https://oscimg.oschina.net/oscnet/up-4cd001fd41b9ecb4c12147fb532184a5bca.png" alt=""></p>
<h4 id="2-2-2-3-Cancel"><a href="#2-2-2-3-Cancel" class="headerlink" title="2.2.2.3 Cancel"></a>2.2.2.3 Cancel</h4><p>Confirm是try都成功后的操作，那么cancel就是try操作异常后才会进入的阶段。如积分服务吧，它执行出错了，订单服务内的TCC事务框架是可以感知到的，然后它会决定对整个TCC分布式事务进行回滚。</p>
<ol>
<li>将订单的状态设置为“CANCELED”，也就是这个订单的状态是已取消。</li>
<li>将冻结库存扣减掉2，加回到可销售库存里去，98 + 2 = 100。</li>
<li>将预增加积分字段的10个积分扣减掉。</li>
<li>将销售出库单的状态修改为“CANCELED”，即已取消。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-fb93fc3b5207a8f22f8bf39b323746421d1.png" alt=""></p>
<h3 id="2-2-3-TCC是补偿形事务"><a href="#2-2-3-TCC是补偿形事务" class="headerlink" title="2.2.3 TCC是补偿形事务"></a>2.2.3 TCC是补偿形事务</h3><p>TCC中的两阶段提交（try+confirm或者try+cancel）并没有对开发者完全屏蔽，也就是说从代码层面，开发者是可以感受到两阶段提交的存在。如上述案例：在第一阶段，相关模块需要提供try接口，为积分库存等预留字段分配资源。在第二阶段，各模块需要提供confirm/cancel接口(确认/取消预留)。开发者明显的感知到了两阶段提交过程的存在。try、confirm/cancel在执行过程中，一般都会开启各自的本地事务，来保证方法内部业务逻辑的ACID特性。其中：</p>
<ol>
<li><p>try过程的本地事务，是保证资源预留的业务逻辑的正确性。</p>
</li>
<li><p>confirm/cancel执行的本地事务逻辑确认/取消预留资源，以保证最终一致性，也就是所谓的补偿型事务(Compensation-Based Transactions)。</p>
</li>
</ol>
<p>由于是多个独立的本地事务，因此不会对资源一直加锁。</p>
<p>另外，这里提到confirm/cancel执行的本地事务是补偿性事务，关于什么事补偿性事务，atomikos 官网上有以下描述：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-91703711c3e922fbf2aa3a584ab318c9a44.png" alt=""></p>
<p>红色框中的内容，是对补偿性事务的解释。大致含义是，”<strong>补偿是一个独立的支持ACID特性的本地事务，用于在逻辑上取消服务提供者上一个ACID事务造成的影响，对于一个长事务(long-running transaction)，与其实现一个巨大的分布式ACID事务，不如使用基于补偿性的方案，把每一次服务调用当做一个较短的本地ACID事务来处理，执行完就立即提交</strong>”。</p>
<p>在这里，笔者理解为confirm和cancel就是补偿事务，用于取消try阶段本地事务造成的影响。因为第一阶段try只是预留资源，之后必须要明确的告诉服务提供者，这个资源你到底要不要，对应第二阶段的confirm/cancel。</p>
<p>现在应该明白为什么把TCC叫做两阶段补偿性事务了，提交过程分为2个阶段，第二阶段的confirm/cancel执行的事务属于补偿事务。</p>
<h3 id="2-2-4-优缺点"><a href="#2-2-4-优缺点" class="headerlink" title="2.2.4 优缺点"></a>2.2.4 优缺点</h3><ul>
<li>优点<ul>
<li>解决了跨应用业务操作的原子性问题，在诸如组合支付、账务拆分场景非常实用。</li>
<li>TCC实际上把数据库层的二阶段提交上提到了应用层来实现，对于数据库来说是一阶段提交，规避了数据库层的2PC性能低下问题。</li>
</ul>
</li>
<li>缺点<ul>
<li>TCC的Try、Confirm和Cancel操作功能需业务提供，开发成本高。</li>
</ul>
</li>
</ul>
<h2 id="2-3-最大努力通知"><a href="#2-3-最大努力通知" class="headerlink" title="2.3 最大努力通知"></a>2.3 最大努力通知</h2><h3 id="2-3-1-简介"><a href="#2-3-1-简介" class="headerlink" title="2.3.1 简介"></a>2.3.1 简介</h3><p>最大努力通知型( Best-effort delivery)是最简单的一种柔性事务，适用于一些最终一致性时间敏感度低的业务，且被动方处理结果不影响主动方的处理结果。典型的使用场景如银行通知、商户通知等。</p>
<p>最大努力通知型的实现方案，一般符合以下特点：</p>
<ol>
<li>不可靠消息：业务活动执行方，在完成业务处理之后，向业务活动的触发方发送消息，直到通知N次后不再通知，允许消息丢失(不可靠消息)。</li>
<li>定期校对：业务活动的触发方，根据定时策略，向业务活动执行方查询(执行方提供查询接口)，恢复丢失的业务消息。</li>
</ol>
<h3 id="2-3-2-内容"><a href="#2-3-2-内容" class="headerlink" title="2.3.2 内容"></a>2.3.2 内容</h3><p>举例来说：设计一个短信发送平台，背景是公司内部有多个业务都有发送短信的需求，如果每个业务独立实现短信发送功能，存在功能实现上的重复。因此专门做了一个短信平台项目，所有的业务方都接入这个短信平台，来实现发送短信的功能。简化后的架构如下所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-78aa56176a8aaa9ed89d8b12928de541e9a.png" alt=""></p>
<p>短信发送流程如下：</p>
<ol>
<li>业务方将短信发送请求提交给短信平台</li>
<li>短信平台接收到要发送的短信，记录到数据库中，并标记其状态为”已接收”</li>
<li>短信平台调用外部短信发送供应商的接口，发送短信。外部供应商的接口也是异步将短信发送到用户手机上，因此这个接口调用后，立即返回，进入第4步。</li>
<li>更新短信发送状态为”已发送”</li>
<li>短信发送供应商异步通知短信平台短信发送结果。而通知可能失败，因此最多只会通知N次。</li>
<li>短信平台接收到短信发送结果后，更新短信发送状态，可能是成功，也可能失败(如手机欠费)。到底是成功还是失败并不重要，重要的是我们知道了这调短信发送的最终结果</li>
<li>如果最多只通知N次，如果都失败了的话，那么短信平台将不知道短信到底有没有成功发送。因此短信发送供应商需要提供一个查询接口，以方便短信平台驱动的去查询，进行定期校对。</li>
</ol>
<p>在这个案例中，<strong>短信发送供应商通知短信平台短信发送结果的过程中，就是最典型的最大努力通知型方案</strong>，尽最大的努力通知了N次就不再通知。通过提供一个短信结果查询接口，让短信平台可以进行定期的校对。而由于短信发送业务的时间敏感度并不高，比较适合采用这个方案。</p>
<p>需要注意的是，定期校对的步骤很重要，短信结果查询接口很重要，必须要进行定期校对。因为后期要进行对账，比如一个月的短信发送总量在高峰期可以达到1亿条左右，即使一条短信只要5分钱，一个月就有500W。</p>
<h3 id="2-3-3-优缺点"><a href="#2-3-3-优缺点" class="headerlink" title="2.3.3 优缺点"></a>2.3.3 优缺点</h3><ul>
<li>优点<ul>
<li>原理简单，实现方便，目前也有现成的实现框架</li>
</ul>
</li>
<li>缺点<ul>
<li>即便柔性事务都只能保证数据的最终一致性，最大努力通知模型的最终时间也可能是最长的，因为消息发送的不确定性，可能会导致通知迟迟无法被消费，只适用于最终一致性时间敏感度低的业务。</li>
<li>回滚逻辑需要业务编写补偿逻辑来实现，比较费力。</li>
</ul>
</li>
</ul>
<h2 id="2-4-本地消息表"><a href="#2-4-本地消息表" class="headerlink" title="2.4 本地消息表"></a>2.4 本地消息表</h2><p>在描述本地消息表之前，我们要先了解一个概念：</p>
<p><strong>消息发送一致性</strong>：是指产生消息的业务动作与消息发送的一致，本地业务逻辑执行与消息发送是原子性的。也就是说，如果业务操作成功，那么由这个业务操作所产生的消息一定要成功投递出去(一般是发送到kafka、rocketmq、rabbitmq等消息中间件中)，否则就丢消息。</p>
<p>以购物场景为例，张三购买物品，账户扣款100元的同时，需要保证在下游的会员服务中给该账户增加100积分。如果扣款100元的业务逻辑执行失败了，但是通知增加积分的消息却没有回滚，而是发送出去了，那就会导致积分无故增加。同样的，如果扣款成功了，但是消息通知失败了，扣款却没有回滚的话，也会导致该增加的积分没有增加。</p>
<h3 id="2-4-1-简介"><a href="#2-4-1-简介" class="headerlink" title="2.4.1 简介"></a>2.4.1 简介</h3><p>本地消息表这种实现方式应该是业界使用最多的，这种实现方式的思路，其实是源于 ebay，后来通过支付宝等公司的布道，在业内广泛使用。其基本的设计思想是将远程分布式事务拆分成一系列的本地事务。如果不考虑性能及设计优雅，借助关系型数据库中的表即可实现。</p>
<h3 id="2-4-2-内容"><a href="#2-4-2-内容" class="headerlink" title="2.4.2 内容"></a>2.4.2 内容</h3><p>我们可以从下面的流程图中看出其中的一些细节：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-62f232513ca7f0682e8e52b0fc796a354ed.png" alt=""></p>
<p>举例说明：下单购买商品</p>
<ol>
<li><p>支付服务器：前提是有个本地消息表A</p>
<ul>
<li>1.1  当你支付的时候，你需要把你支付的金额扣减，并且把消息落到本地消息表A，这两个操作要放入同一个事务(依靠数据库本地事务保证一致性）。</li>
<li>1.2 消息落表后，发送MQ通知到商品库存服务器，发送成功后，更新表A中的状态。</li>
<li>1.3 除此之外，支付服务器还有一个定时任务去轮询这个本地事务表A，把没有发送的消息，重试发送给商品库存服务器。</li>
</ul>
</li>
<li><p>商品库存服务器：前提是有个本地消息表B</p>
<ul>
<li>2.1 MQ到达商品服务器之后，将接收的消息写入这个服务器的本地消息表B，然后进行扣减库存这两个操作要放入同一个事务(依靠数据库本地事务保证一致性）。扣减成功后，更新事务表B中的状态。</li>
<li>2.2 发送反馈消息给支付服务器，如果执行成功了，就反馈成功消息。如果执行失败，则反馈失败消息。</li>
<li>2.3 除此之外，商品库存服务器还有一个定时任务去轮询这个本地事务表B，把没有发送的消息，重试发送给支付服务器。</li>
</ul>
</li>
</ol>
<p>如果支付服务器接收到成功的回馈，那么事务成功。如果接收到失败的反馈，则执行回滚操作，即调用补偿接口进行反向操作。</p>
<p>本地消息表模型，<strong>通过将业务和消息落表的操作放入同一个本地事务，利用本地事务的ACID特性，来确保发送方/接收方的自身业务逻辑的连贯性和紧密型</strong>。</p>
<p>换句话说，只有发送方的业务逻辑执行成功，发送方才会将消息落表，以及发出通知，因为这些步骤在一个本地事务里面，要么都失败，要么都成功。</p>
<p>同理，接收方的业务逻辑执行，接收消息的落表，以及消息表状态的翻转，也都在一个本地事务里面，所以如果接收方发出了通知，那证明接收方的业务逻辑肯定已经执行了。</p>
<p>当两端自身的逻辑都具有连贯性和紧密型，那剩下的只要确保消息可靠就行了。mq的重试机制，以及两方的定时校验机制，都是这种可靠性的保障。</p>
<h3 id="2-4-3-优缺点"><a href="#2-4-3-优缺点" class="headerlink" title="2.4.3 优缺点"></a>2.4.3 优缺点</h3><ul>
<li>优点<ul>
<li>一种非常经典的实现，将整个分布式事务分割成多个端的本地事务，利用本地事务的可靠性来保证分布式事务在各个端的可靠性，从而使我们的精力只要集中要消息通知和校检上。</li>
</ul>
</li>
<li>缺点<ul>
<li>消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。</li>
<li>回滚逻辑需要业务编写补偿逻辑来实现，比较费力。</li>
</ul>
</li>
</ul>
<h2 id="2-5-事务消息机制"><a href="#2-5-事务消息机制" class="headerlink" title="2.5 事务消息机制"></a>2.5 事务消息机制</h2><h3 id="2-5-1-简介"><a href="#2-5-1-简介" class="headerlink" title="2.5.1 简介"></a>2.5.1 简介</h3><p>前文讨论本地消息表的时候，我们提到了<strong>消息发送一致性</strong>，使用本地消息表，将业务逻辑和本地消息表的读写用本地事务来保证，这确实是一个办法。但这种办法需要额外建消息表，还需要手动编写落表逻辑和业务逻辑绑定的代码，耦合较重。有什么更优雅的，但同样能保证消息发送一致性的实现吗？答案就是本章讨论的事务消息机制。</p>
<p>从Apache RocketMQ发布的4.3版本开始，RocketMQ开源了社区最为关心的分布式事务消息，而且实现了对外部组件的零依赖。</p>
<p>RocketMQ事务消息设计则主要是为了解决Producer端的消息发送与本地事务执行的原子性问题，RocketMQ的设计中broker与producer端的双向通信能力，使得broker天生可以作为一个事务协调者存在；而RocketMQ本身提供的存储机制，则为事务消息提供了持久化能力；RocketMQ的高可用机制以及可靠消息设计，则为事务消息在系统在发生异常时，依然能够保证事务的最终一致性达成。</p>
<h3 id="2-5-2-内容"><a href="#2-5-2-内容" class="headerlink" title="2.5.2 内容"></a>2.5.2 内容</h3><p><img src="https://oscimg.oschina.net/oscnet/up-cc069006f772837fad8ab9a113e0dad68bc.png" alt=""></p>
<p>事务消息的逻辑，是由发送端Producer进行保证(消费端无需考虑)</p>
<ol>
<li>首先，发送一个事务消息，这个时候，RocketMQ将消息状态标记为Prepared，注意此时这条消息消费者是无法消费到的。</li>
<li>接着，执行业务代码逻辑，可能是一个本地数据库事务操作</li>
<li>最后，确认发送消息，根据本地业务执行结果返回commit或者是rollback。<ul>
<li>3.1 如果本地业务执行成功，消息是commit，这个时候，RocketMQ将消息状态标记为可消费，这个时候消费者，才能真正的保证消费到这条数据。</li>
<li>3.2 如果消息是rollback，RocketMQ将删除该prepare消息不进行下发。</li>
</ul>
</li>
</ol>
<p>如果发送端发送的确认消息发送失败了怎么办？RocketMQ会定期扫描消息集群中的事务消息，如果发现了Prepared消息，它会向消息发送端(生产者)确认。RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。</p>
<p>消费端的消费成功机制由RocketMQ保证。如果发送的消息消费超时了就一直重试。</p>
<blockquote>
<p>但值得注意的是，如果消费端接到通知，然后执行消费端业务逻辑失败了的话，阿里提供给我们的解决方法是：人工解决。也就是说，两端之间的原子性，需要人工做补偿逻辑，该机制无法保证。</p>
</blockquote>
<h3 id="2-5-3-优缺点"><a href="#2-5-3-优缺点" class="headerlink" title="2.5.3 优缺点"></a>2.5.3 优缺点</h3><ul>
<li>优点<ul>
<li>依靠成熟的消息中间件的事务消息机制，不用耦合太多其他逻辑在业务逻辑中，就可以保证消息发送一致性，实现简单。</li>
</ul>
</li>
<li>缺点<ul>
<li>发送端和消费端之间的原子性无法保证，如果发送回滚，需要人工介入。</li>
</ul>
</li>
</ul>
<h2 id="2-6-Saga事务模型"><a href="#2-6-Saga事务模型" class="headerlink" title="2.6 Saga事务模型"></a>2.6 Saga事务模型</h2><h3 id="2-6-1-简介"><a href="#2-6-1-简介" class="headerlink" title="2.6.1 简介"></a>2.6.1 简介</h3><p>Saga事务模型又叫做长时间运行的事务（Long-running-transaction）, 它是由普林斯顿大学的H.Garcia-Molina等人于1987年提出，是一种异步的分布式事务解决方案，其理论基础在于，其假设所有事件按照顺序推进，总能达到系统的最终一致性，因此saga需要服务分别定义提交接口以及补偿接口，当某个事务分支失败时，调用其它的分支的补偿接口来进行回滚。</p>
<h3 id="2-6-2-内容"><a href="#2-6-2-内容" class="headerlink" title="2.6.2 内容"></a>2.6.2 内容</h3><p>saga的具体实现分为两种：Choreography以及Orchestration：</p>
<p><strong>Choreography</strong>：更接近Saga模型的初衷的一种实现：所有事件按照顺序推进，总能达到系统的最终一致性</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-bb00065fb50b0d891f51e4876d58bfeb3eb.png" alt=""></p>
<p>这种模式下不存在协调器的概念，每个节点均对自己的上下游负责，在监听处理上游节点事件的同时，对下游节点发布事件。</p>
<p><strong>Orchestration</strong>：存在中心节点的模式</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5808d06acd0f587367c8d0b7dcbb18469cc.png" alt=""></p>
<p>该中心节点，即协调器知道整个事务的分布状态，相比于无中心节点方式，该方式有着许多优点：</p>
<ol>
<li>能够避免事务之间的循环依赖关系，由协调器来管理整个事务链条。</li>
<li>参与者只需要执行命令/回复(其实回复消息也是一种事件消息)，无需关心和维护自己的上下游是谁，降低参与者的复杂性。</li>
<li>开发测试门槛低。</li>
<li>扩展性好，在添加新步骤时，事务复杂性保持线性，回滚更容易管理。</li>
</ol>
<p>基于上述优势，因此大多数saga模型实现均采用了这种思路。</p>
<h3 id="2-6-3-优缺点"><a href="#2-6-3-优缺点" class="headerlink" title="2.6.3 优缺点"></a>2.6.3 优缺点</h3><ul>
<li>优点<ul>
<li>降低了事务粒度，使得事务扩展更加容易，同时采用了异步化方式提升性能。</li>
</ul>
</li>
<li>缺点<ul>
<li>很多时候很难定义补偿接口，回滚代价高，而且由于在执行过程中采用了先提交后补偿的思路进行操作，所以单个子事务在并发提交时的隔离性很难保证。</li>
</ul>
</li>
</ul>
<h1 id="3-分布式事务解决方案总结"><a href="#3-分布式事务解决方案总结" class="headerlink" title="3 分布式事务解决方案总结"></a>3 分布式事务解决方案总结</h1><h2 id="3-1-XA协议和TCC的区别"><a href="#3-1-XA协议和TCC的区别" class="headerlink" title="3.1 XA协议和TCC的区别"></a>3.1 XA协议和TCC的区别</h2><p>作为最热门的两种解决方案，XA协议和TCC的区别我们需要重点知晓。</p>
<p>TCC与XA两阶段提交有着异曲同工之妙，下图列出了二者之间的对比：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b4a7a054ce913a80fc6df3267a1b7d1fb82.png" alt=""></p>
<ol>
<li><p>在阶段1：</p>
<ul>
<li>在XA中，各个RM准备提交各自的事务分支，事实上就是准备提交资源的更新操作(insert、delete、update等)；而在TCC中，是主业务活动请求(try)各个从业务服务预留资源。</li>
</ul>
</li>
<li><p>在阶段2：</p>
<ul>
<li>XA根据第一阶段每个RM是否都prepare成功，判断是要提交还是回滚。如果都prepare成功，那么就commit每个事务分支，反之则rollback每个事务分支。</li>
</ul>
</li>
</ol>
<p>TCC中，如果在第一阶段所有业务资源都预留成功，那么confirm各个从业务服务，否则取消(cancel)所有从业务服务的资源预留请求。</p>
<p>TCC两阶段提交与XA两阶段提交的区别是：</p>
<ol>
<li>XA是资源层面的分布式事务，<strong>强一致性</strong>，在两阶段提交的整个过程中，<strong>一直会持有资源的锁</strong>。<ul>
<li>XA事务中的两阶段提交内部过程是对开发者屏蔽的，回顾我们之前讲解JTA规范时，通过UserTransaction的commit方法来提交全局事务，这只是一次方法调用，其内部会委派给TransactionManager进行真正的两阶段提交，因此开发者从代码层面是感知不到这个过程的。</li>
<li>而事务管理器在两阶段提交过程中，从prepare到commit/rollback过程中，资源实际上一直都是被加锁的。如果有其他人需要更新这两条记录，那么就必须等待锁释放。</li>
</ul>
</li>
</ol>
<ol start="2">
<li>TCC是业务层面的分布式事务，<strong>最终一致性</strong>，在TCC整个过程中，<strong>不会一直持有资源的锁</strong>。<ul>
<li>TCC中的两阶段提交并没有对开发者完全屏蔽，也就是说从代码层面，开发者是可以感受到两阶段提交的存在。如上述航班预定案例：在第一阶段，航空公司需要提供try接口(机票资源预留)。</li>
<li>在第二阶段，航空公司提需要提供confirm/cancel接口(确认购买机票/取消预留)。开发者明显的感知到了两阶段提交过程的存在。try、confirm/cancel在执行过程中，一般都会开启各自的本地事务，来保证方法内部业务逻辑的ACID特性。其中：<ol>
<li>try过程的本地事务，是保证资源预留的业务逻辑的正确性。</li>
<li>confirm/cancel执行的本地事务逻辑确认/取消预留资源，以保证最终一致性，也就是所谓的补偿型事务(Compensation-Based Transactions)。</li>
</ol>
</li>
</ul>
</li>
</ol>
<h2 id="3-2-最大努力通知和本地消息表的区别"><a href="#3-2-最大努力通知和本地消息表的区别" class="headerlink" title="3.2 最大努力通知和本地消息表的区别"></a>3.2 最大努力通知和本地消息表的区别</h2><p>虽然都是利用mq，但是本地消息表利用本地事务来绑定业务逻辑和消息发送，使得mq两端的操作（发送前和接收后）是绝对可靠的，原子的。保证了消息发送一致性。</p>
<p>而最大努力通知模型，业务逻辑和发送消息之间没有这种紧密的可靠性保证，一切只能在业务上自己去实现代码来保证可靠。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/09/JAVA%E7%9B%91%E6%8E%A7%E5%92%8C%E8%B0%83%E4%BC%98%E5%B7%A5%E5%85%B7%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%88%E6%AD%A4%E5%9D%91%E6%9C%AA%E5%A1%AB%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/09/JAVA%E7%9B%91%E6%8E%A7%E5%92%8C%E8%B0%83%E4%BC%98%E5%B7%A5%E5%85%B7%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%88%E6%AD%A4%E5%9D%91%E6%9C%AA%E5%A1%AB%EF%BC%89/" itemprop="url">JAVA监控和调优工具操作指南</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-09T20:39:02+08:00">
                2020-11-09
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/11/09/JAVA%E7%9B%91%E6%8E%A7%E5%92%8C%E8%B0%83%E4%BC%98%E5%B7%A5%E5%85%B7%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%88%E6%AD%A4%E5%9D%91%E6%9C%AA%E5%A1%AB%EF%BC%89/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/11/09/JAVA监控和调优工具操作指南（此坑未填）/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  5.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  22
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我们在日常的开发和维护工作中，免不了需要对JAVA程序进行监控、调优以及问题排查。</p>
<p>给一个系统定位问题的时候，知识、经验是关键基础，数据是依据，工具是运用知识处理数据的手段。这里说的数据包括∶运行日志、异常堆栈、GC日志、线程快照（thread dump/java core文件）、堆转储快照（heap dump/hprof文件）等。</p>
<p>经常使用适当的监控和分析工具可以加快我们分析数据、定位解决问题的速度，但在学习工具前，也应当意识到工具永远都是知识技能的一层包装，没有什么工具是”秘密武器”，不可能学会了就能包治百病。</p>
<h2 id="进程id的获取"><a href="#进程id的获取" class="headerlink" title="进程id的获取"></a>进程id的获取</h2><p>许多工具或者命令需要用到java进程的进程id，有必要回顾一下。</p>
<blockquote>
<ol>
<li>查看当前运行的所有的java进程：<code>ps -ef|grep java</code>；</li>
<li>准确获取定位到tomcat下正在运行的java进程的PID命令：<code>ps -ef|grep java | grep catalina | awk &#39;{print $2}&#39;</code></li>
<li>准确定位到tomcat下正在运行的java进程相关信息：<code>ps -ef|grep java | grep catalina</code>.</li>
</ol>
</blockquote>
<h2 id="jinfo-jmap访问受限的解决"><a href="#jinfo-jmap访问受限的解决" class="headerlink" title="jinfo/jmap访问受限的解决"></a>jinfo/jmap访问受限的解决</h2><p>一般情况下，我们使用jinfo命令，可能会遇到如下的报错：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3bcb4835de13ba36eadb8b19630a824973f.png" alt=""></p>
<p>这是因为新版的Linux系统加入了 ptrace-scope 机制,该机制的目的是防止用户访问正在执行的进程的内存，但是如jinfo,jmap这些调试类工具本身就是利用ptrace来获取执行进程的内存等信息。</p>
<p><strong>解决：</strong></p>
<ol>
<li>临时解决，该方法在下次重启前有效：<code>echo 0 | sudo tee /proc/sys/kernel/yama/ptrace_scope</code></li>
<li>永久解决，直接修改内核参数：<code>sudo vi /etc/sysctl.d/10-ptrace.conf</code><ul>
<li>编辑这行: <code>kernel.yama.ptrace_scope = 1</code></li>
<li>修改为: <code>kernel.yama.ptrace_scope = 0</code></li>
<li>重启系统，使修改生效。</li>
</ul>
</li>
</ol>
<blockquote>
<p>参数名：kernel.yama.ptrace_scope（值为１：表示禁止用户访问正在执行的进程的内存；０表示可以访问）</p>
</blockquote>
<h1 id="1-程序数据"><a href="#1-程序数据" class="headerlink" title="1. 程序数据"></a>1. 程序数据</h1><h2 id="1-1-【命令】jps（显示java进程）"><a href="#1-1-【命令】jps（显示java进程）" class="headerlink" title="1.1 【命令】jps（显示java进程）"></a>1.1 【命令】jps（显示java进程）</h2><p>jps (Java Virtual Machine Process Status Tool)，是java提供的一个显示当前所有JAVA进程pid的命令，适合在linux/unix平台上简单察看当前java进程的一些简单情况。</p>
<p>我们常常会用到unix系统里的ps命令，这个命令主要是用来显示当前系统的进程情况，有哪些进程以及进程id。</p>
<p><strong>jps就是java程序版本的ps命令，它的作用是显示当前系统的java进程情况及进程id。</strong></p>
<p><strong>格式：<code>jps [-命令选项]</code></strong></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2c4c5b7173045d72f971624168e8cb70e73.png" alt=""></p>
<h3 id="1-1-1-jps的选项"><a href="#1-1-1-jps的选项" class="headerlink" title="1.1.1 jps的选项"></a>1.1.1 jps的选项</h3><p>jps默认只会打印进程id和java类名，如果要更具体的信息，则要借助更多的选项：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-16840d91b4bfcceb7cfb57aacb4b7f4e3b3.png" alt=""></p>
<ol>
<li><p>jps -q</p>
<ul>
<li>只显示pid，不显示class名称,jar文件名和传递给main方法的参数</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-62cd627d9ee93c1fe76cb2474e5b75dbba4.png" alt=""></li>
</ul>
</li>
<li><p>jps -m</p>
<ul>
<li>输出传递给main方法的参数，在嵌入式jvm上可能是null</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-a56eedc39b84a2f57451b3f7c5172fc7d32.png" alt=""></li>
</ul>
</li>
<li><p>jps -l</p>
<ul>
<li>输出应用程序main class的完整package名或者应用程序的jar文件完整路径名</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-7bf94c1599ea21d939c982c152f76125f6b.png" alt=""></li>
</ul>
</li>
<li><p>jps -v</p>
<ul>
<li>输出传递给JVM的参数</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-17e285a83ecb8b6d0aedd6efe5b5e3c91eb.png" alt=""></li>
</ul>
</li>
<li><p>jps -V</p>
<ul>
<li>隐藏输出传递给JVM的参数</li>
</ul>
</li>
</ol>
<h2 id="1-2-【命令】jinfo（显示JVM配置信息）"><a href="#1-2-【命令】jinfo（显示JVM配置信息）" class="headerlink" title="1.2 【命令】jinfo（显示JVM配置信息）"></a>1.2 【命令】jinfo（显示JVM配置信息）</h2><p>jinfo 是 JDK 自带的命令，可以用来查看正在运行的 java 应用程序的扩展参数，包括Java System属性和JVM命令行参数；也可以动态的修改正在运行的JVM一些参数。当系统崩溃时，jinfo也可以从core文件里面知道崩溃的Java应用程序的配置信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Usage:</span><br><span class="line">    jinfo [option] &lt;pid&gt;</span><br><span class="line">        (to connect to running process)</span><br><span class="line">    jinfo [option] &lt;executable &lt;core&gt;</span><br><span class="line">        (to connect to a core file)</span><br><span class="line">    jinfo [option] [server_id@]&lt;remote server IP or hostname&gt;</span><br><span class="line">        (to connect to remote debug server)</span><br><span class="line"></span><br><span class="line">where &lt;option&gt; is one of:</span><br><span class="line">    -flag &lt;name&gt;         to print the value of the named VM flag</span><br><span class="line">    -flag [+|-]&lt;name&gt;    to enable or disable the named VM flag</span><br><span class="line">    -flag &lt;name&gt;&#x3D;&lt;value&gt; to set the named VM flag to the given value</span><br><span class="line">    -flags               to print VM flags</span><br><span class="line">    -sysprops            to print Java system properties</span><br><span class="line">    &lt;no option&gt;          to print both of the above</span><br><span class="line">    -h | -help           to print this help message</span><br></pre></td></tr></table></figure>

<p><strong>格式：<code>jinfo [-命令选项] &lt;pid&gt;</code> 或 <code>jinfo [-命令选项] &lt;executable core&gt;</code> 或 <code>jinfo [-命令选项] [server_id@] &lt;remote ip or hostname&gt;</code></strong></p>
<ul>
<li><code>pid</code>：对应jvm的进程id</li>
<li><code>executable core</code>：产生core dump文件</li>
<li><code>remote server IP or hostname</code>：远程调试服务的ip或者hostname</li>
<li><code>server-id</code>：唯一id,假如一台主机上多个远程debug服务;</li>
</ul>
<blockquote>
<p>Javacore，也可以称为“threaddump”或是“javadump”，它是 Java 提供的一种诊断特性，能够提供一份可读的当前运行的 JVM 中线程使用情况的快照。即在某个特定时刻，JVM 中有哪些线程在运行，每个线程执行到哪一个类，哪一个方法。<br>应用程序如果出现不可恢复的错误或是内存泄露，就会自动触发 Javacore 的生成。</p>
</blockquote>
<p>jinfo工具特别强大，有众多的可选命令选项，比如：</p>
<h3 id="1-2-1-输出JVM进程的参数和属性"><a href="#1-2-1-输出JVM进程的参数和属性" class="headerlink" title="1.2.1 输出JVM进程的参数和属性"></a>1.2.1 输出JVM进程的参数和属性</h3><p><code>jinfo &lt;pid&gt;</code></p>
<p>不带任何选项的情况下，输出当前 jvm 进程的全部参数和系统属性</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3d8f5e1a88b7882699b13e00bf379611362.png" alt=""></p>
<h3 id="1-2-2-打印JVM特定参数的值"><a href="#1-2-2-打印JVM特定参数的值" class="headerlink" title="1.2.2 打印JVM特定参数的值"></a>1.2.2 打印JVM特定参数的值</h3><p><code>jinfo -flag &lt;name&gt; &lt;pid&gt;</code></p>
<p>用于打印虚拟机标记参数的值，name表示虚拟机标记参数的名称。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4ea5b8737fb9011c4030aa2c2d57e242811.png" alt=""></p>
<h3 id="1-2-3-开启或关闭JVM特定参数"><a href="#1-2-3-开启或关闭JVM特定参数" class="headerlink" title="1.2.3 开启或关闭JVM特定参数"></a>1.2.3 开启或关闭JVM特定参数</h3><p><code>jinfo -flag [+|-]&lt;name&gt; &lt;pid&gt;</code></p>
<p>用于开启或关闭虚拟机标记参数。+表示开启，-表示关闭。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9379bda74d5e129a548ffe7cfd724167ab1.png" alt=""></p>
<h3 id="1-2-4-设置JVM特定参数的值"><a href="#1-2-4-设置JVM特定参数的值" class="headerlink" title="1.2.4 设置JVM特定参数的值"></a>1.2.4 设置JVM特定参数的值</h3><p><code>jinfo -flag &lt;name&gt;=&lt;value&gt; &lt;pid&gt;</code></p>
<p>用于设置虚拟机标记参数，但并不是每个参数都可以被动态修改的。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-adb15a8f73ef408099cbee2110bc9879f02.png" alt=""></p>
<h3 id="1-2-5-打印所有JVM参数"><a href="#1-2-5-打印所有JVM参数" class="headerlink" title="1.2.5 打印所有JVM参数"></a>1.2.5 打印所有JVM参数</h3><p><code>jinfo -flags &lt;pid&gt;</code></p>
<p>打印虚拟机参数。什么是虚拟机参数呢？如<code>-XX:NewSize,-XX:OldSize</code>等就是虚拟机参数。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b79b41e6b74426fa258da530dcfd256847b.png" alt=""></p>
<h3 id="1-2-6-打印所有系统参数"><a href="#1-2-6-打印所有系统参数" class="headerlink" title="1.2.6 打印所有系统参数"></a>1.2.6 打印所有系统参数</h3><p><code>jinfo -sysprops &lt;pid&gt;</code></p>
<p>打印所有系统参数</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e4bb4b35ac7fed34239fc2785067e3e7574.png" alt=""></p>
<h1 id="2-快照采集"><a href="#2-快照采集" class="headerlink" title="2. 快照采集"></a>2. 快照采集</h1><h2 id="2-1-【命令】jmap（生成内存快照文件）"><a href="#2-1-【命令】jmap（生成内存快照文件）" class="headerlink" title="2.1 【命令】jmap（生成内存快照文件）"></a>2.1 【命令】jmap（生成内存快照文件）</h2><p>jmap命令是一个可以输出所有内存中对象的工具，甚至可以将VM 中的heap，以二进制输出成文本。打印出某个java进程（使用pid）内存内的，所有‘对象’的情况（如：产生那些对象，及其数量）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Usage:</span><br><span class="line">    jmap [option] &lt;pid&gt;</span><br><span class="line">        (to connect to running process)</span><br><span class="line">    jmap [option] &lt;executable &lt;core&gt;</span><br><span class="line">        (to connect to a core file)</span><br><span class="line">    jmap [option] [server_id@]&lt;remote server IP or hostname&gt;</span><br><span class="line">        (to connect to remote debug server)</span><br><span class="line"></span><br><span class="line">where &lt;option&gt; is one of:</span><br><span class="line">    &lt;none&gt;               to print same info as Solaris pmap</span><br><span class="line">    -heap                to print java heap summary</span><br><span class="line">    -histo[:live]        to print histogram of java object heap; if the &quot;live&quot;</span><br><span class="line">                         suboption is specified, only count live objects</span><br><span class="line">    -clstats             to print class loader statistics</span><br><span class="line">    -finalizerinfo       to print information on objects awaiting finalization</span><br><span class="line">    -dump:&lt;dump-options&gt; to dump java heap in hprof binary format</span><br><span class="line">                         dump-options:</span><br><span class="line">                           live         dump only live objects; if not specified,</span><br><span class="line">                                        all objects in the heap are dumped.</span><br><span class="line">                           format&#x3D;b     binary format</span><br><span class="line">                           file&#x3D;&lt;file&gt;  dump heap to &lt;file&gt;</span><br><span class="line">                         Example: jmap -dump:live,format&#x3D;b,file&#x3D;heap.bin &lt;pid&gt;</span><br><span class="line">    -F                   force. Use with -dump:&lt;dump-options&gt; &lt;pid&gt; or -histo</span><br><span class="line">                         to force a heap dump or histogram when &lt;pid&gt; does not</span><br><span class="line">                         respond. The &quot;live&quot; suboption is not supported</span><br><span class="line">                         in this mode.</span><br><span class="line">    -h | -help           to print this help message</span><br><span class="line">    -J&lt;flag&gt;             to pass &lt;flag&gt; directly to the runtime system</span><br></pre></td></tr></table></figure>

<p>64位机上使用需要使用如下方式：<code>jmap -J-d64 -heap pid</code></p>
<p><strong>格式：<code>jmap [option] &lt;pid&gt;</code> 或 <code>jmap [option] &lt;executable &lt;core&gt;</code> 或 <code>jmap [option] [server_id@]&lt;remote server IP or hostname&gt;</code></strong></p>
<ul>
<li><code>pid</code>：对应jvm的进程id</li>
<li><code>executable core</code>：产生core dump文件</li>
<li><code>remote server IP or hostname</code>：远程调试服务的ip或者hostname</li>
<li><code>server-id</code>：唯一id,假如一台主机上多个远程debug服务;</li>
</ul>
<p>jinfo工具特别强大，有众多的可选命令选项，比如：</p>
<h3 id="2-1-1-输出hprof二进制格式的heap文件"><a href="#2-1-1-输出hprof二进制格式的heap文件" class="headerlink" title="2.1.1 输出hprof二进制格式的heap文件"></a>2.1.1 输出hprof二进制格式的heap文件</h3><p><code>jmap -dump:live,format=b,file=myjmapfile.txt  &lt;pid&gt;</code><br>或<br><code>jmap -dump:file=myjmapfile.hprof,format=b &lt;pid&gt;</code></p>
<p>使用hprof二进制形式,输出jvm的heap内容到文件，file=可以指定文件存放的目录。live子选项是可选的，假如指定live选项，那么只输出活的对象到文件。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-35d57224bda3c1ce43daa4eed065ae0e0a2.png" alt=""></p>
<h3 id="2-1-2-打印正等候回收的对象的信息"><a href="#2-1-2-打印正等候回收的对象的信息" class="headerlink" title="2.1.2 打印正等候回收的对象的信息"></a>2.1.2 打印正等候回收的对象的信息</h3><p><code>jmap -finalizerinfo  &lt;pid&gt;</code></p>
<p>打印正等候回收的对象的信息。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f2d9d9dfa286b51df4e3575ae27423cd93e.png" alt=""></p>
<p>Number of objects pending for finalization: 0 表示等候回收的对象为0个</p>
<h3 id="2-1-3-打印heap的概要信息"><a href="#2-1-3-打印heap的概要信息" class="headerlink" title="2.1.3 打印heap的概要信息"></a>2.1.3 打印heap的概要信息</h3><p><code>jmap -heap  &lt;pid&gt;</code></p>
<p>打印heap的概要信息，GC使用的算法，heap（堆）的配置及JVM堆内存的使用情况。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-992e8f7a9ced2b305f6a16d2184c77a5686.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">Attaching to process ID 2805, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 25.181-b13</span><br><span class="line"></span><br><span class="line">using thread-local object allocation.</span><br><span class="line">Parallel GC with 4 thread(s)   ##GC 方式</span><br><span class="line"></span><br><span class="line">Heap Configuration:  ##堆配置情况，也就是JVM参数配置的结果[平常说的tomcat配置JVM参数，就是在配置这些]</span><br><span class="line">   MinHeapFreeRatio         &#x3D; 0  ##最小堆使用比例</span><br><span class="line">   MaxHeapFreeRatio         &#x3D; 100  ##最大堆可用比例</span><br><span class="line">   MaxHeapSize              &#x3D; 734003200 (700.0MB)  ##最大堆空间大小</span><br><span class="line">   NewSize                  &#x3D; 21495808 (20.5MB)  ##新生代分配大小</span><br><span class="line">   MaxNewSize               &#x3D; 244318208 (233.0MB)  ##最大可新生代分配大小</span><br><span class="line">   OldSize                  &#x3D; 43515904 (41.5MB)  ##老年代大小</span><br><span class="line">   NewRatio                 &#x3D; 2  ##新生代比例</span><br><span class="line">   SurvivorRatio            &#x3D; 8  ##新生代与suvivor的比例</span><br><span class="line">   MetaspaceSize            &#x3D; 21807104 (20.796875MB)  ## 元数据空间大小</span><br><span class="line">   CompressedClassSpaceSize &#x3D; 1073741824 (1024.0MB)  ## 压缩空间大小</span><br><span class="line">   MaxMetaspaceSize         &#x3D; 17592186044415 MB  ## 最大元数据空间大小</span><br><span class="line">   G1HeapRegionSize         &#x3D; 0 (0.0MB)  ## G1的对region空间大小</span><br><span class="line"></span><br><span class="line">Heap Usage:  ##堆使用情况【堆内存实际的使用情况】</span><br><span class="line">PS Young Generation  ##新生代（伊甸区Eden区 + 幸存区survior(1+2)空间）</span><br><span class="line">Eden Space:   ##伊甸区</span><br><span class="line">   capacity &#x3D; 32505856 (31.0MB)</span><br><span class="line">   used     &#x3D; 0 (0.0MB)</span><br><span class="line">   free     &#x3D; 32505856 (31.0MB)</span><br><span class="line">   0.0% used</span><br><span class="line">From Space:  ##survior1区</span><br><span class="line">   capacity &#x3D; 2621440 (2.5MB)</span><br><span class="line">   used     &#x3D; 0 (0.0MB)</span><br><span class="line">   free     &#x3D; 2621440 (2.5MB)</span><br><span class="line">   0.0% used</span><br><span class="line">To Space:  ##survior2 区</span><br><span class="line">   capacity &#x3D; 4194304 (4.0MB)</span><br><span class="line">   used     &#x3D; 0 (0.0MB)</span><br><span class="line">   free     &#x3D; 4194304 (4.0MB)</span><br><span class="line">   0.0% used</span><br><span class="line">PS Old Generation  ##老年代使用情况</span><br><span class="line">   capacity &#x3D; 21495808 (20.5MB)</span><br><span class="line">   used     &#x3D; 3738528 (3.565338134765625MB)</span><br><span class="line">   free     &#x3D; 17757280 (16.934661865234375MB)</span><br><span class="line">   17.391893340320124% used</span><br><span class="line"></span><br><span class="line">4524 interned Strings occupying 360168 bytes.</span><br></pre></td></tr></table></figure>

<h3 id="2-1-4-打印每个class的实例信息"><a href="#2-1-4-打印每个class的实例信息" class="headerlink" title="2.1.4 打印每个class的实例信息"></a>2.1.4 打印每个class的实例信息</h3><p><code>jmap -histo:live &lt;pid&gt;</code><br>或<br><code>jmap -histo: &lt;pid&gt;</code></p>
<p>打印每个class的实例数目，内存占用,类全名信息，VM的内部类名字开头会加上前缀”*”。如果live子参数加上后，只统计活的对象数量</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-67f49e0ba5cdbfe3ac02c26aaa396f42648.png" alt=""></p>
<blockquote>
<p>采用jmap -histo pid&gt;a.log日志将其保存，在一段时间后，使用文本对比工具，可以对比出GC回收了哪些对象。</p>
</blockquote>
<blockquote>
<p>jmap -dump:format=b,file=outfile 3024可以将3024进程的内存heap输出出来到outfile文件里，再配合MAT（内存分析工具）。</p>
</blockquote>
<h3 id="2-1-5-打印类加载器的数据"><a href="#2-1-5-打印类加载器的数据" class="headerlink" title="2.1.5 打印类加载器的数据"></a>2.1.5 打印类加载器的数据</h3><p><code>jmap -clstats &lt;pid&gt;</code></p>
<p>-clstats是-permstat的替代方案，在JDK8之前，-permstat用来打印类加载器的数据。打印Java堆内存的永久保存区域的类加载器的智能统计信息。</p>
<p>对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、它所加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4f07b6ea610226208c0791082ab70ce0689.png" alt=""></p>
<h3 id="2-1-6-指定传递给运行jmap的JVM的参数"><a href="#2-1-6-指定传递给运行jmap的JVM的参数" class="headerlink" title="2.1.6 指定传递给运行jmap的JVM的参数"></a>2.1.6 指定传递给运行jmap的JVM的参数</h3><p><code>jmap -J&lt;flag&gt; &lt;pid&gt;</code></p>
<p>指定传递给运行jmap的JVM的参数</p>
<p>如<code>jmap -J-d64 -heap pid</code>表示在64位机上使用<code>jmap -heap</code></p>
<h2 id="2-3-【命令】jstack（输出线程快照）"><a href="#2-3-【命令】jstack（输出线程快照）" class="headerlink" title="2.3 【命令】jstack（输出线程快照）"></a>2.3 【命令】jstack（输出线程快照）</h2><p>jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息（也就是线程），如果是在64位机器上，需要指定选项”-J-d64”，Windows的jstack使用方式只支持以下的这种方式：<code>jstack [-l] pid</code></p>
<p>如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。</p>
<p>另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息，如果现在运行的java程序呈现hung的状态，jstack是非常有用的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Usage:</span><br><span class="line">    jstack [-l] &lt;pid&gt;</span><br><span class="line">        (to connect to running process)</span><br><span class="line">    jstack -F [-m] [-l] &lt;pid&gt;</span><br><span class="line">        (to connect to a hung process)</span><br><span class="line">    jstack [-m] [-l] &lt;executable&gt; &lt;core&gt;</span><br><span class="line">        (to connect to a core file)</span><br><span class="line">    jstack [-m] [-l] [server_id@]&lt;remote server IP or hostname&gt;</span><br><span class="line">        (to connect to a remote debug server)</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">    -F  to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung)</span><br><span class="line">    -m  to print both java and native frames (mixed mode)</span><br><span class="line">    -l  long listing. Prints additional information about locks</span><br><span class="line">    -h or -help to print this help message</span><br></pre></td></tr></table></figure>

<p><strong>格式：<code>jstack [option] &lt;pid&gt;</code> 或 <code>jstack [option] &lt;executable &lt;core&gt;</code> 或 <code>jstack [option] [server_id@]&lt;remote server IP or hostname&gt;</code></strong></p>
<ul>
<li><code>pid</code>：对应jvm的进程id</li>
<li><code>executable core</code>：产生core dump文件</li>
<li><code>remote server IP or hostname</code>：远程调试服务的ip或者hostname</li>
<li><code>server-id</code>：唯一id,假如一台主机上多个远程debug服务;</li>
</ul>
<p>jstack工具特别强大，有众多的可选命令选项和适用场景，比如：</p>
<h3 id="2-3-1-程序没有响应时强制打印线程"><a href="#2-3-1-程序没有响应时强制打印线程" class="headerlink" title="2.3.1 程序没有响应时强制打印线程"></a>2.3.1 程序没有响应时强制打印线程</h3><p><code>jstack -F &lt;pid&gt;</code></p>
<p>当pid对应的程序没有响应时，强制打印线程堆栈信息。</p>
<h3 id="2-3-2-打印完整的堆栈信息"><a href="#2-3-2-打印完整的堆栈信息" class="headerlink" title="2.3.2 打印完整的堆栈信息"></a>2.3.2 打印完整的堆栈信息</h3><p><code>jstack -l &lt;pid&gt;</code></p>
<p>长列表，打印关于锁的附加信息，例如属于java.util.concurrent的ownable synchronizers列表。</p>
<h3 id="2-3-3-打印java-native框架的所有堆栈"><a href="#2-3-3-打印java-native框架的所有堆栈" class="headerlink" title="2.3.3 打印java/native框架的所有堆栈"></a>2.3.3 打印java/native框架的所有堆栈</h3><p><code>jstack -m &lt;pid&gt;</code></p>
<p>打印java和native c/c++框架的所有栈信息。</p>
<h3 id="2-3-4"><a href="#2-3-4" class="headerlink" title="2.3.4"></a>2.3.4</h3><p><a href="https://www.jianshu.com/p/8d5782bc596e" target="_blank" rel="noopener">https://www.jianshu.com/p/8d5782bc596e</a></p>
<h1 id="3-监控跟踪"><a href="#3-监控跟踪" class="headerlink" title="3. 监控跟踪"></a>3. 监控跟踪</h1><h2 id="3-1-【命令】jstat（收集JVM运行数据）"><a href="#3-1-【命令】jstat（收集JVM运行数据）" class="headerlink" title="3.1 【命令】jstat（收集JVM运行数据）"></a>3.1 【命令】jstat（收集JVM运行数据）</h2><p>Jstat是JDK自带的一个轻量级小工具。全称“Java Virtual Machine statistics monitoring tool”，它位于java的bin目录下，主要利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了堆内存各部分的使用量，以及加载类的数量，还有垃圾回收状况的监控。</p>
<p>可见，Jstat是轻量级的、专门针对JVM的工具。</p>
<p><strong>格式：<code>jstat [-命令选项] &lt;pid&gt;</code></strong></p>
<p>jstat工具特别强大，有众多的可选项，详细查看堆内各个部分的使用量，以及加载类的数量。使用时，需加上查看进程的进程id，和所选参数。参考格式如下：</p>
<h3 id="3-1-1-类加载统计"><a href="#3-1-1-类加载统计" class="headerlink" title="3.1.1 类加载统计"></a>3.1.1 类加载统计</h3><p><code>jstat –class &lt;pid&gt;</code></p>
<p>显示加载class的数量，及所占空间等信息。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2e60bd64a892a063c76037f7fbaa5ceb196.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>Loaded</td>
<td>装载的类的数量</td>
</tr>
<tr>
<td>Bytes</td>
<td>装载类所占用的字节数</td>
</tr>
<tr>
<td>Unloaded</td>
<td>卸载类的数量</td>
</tr>
<tr>
<td>Bytes</td>
<td>卸载类的字节数</td>
</tr>
<tr>
<td>Time</td>
<td>装载和卸载类所花费的时间</td>
</tr>
</tbody></table>
<h3 id="3-1-2-编译统计"><a href="#3-1-2-编译统计" class="headerlink" title="3.1.2 编译统计"></a>3.1.2 编译统计</h3><p><code>jstat -compiler &lt;pid&gt;</code></p>
<p>显示VM实时编译的数量等信息。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-452f7c3598597bea5efd6a2596c52f13228.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>Compiled</td>
<td>编译任务执行数量</td>
</tr>
<tr>
<td>Failed</td>
<td>编译任务执行失败数量</td>
</tr>
<tr>
<td>Invalid</td>
<td>编译任务执行失效数量</td>
</tr>
<tr>
<td>Time</td>
<td>编译任务消耗时间</td>
</tr>
<tr>
<td>FailedType</td>
<td>最后一个编译失败任务的类型</td>
</tr>
<tr>
<td>FailedMethod</td>
<td>最后一个编译失败任务所在的类及方法</td>
</tr>
</tbody></table>
<h3 id="3-1-3-垃圾回收统计"><a href="#3-1-3-垃圾回收统计" class="headerlink" title="3.1.3 垃圾回收统计"></a>3.1.3 垃圾回收统计</h3><p><code>jstat -gc &lt;pid&gt;</code></p>
<p>显示gc的信息，查看gc的次数，及时间。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6c7772ec1a693d7702905d45950f2a661d0.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>S0C</td>
<td>年轻代中第一个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S1C</td>
<td>年轻代中第二个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S0U</td>
<td>年轻代中第一个survivor（幸存区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>S1U</td>
<td>年轻代中第二个survivor（幸存区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>EC</td>
<td>年轻代中Eden（伊甸区）的容量 (字节)</td>
</tr>
<tr>
<td>EU</td>
<td>年轻代中Eden（伊甸区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>OC</td>
<td>Old代的容量 (字节)</td>
</tr>
<tr>
<td>OU</td>
<td>Old代目前已使用空间 (字节)</td>
</tr>
<tr>
<td>PC</td>
<td>Perm(持久代)的容量 (字节)</td>
</tr>
<tr>
<td>PU</td>
<td>Perm(持久代)目前已使用空间 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>YGCT</td>
<td>从应用程序启动到采样时年轻代中gc所用时间(s)</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
<tr>
<td>FGCT</td>
<td>从应用程序启动到采样时old代(full gc)gc所用时间(s)</td>
</tr>
<tr>
<td>GCT</td>
<td>从应用程序启动到采样时gc用的总时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-4-堆内存统计"><a href="#3-1-4-堆内存统计" class="headerlink" title="3.1.4 堆内存统计"></a>3.1.4 堆内存统计</h3><p><code>jstat -gccapacity &lt;pid&gt;</code></p>
<p>显示VM内存中三代（young，old，perm）对象的使用和占用大小</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c3cb2a0c165067a785f1e82eac8e86d5d6a.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>NGCMN</td>
<td>年轻代(young)中初始化(最小)的大小(字节)</td>
</tr>
<tr>
<td>NGCMX</td>
<td>年轻代(young)的最大容量 (字节)</td>
</tr>
<tr>
<td>NGC</td>
<td>年轻代(young)中当前的容量 (字节)</td>
</tr>
<tr>
<td>S0C</td>
<td>年轻代中第一个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S1C</td>
<td>年轻代中第二个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>EC</td>
<td>年轻代中Eden（伊甸区）的容量 (字节)</td>
</tr>
<tr>
<td>OGCMN</td>
<td>old代中初始化(最小)的大小 (字节)</td>
</tr>
<tr>
<td>OGCMX</td>
<td>old代的最大容量(字节)</td>
</tr>
<tr>
<td>OGC</td>
<td>old代当前新生成的容量 (字节)</td>
</tr>
<tr>
<td>OC</td>
<td>old代的容量 (字节)</td>
</tr>
<tr>
<td>PGCMN</td>
<td>perm代中初始化(最小)的大小 (字节)</td>
</tr>
<tr>
<td>PGCMX</td>
<td>perm代的最大容量 (字节)</td>
</tr>
<tr>
<td>PGC</td>
<td>perm代当前新生成的容量 (字节)</td>
</tr>
<tr>
<td>PC</td>
<td>Perm(持久代)的容量 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
</tbody></table>
<h3 id="3-1-5-新生代垃圾回收统计"><a href="#3-1-5-新生代垃圾回收统计" class="headerlink" title="3.1.5 新生代垃圾回收统计"></a>3.1.5 新生代垃圾回收统计</h3><p><code>jstat -gcnew &lt;pid&gt;</code></p>
<p>统计年轻代对象的信息</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ba28e19bd75231959a868d3fa24644cb3ef.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>S0C</td>
<td>年轻代中第一个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S1C</td>
<td>年轻代中第二个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S0U</td>
<td>年轻代中第一个survivor（幸存区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>S1U</td>
<td>年轻代中第二个survivor（幸存区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>TT</td>
<td>持有次数限制</td>
</tr>
<tr>
<td>MTT</td>
<td>最大持有次数限制</td>
</tr>
<tr>
<td>DSS</td>
<td>期望的幸存区大小</td>
</tr>
<tr>
<td>EC</td>
<td>年轻代中Eden（伊甸区）的容量 (字节)</td>
</tr>
<tr>
<td>EU</td>
<td>年轻代中Eden（伊甸区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>YGCT</td>
<td>从应用程序启动到采样时年轻代中gc所用时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-6-新生代内存统计"><a href="#3-1-6-新生代内存统计" class="headerlink" title="3.1.6 新生代内存统计"></a>3.1.6 新生代内存统计</h3><p><code>jstat -gcnewcapacity &lt;pid&gt;</code></p>
<p>统计年轻代对象的信息及其占用量。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-be84ee14d1f8990973fbfffa1f014827082.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>NGCMN</td>
<td>年轻代(young)中初始化(最小)的大小(字节)</td>
</tr>
<tr>
<td>NGCMX</td>
<td>年轻代(young)的最大容量 (字节)</td>
</tr>
<tr>
<td>NGC</td>
<td>年轻代(young)中当前的容量 (字节)</td>
</tr>
<tr>
<td>S0CMX</td>
<td>年轻代中第一个survivor（幸存区）的最大容量 (字节)</td>
</tr>
<tr>
<td>S0C</td>
<td>年轻代中第一个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S1CMX</td>
<td>年轻代中第二个survivor（幸存区）的最大容量 (字节)</td>
</tr>
<tr>
<td>S1C</td>
<td>年轻代中第二个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>ECMX</td>
<td>年轻代中Eden（伊甸区）的最大容量 (字节)</td>
</tr>
<tr>
<td>EC</td>
<td>年轻代中Eden（伊甸区）的容量 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
</tbody></table>
<h3 id="3-1-7-老年代垃圾回收统计"><a href="#3-1-7-老年代垃圾回收统计" class="headerlink" title="3.1.7 老年代垃圾回收统计"></a>3.1.7 老年代垃圾回收统计</h3><p><code>jstat -gcold &lt;pid&gt;</code></p>
<p>统计老年代对象的信息</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-44a6d03fa59ee3d179a5352c3f8c17c15b7.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>MC</td>
<td>方法区大小</td>
</tr>
<tr>
<td>MU</td>
<td>方法区使用大小</td>
</tr>
<tr>
<td>CCSC</td>
<td>压缩类空间大小</td>
</tr>
<tr>
<td>CCSU</td>
<td>压缩类空间使用大小</td>
</tr>
<tr>
<td>OC</td>
<td>Old代的容量 (字节)</td>
</tr>
<tr>
<td>OU</td>
<td>Old代目前已使用空间 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
<tr>
<td>YGCT</td>
<td>从应用程序启动到采样时年轻代中gc所用时间(s)</td>
</tr>
<tr>
<td>GCT</td>
<td>从应用程序启动到采样时gc用的总时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-8-老年代内存统计"><a href="#3-1-8-老年代内存统计" class="headerlink" title="3.1.8 老年代内存统计"></a>3.1.8 老年代内存统计</h3><p><code>jstat -gcoldcapacity &lt;pid&gt;</code></p>
<p>统计老年代对象的信息及其占用量</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fcb6eca9c1dd7c229a8833e66412f56fe94.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>OGCMN</td>
<td>old代中初始化(最小)的大小 (字节)</td>
</tr>
<tr>
<td>OGCMX</td>
<td>old代的最大容量(字节)</td>
</tr>
<tr>
<td>OGC</td>
<td>old代当前新生成的容量 (字节)</td>
</tr>
<tr>
<td>OC</td>
<td>Old代的容量 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
<tr>
<td>YGCT</td>
<td>从应用程序启动到采样时年轻代中gc所用时间(s)</td>
</tr>
<tr>
<td>GCT</td>
<td>从应用程序启动到采样时gc用的总时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-9-元数据空间统计"><a href="#3-1-9-元数据空间统计" class="headerlink" title="3.1.9 元数据空间统计"></a>3.1.9 元数据空间统计</h3><p><code>jstat -gcmetacapacity &lt;pid&gt;</code></p>
<p>统计元数据空间容量</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b99529bc7810a586ef2d23f874cc9519a9f.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>MCMN</td>
<td>最小元数据容量</td>
</tr>
<tr>
<td>MCMX</td>
<td>最大元数据容量</td>
</tr>
<tr>
<td>MC</td>
<td>方法区大小</td>
</tr>
<tr>
<td>CCSMN</td>
<td>最小压缩类空间大小</td>
</tr>
<tr>
<td>CCSMX</td>
<td>最大压缩类空间大小</td>
</tr>
<tr>
<td>CCSC</td>
<td>压缩类空间大小</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
<tr>
<td>FGCT</td>
<td>从应用程序启动到采样时old代(full gc)gc所用时间(s)</td>
</tr>
<tr>
<td>GCT</td>
<td>从应用程序启动到采样时gc用的总时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-10-总结垃圾回收统计"><a href="#3-1-10-总结垃圾回收统计" class="headerlink" title="3.1.10 总结垃圾回收统计"></a>3.1.10 总结垃圾回收统计</h3><p><code>jstat -gcutil &lt;pid&gt;</code></p>
<p>统计gc容量占比信息</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e9c3e67acc4d4e817d3c206512b067d181e.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>S0</td>
<td>年轻代中第一个survivor（幸存区）已使用的占当前容量百分比</td>
</tr>
<tr>
<td>S1</td>
<td>年轻代中第二个survivor（幸存区）已使用的占当前容量百分比</td>
</tr>
<tr>
<td>E</td>
<td>年轻代中Eden（伊甸区）已使用的占当前容量百分比</td>
</tr>
<tr>
<td>O</td>
<td>old代已使用的占当前容量百分比</td>
</tr>
<tr>
<td>P</td>
<td>perm代已使用的占当前容量百分比</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>YGCT</td>
<td>从应用程序启动到采样时年轻代中gc所用时间(s)</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
<tr>
<td>FGCT</td>
<td>从应用程序启动到采样时old代(full gc)gc所用时间(s)</td>
</tr>
<tr>
<td>GCT</td>
<td>从应用程序启动到采样时gc用的总时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-11-JVM编译方法统计"><a href="#3-1-11-JVM编译方法统计" class="headerlink" title="3.1.11 JVM编译方法统计"></a>3.1.11 JVM编译方法统计</h3><p><code>jstat -printcompilation &lt;pid&gt;</code></p>
<p>统计 JVM编译方法的信息</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-918c3cea79f7a31ccdf12b7a0aa75eb461a.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>Compiled</td>
<td>最近编译方法的数量</td>
</tr>
<tr>
<td>Size</td>
<td>最近编译方法的字节码数量</td>
</tr>
<tr>
<td>Type</td>
<td>最近编译方法的编译类型。</td>
</tr>
<tr>
<td>Method</td>
<td>方法名标识</td>
</tr>
</tbody></table>
<h2 id="3-2-jconsole（可视化监控控制台）"><a href="#3-2-jconsole（可视化监控控制台）" class="headerlink" title="3.2 jconsole（可视化监控控制台）"></a>3.2 jconsole（可视化监控控制台）</h2><h2 id="3-3-jhat（用于分析内存快照文件）"><a href="#3-3-jhat（用于分析内存快照文件）" class="headerlink" title="3.3 jhat（用于分析内存快照文件）"></a>3.3 jhat（用于分析内存快照文件）</h2><h1 id="4-分析工具"><a href="#4-分析工具" class="headerlink" title="4. 分析工具"></a>4. 分析工具</h1><h2 id="4-1-visualvm（故障分析工具）"><a href="#4-1-visualvm（故障分析工具）" class="headerlink" title="4.1 visualvm（故障分析工具）"></a>4.1 visualvm（故障分析工具）</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/14/JAVA%E5%86%85%E7%BD%AE%E6%8E%92%E5%BA%8FArrays-sort%E5%AE%9E%E7%8E%B0%E7%AE%80%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/14/JAVA%E5%86%85%E7%BD%AE%E6%8E%92%E5%BA%8FArrays-sort%E5%AE%9E%E7%8E%B0%E7%AE%80%E8%BF%B0/" itemprop="url">JAVA内置排序Arrays.sort实现简述</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-10-14T21:29:28+08:00">
                2020-10-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/JAVA%E5%AE%9E%E7%8E%B0%E6%88%96%E7%89%B9%E6%80%A7/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA实现或特性</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/10/14/JAVA%E5%86%85%E7%BD%AE%E6%8E%92%E5%BA%8FArrays-sort%E5%AE%9E%E7%8E%B0%E7%AE%80%E8%BF%B0/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/10/14/JAVA内置排序Arrays-sort实现简述/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  8
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在JAVA开发中，我们经常需要操作数组和集合，其中数组和链表的排序是重中之重。</p>
<p>Arrays.sort方法用来对数组排序。Collections.sort()方法用来对链表排序，而Collections.sort()的底层，其实使用的也是Arrays.sort方法。</p>
<p>所以JAVA内置排序的核心类，都在于Arrays工具类，接下来我们也重点剖析该类。</p>
<h1 id="1-Arrays工具类"><a href="#1-Arrays工具类" class="headerlink" title="1. Arrays工具类"></a>1. Arrays工具类</h1><p>我们先来看下Arrays工具类对外暴露的sort方法列表。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-53f7ef7792c0b7ceae71ba767016263106b.png" alt=""></p>
<p><strong>A：从排序范围角度划分，sort方法分为了</strong></p>
<ol>
<li>针对数组的整体做排序的方法，如<ul>
<li><code>sort(int[] a)</code></li>
<li><code>sort(Object[] a)</code></li>
<li><code>sort(T[] a, Comparator&lt;? super T&gt; c)</code></li>
</ul>
</li>
<li>针对数组的局部做排序的方法，如<ul>
<li><code>sort(int[] a, int fromIndex, int toIndex)</code></li>
<li><code>sort(Object[] a , int fromIndex, int toIndex)</code></li>
<li><code>sort(T[] a, int fromIndex, int toIndex,Comparator&lt;? super T&gt; c)</code></li>
</ul>
</li>
</ol>
<p><strong>B：从排序类型角度划分，sort方法分为了</strong></p>
<ol>
<li>对数组按照默认升序的方式进行排序的方法，如<ul>
<li><code>sort(int[] a)</code></li>
<li><code>sort(Object[] a)</code></li>
<li><code>sort(int[] a, int fromIndex, int toIndex)</code></li>
<li><code>sort(Object[] a , int fromIndex, int toIndex)</code></li>
</ul>
</li>
<li>对数组按照自定义排序类型进行排序的方法，如<ul>
<li><code>sort(T[] a, Comparator&lt;? super T&gt; c)</code></li>
<li><code>sort(T[] a, int fromIndex, int toIndex,Comparator&lt;? super T&gt; c)</code></li>
</ul>
</li>
</ol>
<p><strong>C：从操作对象角度划分，sort方法分为了</strong></p>
<ol>
<li>对基本类型（byte，int，char等）数组操作的方法<ul>
<li><code>sort(int[] a)</code></li>
<li><code>sort(int[] a, int fromIndex, int toIndex)</code></li>
</ul>
</li>
<li>对对象类型（object）数组操作的方法<ul>
<li><code>sort(Object[] a)</code></li>
<li><code>sort(Object[] a , int fromIndex, int toIndex)</code></li>
<li><code>sort(T[] a, Comparator&lt;? super T&gt; c)</code></li>
<li><code>sort(T[] a, int fromIndex, int toIndex,Comparator&lt;? super T&gt; c)</code></li>
</ul>
</li>
</ol>
<p>这里最重要的划分是C：从操作对象角度划分，因为JAVA对不同类型的数组，定义了不同的实现方法（以常用的JDK 1.8版本为例），我们先来开门见山的总结一下：</p>
<h1 id="2-基本类型数组的排序"><a href="#2-基本类型数组的排序" class="headerlink" title="2. 基本类型数组的排序"></a>2. 基本类型数组的排序</h1><p>对于基本数据类型的数组，假设数组长度为length：</p>
<ol>
<li>如果length&lt;47，那么采用<strong>插入排序算法</strong>。</li>
<li>如果47&lt;=length&lt;286，或者286&lt;=length，但数组不具备特定结构，那么使用<strong>快速排序的一种优化形式：双轴快排算法</strong>。</li>
<li>如果286&lt;=length，并且数组具备特定结构，那么使用<strong>归并排序算法</strong>。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-205a0fbd3c9218e765bbbd1a17947a400d9.png" alt=""></p>
<h2 id="2-1-数组是否具备特定结构"><a href="#2-1-数组是否具备特定结构" class="headerlink" title="2.1 数组是否具备特定结构"></a>2.1 数组是否具备特定结构</h2><p>在判断是否使用归并排序前，要先判断数组是否具备特定结构，这是一个什么意思呢？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Check if the array is nearly sorted</span><br><span class="line">    for (int k &#x3D; left; k &lt; right; run[count] &#x3D; k) &#123;        if (a[k] &lt; a[k + 1]) &#123; &#x2F;&#x2F; ascending</span><br><span class="line">            while (++k &lt;&#x3D; right &amp;&amp; a[k - 1] &lt;&#x3D; a[k]);</span><br><span class="line">        &#125; else if (a[k] &gt; a[k + 1]) &#123; &#x2F;&#x2F; descending</span><br><span class="line">            while (++k &lt;&#x3D; right &amp;&amp; a[k - 1] &gt;&#x3D; a[k]);            for (int lo &#x3D; run[count] - 1, hi &#x3D; k; ++lo &lt; --hi; ) &#123;                int t &#x3D; a[lo]; a[lo] &#x3D; a[hi]; a[hi] &#x3D; t;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123; &#x2F;&#x2F; equal</span><br><span class="line">            for (int m &#x3D; MAX_RUN_LENGTH; ++k &lt;&#x3D; right &amp;&amp; a[k - 1] &#x3D;&#x3D; a[k]; ) &#123;                if (--m &#x3D;&#x3D; 0) &#123;</span><br><span class="line">                    sort(a, left, right, true);                    return;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;        &#x2F;*</span><br><span class="line">         * The array is not highly structured,</span><br><span class="line">         * use Quicksort instead of merge sort.</span><br><span class="line">         *&#x2F;</span><br><span class="line">        if (++count &#x3D;&#x3D; MAX_RUN_COUNT) &#123;</span><br><span class="line">            sort(a, left, right, true);            return;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>这里主要作用是看他数组具不具备结构：实际逻辑是分组排序，每个降序序列为一个组，像1,9,8,7,6,8。9到6是降序，为一个组，然后把降序的一组排成升序：1,6,7,8,9,8。然后再从最后的8开始继续往后面找。</p>
<p>每遇到这样一个降序组，++count，当count大于<code>MAX_RUN_COUNT（67）</code>，被判断为这个数组不具备结构，也就是说这数据时而升时而降，波峰波谷太多，排列太过陡峭，说明不适合采用归并排序，还是使用快速排序为宜。</p>
<p>如果count少于MAX_RUN_COUNT（67）的，说明这个数组还有点结构，就继续往下走下面的归并排序。</p>
<h2 id="2-2-双轴快排"><a href="#2-2-双轴快排" class="headerlink" title="2.2 双轴快排"></a>2.2 双轴快排</h2><p>双轴快排（DualPivotQuickSort）是快排的一种优化版本。双轴快速排序，顾名思义，取两个中心点pivot1，pivot2，且pivot≤pivot2，可将序列分成三段：x&lt;pivot1、pivot1≤x≤pivot2，x&lt;pivot2，然后分别对三段进行递归。基本过程如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b5a42087e1f49243697d3cd080bdfb1b949.png" alt=""></p>
<p>具体详细内容可见博客<a href="https://blog.csdn.net/Holmofy/article/details/71168530" target="_blank" rel="noopener" title="单轴快排（SinglePivotQuickSort）和双轴快排（DualPivotQuickSort）及其JAVA实现">单轴快排（SinglePivotQuickSort）和双轴快排（DualPivotQuickSort）及其JAVA实现</a></p>
<h1 id="3-对象类型数组的排序"><a href="#3-对象类型数组的排序" class="headerlink" title="3. 对象类型数组的排序"></a>3. 对象类型数组的排序</h1><p>对于对象类型的数组，假设数组长度为length：</p>
<ul>
<li><ol>
<li>如果length&lt;32，那么采用<strong>不包含合并操作的mini-TimSort算法</strong>。</li>
</ol>
</li>
<li><ol start="2">
<li>如果32&lt;=length，那么采用<strong>完整TimSort排序算法（一种结合了归并排序和插入排序的算法）</strong>。</li>
</ol>
</li>
</ul>
<h2 id="3-1-TimSort"><a href="#3-1-TimSort" class="headerlink" title="3.1 TimSort"></a>3.1 TimSort</h2><p>TimSort算法是一种起源于归并排序和插入排序的混合排序算法，设计初衷是为了在真实世界中的各种数据中可以有较好的性能。</p>
<p>基本工作过程是：</p>
<ol>
<li>扫描数组，确定其中的单调上升段和严格单调下降段，将严格下降段反转。我们将这样的段称之为run。 </li>
<li>定义最小run长度，短于此的run通过插入排序合并为长度高于最小run长度； </li>
<li>反复归并一些相邻run，过程中需要避免归并长度相差很大的run，直至整个排序完成； </li>
<li>如何避免归并长度相差很大run呢， 依次将run压入栈中，若栈顶run X，run Y，run Z 的长度违反了X&gt;Y+Z 或 Y&gt;Z 则Y run与较小长度的run合并，并再次放入栈中。 依据这个法则，能够尽量使得大小相同的run合并，以提高性能。注意Timsort是稳定排序故只有相邻的run才能归并。</li>
<li>Merge操作还可以辅之以galloping，具体细节可以自行研究。</li>
</ol>
<p>总之，timsort是工业级算法，其混用插入排序与归并排序，二分搜索等算法，亮点是充分利用待排序数据可能部分有序的事实，并且依据待排序数据内容动态改变排序策略——选择性进行归并以及galloping。</p>
<p>具体内容我们不展开，可详见<a href="https://www.imooc.com/article/257268" target="_blank" rel="noopener" title="Collections.sort()源码分析(基于JAVA8)">Collections.sort()源码分析(基于JAVA8)</a></p>
<h1 id="4-为什么要采用不同的算法？"><a href="#4-为什么要采用不同的算法？" class="headerlink" title="4. 为什么要采用不同的算法？"></a>4. 为什么要采用不同的算法？</h1><p>对于长度较小的数组使用插入排序这很好理解，虽然插入排序的时间复杂度为O(n^2)，但在n较小的情况下，插入排序性能要高于快速排序。</p>
<p>其次我们要知道，在n的数量较大时，归并排序和快速排序，都是性能最优的排序算法，他们的时间复杂度平均都在O(nlogn)左右，只不过区别在于归并排序是稳定的，快速排序是不稳定的。</p>
<blockquote>
<p>稳定是指相等的数据在排序之后仍然按照排序之前的前后顺序排列。</p>
</blockquote>
<p>对于基本数据类型，稳定性没有意义，所以它可以使用不稳定的快排（当然它也使用了归并排序）</p>
<p>而对于对象类型，稳定性是比较重要的，因为对象相等的判断比较复杂，我们无法寄希望于每个程序员都会重写准确的equal方法，故而稳妥起见，最好相等对象尽量保持排序前的顺序，故而我们使用都是稳定算法的<strong>归并排序和插入排序结合而成的TimSort算法</strong>。</p>
<p>另外一个原因是归并排序的比较次数比快排少，移动（对象引用的移动）次数比快排多，而对于对象来说，比较是相对耗时的操作，所以它不适合使用快排。</p>
<p>而对于基本数据类型来说，比较和移动都不怎么耗时，所以它用归并或者快排都可以</p>
<p>总结：</p>
<ol>
<li><p>基本数据类型数组使用快排+归并是因为：</p>
<ul>
<li>基本数据类型无所谓稳定性，可以采用非稳定的快排。</li>
<li>对于基本数据类型来说，比较和移动都不怎么耗时，所以它用归并或者快排都可以。</li>
</ul>
</li>
<li><p>对象数据类型数组使用TimSort排序是因为（或者换句话说，对象数据类型不使用快排是因为）：</p>
<ul>
<li>对象数据类型要求稳定性，需要采用稳定的归并+插入。</li>
<li>对于对象来说，比较操作相对耗时，所以用比较操作较少的归并排序可以扬长避短。</li>
</ul>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/30/MySQL%E6%97%A5%E5%BF%97%E4%BD%93%E7%B3%BB%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/30/MySQL%E6%97%A5%E5%BF%97%E4%BD%93%E7%B3%BB%E8%AF%A6%E8%A7%A3/" itemprop="url">MySQL日志体系详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-30T23:44:48+08:00">
                2020-09-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/30/MySQL%E6%97%A5%E5%BF%97%E4%BD%93%E7%B3%BB%E8%AF%A6%E8%A7%A3/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/30/MySQL日志体系详解/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  8.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  34
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>日志是MySQL数据库的重要组成部分。日志文件中记录着MySQL数据库运行期间发生的变化；也就是说用来记录MySQL数据库的客户端连接状况、SQL语句的执行情况和错误信息等。当数据库遭到意外的损坏时，可以通过日志查看文件出错的原因，并且可以通过日志文件进行数据恢复。</p>
<p>MySQL的日志体系有如下几种分类：</p>
<ol>
<li>错误日志</li>
<li>查询日志</li>
<li>慢查询日志</li>
<li><strong>事务日志(Redo log/undo log)</strong></li>
<li><strong>二进制日志</strong></li>
<li>中继日志</li>
</ol>
<p>其中标粗的事务日志和二进制日志，是重中之重。</p>
<h1 id="1-错误日志"><a href="#1-错误日志" class="headerlink" title="1 错误日志"></a>1 错误日志</h1><p>在默认情况下，MySQL的错误日志是开启的，且无法被禁止。在没有指定的情况下，它一般是存储在数据库的数据文件目录中，名称为hostname.err，其中，hostname为服务器主机名。</p>
<h2 id="1-1-错误日志的内容"><a href="#1-1-错误日志的内容" class="headerlink" title="1.1 错误日志的内容"></a>1.1 错误日志的内容</h2><ol>
<li>服务器启动和关闭过程中的信息，未必是错误信息，比如mysql是如何去初始化存储引擎的过程记录在错误日志里等等</li>
<li>服务器运行过程中的错误信息（或者告警信息），比如sock文件找不到，无法加载mysql数据库的数据文件，如果忘记初始化mysql或data dir路径找不到，或权限不正确等 都会记录在此</li>
<li>事件调度器运行一个事件时产生的信息，一旦mysql调度启动一个计划任务（event scheduler）的时候，它也会将相关信息记录在错误日志中</li>
<li>在从服务器上启动从服务器进程时产生的信息，在复制环境下，从服务器进程的信息也会被记录进错误日志</li>
</ol>
<h2 id="1-2-配置相关"><a href="#1-2-配置相关" class="headerlink" title="1.2 配置相关"></a>1.2 配置相关</h2><h3 id="1-2-1-开启错误日志"><a href="#1-2-1-开启错误日志" class="headerlink" title="1.2.1 开启错误日志"></a>1.2.1 开启错误日志</h3><ol>
<li><p>在/etc/my.cnf配置文件中设置：</p>
<ul>
<li>如果需要手动指定错误日志路径的话只需要在<code>[mysqld]</code>字段中增加相关配置：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-cecfbe4ae32adc82200e726bfcee974be9f.png" alt=""></li>
</ul>
</li>
<li><p>如果没有在my.cnf配置文件中指定错误日志</p>
<ul>
<li>MySQL会自动将错误日志文件存放在datadir（数据目录）下，名为hostname.err（hostname根据实际主机名变化）。</li>
</ul>
</li>
<li><p>如果是通过YUM源进行安装</p>
<ul>
<li>错误日志会被配置在/var/log/mysqld.log中，这个也是由自动创建出的/etc/my.cnf所指定的。</li>
</ul>
</li>
</ol>
<h3 id="1-2-2-设置错误日志时区"><a href="#1-2-2-设置错误日志时区" class="headerlink" title="1.2.2 设置错误日志时区"></a>1.2.2 设置错误日志时区</h3><p>错误日志默认是使用utc时间，可以修改为系统时间方便查看</p>
<p><code>mysql &gt; set global log_timestamps=&#39;SYSTEM&#39;`</code></p>
<h3 id="1-2-3-删除错误日志"><a href="#1-2-3-删除错误日志" class="headerlink" title="1.2.3 删除错误日志"></a>1.2.3 删除错误日志</h3><p>在mysql5.5.7之前：数据库管理员可以删除很长时间之前的错误日志，以保证mysql服务器上的硬盘空间。mysql数据库中，可以使用mysqladmin命令开启新的错误日志。mysqladmin命令的语法如下：</p>
<p><code>mysqladmin –u root –pflush-logs</code></p>
<p>也可以使用登录mysql数据库中使用FLUSHLOGS语句来开启新的错误日志。</p>
<p>在mysql5.5.7之后：服务器将关闭此项功能。只能使用重命名原来的错误日志文件，手动冲洗日志创建一个新的：方式如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@stu18 data]<span class="comment"># mv stu18.magedu.com.err  stu18.magedu.com.err.old</span></span><br><span class="line">[root@stu18 data]<span class="comment">#  mysqladmin flush-logs</span></span><br><span class="line">[root@stu18 data]<span class="comment"># ls</span></span><br><span class="line">hellodb  myclass  mysql-bin.000003  mysql-bin.index           stu18.magedu.com.pid     ibda</span><br></pre></td></tr></table></figure>

<p>或者手动清理掉错误日志</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &gt; &#x2F;var&#x2F;log&#x2F;mysqld.log</span><br></pre></td></tr></table></figure>

<h2 id="1-3-查看错误日志和配置"><a href="#1-3-查看错误日志和配置" class="headerlink" title="1.3 查看错误日志和配置"></a>1.3 查看错误日志和配置</h2><p>查看log_error的配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;log_error&#39;;</span><br><span class="line">+---------------+---------------------+</span><br><span class="line">| Variable_name | Value               |</span><br><span class="line">+---------------+---------------------+</span><br><span class="line">| log_error     | &#x2F;var&#x2F;log&#x2F;mysqld.log |</span><br><span class="line">+---------------+---------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>查看错误日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql]# tailf &#x2F;var&#x2F;log&#x2F;mysqld.log</span><br><span class="line">130813  15:30:50  InnoDB: Starting shutdown...</span><br><span class="line">130813  15:30:51  InnoDB: Shutdown completed;  log sequence number 1630920</span><br><span class="line">130813 15:30:51  [Note] &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysqld: Shutdown complete</span><br><span class="line">130813 15:30:52  mysqld_safe mysqld from pid file &#x2F;mydata&#x2F;data&#x2F;stu18.magedu.com.pid ended</span><br><span class="line">130813 15:30:53  mysqld_safe Starting mysqld daemon with databases from &#x2F;mydata&#x2F;data</span><br><span class="line">130813 15:30:54  InnoDB: The InnoDB memory heap is disabled     #禁用了InnoDB memory的堆功能。</span><br><span class="line">130813 15:30:54  InnoDB: Mutexes and rw_locks use GCC atomic builtins #Mutexes（互斥量）和rw_locks（行级锁）是GCC编译的是InnoDB内置的。</span><br><span class="line">130813 15:30:54  InnoDB: Compressed tables use zlib 1.2.3     #默认压缩工具是zlib</span><br><span class="line">130813 15:30:55  InnoDB: Initializing buffer pool, size &#x3D; 128.0M    #InnoDB引擎的缓冲池（buffer pool）的值大小</span><br><span class="line">130813 15:30:55  InnoDB: Completed initialization of buffer pool</span><br><span class="line">130813 15:30:55  InnoDB: highest supported file format is Barracuda.</span><br><span class="line">130813  15:30:57  InnoDB: Waiting for the  background threads to start</span><br><span class="line">130813 15:30:58  InnoDB: 5.5.33 started; log sequence number 1630920</span><br><span class="line">130813 15:30:58  [Note] Server hostname (bind-address): &#39;0.0.0.0&#39;; port: 3306</span><br><span class="line">130813 15:30:58  [Note]   - &#39;0.0.0.0&#39; resolves to  &#39;0.0.0.0&#39;;  #0.0.0.0会反解主机名，这里反解失败</span><br><span class="line">130813 15:30:58  [Note] Server socket created on IP: &#39;0.0.0.0&#39;.</span><br><span class="line">130813 15:30:58  [Note] Event Scheduler: Loaded 0 events    #事件调度器没有任何事件，因为没有装载。</span><br><span class="line">130813 15:30:58  [Note] &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysqld: ready for connections. #mysql启动完成等待客户端的请求。</span><br><span class="line">Version:  &#39;5.5.33-log&#39;  socket:  &#39;&#x2F;tmp&#x2F;mysql.sock&#39;  port: 3306  Source distribution  #创建一个本地sock用于本地连接。</span><br></pre></td></tr></table></figure>

<h1 id="2-查询日志"><a href="#2-查询日志" class="headerlink" title="2 查询日志"></a>2 查询日志</h1><p>查询日志在MySQL中被称为general log(通用日志)，查询日志里的内容不要被”查询日志”误导，认为里面只存储select语句，其实不然，查询日志里面记录了数据库执行的<strong>所有命令</strong>，不管语句是否正确，都会被记录，因为本质上insert/update/delete语句中，都包含了查询操作:</p>
<ul>
<li>insert的查询是为了避免数据冲突，如果此前插入过数据，当前插入的数据如果跟主键或唯一键的数据重复那肯定会报错</li>
<li>update时也会查询，因为更新的时候是更新某一块数据，要先根据where定位到更新的记录。</li>
<li>delete查询，只删除符合条件的数据，同样是根据where定位。</li>
</ul>
<p>因此增删改查都会产生日志，在并发操作非常多的场景下，查询信息会非常多，那么如果都记录下来会导致IO非常大，影响MySQL性能，因此如果不是在调试环境下，是不建议开启查询日志功能的。</p>
<p>查询日志的开启有助于帮助我们分析哪些语句执行密集，执行密集的select语句对应的数据是否能够被缓存，同时也可以帮助我们分析问题，所以，我们可以根据自己的实际情况来决定是否开启查询日志。</p>
<h2 id="2-1-查询日志配置相关"><a href="#2-1-查询日志配置相关" class="headerlink" title="2.1 查询日志配置相关"></a>2.1 查询日志配置相关</h2><h3 id="2-1-1-查看配置"><a href="#2-1-1-查看配置" class="headerlink" title="2.1.1 查看配置"></a>2.1.1 查看配置</h3><p>所以如果你要判断MySQL数据库是否开启了查询日志，可以使用下面命令。general_log为ON表示开启查询日志，OFF表示关闭查询日志。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;%general_log%&#39; or variables like &#39;%log_output%&#39;;</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">| Variable_name    | Value                        |</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">| general_log      | OFF                          |</span><br><span class="line">| general_log_file | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log |</span><br><span class="line">| log_output       | FILE                         |</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>参数general_log用来控制开启、关闭MySQL查询日志</li>
<li>参数general_log_file用来控制查询日志的位置</li>
<li>如果开启了查询日志，参数log_output控制着查询日志的存储方式，log_output可以设置为以下4种值:<ol>
<li>FILE : 表示日志存储在文件中</li>
<li>TABLE : 表示日志存储在mysql库中的general_log表中</li>
<li>FILE, TABLE : 表示将日志同时存储在文件和general_log表中，改值会徒增很多IO压力，一般不会这样设置</li>
<li>NONE : 表示不记录日志，即使general_log设置为ON， 如果log_output设置为NONE，也不会记录查询日志</li>
</ol>
</li>
</ul>
<blockquote>
<p>log_output不仅控制查询日志的输出，也控制着慢查询日志的输出，即: log_output设置为FILE，就表示查询日志和慢查询日志都存放在文件中，设置为TABLE，查询日志和慢查询日志都存放在mysql库中的general_log表中</p>
</blockquote>
<h3 id="2-1-2-开启或关闭查询日志"><a href="#2-1-2-开启或关闭查询日志" class="headerlink" title="2.1.2 开启或关闭查询日志"></a>2.1.2 开启或关闭查询日志</h3><ul>
<li>方法1: 在配置文件中设置(不推荐)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#可以在my.cnf里添加,1开启（0关闭）,当然了,这样要重启才能生效,有点多余了</span><br><span class="line">general-log &#x3D; 1</span><br><span class="line">log_output&#x3D;&#39;table&#39;</span><br></pre></td></tr></table></figure>

<p>然后重启MySQL实例</p>
<ul>
<li>方法2 : 通过命令设置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#也可以设置变量那样更改,1开启（0关闭）,即时生效,不用重启,首选当然是这样的了</span><br><span class="line">set global general_log&#x3D;1</span><br><span class="line">set global log_output&#x3D;&#39;table&#39;;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>通过该方式设置，MySQL实例重启后，相关配置又恢复到默认值。如果只是短暂时间内使用，推荐使用命令行方式</p>
</blockquote>
<h3 id="2-1-3-修改查询日志名称或位置"><a href="#2-1-3-修改查询日志名称或位置" class="headerlink" title="2.1.3 修改查询日志名称或位置"></a>2.1.3 修改查询日志名称或位置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;general_log%&#39;;</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">| Variable_name    | Value                        |</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">| general_log      | ON                           |</span><br><span class="line">| general_log_file | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log |</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set global general_log&#x3D;&#39;OFF&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set global general_log_file&#x3D;&#39;&#x2F;u02&#x2F;mysql_log.log&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set global general_log&#x3D;&#39;ON&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br></pre></td></tr></table></figure>

<h2 id="2-2-查询日志的查看"><a href="#2-2-查询日志的查看" class="headerlink" title="2.2 查询日志的查看"></a>2.2 查询日志的查看</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from mysql.general_log;</span><br><span class="line">+---------------------+---------------------------+-----------+-----------+--------------+----------------------------------+</span><br><span class="line">| event_time          | user_host                 | thread_id | server_id | command_type | argument                         |</span><br><span class="line">+---------------------+---------------------------+-----------+-----------+--------------+----------------------------------+</span><br><span class="line">| 2017-07-06 12:32:05 | root[root] @ localhost [] |         1 |         1 | Query        | show variables like &#39;general%&#39;   |</span><br><span class="line">| 2017-07-06 12:32:28 | root[root] @ localhost [] |         1 |         1 | Query        | show variables like &#39;log_output&#39; |</span><br><span class="line">| 2017-07-06 12:32:41 | root[root] @ localhost [] |         1 |         1 | Query        | select * from MyDB.test          |</span><br><span class="line">| 2017-07-06 12:34:36 | [root] @ localhost []     |         3 |         1 | Connect      | root@localhost on                |</span><br><span class="line">| 2017-07-06 12:34:36 | root[root] @ localhost [] |         3 |         1 | Query        | KILL QUERY 1                     |</span><br><span class="line">| 2017-07-06 12:34:36 | root[root] @ localhost [] |         3 |         1 | Quit         |                                  |</span><br><span class="line">| 2017-07-06 12:34:51 | root[root] @ localhost [] |         1 |         1 | Query        | select * from mysql.general_log  |</span><br><span class="line">+---------------------+---------------------------+-----------+-----------+--------------+----------------------------------+</span><br><span class="line">7 rows in set (0.02 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure>

<h2 id="2-3-查询日志的归档"><a href="#2-3-查询日志的归档" class="headerlink" title="2.3 查询日志的归档"></a>2.3 查询日志的归档</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; system mv &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log  &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log.20170706</span><br><span class="line"></span><br><span class="line">mysql&gt; system mysqladmin flush-logs -p</span><br><span class="line"></span><br><span class="line">Enter password:</span><br></pre></td></tr></table></figure>

<p>或者你在shell中执行下面命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@DB-Server mysql]# mv &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log  &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log.20170706</span><br><span class="line"></span><br><span class="line">[root@DB-Server mysql]# mysqladmin flush-logs -p</span><br><span class="line"></span><br><span class="line">Enter password:</span><br></pre></td></tr></table></figure>

<h1 id="3-慢查询日志"><a href="#3-慢查询日志" class="headerlink" title="3 慢查询日志"></a>3 慢查询日志</h1><p>慢查询会导致CPU，IOPS，内存消耗过高。当数据库遇到性能瓶颈时，大部分时间都是由于慢查询导致的。 开启慢查询日志，可以让MySQL记录下查询超过指定时间的语句，之后运维人员通过定位分析，能够很好的优化数据库性能。</p>
<p>慢查询日志记录的慢查询不仅仅是执行比较慢的SELECT语句，还有INSERT，DELETE，UPDATE，CALL等DML操作，只要超过了指定时间，都可以称为”慢查询”，被记录到慢查询日志中。</p>
<p>默认情况下，慢查询日志是不开启的，只有手动开启了，慢查询才会被记录到慢查询日志中。</p>
<h2 id="3-1-慢查询日志配置相关"><a href="#3-1-慢查询日志配置相关" class="headerlink" title="3.1 慢查询日志配置相关"></a>3.1 慢查询日志配置相关</h2><h3 id="3-1-1-查看配置"><a href="#3-1-1-查看配置" class="headerlink" title="3.1.1 查看配置"></a>3.1.1 查看配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &quot;%slow%&quot; or variables like &quot;%log_queries_not_using_indexes%&quot;;</span><br><span class="line">+-------------------------------+-------------------------------------------------+</span><br><span class="line">| Variable_name                 | Value                                           |</span><br><span class="line">+-------------------------------+-------------------------------------------------+</span><br><span class="line">| log_slow_admin_statements     | OFF                                             |</span><br><span class="line">| log_slow_slave_statements     | OFF                                             |</span><br><span class="line">| slow_launch_time              | 2                                               |</span><br><span class="line">| slow_query_log                | OFF                                             |</span><br><span class="line">| slow_query_log_file           | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;iz2zeaf3cg1099kiidi06mz-slow.log |</span><br><span class="line">| log_queries_not_using_indexes | ON                                              |</span><br><span class="line">+-------------------------------+-------------------------------------------------+</span><br><span class="line">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>其中</p>
<ul>
<li>slow_query_log：慢查询开关，表示是否打开慢查询日志</li>
<li>long_query_time：慢查询指定时间设置，表示”多长时间的查询”被认定为”慢查询”，单位是秒(s)，默认是10s，即超过10s的查询都被认定为慢查询。</li>
<li>log_queries_not_using_indexes：表示如果运行的SQL语句没有使用到索引，是否也被当作慢查询语句记录到慢查询记录中，OFF表示不记录，ON表示记录。</li>
<li>如果开启了查询日志，参数log_output控制着查询日志的存储方式，log_output可以设置为以下4种值:<ol>
<li>FILE : 表示日志存储在文件中</li>
<li>TABLE : 表示日志存储在mysql库中的general_log表中</li>
<li>FILE, TABLE : 表示将日志同时存储在文件和general_log表中，改值会徒增很多IO压力，一般不会这样设置</li>
<li>NONE : 表示不记录日志，即使general_log设置为ON， 如果log_output设置为NONE，也不会记录查询日志</li>
</ol>
</li>
<li>slow_query_log_file：当使用文件存储慢查询日志时(log_output设置为”FILE”或者”FILE,TABLE”时)，制定慢查询日志存储在哪个文件中，默认的文件名是”主机名-slow.log”，存储目录为数据目录</li>
<li>log_throttle_queries_not_using_indexes: MySQL5.6.5版本新引入的参数，用来限制没有使用索引的语句每分钟记录到慢查询日志中的次数。在生产环境中，有可能有很多没有使用索引的语句，可能会导致慢查询日志快速增长。</li>
</ul>
<blockquote>
<p>log_output不仅控制查询日志的输出，也控制着慢查询日志的输出，即: log_output设置为FILE，就表示查询日志和慢查询日志都存放在文件中，设置为TABLE，查询日志和慢查询日志都存放在mysql库中的general_log表中</p>
</blockquote>
<h3 id="3-1-2-开启或关闭慢查询日志"><a href="#3-1-2-开启或关闭慢查询日志" class="headerlink" title="3.1.2 开启或关闭慢查询日志"></a>3.1.2 开启或关闭慢查询日志</h3><ul>
<li>方法1: 在配置文件中设置(不推荐)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#可以在my.cnf里添加,1开启（0关闭）,当然了,这样要重启才能生效,有点多余了</span><br><span class="line">slow_query_log&#x3D;1</span><br></pre></td></tr></table></figure>

<p>然后重启MySQL实例</p>
<ul>
<li>方法2 : 通过命令设置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#也可以设置变量那样更改,ON开启（OFF关闭）,即时生效,不用重启,首选当然是这样的了</span><br><span class="line">mysql&gt; set global slow_query_log&#x3D;&#39;ON&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"># 设置慢查询时间</span><br><span class="line">mysql&gt; set global long_query_time&#x3D;0.05;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"># 关闭慢查询</span><br><span class="line">mysql&gt; set global slow_query_log&#x3D;&#39;OFF&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>通过该方式设置，MySQL实例重启后，相关配置又恢复到默认值。如果只是短暂时间内使用，推荐使用命令行方式</p>
</blockquote>
<blockquote>
<p>设置long_query_time这个阈值之后，MySQL数据库会记录运行时间超过该值的所有SQL语句，但对于运行时间正好等于 long_query_time 的情况，并不会被记录下。可以设置 long_query_time为0来捕获所有的查询</p>
</blockquote>
<h3 id="3-1-3-查看当前有多少条慢日志"><a href="#3-1-3-查看当前有多少条慢日志" class="headerlink" title="3.1.3 查看当前有多少条慢日志"></a>3.1.3 查看当前有多少条慢日志</h3><p>如果你想查询有多少条慢查询记录，可以使用系统变量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global status like &#39;%slow_queries%&#39;;</span><br><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| Slow_queries  | 0     |</span><br><span class="line">+---------------+-------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; &#96;</span><br></pre></td></tr></table></figure>

<h2 id="3-2-慢查询日志分析工具pt-query-digest"><a href="#3-2-慢查询日志分析工具pt-query-digest" class="headerlink" title="3.2 慢查询日志分析工具pt-query-digest"></a>3.2 慢查询日志分析工具pt-query-digest</h2><h3 id="3-2-1-pt-query-digest的使用"><a href="#3-2-1-pt-query-digest的使用" class="headerlink" title="3.2.1 pt-query-digest的使用"></a>3.2.1 pt-query-digest的使用</h3><p>pt-query-digest 是分析MySQL查询日志最有力的工具，该工具功能强大，它可以分析binlog，Generallog，slowlog，也可以通过show processlist或者通过 tcpdump 抓取的MySQL协议数据来进行分析，比 mysqldumpslow 更具体，更完善。</p>
<p>下载安装 <a href="https://www.percona.com/downloads/percona-toolkit/LATEST/" target="_blank" rel="noopener">https://www.percona.com/downloads/percona-toolkit/LATEST/</a></p>
<p>在windows下，下载tar.gz包，解压之后，使用perl命令运行</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9f38776eb1af0452f182405bcc051088b47.png" alt=""></p>
<p>其命令格式如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">pt-query-digest [OPTIONS] [FILES] [DSN]</span><br><span class="line">--create-review-table  当使用--review参数把分析结果输出到表中时，如果没有表就自动创建。</span><br><span class="line">--create-history-table  当使用--history参数把分析结果输出到表中时，如果没有表就自动创建。</span><br><span class="line">--filter  对输入的慢查询按指定的字符串进行匹配过滤后再进行分析</span><br><span class="line">--limit    限制输出结果百分比或数量，默认值是20,即将最慢的20条语句输出，如果是50%则按总响应时间占比从大到小排序，输出到总和达到50%位置截止。</span><br><span class="line">--host  mysql服务器地址</span><br><span class="line">--user  mysql用户名</span><br><span class="line">--password  mysql用户密码</span><br><span class="line">--history 将分析结果保存到表中，分析结果比较详细，下次再使用--history时，如果存在相同的语句，且查询所在的时间区间和历史表中的不同，则会记录到数据表中，可以通过查询同一CHECKSUM来比较某类型查询的历史变化。</span><br><span class="line">--review 将分析结果保存到表中，这个分析只是对查询条件进行参数化，一个类型的查询一条记录，比较简单。当下次使用--review时，如果存在相同的语句分析，就不会记录到数据表中。</span><br><span class="line">--output 分析结果输出类型，值可以是report(标准分析报告)、slowlog(Mysql slow log)、json、json-anon，一般使用report，以便于阅读。</span><br><span class="line">--since 从什么时间开始分析，值为字符串，可以是指定的某个”yyyy-mm-dd [hh:mm:ss]”格式的时间点，也可以是简单的一个时间值：s(秒)、h(小时)、m(分钟)、d(天)，如12h就表示从12小时前开始统计。</span><br><span class="line">--until 截止时间，配合—since可以分析一段时间内的慢查询。</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-pt-query-digest的结果"><a href="#3-2-2-pt-query-digest的结果" class="headerlink" title="3.2.2 pt-query-digest的结果"></a>3.2.2 pt-query-digest的结果</h3><p>输出结果分为三部分</p>
<ol>
<li>总体统计结果</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 该工具执行日志分析的用户时间，系统时间，物理内存占用大小，虚拟内存占用大小</span><br><span class="line"># 343ms user time, 78ms system time, 0 rss, 0 vsz</span><br><span class="line"># 工具执行时间</span><br><span class="line"># Current date: Thu Mar 29 15:51:38 2018</span><br><span class="line"># 运行分析工具的主机名</span><br><span class="line"># Hostname: NB2015041602</span><br><span class="line"># 被分析的文件名</span><br><span class="line"># Files: &#x2F;d&#x2F;xampp&#x2F;mysql&#x2F;data&#x2F;NB2015041602-slow.log</span><br><span class="line"># 语句总数量，唯一的语句数量，QPS，并发数</span><br><span class="line"># Overall: 5 total, 3 unique, 0.00 QPS, 0.05x concurrency ________________</span><br><span class="line"># 日志记录的时间范围</span><br><span class="line"># Time range: 2018-03-28 14:02:06 to 14:22:10</span><br><span class="line"># 属性               总计      最小    最大    平均    95%  标准    中等</span><br><span class="line"># Attribute          total     min     max     avg     95%  stddev  median</span><br><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;     &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"># 语句执行时间</span><br><span class="line"># Exec time            60s     10s     17s     12s     17s      3s     11s</span><br><span class="line"># 锁占用时间</span><br><span class="line"># Lock time            1ms       0   500us   200us   490us   240us       0</span><br><span class="line"># 发送到客户端的行数</span><br><span class="line"># Rows sent             50      10      10      10      10       0      10</span><br><span class="line"># select语句扫描行数</span><br><span class="line"># Rows examine     629.99k  45.43k 146.14k 126.00k 143.37k  39.57k 143.37k</span><br><span class="line"># 查询的字符数</span><br><span class="line"># Query size         2.81k     235   1.36k  575.40   1.33k  445.36  234.30</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>查询分组统计结果</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># rank：所有语句的排序，默认按照查询时间降序排序，通过--order-by指定</span><br><span class="line"># # query id：语句的id，（去掉多余空格和文本字符，计算hash值）</span><br><span class="line"># response：总的响应时间</span><br><span class="line"># time：该查询在本次分析中总的时间占比</span><br><span class="line"># calls：执行次数，即本次分析总共有多少条这种类型的查询语句</span><br><span class="line"># r&#x2F;call：平均每次执行的响应时间</span><br><span class="line"># v&#x2F;m：响应时间variance-to-mean的比率</span><br><span class="line"># item：查询对象</span><br><span class="line"></span><br><span class="line"># Profile</span><br><span class="line"># Rank Query ID           Response time Calls R&#x2F;Call  V&#x2F;M   Item</span><br><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">#    1 0x96112A601F7BCCC0 32.9042 55.0%     3 10.9681  0.01 SELECT affiliatemerchant_list user_list</span><br><span class="line">#    2 0x70885F9703A0E38D 17.2162 28.8%     1 17.2162  0.00 SELECT normalmerchant merchant_mapping normalmerchant_addinfo merchant_search_filter affiliatemerchant_list user_list</span><br><span class="line">#    3 0x43D8527285567FC4  9.7367 16.3%     1  9.7367  0.00 SELECT affiliatemerchant_list user_list affiliatemerchant_list user_list</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>每一种查询的详细统计结果</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"># id：查询的id号，和上面的query id对应</span><br><span class="line"># # databases：数据库名</span><br><span class="line"># users：各个用户执行的次数（占比）</span><br><span class="line"># query_time_distribution：查询时间分布，长短体现区间占比</span><br><span class="line"># tables：查询中设计到的表</span><br><span class="line"># explain：sql语句</span><br><span class="line"></span><br><span class="line"># Query 1: 0.00 QPS, 0.03x concurrency, ID 0x96112A601F7BCCC0 at byte 2647</span><br><span class="line"># This item is included in the report because it matches --limit.</span><br><span class="line"># Scores: V&#x2F;M &#x3D; 0.01</span><br><span class="line"># Time range: 2018-03-28 14:03:31 to 14:19:54</span><br><span class="line"># Attribute    pct   total     min     max     avg     95%  stddev  median</span><br><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"># Count         60       3</span><br><span class="line"># Exec time     54     33s     11s     11s     11s     11s   243ms     11s</span><br><span class="line"># Lock time     50   500us       0   500us   166us   490us   231us       0</span><br><span class="line"># Rows sent     60      30      10      10      10      10       0      10</span><br><span class="line"># Rows examine  69 438.42k 146.14k 146.14k 146.14k 146.14k       0 146.14k</span><br><span class="line"># Query size    24     707     235     236  235.67  234.30       0  234.30</span><br><span class="line"># String:</span><br><span class="line"># Databases    database_base</span><br><span class="line"># Hosts        localhost</span><br><span class="line"># Users        root</span><br><span class="line"># Query_time distribution</span><br><span class="line">#   1us</span><br><span class="line">#  10us</span><br><span class="line"># 100us</span><br><span class="line">#   1ms</span><br><span class="line">#  10ms</span><br><span class="line"># 100ms</span><br><span class="line">#    1s</span><br><span class="line">#  10s+  ################################################################</span><br><span class="line"># Tables</span><br><span class="line">#    SHOW TABLE STATUS FROM &#96;database_base&#96; LIKE &#39;table_list1&#39;\G</span><br><span class="line">#    SHOW CREATE TABLE &#96;database_base&#96;.&#96;table_list1&#96;\G</span><br><span class="line">#    SHOW TABLE STATUS FROM &#96;database_base&#96; LIKE &#39;user_list&#39;\G</span><br><span class="line">#    SHOW CREATE TABLE &#96;database_base&#96;.&#96;user_list&#96;\G</span><br><span class="line"># EXPLAIN &#x2F;*!50100 PARTITIONS*&#x2F;</span><br><span class="line">select SQL_CALC_FOUND_ROWS al.*, ul.Alias as userName</span><br><span class="line">        FROM table_list1 al</span><br><span class="line">        LEFT JOIN user_list ul ON ul.ID &#x3D; al.UserId</span><br><span class="line">         WHERE TRUE  AND (al.SupportCountrys LIKE &#39;%%&#39;)</span><br><span class="line">         limit 80, 10\G</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3-pt-query-digest的命令"><a href="#3-2-3-pt-query-digest的命令" class="headerlink" title="3.2.3 pt-query-digest的命令"></a>3.2.3 pt-query-digest的命令</h3><p>以下是使用pt-query-digest的示例:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;直接分析慢查询文件</span><br><span class="line">pt-query-digest  slow.log &gt; slow_report.log</span><br><span class="line"></span><br><span class="line">分析最近12小时内的查询</span><br><span class="line">pt-query-digest  --since&#x3D;12h  slow.log &gt; slow_report2.log</span><br><span class="line"></span><br><span class="line">分析指定时间范围内的查询</span><br><span class="line">pt-query-digest slow.log --since &#39;2017-01-07 09:30:00&#39; --until &#39;2017-01-07 10:00:00&#39;&gt; &gt; slow_report3.log</span><br><span class="line"></span><br><span class="line">分析含有select语句的慢查询</span><br><span class="line">pt-query-digest --filter &#39;$event-&gt;&#123;fingerprint&#125; &#x3D;~ m&#x2F;^select&#x2F;i&#39; slow.log&gt; slow_report4.log</span><br><span class="line"></span><br><span class="line">针对某个用户的慢查询</span><br><span class="line">pt-query-digest --filter &#39;($event-&gt;&#123;user&#125; || &quot;&quot;) &#x3D;~ m&#x2F;^root&#x2F;i&#39; slow.log&gt; slow_report5.log</span><br><span class="line"></span><br><span class="line">查询所有全表扫描或full join的慢查询</span><br><span class="line">pt-query-digest --filter &#39;(($event-&gt;&#123;Full_scan&#125; || &quot;&quot;) eq &quot;yes&quot;) ||(($event-&gt;&#123;Full_join&#125; || &quot;&quot;) eq &quot;yes&quot;)&#39; slow.log&gt; slow_report6.log</span><br><span class="line"></span><br><span class="line">把查询保存到query_review表</span><br><span class="line">pt-query-digest --user&#x3D;root –password&#x3D;abc123 --review  h&#x3D;localhost,D&#x3D;test,t&#x3D;query_review--create-review-table  slow.log</span><br><span class="line"></span><br><span class="line">把查询保存到query_history表</span><br><span class="line">pt-query-digest  --user&#x3D;root –password&#x3D;abc123 --review  h&#x3D;localhost,D&#x3D;test,t&#x3D;query_history--create-review-table  slow.log_0001</span><br><span class="line">pt-query-digest  --user&#x3D;root –password&#x3D;abc123 --review  h&#x3D;localhost,D&#x3D;test,t&#x3D;query_history--create-review-table  slow.log_0002</span><br><span class="line"></span><br><span class="line">通过tcpdump抓取的tcp协议数据，然后分析</span><br><span class="line">tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 &gt; mysql.tcp.txt</span><br><span class="line">pt-query-digest --type tcpdump mysql.tcp.txt&gt; slow_report9.log</span><br><span class="line"></span><br><span class="line">分析biglog</span><br><span class="line">mysqlbinlog mysql-bin.000093 &gt; mysql-bin000093.sql</span><br><span class="line">pt-query-digest  --type&#x3D;binlog  mysql-bin000093.sql &gt; slow_report10.log</span><br><span class="line"></span><br><span class="line">分析general log</span><br><span class="line">pt-query-digest  --type&#x3D;genlog  localhost.log &gt; slow_report11.log</span><br></pre></td></tr></table></figure>

<p>该工具可以将查询的剖析报告打印出来，可以分析结果输出到文件中，分析过程是先对查询语句的条件进行参数化，然后对参数化以后的查询进行分组统计，统计出各查询的执行时间，次数，占比等，可以借助分析结果找出问题进行优化。</p>
<h2 id="3-3-慢查询日志分析工具mysqldumpslow"><a href="#3-3-慢查询日志分析工具mysqldumpslow" class="headerlink" title="3.3 慢查询日志分析工具mysqldumpslow"></a>3.3 慢查询日志分析工具mysqldumpslow</h2><p>mysqldumpslow是mysql自身提供的日志分析工具，一般在mysql的bin目录下</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4485cce5b262eea9f252ec10f4ce6b93f8b.png" alt=""></p>
<p>帮助信息如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">$ mysqldumpslow.pl --help</span><br><span class="line">Usage: mysqldumpslow [ OPTS... ] [ LOGS... ]</span><br><span class="line"></span><br><span class="line">Parse and summarize the MySQL slow query log. Options are</span><br><span class="line"></span><br><span class="line">  --verbose    verbose</span><br><span class="line">  --debug      debug</span><br><span class="line">  --help       write this text to standard output</span><br><span class="line"></span><br><span class="line">  -v           verbose</span><br><span class="line">  -d           debug</span><br><span class="line"></span><br><span class="line"> -s, 是表示按照何种方式排序</span><br><span class="line">    c: 访问计数</span><br><span class="line"></span><br><span class="line">    l: 锁定时间</span><br><span class="line"></span><br><span class="line">    r: 返回记录</span><br><span class="line"></span><br><span class="line">    t: 查询时间</span><br><span class="line"></span><br><span class="line">    al:平均锁定时间</span><br><span class="line"></span><br><span class="line">    ar:平均返回记录数</span><br><span class="line"></span><br><span class="line">    at:平均查询时间</span><br><span class="line"></span><br><span class="line">-t, 是top n的意思，即为返回前面多少条的数据；</span><br><span class="line">-g, 后边可以写一个正则匹配模式，大小写不敏感的；</span><br><span class="line"></span><br><span class="line">比如:</span><br><span class="line">得到返回记录集最多的10个SQL。</span><br><span class="line">mysqldumpslow -s r -t 10 &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log</span><br><span class="line"></span><br><span class="line">得到访问次数最多的10个SQL</span><br><span class="line">mysqldumpslow -s c -t 10 &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log</span><br><span class="line"></span><br><span class="line">得到按照时间排序的前10条里面含有左连接的查询语句。</span><br><span class="line">mysqldumpslow -s t -t 10 -g “left join” &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log</span><br><span class="line"></span><br><span class="line">另外建议在使用这些命令时结合 | 和more 使用 ，否则有可能出现刷屏的情况。</span><br><span class="line">mysqldumpslow -s r -t 20 &#x2F;mysqldata&#x2F;mysql&#x2F;mysql06-slow.log | more</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果不能执行，可以先安装perl，然后通过perl mysqldumpslow xxx.log</p>
</blockquote>
<h1 id="4-事务日志"><a href="#4-事务日志" class="headerlink" title="4 事务日志"></a>4 事务日志</h1><p>事务日志包括redo log和undo log，在阐述二者之前，我们必须明确，redo log是InnoDB引擎的一类日志，而不是MySQL服务端的日志。它是InnoDB实现事务的重要机制。</p>
<p>具体内容详见本博客文章《【InnoDB详解四】redo log和undo log》</p>
<h1 id="5-二进制日志"><a href="#5-二进制日志" class="headerlink" title="5 二进制日志"></a>5 二进制日志</h1><p>MySQL的二进制日志（binary log，简称binlog）是一个二进制文件，主要记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的所有操作。二进制日志（binary log）中记录了对MySQL数据库执行更改的所有操作，并且记录了语句发生时间、执行时长、操作数据等其它额外信息，但是它不记录SELECT、SHOW等那些不修改数据的SQL语句。</p>
<p>它和InnoDB的redo log很像，但注意redo log是InnoDB的，是引擎级别的，binlog是MySQL级别的，换言之，不论MySQL使用什么存储引擎，它都会产生binlog。</p>
<h2 id="5-1-binlog的作用"><a href="#5-1-binlog的作用" class="headerlink" title="5.1 binlog的作用"></a>5.1 binlog的作用</h2><ol>
<li><p>恢复（recovery）：某些数据的恢复需要二进制日志。例如，在一个数据库全备文件恢复后，用户可以通过二进制日志进行point-in-time的恢复。</p>
</li>
<li><p>复制（replication）：其原理与恢复类似，通过复制和执行二进制日志使一台远程的MySQL数据库（一般称为slave或者standby）与一台MySQL数据库（一般称为master或者primary）进行实时同步。</p>
</li>
<li><p>审计（audit）：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击。</p>
</li>
</ol>
<p>除了上面介绍的几个作用外，binlog对于事务存储引擎的崩溃恢复也有非常重要的作用。</p>
<p>在开启binlog的情况下，为了保证binlog与redo的一致性，MySQL将采用事务的两阶段提交协议。当MySQL系统发生崩溃时，事务在存储引擎内部的状态可能为prepared和commit两种。对于prepared状态的事务，是进行提交操作还是进行回滚操作，这时需要参考binlog：如果事务在binlog中存在，那么将其提交；如果不在binlog中存在，那么将其回滚，这样就保证了数据在主库和从库之间的一致性。</p>
<h2 id="5-2-binlog的存储"><a href="#5-2-binlog的存储" class="headerlink" title="5.2 binlog的存储"></a>5.2 binlog的存储</h2><p>为了管理所有的binlog文件，MySQL额外创建了一个base-name.index文件，它按顺序记录了MySQL使用的所有binlog文件。如果你想自定义index文件的名称，可以设置log_bin_index=file参数。千万不要在mysqld运行的时候手动修改index文件的内容，这样会使mysqld产生混乱。</p>
<h2 id="5-3-binlog的开启"><a href="#5-3-binlog的开启" class="headerlink" title="5.3 binlog的开启"></a>5.3 binlog的开启</h2><p>binlog默认关闭，如果想开启binlog，可以在MySQL配置文件中通过配置参数<code>log-bin = [base-name]</code>启动二进制日志。如果不指定base-name，则默认以主机名为二进制日志的文件名，并以自增的数字作为后缀，例如<code>mysql-bin.000001</code>，所在目录为数据库所在目录（datadir）。</p>
<p>顺序说一下，对于二进制文件当满足下面三种情况时会创建新的文件，文件后缀会自增。</p>
<ol>
<li>文件大小达到<code>max_binlog_size</code>参数设置值时。</li>
<li>执行flush logs命令。</li>
<li>重启mysqld进程。</li>
</ol>
<blockquote>
<p>你可能会有顾虑，当文件后缀从000001增长到999999时会怎样？有网友测试过，当文件达到999999时又会回到000001，并不会有什么异常。</p>
</blockquote>
<h2 id="5-4-binlog格式"><a href="#5-4-binlog格式" class="headerlink" title="5.4 binlog格式"></a>5.4 binlog格式</h2><p>binlog格式分为: STATEMENT、ROW和MIXED三种，详情如下:</p>
<ol>
<li><p>STATEMENT</p>
<ul>
<li>STATEMENT格式的binlog记录的是数据库上执行的原生SQL语句。</li>
<li>这种方式有好处：<ul>
<li>好处就是相当简单，简单地记录和执行这些语句，能够让主备保持同步，在主服务器上执行的SQL语句，在从服务器上执行同样的语句。</li>
<li>另一个好处是二进制日志里的时间更加紧凑，所以相对而言，基于语句的复制模式不会使用太多带宽，同时也节约磁盘空间。并且通过mysqlbinlog工具容易读懂其中的内容。</li>
</ul>
</li>
<li>这种方式也有坏处：<ul>
<li>坏处就是同一条SQL在主库和从库上执行的时间可能稍微或很大不相同，因此在传输的二进制日志中，除了查询语句，还包括了一些元数据信息，如当前的时间戳。<ul>
<li>即便如此，还存在着一些无法被正确复制的SQL。例如，使用INSERT INTO TB1 VALUE(CUURENT_DATE())这一条使用函数的语句插入的数据复制到当前从服务器上来就会发生变化。存储过程和触发器在使用基于语句的复制模式时也可能存在问题。</li>
<li>另外一个问题就是基于语句的复制必须是串行化的。这要求大量特殊的代码，配置，例如InnoDB的next-key锁等。并不是所有的存储引擎都支持基于语句的复制。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>ROW</p>
<ul>
<li>从MySQL5.1开始支持基于行的复制，也就是基于数据的复制，基于行的更改。这种方式会将实际数据记录在二进制日志中。</li>
<li>这种方式有好处：<ul>
<li>最大的好处是可以正确地复制每一行数据。一些语句可以被更加有效地复制</li>
<li>另外就是几乎没有基于行的复制模式无法处理的场景，对于所有的SQL构造、触发器、存储过程等都能正确执行。</li>
</ul>
</li>
<li>这种方式也有坏处：<ul>
<li>主要的缺点就是二进制日志可能会很大，而且不直观，所以，你不能使用mysqlbinlog来查看二进制日志。也无法通过看二进制日志判断当前执行到那一条SQL语句了。</li>
</ul>
</li>
</ul>
</li>
</ol>
<blockquote>
<p>现在对于ROW格式的二进制日志基本是标配了，主要是因为它的优势远远大于缺点。并且由于ROW格式记录行数据，所以可以基于这种模式做一些DBA工具，比如数据恢复，不同数据库之间数据同步等。</p>
</blockquote>
<ol start="3">
<li><p>MIXED</p>
<ul>
<li>MIXED也是MySQL默认使用的二进制日志记录方式，但MIXED格式默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。比如用到UUID()、USER()、CURRENT_USER()、ROW_COUNT()等无法确定的函数。</li>
</ul>
</li>
</ol>
<h1 id="6-中继日志"><a href="#6-中继日志" class="headerlink" title="6 中继日志"></a>6 中继日志</h1><p>relay log是复制过程中产生的日志，很多方面都跟binary log差不多，区别是: relay log是从库服务器I/O线程将<strong>主库服务器</strong>的二进制日志读取过来记录到<strong>从库服务器</strong>本地文件，然后<strong>从库</strong>的SQL线程会读取relay-log日志的内容并应用到<strong>从库服务器</strong>上。</p>
<h2 id="6-1-中继日志参数"><a href="#6-1-中继日志参数" class="headerlink" title="6.1 中继日志参数"></a>6.1 中继日志参数</h2><ul>
<li><p>max_relay_log_size<br>标记relay log 允许的最大值，如果该值为0，则默认值为max_binlog_size(1G)；如果不为0，则max_relay_log_size则为最大的relay_log文件大小；</p>
</li>
<li><p>relay_log<br>定义relay_log的位置和名称，如果值为空，则默认位置在数据文件的目录，文件名为host_name-relay-bin.nnnnnn（By default, relay log file names have the form host_name-relay-bin.nnnnnn in the data directory）；</p>
</li>
<li><p>relay_log_index<br>同relay_log，定义relay_log的位置和名称；</p>
</li>
<li><p>relay_log_info_file<br>设置<code>http://relay-log.info</code>的位置和名称（<a href="http://relay-log.info记录MASTER的binary_log的恢复位置和relay_log的位置）" target="_blank" rel="noopener">http://relay-log.info记录MASTER的binary_log的恢复位置和relay_log的位置）</a></p>
</li>
<li><p>relay_log_purge<br>是否自动清空不再需要中继日志时。默认值为1(启用)。</p>
</li>
<li><p>relay_log_recovery<br>当slave从库宕机后，假如relay-log损坏了，导致一部分中继日志没有处理，则自动放弃所有未执行的relay-log，并且重新从master上获取日志，这样就保证了relay-log的完整性。默认情况下该功能是关闭的，将relay_log_recovery的值设置为 1时，可在slave从库上开启该功能，建议开启。</p>
</li>
<li><p>relay_log_space_limit<br>防止中继日志写满磁盘，这里设置中继日志最大限额。但此设置存在主库崩溃，从库中继日志不全的情况，不到万不得已，不推荐使用；</p>
</li>
<li><p>sync_relay_log<br>这个参数和sync_binlog是一样的，当设置为1时，slave的I/O线程每次接收到master发送过来的binlog日志都要写入系统缓冲区，然后刷入relay log中继日志里，这样是最安全的，因为在崩溃的时候，你最多会丢失一个事务，但会造成磁盘的大量I/O。当设置为0时，并不是马上就刷入中继日志里，而是由操作系统决定何时来写入，虽然安全性降低了，但减少了大量的磁盘I/O操作。这个值默认是0，可动态修改。</p>
</li>
<li><p>sync_relay_log_info<br>这个参数和sync_relay_log参数一样，当设置为1时，slave的I/O线程每次接收到master发送过来的binlog日志都要写入系统缓冲区，然后刷入<code>http://relay-log.info</code>里，这样是最安全的，因为在崩溃的时候，你最多会丢失一个事务，但会造成磁盘的大量I/O。当设置为0时，并不是马上就刷入<code>http://relay-log.info</code> 里，而是由操作系统决定何时来写入，虽然安全性降低了，但减少了大量的磁盘I/O操作。这个值默认是0，可动态修改。</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/" itemprop="url">【InnoDB详解四】redo log和undo log</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-27T23:36:33+08:00">
                2020-09-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/27/【InnoDB详解四】redo-log和undo-log/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  12.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  45
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-redo-log"><a href="#1-redo-log" class="headerlink" title="1 redo log"></a>1 redo log</h1><p>首先我们先明确一下InnoDB的修改数据的基本流程，当我们想要修改DB上某一行数据的时候，InnoDB是把数据从磁盘读取到内存的缓冲池上进行修改。这个时候数据在内存中被修改，与磁盘中相比就存在了差异，我们称这种有差异的数据为脏页。</p>
<p>InnoDB对脏页的处理不是每次生成脏页就将脏页刷新回磁盘，<strong>这样会产生海量的IO操作，严重影响InnoDB的处理性能</strong>。对于此，InnoDB有一套完善的处理策略，与我们这次主题关系不大，表过不提。既然脏页与磁盘中的数据存在差异，那么如果在这期间DB出现故障就会造成数据的丢失（持久性问题产生了）。为了解决这个问题，redo log就应运而生了。</p>
<h2 id="1-1-redo-log的特点"><a href="#1-1-redo-log的特点" class="headerlink" title="1.1 redo log的特点"></a>1.1 redo log的特点</h2><ul>
<li><p>redo log在<strong>数据库重启恢复的时候被使用</strong>。</p>
</li>
<li><p>redo日志占用的空间非常小，存储表空间ID、页号、偏移量以及需要更新的值所需的存储空间是很小的。</p>
</li>
<li><p>redo log属于物理日志，他可以将已提交事务修改的记录记录下来，即某个表空间中某页的某个偏移量的值更新为多少。因为其属于<strong>物理日志</strong>的特性，恢复速度远快于逻辑日志。而我们下文即将介绍的binlog和undo log就属于典型的逻辑日志。</p>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-e43816535e5b18dcd0b5bb54be94f21344a.png" alt=""></p>
<ul>
<li><p>redo日志不止记录索引插入/更新记录等操作，还有执行这个操作影响到的其他动作，如页分裂新增目录项记录，修改页信息等对数据页做的任何修改等等。</p>
</li>
<li><p>redo日志记录的是物理页的情况，它具有幂等性，因此记录日志的方式极其简练。幂等性的意思是多次操作前后状态是一样的，例如新插入一行后又删除该行，前后状态没有变化。</p>
</li>
<li><p>redo日志是顺序写入磁盘的，在执行事务的过程中，每执行一条语句，就可能产生若干条redo日志，这些日志是按照产生的顺序写入磁盘的，也就是使用顺序IO，这比随机IO的性能要高得多。</p>
</li>
</ul>
<h2 id="1-2-redo-log的工作机制简述"><a href="#1-2-redo-log的工作机制简述" class="headerlink" title="1.2 redo log的工作机制简述"></a>1.2 redo log的工作机制简述</h2><p>redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的，并且事务的记录是顺序追加的，性能非常高(磁盘的<strong>顺序写</strong>性能比内存的写性能差不了太多)。</p>
<p>InnoDB使用日志+缓存的策略来减少提交事务时的开销。因为日志中已经记录了事务，所以就无须为了保证持久性而在每个事务提交时都把缓冲池的脏数据刷新(flush)到磁盘中。</p>
<p>事务修改的数据和索引通常会映射到表空间的随机位置，所以刷新这些变更到磁盘需要很多随机IO。InnoDB假设使用常规磁盘，随机IO比顺序IO昂贵得多，因为一个IO请求需要时间把磁头移到正确的位置，然后等待磁盘上读出需要的部分，再转到开始位置。</p>
<p>InnoDB用日志把随机IO变成顺序IO。一旦日志安全写到磁盘，事务就持久化了，即使断电了，InnoDB可以重放日志并且恢复已经提交的事务。</p>
<p>为了确保每次日志数据都能写入到磁盘的事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作(即fsync()系统调用)。</p>
<p>因为MySQL是工作在用户空间的，MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中(也就是redo的ib_logfileN文件，undo的share tablespace或.ibd文件，后面讲undo log时会讲到)，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将OS buffer中的日志刷到磁盘上的log file中。</p>
<p>也就是说，从redo log buffer写日志到磁盘的redo log file中，过程如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c1152ce0028d1f668da73cbc4b28b1794a3.png" alt=""></p>
<h2 id="1-3-redo-log的数据结构（log-block）"><a href="#1-3-redo-log的数据结构（log-block）" class="headerlink" title="1.3 redo log的数据结构（log block）"></a>1.3 redo log的数据结构（log block）</h2><p>InnoDB存储引擎中，redo log以块为单位进行存储的，每个块占512字节（同磁盘扇区大小一致，可以保证块的写入是原子操作。），这称为redo log block。<strong>所以不管是log buffer中还是os buffer中以及redo log file on disk中，都是这样以512字节的块存储的</strong>。</p>
<p>每个redo log block由3部分组成：header、tailer和body。其中日志块头header占用12字节，日志块尾tailer占用8字节，所以每个redo log block的日志主体部分body只有512-12-8=492字节。</p>
<p>因为redo log记录的是数据页的变化，当一个数据页产生的变化需要使用超过492字节的redo log来记录，那么就会使用多个redo log block来记录该数据页的变化。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c6ca3a15d7c42bf5fa449dbe802b692605b.png" alt=""></p>
<p>上面所说的是一个日志块的内容，在redo log buffer或者redo log file on disk中，由很多log block组成。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e7ea51e63422a5719c70835176b989e073e.png" alt=""></p>
<h3 id="1-3-1-block-header"><a href="#1-3-1-block-header" class="headerlink" title="1.3.1 block header"></a>1.3.1 block header</h3><p>header包含4部分：</p>
<ul>
<li>log_block_hdr_no：(4字节)该日志块在redo log buffer/os buffer/log file中的位置ID。log buffer/redo log file on disk是由log block组成，在log buffer内部就好似一个数组，因此LOG_BLOCK HDR_NO用来标记这个数组中的位置。其是递增并且循环使用的。</li>
<li>log_block_hdr_data_len：(2字节)该log block中<strong>已记录</strong>的log大小。写满该log block时为0x200，表示512字节。</li>
<li>log_block_first_rec_group：(2字节)该log block中新的数据页对应的log的开始偏移位置。</li>
<li>lock_block_checkpoint_no：(4字节)写入checkpoint信息的位置。</li>
</ul>
<p>关于log block块头的第三部分<code>log_block_first_rec_group</code>，因为有时候一个数据页产生的日志量<strong>超出了一个日志块</strong>，这时需要用多个日志块来记录该页的相关日志。</p>
<p>例如，某一T1事务产生了792个字节的日志量，那么需要占用两个日志块，第一个日志块占用492字节，第二个日志块需要占用270个字节，那么对于第二个日志块来说，它记录的关于下一个数据页B的第一个log的开始位置就是282字节(270+12)。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fa477acf42ce4e51969e8127c867d22560e.png" alt=""></p>
<p>如果<code>log_block_first_rec_group</code>的值和<code>log_block_hdr_data_len</code>相等，则说明该log block中没有新开始记录下一个数据页的日志，即<strong>表示该日志块用来延续前一个日志块</strong>。</p>
<h3 id="1-3-2-block-tailer"><a href="#1-3-2-block-tailer" class="headerlink" title="1.3.2 block tailer"></a>1.3.2 block tailer</h3><p>tailer只有一个部分：</p>
<ul>
<li><code>log_block_trl_no</code> ，该值和块头的 <code>log_block_hdr_no</code> 相等。</li>
</ul>
<h3 id="1-3-3-block-body"><a href="#1-3-3-block-body" class="headerlink" title="1.3.3 block body"></a>1.3.3 block body</h3><p>因为innodb存储引擎存储数据的单元是页(和SQL Server中一样)，所以redo log也是基于页的格式来存放的。默认情况下，innodb的页大小是16KB(由<code>innodb_page_size</code>变量控制)，一个页内可以存放非常多的log block(每个512字节)，而log block中记录的又是数据页的变化。</p>
<p>其中log block中492字节的部分是block body，<strong>block body存储了很多条的redo日志，每条redo日志的格式分为4部分</strong>：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-952af4bd6ec616062dc8b8ce0a9ec050c1d.png" alt=""></p>
<ul>
<li><p>type：占用1个字节，8bit，其中高位的一个bit另做它用，剩下7个bit表示redo log的日志类型，其值有很多，在MySQL 5.7.21这个版本中，InnoDB一共为redo日志设计了53种不同的类型，下文将详细分析。</p>
</li>
<li><p>space ID：表示表空间的ID，采用压缩的方式后，占用的空间可能小于4字节。</p>
</li>
<li><p>page number：表示页的偏移量，同样是压缩过的。</p>
</li>
<li><p>data：表示每个redo日志的数据部分，恢复时会调用相应的函数进行解析。例如insert语句和delete语句写入redo log的内容是不一样的。</p>
</li>
</ul>
<h3 id="1-3-4-redo-log的类型"><a href="#1-3-4-redo-log的类型" class="headerlink" title="1.3.4 redo log的类型"></a>1.3.4 redo log的类型</h3><p>type字段的低位7个bit用来区分redo log的日志类型，我们来看下简单的场景和复杂的场景下，redo日志的不同类型。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c6af77a689edc02a3cafabd97c02942128c.png" alt=""></p>
<h4 id="1-3-4-1-简单的redo日志类型"><a href="#1-3-4-1-简单的redo日志类型" class="headerlink" title="1.3.4.1 简单的redo日志类型"></a>1.3.4.1 简单的redo日志类型</h4><p>我们前边介绍InnoDB的记录行格式的时候说过，如果我们没有为某个表显式的定义主键，并且表中也没有定义Unique键，那么InnoDB会自动的为表添加一个称之为row_id的隐藏列作为主键。</p>
<p>这时服务器会在内存中维护一个全局变量，每当向某个包含隐藏的row_id列的表中插入一条记录时，就会把该变量的当前值当作新记录的row_id列的值，并且把该变量自增1。</p>
<p>每当这个变量的值为256的倍数时，就会将该变量的值刷新到系统表空间的页号为7的页中一个称之为Max Row ID的属性处。</p>
<p>这是Max Row ID的持久化，即Max Row ID每增加256，就持久化一次，如果期间发生了系统宕机，那么重新启动后，服务器会将持久化的最大的Max Row ID取出，并加上256，当做新的Max Row ID。</p>
<blockquote>
<p>比如Max Row ID自增到800的时候，系统已经持久化了Max Row ID的三个值256，512，768。这时，系统崩溃了，重新启动后，系统取出了最新的768，但不能直接从768开始用，为了防止重复，新的Max Row ID=768+256=1024。</p>
</blockquote>
<p>这个Max Row ID属性占用的存储空间是8个字节，当某个事务向某个包含row_id隐藏列的表插入一条记录，并且为该记录分配的row_id值刚好为256的倍数时，就会向系统表空间页号为7的页面的相应偏移量处写入8个字节的值。</p>
<p>但是我们要知道，这个写入实际上是在Buffer Pool中完成的，我们需要为这个页的修改记录一条redo日志，以便在系统奔溃后能将已经提交的该事务对该页面所做的修改恢复出来。这种情况下对页的修改是极其简单的，<strong>redo日志中只需要记录一下页号为7的页面的某个偏移量处修改了几个字节的值，以及具体被修改的内容是啥就好了</strong>。</p>
<p>这种简单的redo日志，InnoDB定义了如下的type的值，来表示对应字节的redo日志的产生。</p>
<ul>
<li>MLOG_1BYTE(type字段对应的⼗进制数字为1)：表示在⻚⾯的某个偏移量处写⼊1个字节的redo⽇志类型。</li>
<li>MLOG_2BYTE(type字段对应的⼗进制数字为2)：表示在⻚⾯的某个偏移量处写⼊2个字节的redo⽇志类型。</li>
<li>MLOG_4BYTE(type字段对应的⼗进制数字为4)：表示在⻚⾯的某个偏移量处写⼊4个字节的redo⽇志类型。</li>
<li>MLOG_8BYTE(type字段对应的⼗进制数字为8)：表示在⻚⾯的某个偏移量处写⼊8个字节的redo⽇志类型。</li>
<li>MLOG_WRITE_STRING(type字段对应的⼗进制数字为30)：表示在⻚⾯的某个偏移量处写⼊⼀串数据。</li>
</ul>
<p>我们上边提到的Max Row ID属性实际占用8个字节的存储空间，所以在修改页面中的该属性时，会记录一条类型为MLOG_8BYTE的redo日志，MLOG_8BYTE的redo日志结构如下所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c32188a1f15479176b8ec9188c67c622f21.png" alt=""></p>
<p>其余MLOG_1BYTE、MLOG_2BYTE、MLOG_4BYTE类型的redo日志结构和MLOG_8BYTE的类似，只不过具体数据中包含对应个字节的数据罢了。MLOG_WRITE_STRING类型的redo日志表示写入一串数据，但是因为不能确定写入的具体数据占用多少字节，所以需要在日志结构中添加一个len字段：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-554313fb140cc3234089d0f76ff3c927c36.png" alt=""></p>
<blockquote>
<p>其实只要将MLOG_WRITE_STRING类型的redo日志的len字段填充上1、2、4、8这些数字，就可以分别替代MLOG_1BYTE、MLOG_2BYTE、MLOG_4BYTE、MLOG_8BYTE这些类型的redo日志，为啥还要多此一举设计这么多类型呢？还不是因为省空间啊，能不写len字段就不写len字段，省一个字节算一个字节。</p>
</blockquote>
<h4 id="1-3-4-2-复杂的redo日志类型"><a href="#1-3-4-2-复杂的redo日志类型" class="headerlink" title="1.3.4.2 复杂的redo日志类型"></a>1.3.4.2 复杂的redo日志类型</h4><p>有时候执行一条语句会修改非常多的页面，包括系统数据页面（比如上文提到的全局变量Max Row ID的更新）和用户数据页面（用户数据指的就是聚簇索引和二级索引对应的B+树）。</p>
<p>以一条INSERT语句为例，它除了要向B+树的页面中插入数据，也可能更新系统数据Max Row ID的值，不过对于我们用户来说，平时更关心的是语句对B+树所做更新：</p>
<ul>
<li>表中包含多少个索引，一条INSERT语句就可能更新多少棵B+树。</li>
<li>针对某一棵B+树来说，既可能更新叶子节点页面，也可能更新内节点页面，也可能创建新的页面（在该记录插入的叶子节点的剩余空间比较少，不足以存放该记录时，会进行页面的分裂）。</li>
<li>对于B+树上的页来说，新的行被插入，页中的<code>Page Directory</code>的槽信息、<code>Page Header</code>中的各种统计信息，行记录链表的后驱<code>next_record</code>等都要随之更新。</li>
</ul>
<p>画一个简易的示意图就像是这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3371ed59e2f4a43841d84d37c5e6f0d35c5.png" alt=""></p>
<p>说了这么多，就是想表达：把一条记录插入到一个页面时需要更改的地方非常多。这时我们如果使用上边介绍的简单的物理redo日志来记录这些修改时，可以有两种解决方案：</p>
<ul>
<li><p>方案一：在每个修改的地方都记录一条redo日志。</p>
<ul>
<li>也就是如上图所示，有多少个加粗的块，就写多少条物理redo日志。这样子记录redo日志的缺点是显而易见的，因为被修改的地方是在太多了，可能记录的redo日志占用的空间都比整个页面占用的空间都多了。</li>
</ul>
</li>
<li><p>方案二：将整个页面的第一个被修改的字节到最后一个修改的字节之间所有的数据当成是一条物理redo日志中的具体数据。</p>
<ul>
<li>从图中也可以看出来，第一个被修改的字节到最后一个修改的字节之间仍然有许多没有修改过的数据，我们把这些没有修改的数据也加入到redo日志中去岂不是太浪费了。</li>
</ul>
</li>
</ul>
<p>正因为上述两种使用物理redo日志的方式来记录某个页面中做了哪些修改比较浪费，InnoDB的设计者本着勤俭节约的初心，提出了一些新的redo日志类型，比如：</p>
<ul>
<li>MLOG_REC_INSERT(type字段对应的十进制数字为9)：表示插入一条使用非紧凑行格式记录时的redo日志类型（如redundant）</li>
<li>MLOG_COMP_REC_INSERT(type字段对应的十进制数字为38)：表示插入一条使用紧凑行格式记录时的redo日志类型（如compact/dynamic/compressed）</li>
<li>MLOG_COMP_PAGE_CREATE（type字段对应的十进制数字为58）：表示创建一个存储紧凑行格式记录的页面的redo日志类型。</li>
<li>MLOG_COMP_REC_DELET(type字段对应的十进制数字为42)：表示删除一条使用紧凑行格式记录的redo日志类型</li>
<li>MLOG_COMP_LIST_START_DELETE（type字段对应的十进制数字为44）：表示从某条给定记录开始删除页面中的一系列使用紧凑行格式记录的redo日志类型。</li>
<li>MLOG_ZIP_PAGE_COMPRESS（type字段对应的十进制数字为51）：表示压缩一个数据页的redo日志类型。</li>
<li>MLOG_COMP_LIST_END_DELETE（type字段对应的十进制数字为43）：与MLOG_COMP_LIST_START_DELETE类型的redo日志呼应，表示删除一系列记录直到MLOG_COMP_LIST_END_DELETE类型的redo日志对应的记录为止。</li>
</ul>
<p>那这些新类型和旧的类型有什么区别呢？如果还是简单的把所有的物理层面的数据变动都记录下来，那岂不是没什么区别？</p>
<p>区别就是，新的日志类型，除了能体现物理层面的变动，还包含了逻辑层面的变动，它主要是搭配系统恢复的函数的来使用的。</p>
<ol>
<li>物理层面：修改的是哪个表空间，哪个页，以及页的偏移量。</li>
<li>逻辑层面：是插入操作还是删除操作；操作对象是行记录还是其他？如果是行记录，那是什么格式的行记录？紧凑的还是非紧凑的。</li>
</ol>
<p>这样有什么好处呢？？我们以插入一条使用紧凑行格式的记录时的redo日志（MLOG_COMP_REC_INSERT）为例，直接看一下这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志的结构，橙色部分都是block body：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-eda1ea874ed13e2c18c96c51b3c426d2bac.png" alt=""></p>
<p>这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志结构有几个地方需要大家注意：</p>
<ol>
<li>在一个数据页里，行记录都是按照索引列从小到大的顺序排序的。对于二级索引来说，当索引列的值相同时，记录还需要按照主键值进行排序。图中n_uniques的值的含义是在一条记录中，需要几个字段的值才能确保记录的唯一性，这样当插入一条记录时就可以按照记录的前n_uniques个字段进行排序。对于聚簇索引来说，n_uniques的值为主键的列数，对于其他二级索引来说，该值为索引列数+主键列数。这里需要注意的是，唯一二级索引的值可能为NULL，所以该值仍然为索引列数+主键列数。</li>
<li>field1_len ~ fieldn_len代表着该记录若干个字段占用存储空间的大小，需要注意的是，这里不管该字段的类型是固定长度大小的（比如INT），还是可变长度大小（比如VARCHAR(M)）的，该字段占用的大小始终要写入redo日志中。</li>
<li>offset代表的是该记录的前一条记录在页面中的地址。为啥要记录前一条记录的地址呢？这是因为每向数据页插入一条记录，都需要修改该页面中维护的记录链表，每条记录的记录头信息中都包含一个称为next_record的属性，所以在插入新记录时，需要修改前一条记录的next_record属性。</li>
</ol>
<p>很显然这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志并没有记录PAGE_N_DIR_SLOTS的值修改为了啥，PAGE_HEAP_TOP的值修改为了啥，PAGE_N_HEAP的值修改为了啥等等这些信息，<strong>而只是把在本页面中插入一条记录所有必备的要素记了下来</strong>，之后系统奔溃重启时，<strong>服务器会调用相关向某个页面插入一条记录的那个函数，而redo日志中的那些数据就可以被当成是调用这个函数所需的参数</strong>，在调用完该函数后，页面中的PAGE_N_DIR_SLOTS、PAGE_HEAP_TOP、PAGE_N_HEAP等等的值也就都被恢复到系统奔溃前的样子了。这就是所谓的逻辑日志的意思。</p>
<p>如下图，分别是insert和delete大致的记录方式。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1c95c4a1e07f6afdf1f7f9bdb9c5cfa80c2.png" alt=""></p>
<h2 id="1-4-redo日志的原子性（Mini-Transaction）"><a href="#1-4-redo日志的原子性（Mini-Transaction）" class="headerlink" title="1.4  redo日志的原子性（Mini-Transaction）"></a>1.4  redo日志的原子性（Mini-Transaction）</h2><p>前文说到执行一条INSERT的SQL语句，InnoDB在向某个B+树中插入新的记录的过程，会产生许多条的redo日志，因为可能涉及页的分裂，各种段的修改、区的统计信息，各种链表的统计信息等等。</p>
<p>我们知道向某个索引对应的B+树中插入一条记录的这个过程必须是原子的，不能说插了一半之后就停止了。在B+树上插入一个新的行，触发的页的分裂，这时新的页面已经分配好了，数据也复制过去了，新的记录也插入到页面中了，可是没有向数据节点中插入一条目录项记录，那么这个插入过程就是不完整的，这样会形成一棵不正确的B+树。</p>
<p>我们知道redo日志是为了在系统奔溃重启时恢复崩溃前的状态，如果在INSERT的过程中只记录了一部分redo日志，那么在系统奔溃重启时会将索引对应的B+树恢复成一种不正确的状态，这是InnoDB设计者们所不能忍受的。</p>
<p>MySQL把这种<strong>不容许分割的，对底层页面中的一次原子操作的过程</strong>称之为一个<strong>Mini-Transaction</strong>，简称mtr，比如上边所说的修改一次Max Row ID的值算是一个Mini-Transaction，向某个索引对应的B+树中插入一条记录的过程也算是一个Mini-Transaction。</p>
<p>一个mtr可能产生单条或者多条redo日志，就像对redo日志进行编组一样，在进行奔溃恢复时这一组redo日志将作为一个不可分割的整体，要么一起恢复，要么都不恢复。</p>
<blockquote>
<p>一个事务可以包含若干条语句，每一条语句其实是由若干个mtr组成，每一个mtr又可以包含若干条redo日志，画个图表示它们的关系就是这样：</p>
</blockquote>
<p><img src="https://oscimg.oschina.net/oscnet/up-391c80e95bda8d4ae7b97e571b2a5a77e33.png" alt=""></p>
<p>那么如何对一个mtr产生的redo日志进行编组呢？这得分情况讨论：</p>
<ol>
<li>有的操作会生成多条redo日志，比如向某个索引对应的B+树中进行一次插入就需要生成许多条redo日志。</li>
<li>有的需要保证原子性的操作只生成一条redo日志，比如更新全局变量Max Row ID属性的操作就只会生成一条redo日志。</li>
</ol>
<h3 id="1-4-1-原子操作生成多条redo日志"><a href="#1-4-1-原子操作生成多条redo日志" class="headerlink" title="1.4.1 原子操作生成多条redo日志"></a>1.4.1 原子操作生成多条redo日志</h3><p><strong>针对第一种情况</strong>，InnoDB定义了一种新的类型（<code>MLOG_MULTI_REC_END</code>，type字段对应的十进制数字为31）的redo log结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-020bd4a48f5f5c3000bd25452a3b8c4a5cb.png" alt=""></p>
<p>所以某个需要保证原子性的操作产生的一系列redo日志必须要以一个类型为<code>MLOG_MULTI_REC_END</code>结尾，就像这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b10b12fd333ba38b1faf25732f1669596a2.png" alt=""></p>
<p>这样在系统奔溃重启进行恢复时，只有当解析到类型为MLOG_MULTI_REC_END的redo日志，才认为解析到了一组完整的redo日志，才会进行恢复。否则的话直接放弃前边解析到的不完整部分的redo日志。</p>
<h3 id="1-4-2-原子操作生成单条redo日志"><a href="#1-4-2-原子操作生成单条redo日志" class="headerlink" title="1.4.2 原子操作生成单条redo日志"></a>1.4.2 原子操作生成单条redo日志</h3><p><strong>针对第二种情况</strong>，其实在一条日志后边跟一个类型为MLOG_MULTI_REC_END的redo日志也是可以的，但这比较浪费。</p>
<p>别忘了虽然redo日志的类型比较多，但撑死了也就是几十种，是小于127这个数字的，也就是说我们用7个比特位就足以包括所有的redo日志类型，而type字段其实是占用1个字节8比特位的，也就是说我们可以省出来一个比特位用来表示该需要保证原子性的操作只产生单一的一条redo日志，示意图如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c6af77a689edc02a3cafabd97c02942128c.png" alt=""></p>
<p>如果type字段的第一个比特为为1，代表该需要保证原子性的操作只产生了单一的一条redo日志，否则表示该需要保证原子性的操作产生了一系列的redo日志。</p>
<h2 id="1-5-redo日志的写入"><a href="#1-5-redo日志的写入" class="headerlink" title="1.5 redo日志的写入"></a>1.5 redo日志的写入</h2><p>我们前边说过，InnoDB为了解决磁盘速度过慢的问题而引入了Buffer Pool。同理，写入redo日志时也不能直接直接写到磁盘上，实际上在服务器启动时就向操作系统申请了一大片称之为redo log buffer的连续内存空间，翻译成中文就是redo日志缓冲区，我们也可以简称为log buffer。这片内存空间被划分成若干个连续的redo log block，就像这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3166883a72a3121c950bc3e38a1ad5ac71c.png" alt=""></p>
<p>向log buffer中写入redo日志的过程是顺序的，也就是先往前边的block中写，当该block的空闲空间用完之后再往下一个block中写。当我们想往log buffer中写入redo日志时，第一个遇到的问题就是应该写在哪个block的哪个偏移量处，所以InnoDB特意提供了一个称之为<code>buf_free</code>的全局变量，该变量指明后续写入的redo日志应该写入到log buffer中的哪个位置，如图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-34ddf107ece3e7f268d7097b01a4bc312f8.png" alt=""></p>
<p>我们前边说过一个mtr执行过程中可能产生若干条redo日志，这些redo日志是一个不可分割的组，所以其实并不是每生成一条redo日志，就将其插入到log buffer中，<strong>而是每个mtr运行过程中产生的日志先暂时存到一个地方，当该mtr结束的时候，将过程中产生的一组redo日志再全部复制到log buffer中（所以同一mtr的一组log都是一起连续出现）</strong>。</p>
<p>我们现在假设有两个名为T1、T2的事务，每个事务都包含2个mtr，每个mtr都产生若干个redo log：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-19d955d351169129ad49610058aa3f07fcd.png" alt=""></p>
<p>不同的事务可能是并发执行的，所以T1、T2之间的mtr可能是交替执行的。</p>
<p>每当一个mtr执行完成时，伴随该mtr生成的一组redo日志就需要被复制到log buffer中，也就是说不同事务的mtr可能是交替写入log buffer的，我们画个示意图（为了美观，我们把一个mtr中产生的所有的redo日志当作一个整体来画）：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-687b270013902ff1f4d3d65701700de0ef5.png" alt=""></p>
<p>从示意图中我们可以看出来，不同的mtr产生的一组redo日志占用的存储空间可能不一样，有的mtr产生的redo日志量很少，比如mtr_t1_1、mtr_t2_1就被放到同一个block中存储，有的mtr产生的redo日志量非常大，比如mtr_t1_2产生的redo日志甚至占用了3个block来存储。</p>
<h2 id="1-6-redo日志的持久化"><a href="#1-6-redo日志的持久化" class="headerlink" title="1.6 redo日志的持久化"></a>1.6 redo日志的持久化</h2><p>前面我们说过，和InnoDB的数据修改一样，redo log也是借助了日志缓冲区来调节磁盘和CPU的矛盾，提升了性能。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0c9e8dfa4efc1da25a6055de1a9232833db.png" alt=""></p>
<h3 id="1-6-1-redo日志的持久化文件"><a href="#1-6-1-redo日志的持久化文件" class="headerlink" title="1.6.1 redo日志的持久化文件"></a>1.6.1 redo日志的持久化文件</h3><p>我们知道数据页持久化后，是保存在ibdata1（没有开启<code>innodb_file_per_table</code>时的共享表空间文件）或者.ibd（开启 <code>innodb_file_per_table</code>时）文件中的。</p>
<p>InnoDB定义了一个组（log group）的概念，一个组内由多个<strong>大小完全相同</strong>的redo log file组成。组内redo log file的数量由变量<code>innodb_log_files_group</code>决定，默认值为2，即两个redo log file。</p>
<blockquote>
<p>log group为redo日志组，其中有多个redo log file。虽然源码中已支持log group 的镜像功能，但是在ha_innobase.cc 文件中禁止了该功能。因此InnoDB存储引擎实际只有一个log group。</p>
</blockquote>
<p>这个组是一个逻辑的概念，并没有真正的文件来表示这是一个组，但是可以通过变量<code>innodb_log_group_home_dir</code>来定义组的目录，redo log file都放在这个目录下，默认是在datadir下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global variables like &quot;innodb_log%&quot;;</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">| Variable_name               | Value    |</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">| innodb_log_buffer_size      | 8388608  |</span><br><span class="line">| innodb_log_compressed_pages | ON       |</span><br><span class="line">| innodb_log_file_size        | 50331648 |</span><br><span class="line">| innodb_log_files_in_group   | 2        |</span><br><span class="line">| innodb_log_group_home_dir   | .&#x2F;       |</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">[root@xuexi data]# ll &#x2F;mydata&#x2F;data&#x2F;ib*</span><br><span class="line">-rw-rw---- 1 mysql mysql 79691776 Mar 30 23:12 &#x2F;mydata&#x2F;data&#x2F;ibdata1</span><br><span class="line">-rw-rw---- 1 mysql mysql 50331648 Mar 30 23:12 &#x2F;mydata&#x2F;data&#x2F;ib_logfile0</span><br><span class="line">-rw-rw---- 1 mysql mysql 50331648 Mar 30 23:12 &#x2F;mydata&#x2F;data&#x2F;ib_logfile1</span><br></pre></td></tr></table></figure>
<p>可以看到在默认的数据目录下，有两个ib_logfile开头的文件，它们就是log group中的redo log file，而且它们的大小完全一致且等于变量<code>innodb_log_file_size</code>定义的值。</p>
<p>在innodb将log buffer中的redo log block刷到这些log file中时，会以追加写入的方式循环轮训写入。即先在ib_logfile0的尾部追加写，直到满了之后向ib_logfile1追加写。<strong>当ib_logfile1满了，则又重新向ib_logfile0进行覆盖写</strong>。</p>
<p>由于是将log buffer中的日志刷到log file，所以在log file中记录日志的方式也是log block的方式。在每个组的第一个redo log file中，前2KB负责记录4个特定的部分，从2KB之后才开始记录log block。除了第一个redo log file中会记录这2KB的部分外，<strong>log group中的其他log file不会记录这2KB，但是却会腾出这2KB的空间</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0e974f07531a01ac0003212eab079cea38b.png" alt=""></p>
<blockquote>
<p>redo log file的大小对innodb的性能影响非常大，设置的太大，恢复的时候就会时间较长，设置的太小，就会导致在写redo log的时候循环切换redo log file。</p>
</blockquote>
<h3 id="1-6-1-redo日志的持久化策略"><a href="#1-6-1-redo日志的持久化策略" class="headerlink" title="1.6.1 redo日志的持久化策略"></a>1.6.1 redo日志的持久化策略</h3><p>那么，log buffer里面的日志，什么时候刷到log file中呢？</p>
<ol>
<li>事务提交时</li>
<li>当log buffer中有一半的内存空间已经被使用时</li>
<li>log checkpoint 时</li>
</ol>
<p>其中<code>1. 事务提交时</code>是InnoDB事务的持久性的保证，但就像我们在《【InnoDB详解三】锁和事务》一文中介绍的那样，为了性能，InnoDB允许牺牲一定的持久性，允许执行不同的redo日志持久化策略。</p>
<p>MySQL支持用户自定义在事务提交时是否将log buffer中的日志刷log file中。这种控制通过变量 <code>innodb_flush_log_at_trx_commit</code> 的值来决定。该变量有3种值：0、1、2，默认为1。</p>
<ul>
<li>当设置为0的时候，<strong>事务提交时</strong>不会将log buffer中日志写入到os buffer。那什么时候写入呢？由master thread通过每秒一次的频率来异步写入。该值为0时性能较好，但是会丢失掉master thread还没刷新进磁盘部分的数据。<blockquote>
<p>这里我想简单介绍一下master thread，这是InnoDB一个在后台运行的主线程，从名字就能看出这个线程相当的重要。它做的主要工作包括但不限于：刷新日志缓冲，合并插入缓冲，刷新脏页等。master thread大致分为每秒运行一次的操作和每10秒运行一次的操作。master thread中刷新数据，属于checkpoint的一种。</p>
</blockquote>
</li>
<li>当设置为1的时候，当然是最安全的，即每次commit都会强迫flush到log file，但是数据库性能会受一定影响。</li>
<li>当设置为2的时候，每次提交都仅写入到操作系统的内核空间os buffer，然后由操作系统异步每秒调用一次fsync()将os buffer中的日志写入到log file。</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-29558eb65234c525c09f9651c104f0f9bb1.png" alt=""></p>
<h3 id="1-6-3-redo日志持久化策略的性能"><a href="#1-6-3-redo日志持久化策略的性能" class="headerlink" title="1.6.3 redo日志持久化策略的性能"></a>1.6.3 redo日志持久化策略的性能</h3><p>选择刷日志的策略会严重影响数据修改时的性能，特别是刷到磁盘的过程。下例就测试了<code>innodb_flush_log_at_trx_commit</code>分别为0、1、2时的差距。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#创建测试表</span><br><span class="line">drop table if exists test_flush_log;</span><br><span class="line">create table test_flush_log(id int,name char(50))engine&#x3D;innodb;</span><br><span class="line"></span><br><span class="line">#创建插入指定行数的记录到测试表中的存储过程</span><br><span class="line">drop procedure if exists proc;</span><br><span class="line">delimiter $$</span><br><span class="line">create procedure proc(i int)</span><br><span class="line">begin</span><br><span class="line">    declare s int default 1;</span><br><span class="line">    declare c char(50) default repeat(&#39;a&#39;,50);</span><br><span class="line">    while s&lt;&#x3D;i do</span><br><span class="line">        start transaction;</span><br><span class="line">        insert into test_flush_log values(null,c);</span><br><span class="line">        commit;</span><br><span class="line">        set s&#x3D;s+1;</span><br><span class="line">    end while;</span><br><span class="line">end$$</span><br><span class="line">delimiter ;</span><br></pre></td></tr></table></figure>

<p>当前环境下， <code>innodb_flush_log_at_trx_commit</code> 的值为1，即每次提交都刷日志到磁盘。测试此时插入10W条记录的时间。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; call proc(100000);</span><br><span class="line">Query OK, 0 rows affected (15.48 sec)</span><br></pre></td></tr></table></figure>

<p>结果是15.48秒。</p>
<p>再测试值为2的时候，即每次提交都刷新到os buffer，但每秒才刷入磁盘中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set @@global.innodb_flush_log_at_trx_commit&#x3D;2;</span><br><span class="line">mysql&gt; truncate test_flush_log;</span><br><span class="line"></span><br><span class="line">mysql&gt; call proc(100000);</span><br><span class="line">Query OK, 0 rows affected (3.41 sec)</span><br></pre></td></tr></table></figure>

<p>结果插入时间大减，只需3.41秒。</p>
<p>最后测试值为0的时候，即每秒才刷到os buffer和磁盘。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set @@global.innodb_flush_log_at_trx_commit&#x3D;0;</span><br><span class="line">mysql&gt; truncate test_flush_log;</span><br><span class="line"></span><br><span class="line">mysql&gt; call proc(100000);</span><br><span class="line">Query OK, 0 rows affected (2.10 sec)</span><br></pre></td></tr></table></figure>

<p>结果只有2.10秒。</p>
<p>最后可以发现，其实值为2和0的时候，它们的差距并不太大，但2却比0要安全的多。它们都是每秒从os buffer刷到磁盘，它们之间的时间差体现在log buffer刷到os buffer上。因为将log buffer中的日志刷新到os buffer只是内存数据的转移，并没有太大的开销，所以每次提交和每秒刷入差距并不大。可以测试插入更多的数据来比较，以下是插入100W行数据的情况。从结果可见，值为2和0的时候差距并不大，但值为1的性能却差太多。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5a84cadbc4f69368f44b55bbb5b8c4cb33b.png" alt=""></p>
<p>尽管设置为0和2可以大幅度提升插入性能，但是在故障的时候可能会丢失1秒钟数据，这1秒钟很可能有大量的数据，从上面的测试结果看，100W条记录也只消耗了20多秒，1秒钟大约有4W-5W条数据，尽管上述插入的数据简单，但却说明了数据丢失的大量性。<strong>更好的插入数据的做法是将值设置为1，然后修改存储过程，将每次循环都提交修改为只提交一次，这样既能保证数据的一致性，也能提升性能</strong>，修改如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">drop procedure if exists proc;</span><br><span class="line">delimiter $$</span><br><span class="line">create procedure proc(i int)</span><br><span class="line">begin</span><br><span class="line">    declare s int default 1;</span><br><span class="line">    declare c char(50) default repeat(&#39;a&#39;,50);</span><br><span class="line">    start transaction;</span><br><span class="line">    while s&lt;&#x3D;i DO</span><br><span class="line">        insert into test_flush_log values(null,c);</span><br><span class="line">        set s&#x3D;s+1;</span><br><span class="line">    end while;</span><br><span class="line">    commit;</span><br><span class="line">end$$</span><br><span class="line">delimiter ;</span><br></pre></td></tr></table></figure>

<p>测试值为1时的情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set @@global.innodb_flush_log_at_trx_commit&#x3D;1;</span><br><span class="line">mysql&gt; truncate test_flush_log;</span><br><span class="line"></span><br><span class="line">mysql&gt; call proc(1000000);</span><br><span class="line">Query OK, 0 rows affected (11.26 sec)</span><br></pre></td></tr></table></figure>


<h2 id="1-7-利用redo日志做系统恢复"><a href="#1-7-利用redo日志做系统恢复" class="headerlink" title="1.7 利用redo日志做系统恢复"></a>1.7 利用redo日志做系统恢复</h2><h3 id="1-7-1-LSN和Checkpoint"><a href="#1-7-1-LSN和Checkpoint" class="headerlink" title="1.7.1 LSN和Checkpoint"></a>1.7.1 LSN和Checkpoint</h3><p>说到恢复，就不得不提LSN，我们在《【InnoDB详解一】体系架构和关键特性》一文中已经有过介绍，为方便计，我们粘贴过来。</p>
<p>对于InnoDB存储引擎而言，是通过LSN（Log Sequence Number）来标记版本的。LSN是一个一直递增的8字节整型数字，<strong>表示事务写入到redo日志的字节总量（注意LSN的含义是日志的字节总量）</strong>。每个页都有LSN字段，重做日志中也有LSN，Checkpoint也有LSN。</p>
<p>在每个数据页头部的LSN字段，记录当前页最后一次数据修改所对应的重做日志的LSN值，用于在recovery时对比重做日志LSN值，以决定是否对该页进行恢复数据。前面说的checkpoint也是有LSN号记录的，checkpoint的LSN表示已刷新到磁盘的最新的数据所对应的重做日志的LSN，LSN号串联起一个事务开始到恢复的过程。</p>
<blockquote>
<p>比如redo日志的文件是600M，LSN的值已经为1G了，也就是LSN=1000000000。因为redo日志是循环使用的，所以我们可以知道LSN=1G=600M+400M，所以redo日志已经重复使用过一整遍后，目前最新的可写入点，在redo日志偏移量400M的位置。</p>
</blockquote>
<blockquote>
<p>我们执行了一个update语句，产生了一个事务t，这次数据的修改，假设产生了512个字节的日志量，那么LSN就会增加到1000000512，而事务t的修改使得A、B、C三个数据页成为了脏页，那么A、B、C三个数据页的LSN值就会更新为1000000512。如果这时，触发了checkpoint，刚刚好将事务t为止的修改刷新到磁盘，那么此时checkpoint LSN也是1000000512。</p>
</blockquote>
<p>除了LSN之外，我们还要知道Checkpoint，同样在《【InnoDB详解一】体系架构和关键特性》一文中已经有过介绍。简单来说就是Checkpoint会定时将buffer里面的redo日志持久化到磁盘。</p>
<h3 id="1-7-2-恢复过程"><a href="#1-7-2-恢复过程" class="headerlink" title="1.7.2 恢复过程"></a>1.7.2 恢复过程</h3><p>InnoDB存储引擎在启动时<strong>不管上次数据库运行时是否正常关闭，都会尝试进行恢复</strong>。因为重做日志记录的是物理日志，因此恢复的速度比逻辑日志，如二进制日毒要快很多。与此同时，InnoDB存储引擎自身也对恢复进行了一定程度的优化，如顺序读取及并行应用重做日志，这样可以进一步地提高数据库恢复的速度。</p>
<p>由于checkpoint会记录已经刷新到磁盘页上的LSN，因此在恢复过程中仅需恢复checkpoint开始的日志部分。假设当数据库在checkpoint的LSN为10000时发生宕机，恢复操作仅恢复LSN10000～13000范围内的日志。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f46c3e46759e30a6596ccab8491f2c7c8af.png" alt=""></p>
<p>恢复的过程中，系统会根据redo日志的类型，调用相关的恢复函数进行恢复，而redo日志中的那些数据就可以被当成是调用这个函数所需的参数。从而使数据库恢复原样。</p>
<p>注意，调用相关的恢复函数的结果是幂等的，即便是insert一条行记录的redo日志，即便多次被恢复函数调用，其结果也是幂等的。</p>
<h1 id="2-undo-log"><a href="#2-undo-log" class="headerlink" title="2 undo log"></a>2 undo log</h1><p>undo log有两个作用：</p>
<ol>
<li>提供回滚<ul>
<li>InnoDB在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。</li>
</ul>
</li>
<li>多个行版本控制(MVCC)<ul>
<li>有时候应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而根据事务的版本和行记录的版本匹配，让用户实现非锁定一致性读取。</li>
</ul>
</li>
</ol>
<p>undo log和redo log记录物理日志不一样，<strong>它是逻辑日志</strong>。因此只是将数据库<strong>逻辑地</strong>恢复到原来的样子。所有修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能大不相同。</p>
<p>这是因为在多用户并发系统中，可能会有数十、数百甚至数千个并发事务。数据库的主要任务就是协调对数据记录的并发访问。比如，一个事务在修改当前一个页中某几条记录，同时还有别的事务在对同一个页中另几条记录进行修改。因此，不能将一个页回滚到事务开始的样子，<strong>因为这样会影响其他事务正在进行的工作</strong>。</p>
<p>例如，用户执行了一个INSERT 10W条记录的事务，这个事务会导致分配一个新的段，即表空间会增大。在用户执行ROLLBACK时，会将插入的事务进行回滚，但是表空间的大小<strong>并不会因此而收缩</strong>。因此，当InnoDB存储引擎回滚时，它实际上做的是与先前相反的工作。</p>
<p><strong>可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录</strong>。</p>
<p><strong>undo log是采用段(segment)的方式来记录的</strong>，每个undo操作在记录的时候占用一个undo log segment。</p>
<p><strong>另外，undo log也会产生redo log，因为undo log也要实现持久性保护</strong>。</p>
<h2 id="2-1-purge线程"><a href="#2-1-purge线程" class="headerlink" title="2.1 purge线程"></a>2.1 purge线程</h2><p>在详述undo log之前，我们需要了解一个前置知识点：purge线程</p>
<p>delete和update操作可能并不直接删除原有的数据。例如表t（a,b）如下的SQL语句∶</p>
<p><code>DELETE FROM t WHERE a=1;</code></p>
<p>表t上列a有聚集索引，列b上有辅助索引。</p>
<p>对于上述的delete操作，在MVCC的章节介绍已经知道仅是将主键列等于1的记录delete flag设置为1，记录并没有被删除，即记录还是存在于B+树中。其次，对辅助索引上a等于1，b等于1的记录同样没有做任何处理，甚至没有产生undo log。而真正删除这行记录的操作其实被”延时”了，最终在 purge操作中完成。</p>
<p>purge用于最终完成delete和 update操作。这样设计是因为InnoDB存储引擎支持MVCC，所以记录不能在事务提交时立即进行处理。这时其他事物可能正在引用这行，故InnoDB存储引擎需要保存记录之前的版本。而是否可以删除该条记录通过purge来进行判断。若该行记录已不被任何其他事务引用，那么就可以进行真正的delete操作。</p>
<p>可见，purge操作是清理之前的delete和update操作，将上述操作”最终”完成。而实际执行的操作为delete操作，清理之前行记录的版本。</p>
<p>为了节省存储空间，InnoDB存储引擎的undo log设计是这样的：</p>
<ol>
<li>一个页上允许多个事务的undo log存在。虽然这不代表事务在全局过程中提交的顺序，但是后面的事务产生的undo log总在最后。</li>
<li>此外，ImnoDB存储引擎还有一个history列表，它根据事务提交的顺序，将undo log进行链接。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-88c56db52cf6ad7facfd77561eae1e1e56b.png" alt=""></p>
<p>在图7-17的例子中，history list表示<strong>按照事务提交的顺序</strong>将undo log进行组织。在InnoDB存储引擎的设计中，先提交的事务总在尾端。</p>
<p>undo page存放了undo log，由于可以重用，因此一个undo page中可能存放了<strong>多个不同事务</strong>的undo log。tx5的灰色阴影表示该 undo log还被其他事务引用。</p>
<p>执行 purge的过程中，InnoDB存储引擎首先从history list中找到第一个需要被清理的记录，这里为trx1，清理之后InnoDB存储引擎会在trx1的undo log所在的页中继续寻找是否存在可以被清理的记录，这里会找到事务trx3，接着找到trx5，但是发现trx5被其他事务所引用而不能清理，故去再次去history list中查找，发现这时最尾端的记录为trx2，接着找到trx2所在的页，然后依次再把事务trx6、trx4的记录进行清理。</p>
<p>InnoDB存储引擎这种先从history list中找undo log，然后再从undo page中找undo log的设计模式是<strong>为了避免大量的随机读取操作，从而提高 purge的效率</strong>。</p>
<h2 id="2-2-undo-log的存储方式"><a href="#2-2-undo-log的存储方式" class="headerlink" title="2.2 undo log的存储方式"></a>2.2 undo log的存储方式</h2><p>Innodb存储引擎对undo的管理采用段（segment）的方式。rollback segment称为回滚段，每个回滚段中有1024个undo log segment。</p>
<p>在以前老版本，只支持1个rollback segment，这样就只能记录1024个undo log segment。后来MySQL5.5可以支持128个rollback segment，即支持<code>128*1024</code>个undo操作，还可以通过变量 <code>innodb_undo_logs</code> (5.6版本以前该变量是 innodb_rollback_segments )自定义多少个rollback segment，默认值为128。</p>
<p>undo log默认存放在共享表空间中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xuexi data]# ll &#x2F;mydata&#x2F;data&#x2F;ibda*</span><br><span class="line">-rw-rw---- 1 mysql mysql 79691776 Mar 31 01:42 &#x2F;mydata&#x2F;data&#x2F;ibdata1</span><br></pre></td></tr></table></figure>

<p>同样的，如果开启了 innodb_file_per_table ，将放在每个表的.ibd文件中。</p>
<p>在MySQL5.6中，undo的存放位置还可以通过变量 <code>innodb_undo_directory</code> 来自定义存放目录，默认值为”.”表示datadir。</p>
<p>默认rollback segment全部写在一个文件中，但可以通过设置变量 <code>innodb_undo_tablespaces</code> 平均分配到多少个文件中。该变量默认值为0，即全部写入一个表空间文件。该变量为静态变量，只能在数据库示例停止状态下修改，如写入配置文件或启动时带上对应参数。但是innodb存储引擎在启动过程中提示，不建议修改为非0的值，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: Expected to open 3 undo tablespaces but was able</span><br><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: to find only 0 undo tablespaces.</span><br><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: Set the innodb_undo_tablespaces parameter to the</span><br><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: correct value and retry. Suggested value is 0</span><br></pre></td></tr></table></figure>
<h2 id="2-3-undo-log的数据结构"><a href="#2-3-undo-log的数据结构" class="headerlink" title="2.3 undo log的数据结构"></a>2.3 undo log的数据结构</h2><p>InnoDB采用回滚段的方式来维护undo log是为了保证事务并发操作时，在写各自的undo log时不产生冲突。回滚段实际上是一种 Undo 文件组织方式，每个回滚段又有多个undo log slot。具体的文件组织方式如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a25c818ad84c7493b4eb9f92c1c8ea108b8.png" alt=""></p>
<p>当事务开启时，会给它指定使用哪个rollback segment，然后在真正执行操作时，分配具体的slot，通常会有两种slot：</p>
<ul>
<li>insert_undo：只用于事务内的insert语句<ul>
<li>insert undo log是指在insert操作中产生的undo log。因为insert操作的记录，只对事务本身可见，对其他事务不可见（这是事务隔离性的要求），故该undo log不会被其他事务引用，不用进行purge操作，可以在事务提交后直接删除（事务提交后就没有回滚需求了）。</li>
</ul>
</li>
<li>update_undo: 只用于事务内的update语句<ul>
<li>update undo log记录的是对delete和 update操作产生的undo log。该undo log可能需要提供MVCC机制，因此不能在事务提交时就进行删除。提交时放入undo log链表，等待 purge线程进行最后的删除。</li>
</ul>
</li>
</ul>
<p>通常如果事务内只包含一种操作类型，则只使用一个slot。但也有例外，例如insert操作，如果insert的记录在page上已经存在了，但是是无效的，那么就可以直接通过更新这条无效记录的方式来实现插入，这时候使用的是update_undo。</p>
<h3 id="2-3-1-insert-undo的数据结构"><a href="#2-3-1-insert-undo的数据结构" class="headerlink" title="2.3.1 insert_undo的数据结构"></a>2.3.1 insert_undo的数据结构</h3><p>insert undo log的数据结构如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1886e6ec7203188f0fa788d3d6d5c1b6c40.png" alt=""></p>
<p>其中<code>*</code>表示对存储的字段进行了压缩。</p>
<ol>
<li>insete undo log开始的前两个字节next 记录的是下一个undo log的位置，通过该next的字节可以知道一个undo log所占的空间字节数。</li>
<li>类似地，尾部的两个字节记录的是undo log的开始位置。</li>
<li>type_cmpl占用一个字节，记录的是undo的类型，对于insert undo log，该值总是为11。</li>
<li>undo_no记录事务的ID，table_id记录undo log所对应的表对象。这两个值都是在压缩后保存的。</li>
<li>接着的部分记录了所有主键的列和值。在进行 rollback操作时，根据这些值可以定位到具体的记录，然后进行删除即可。</li>
</ol>
<h3 id="2-3-2-update-undo的数据结构"><a href="#2-3-2-update-undo的数据结构" class="headerlink" title="2.3.2 update_undo的数据结构"></a>2.3.2 update_undo的数据结构</h3><p>update undo log的结构如图所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1add9223f47f7e189d289b96332cf7f655e.png" alt=""></p>
<p>update undo log相对于之前介绍的insert undo log，记录的内容更多，所需点用的空间也更大。</p>
<ol>
<li>next、start、undo_no、table_id与之前介绍的insert undo log部分相同。</li>
<li>这里的 type_cmpl，由于update undo log本身还有分类，故其可能的值如下∶<ul>
<li>12 TRXUNDO_UPD_EXIST_REC更新 non-delete-mark的记录</li>
<li>13 TRX_UNDO_UPD_DEL_REC将delete的记录标记为not delete </li>
<li>14 TRX_UNDO_DEL_MARK_REC将记录标记为delete</li>
</ul>
</li>
<li>接着的部分记录 update_vector信息，update_vector表示update操作导致发生改变的列。每个修改的列信息都要记录的undo log中。</li>
</ol>
<p>对于不同的undo log类型，可能还需要记录对索引列所做的修改。</p>
<h2 id="2-4-相关参数"><a href="#2-4-相关参数" class="headerlink" title="2.4 相关参数"></a>2.4 相关参数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global variables like &#39;%undo%&#39;;</span><br><span class="line">+--------------------------+------------+</span><br><span class="line">| Variable_name            | Value      |</span><br><span class="line">+--------------------------+------------+</span><br><span class="line">| innodb_max_undo_log_size | 1073741824 |</span><br><span class="line">| innodb_undo_directory    | .&#x2F;         |</span><br><span class="line">| innodb_undo_log_truncate | OFF        |</span><br><span class="line">| innodb_undo_logs         | 128        |</span><br><span class="line">| innodb_undo_tablespaces  | 3          |</span><br><span class="line">+--------------------------+------------+</span><br><span class="line"> </span><br><span class="line">mysql&gt; show global variables like &#39;%truncate%&#39;;</span><br><span class="line">+--------------------------------------+-------+</span><br><span class="line">| Variable_name                        | Value |</span><br><span class="line">+--------------------------------------+-------+</span><br><span class="line">| innodb_purge_rseg_truncate_frequency | 128   |</span><br><span class="line">| innodb_undo_log_truncate             | OFF   |</span><br><span class="line">+--------------------------------------+-------+</span><br></pre></td></tr></table></figure>
<ul>
<li>innodb_undo_directory<ul>
<li>变量 <code>innodb_undo_directory</code> 来自定义存放目录，默认值为”.”表示datadir。</li>
</ul>
</li>
<li>innodb_max_undo_log_size<ul>
<li>控制最大undo tablespace文件的大小，当启动了innodb_undo_log_truncate 时，undo tablespace 超过innodb_max_undo_log_size 阀值时才会去尝试truncate。该值默认大小为1G，truncate后的大小默认为10M。</li>
</ul>
</li>
<li>innodb_undo_tablespaces<ul>
<li>设置undo独立表空间个数，范围为0-128， 默认为0，0表示表示不开启独立undo表空间，且 undo日志存储在ibdata文件中。该参数只能在最开始初始化MySQL实例的时候指定，如果实例已创建，这个参数是不能变动的，如果在数据库配置文件 .cnf 中指定innodb_undo_tablespaces 的个数大于实例创建时的指定个数，则会启动失败，提示该参数设置有误。</li>
<li>设置该参数后，会在路径inodb_undo_directory看到undo为前缀的文件，该文件就代表rollback segment文件。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-dfb2af1207e6212f287c7518853aae22234.png" alt=""></li>
</ul>
</li>
<li><strong>innodb_undo_log_truncate</strong><ul>
<li>InnoDB的purge线程，根据innodb_undo_log_truncate设置开启或关闭、innodb_max_undo_log_size的参数值，以及truncate的频率来进行空间回收和undo file的重新初始化。</li>
<li>该参数生效的前提是，已设置独立表空间且独立表空间个数大于等于2个。</li>
<li>purge线程在truncate undo log file的过程中，需要检查该文件上是否还有活动事务，如果没有，需要把该undo log file标记为不可分配，这个时候，undo log 都会记录到其他文件上，所以至少需要2个独立表空间文件，才能进行truncate 操作。</li>
<li>标注不可分配后，会创建一个独立的文件undo__trunc.log，记录现在正在truncate 某个undo log文件，然后开始初始化undo log file到10M，操作结束后，删除表示truncate动作的 undo__trunc.log 文件，这个文件保证了即使在truncate过程中发生了故障重启数据库服务，重启后，服务发现这个文件，也会继续完成truncate操作，删除文件结束后，标识该undo log file可分配。</li>
</ul>
</li>
<li>innodb_purge_rseg_truncate_frequency<ul>
<li>用于控制purge回滚段的频度，默认为128。假设设置为n，则说明，当Innodb Purge操作的协调线程 purge事务128次时，就会触发一次History purge，检查当前的undo log 表空间状态是否会触发truncate。</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/" itemprop="url">【InnoDB详解三】锁和事务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-21T21:26:54+08:00">
                2020-09-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/21/【InnoDB详解三】锁和事务/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  9.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  34
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-InnoDB锁机制"><a href="#1-InnoDB锁机制" class="headerlink" title="1. InnoDB锁机制"></a>1. InnoDB锁机制</h1><p>锁是数据库系统区别于文件系统的一个关键特性。锁机制用于管理对共享资源的并发访问。InnoDB存储引擎会在行级别上对表数据上锁，这固然不错。不过InnoDB存储引擎也会在数据库内部其他多个地方使用锁，从而允许对多种不同资源提供并发访问。例如，操作缓冲池中的LRU列表，删除、添加、移动LRU列表中的元素，为了保证一致性，必须有锁的介入。数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。</p>
<p>InnoDB存储引擎锁的实现和Oracle数据库非常类似，提供一致性的非锁定读、行级锁支持。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。</p>
<h2 id="1-1-InnoDB中锁的类型"><a href="#1-1-InnoDB中锁的类型" class="headerlink" title="1.1 InnoDB中锁的类型"></a>1.1 InnoDB中锁的类型</h2><h3 id="1-1-1-共享锁和排他锁"><a href="#1-1-1-共享锁和排他锁" class="headerlink" title="1.1.1 共享锁和排他锁"></a>1.1.1 共享锁和排他锁</h3><p>InoDB存储引擎实现了如下两种标准的锁∶</p>
<ol>
<li>共享锁（S Lock），S是Share的缩写，也叫作<strong>读锁</strong>，允许事务读取共享资源的数据。</li>
<li>排他锁（X Lock），X是Exclusive的缩写，也叫作<strong>写锁</strong>，允许事务删除或更新资源的数据。</li>
</ol>
<p>InnoDB存储引擎支持多粒度（granular）锁定，S Lock和X Lock锁定的对象可以是行，也可以是页，也可以是表。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a9dd75ae92e3c9b415c077c8106a7bc91be.png" alt=""></p>
<p>如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r 的共享锁，因为读取并没有改变行r的数据，我们称这种情况为锁兼容（Lock Compatible）。</p>
<p>但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁才行——这种情况称为锁不兼容。</p>
<p>下图显示了共享锁和排他锁的兼容性：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-98ab6eecdfd147396fad62b458bc3021d40.png" alt=""></p>
<blockquote>
<p>总结为一句话，只有二者都是共享锁的时候才会兼容。</p>
</blockquote>
<h3 id="1-1-2-意向锁"><a href="#1-1-2-意向锁" class="headerlink" title="1.1.2 意向锁"></a>1.1.2 意向锁</h3><p>我们之前说过，S/X锁针对的对象可以是行，也可以是表。这种多粒度（granular）锁定是InnoDB锁机制的特点，但多粒度锁定会不可避免的带来一种问题：</p>
<ul>
<li>假设事务A锁住了表中的一行，让这一行只能读，不能写。</li>
<li>之后，事务B申请整个表的写锁。</li>
<li>如果事务B申请成功，那么理论上它就能修改表中的任意一行，这与A持有的行锁是冲突的。</li>
</ul>
<p>数据库需要避免这种冲突，就是说要让B的申请被阻塞，直到A释放了行锁。那么数据库要怎么判断这个冲突呢？</p>
<ol>
<li>step1：判断表是否已被其他事务用表锁锁表</li>
<li>step2：判断表中的每一行是否已被行锁锁住。</li>
</ol>
<p>注意step2，这样的判断方法需要遍历整个表，效率实在不高，于是就有了意向锁。</p>
<p>在意向锁存在的情况下，<strong>事务A必须先申请表的意向共享锁，成功后才能申请表中行的行锁</strong>。于是上面的判断可以改成：</p>
<ol>
<li>step1：判断表是否已被其他事务用表锁锁表</li>
<li>step2：发现表上有意向锁：<ol>
<li>如果是意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。</li>
<li>如果是意向排他锁，说明表中有些行被排他行锁锁住了，因此，事务B申请表的写锁会被阻塞。</li>
</ol>
</li>
</ol>
<p>是的没错，InnoDB的意向锁也支持如下两种，不过意向锁不是多粒度的，<strong>它只支持表级锁定</strong>：</p>
<ol>
<li>意向共享锁（IS Lock），表示事务已经获得一张表中某几行的共享锁。</li>
<li>意向排他锁（IX Lock），表示事务已经获得一张表中某几行的排他锁。</li>
</ol>
<blockquote>
<p>IS和IX的I是intention的缩写，意向的意思可以理解为：一个事务在申请行级锁前，先宣称对行所在表的读/写的意向，宣称之后，在不兼容的情况，其他锁就会冲突了。</p>
</blockquote>
<p>因为意向锁是表级锁，所以也不存在和行级锁/页级锁的兼容性问题，但意向锁之间，以及意向锁和表级共享/排他锁之间是存在不兼容的情况的，具体兼容性如下表（注意下标的S和X是表级锁）：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7b141535385456447ca04fd14e64f38744b.png" alt=""></p>
<blockquote>
<p>一句话：意向锁内部都兼容，除此之外，意向共享锁只和表级共享锁兼容。</p>
</blockquote>
<h3 id="1-1-3-自增锁"><a href="#1-1-3-自增锁" class="headerlink" title="1.1.3 自增锁"></a>1.1.3 自增锁</h3><p>自增长在数据库中是非常常见的一种属性，也是很多DBA或开发人员首选的主键方式。在InnoDB存储引擎的内存结构中，对每个含有自增长值的表都有一个自增长计数器（auto-increment counter）。当对含有自增长的计数器的表进行插入操作时，这个计数器会被初始化，执行如下的语句来得到计数器的值∶</p>
<p><code>SELECT MAX(auto_inc_col) FROM t FOR UPDATE;</code></p>
<p>插入操作会依据这个自增长的计数器值加1赋予自增长列。这个实现方式称做AUTO-INC Locking。<strong>这种锁其实是采用一种特殊的表锁机制，为了提高插人的性能，锁不是在一个事务完成后才释放，而是在完成对自增长值插人的SQL语句后立即释放</strong>。</p>
<h2 id="1-2-行锁的加锁方式"><a href="#1-2-行锁的加锁方式" class="headerlink" title="1.2 行锁的加锁方式"></a>1.2 行锁的加锁方式</h2><p>前面我们说过，InnoDB存储引擎支持多粒度（granular）锁定，S Lock和X Lock锁定的对象可以是行，也可以是页，也可以是表。</p>
<p>不过当锁定的对象是<strong>行记录</strong>的时候，InnoDB有三种加锁方式，或者说，有三种锁的算法：</p>
<ol>
<li>Record Lock：锁单条行记录；</li>
<li>Gap Lock：间隙锁，锁定一个范围，但不包含记录本身</li>
<li>Next-Key Lock：Gap Lock+RecordLock，记录锁和间隙锁的组合，锁定一个范围，并且锁定记录本身</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-a52d4cd7eca7873d81b9ba93bd670e0ba7d.png" alt=""></p>
<p><strong>这里需要重点注意间隙锁，它可以解决幻读</strong>，因为MySQL默认的事务隔离级别是<code>可重复读</code>，其底层就是使用Next-Key Lock，也就是说Next-Key Lock是目前InnoDB对行锁默认的加锁方式。下文我们再对各个事务隔离级别的底层实现做描述。</p>
<blockquote>
<p>InnoDB的行锁是通过给索引项加锁实现的（这个我们后面会说到），这就意味着只有通过索引条件检索数据时，InnoDB才使用行锁，否则使用表锁。也就是说，<strong>如果批量update，如果条件的字段没有索引，将会锁表，如果有索引，则只会出现行锁</strong>。</p>
</blockquote>
<h2 id="1-3-并发控制协议"><a href="#1-3-并发控制协议" class="headerlink" title="1.3 并发控制协议"></a>1.3 并发控制协议</h2><h3 id="1-3-1-MVCC和一致性非锁定读"><a href="#1-3-1-MVCC和一致性非锁定读" class="headerlink" title="1.3.1 MVCC和一致性非锁定读"></a>1.3.1 MVCC和一致性非锁定读</h3><p>MVCC全称Multi-Version Concurrent Control，即多版本并发控制，是一种乐观锁的实现。它最大的特点是：读可不加锁，读写不冲突。并发性能很高。</p>
<p>MVCC中默认的读是<strong>非锁定的一致性读</strong>，也称快照读。读取的是记录的可见版本，当读取的的记录正在被别的事务并发修改时，会读取记录的历史版本。读取过程中不对记录加锁。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-03b0ae53e0ab9979a20a7de00545fa3a388.png" alt=""></p>
<p>如上图，如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB存储引擎会去读取行的一个快照数据。之所以称其为非锁定读，因为不需要等待访问的行上X锁的释放。</p>
<p>那么快照数据如何产生呢？</p>
<p>在InnoDB的行记录的列数据中有两个隐藏的列：当前行<strong>创建时的版本号</strong>和<strong>删除时的版本号</strong>（可能为空，其实还有一列称为回滚指针，用于事务回滚，这里暂不讨论）。这里的版本号并不是实际的时间值，而是系统版本号。每开始新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询每行记录的版本号进行比较。</p>
<p>每个事务又有自己的版本号，这样事务内执行CRUD操作时，就通过版本号的比较来达到数据版本控制的目的。</p>
<p>MVCC的实现依赖于undo日志（undo日志具体可见本站博客《【InnoDB详解四】redo log和undo log》），该日志通过回滚指针把一个数据行（Record）的所有快照数据（也都是数据行）连接起来：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cd6044f25be571296c160c23277dc144dc8.png" alt=""></p>
<blockquote>
<p>后文会讲到，MVCC主要用于<strong>可重复读</strong>和<strong>读已提交</strong>这两种事务隔离级别的实现中。</p>
</blockquote>
<p>那么MVCC下InnoDB的增删查改是怎么运作的呢？</p>
<h4 id="1-3-1-1-MVCC下的insert"><a href="#1-3-1-1-MVCC下的insert" class="headerlink" title="1.3.1.1 MVCC下的insert"></a>1.3.1.1 MVCC下的insert</h4><p>插入时，记录的版本号即当前事务的版本号。我们执行一条数据语句：</p>
<p><code>insert into testmvcc values(1,&quot;test&quot;);</code></p>
<p>假设事务id为1，那么插入后的数据行如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-893019c4b35d3863e2820831cd3236e0d37.png" alt=""></p>
<h4 id="1-3-1-2-MVCC下的update"><a href="#1-3-1-2-MVCC下的update" class="headerlink" title="1.3.1.2 MVCC下的update"></a>1.3.1.2 MVCC下的update</h4><p>在更新操作的时候，采用的是先标记旧的那行记录为已删除，并且删除版本号是事务版本号，然后插入一行新的记录的方式。</p>
<p>比如，针对上面那行记录，把name字段更新：</p>
<p><code>update table set name= &#39;new_value&#39; where id=1;</code></p>
<p>假设事务id为2，那么更新后的结果如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-18f88aa062b8044a6961d63c28231563dc3.png" alt=""></p>
<h4 id="1-3-1-3-MVCC下的delete"><a href="#1-3-1-3-MVCC下的delete" class="headerlink" title="1.3.1.3 MVCC下的delete"></a>1.3.1.3 MVCC下的delete</h4><p>在删除操作的时候，就把事务版本号作为删除版本号。比如</p>
<p><code>delete from table where id=1;</code></p>
<p>假设事务id为3，那么删除后的结果如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-37153c8fa1ea12e85f2cfd6f4d1b46c6bec.png" alt=""></p>
<h4 id="1-3-1-4-MVCC下的select"><a href="#1-3-1-4-MVCC下的select" class="headerlink" title="1.3.1.4 MVCC下的select"></a>1.3.1.4 MVCC下的select</h4><p>综合上文，我们可以知道，在查询时要<strong>符合以下两个条件的记录</strong>才能被事务查询出来：</p>
<ol>
<li><p>删除版本号<strong>未指定</strong>或者<strong>大于当前事务版本号</strong>，即要确保查询事务开启时，要读取的行未被删除。(比如上述事务id为2的事务查询时，依然能读取到被id=3的事务所删除的数据行)</p>
</li>
<li><p>创建版本号<strong>小于</strong>或者<strong>等于</strong>当前事务版本号 ，即要确保查询事务开启时，要读取的行记录<strong>正在</strong>（等于的情况）或者<strong>已经</strong>（小于的情况）被创建。(比如上述事务id为2的事务查询时，只能读取到被id=1或者id=2的事务所创建的行)</p>
</li>
</ol>
<h3 id="1-3-2-LBCC和一致性锁定读"><a href="#1-3-2-LBCC和一致性锁定读" class="headerlink" title="1.3.2 LBCC和一致性锁定读"></a>1.3.2 LBCC和一致性锁定读</h3><p>在前文中我们说到，默认配置下，即事务的隔离级别为<code>可重复读</code>模式下，InnoDB存储引擎的SELECT操作使用一致性非锁定读。但是在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。而这要求数据库支持加锁语句，即使是对于SELECT的只读操作。</p>
<p>LBCC全称Lock-Based Concurrent Control，即基于锁的并发控制，是一种悲观锁的实现。LBCC中的读是<strong>一致性锁定读</strong>，也称当前读：读取的是记录的最新版本，并且会对记录加锁。</p>
<p>InnoDB存储引擎对于SELECT语句支持两种一致性的锁定读（locking read）操作∶</p>
<ol>
<li>SELECT…FOR UPDATE<ul>
<li>SELECT…FOR UPDATE 对读取的行记录加一个X锁，其他事务不能对已锁定的行加上任何锁。</li>
</ul>
</li>
<li>SELECT…LOCK IN SHARE MODE<ul>
<li>SELECT.·…LOCKIN SHARE MODE对读取的行记录加一个S锁，其他事务可以向被锁定的行加S锁，但是如果加X锁，则会被阻塞。</li>
</ul>
</li>
</ol>
<blockquote>
<p>对于一致性非锁定读，即使读取的行已被执行了SELECT…FOR UPDATE，也是可以进行读取的，这和之前讨论的情况一样。</p>
</blockquote>
<blockquote>
<p>此外，SELECT.…FOR UPDATE，SELECT.…·LOCK IN SHARE MODE必须在一个事务中，当事务提交了，锁也就释放了。因此在使用上述两句SELECT锁定语句时，务必加上BEGIN，STARTTRANSACTION或者SET AUTOCOMMIT=0。</p>
</blockquote>
<blockquote>
<p>LBCC被用在seraliable隔离级别中，seraliable级别会对每个select语句后面自动加上lock in share mode。</p>
</blockquote>
<h2 id="1-4-锁的数据结构"><a href="#1-4-锁的数据结构" class="headerlink" title="1.4 锁的数据结构"></a>1.4 锁的数据结构</h2><p>锁升级（Lock Escalation）是指将当前锁的粒度降低。举例来说，如果一个页中，有大量的行都被加了锁，那么维护这么多的锁对象，需要占用大量内存，那为了节约内存提高效率，数据库会将锁升级，从行锁升级为页锁。这样只需要维护一个页锁对象就可以替代可能是几千个行锁对象了。同理，页锁升级为表锁也是同样的道理。</p>
<p>如果在数据库的设计中认为锁是一种稀有资源，而且想避免锁的开销，那数据库中会频繁出现锁升级现象，虽然这种做法会降低并发性能。</p>
<p>这种升级保护了系统资源，防止系统使用太多的内存来维护锁，在一定程度上提高了效率。</p>
<p><strong>然而，InnoDB不需要锁升级机制，因为InnoDB对锁对象的维护十分特殊</strong>，InnoDB并非将行锁维护在每一个行记录中，而是使用了位图+哈希表，前者保证了占用少量内存，后者保证了查询效率极高。</p>
<h3 id="1-4-1-锁对象和位图"><a href="#1-4-1-锁对象和位图" class="headerlink" title="1.4.1 锁对象和位图"></a>1.4.1 锁对象和位图</h3><p>InnoDB定义了<strong>页锁结构</strong>和<strong>表锁结构</strong>两种数据结构，来分别描述<strong>行级锁和表级锁</strong></p>
<h4 id="1-4-1-1-页锁结构"><a href="#1-4-1-1-页锁结构" class="headerlink" title="1.4.1.1 页锁结构"></a>1.4.1.1 页锁结构</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;页锁结构</span><br><span class="line">typedef struct lock_rec_struct        lock_rec_t</span><br><span class="line">struct lock_rec_struct&#123;</span><br><span class="line">    ulint space;    &#x2F;*space id*&#x2F;</span><br><span class="line">    ulint page_no;  &#x2F;*page number*&#x2F;</span><br><span class="line">    unint n_bits;   &#x2F;*number of bits in the lock bitmap*&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>space+page_no可以唯一定位一个页，所以InnoDB中有多少个数据页，就最多有多少个页锁对象。</li>
<li>n_bits是一个位图。如果要查看锁对象某行记录是否上锁，只需要根据space／page_no找到对应的页，然后根据位图中对应位置是否是1来决定此行记录是否上锁。</li>
</ul>
<p>假设页中有250条行记录，那么位图n_bit的占用空间为=250bit+64bit(额外预留的)=314bit，那么实际位图需要40个字节（320bit）用于位图的管理，若页中heap_no为2，3，4的记录都已经上锁，则对应的数据结构lock_rec_t 在内存中的关系如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a64fdbec884bcbc7141720cf86b5edf2092.png" alt=""></p>
<p>我们可以看到，行级锁并非维护在数据页的行记录里面，而是另外寻了一处空间来存放，这种锁的实现机制可以最大程度地重用锁对象，节省系统资源，不存在锁升级的问题。</p>
<p>可想而知，如果每个行锁都生成一个锁对象，将会导致严重的性能损耗，比如接近于全表扫描的查询就会生成大量的锁对象，内存开销将会很大。位图的方式很好地避免了这个问题。</p>
<h4 id="1-4-1-2-表锁结构"><a href="#1-4-1-2-表锁结构" class="headerlink" title="1.4.1.2 表锁结构"></a>1.4.1.2 表锁结构</h4><p>表级锁的数据结构（用于表的意向锁和自增锁）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">typedef struct lock_table_struct lock_table_t;</span><br><span class="line">struct lock_table_struct &#123;</span><br><span class="line">    dict_table_t*          table;   &#x2F;*database table in dictionary cache*&#x2F;</span><br><span class="line">    UT_LIST_NODE_T(lock_t) locks;   &#x2F;*list of locks on the same table*&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#define UT_LIST_NODE_T(TYPE)</span><br><span class="line">struct &#123;</span><br><span class="line">       TYPE *   prev;       &#x2F;* pointer to the previous node,NULL if start of list *&#x2F;</span><br><span class="line">       TYPE *   next;       &#x2F;* pointer to next node, NULL if end of list *&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一目了然，结构内的table变量是一个表结构（dict_table_t）的指针，它表示被锁住的是哪个表，一个表锁结构对应一张表。</p>
<p>然后locks变量是lock_struct结构（<code>typedef struct lock_struct  lock_t;</code>）组成的链表节点，UT_LIST_NODE_T是一个典型的链表节点结构，有前驱和后驱。</p>
<p>lock_struct是锁信息的整合结构，下面我们会介绍，locks所在的这个链表，连接了所有加在当前table上的锁对象，<strong>这样就能通过locks变量，遍历到当前表级锁对象所锁定的表上一共有哪些类型的锁</strong>。</p>
<h4 id="1-4-1-3-整合的锁结构"><a href="#1-4-1-3-整合的锁结构" class="headerlink" title="1.4.1.3 整合的锁结构"></a>1.4.1.3 整合的锁结构</h4><p>上面我们知道InnoDB定义了页锁结构和表锁结构，但通过这二者，我们只能知道哪些行记录或者表被加了锁，<strong>却不知道这锁是由哪个事务加的，加的是什么类型的锁</strong>，于是，InnoDB定义了一个新的锁结构，它就是我们前面看到的struct lock_struct  lock_t：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">typedef struct lock_struct  lock_t;</span><br><span class="line">struct lock_struct&#123;</span><br><span class="line">    trx_t*                  trx;       &#x2F;*这个锁属于哪个事务*&#x2F;</span><br><span class="line">    UT_LIST_NODE_T(lock_t)  trx_locks;  &#x2F;*该事务拥有的锁通过一个链表连接起来*&#x2F;</span><br><span class="line">    ulint                   type_mode;  &#x2F;* lock type, mode, gap flag, and wait flag, ORed *&#x2F;</span><br><span class="line">    hash_node_t             hash;       &#x2F;* hash chain node for a record lock *&#x2F;</span><br><span class="line">    dict_index_t*           index;      &#x2F;* 在该锁类型是行锁是有效，指向一个索引，因为行锁本质是索引记录锁。 *&#x2F;</span><br><span class="line">    union &#123;</span><br><span class="line">        lock_table_t    tab_lock; &#x2F;* table lock *&#x2F;</span><br><span class="line">        lock_rec_t      rec_lock; &#x2F;* record lock *&#x2F;</span><br><span class="line">    &#125; un_member;  &#x2F;*如果是表锁则un_member为lock_table_t，如果是记录锁则un_member为lock_rec_t，通过type_mode来判断类型*&#x2F;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>lock_struct是<code>&lt;事务，页/表&gt;</code>维度的结构，不同事务的每个页（或每个表）都要定义一个lock_struct结构。但一个事务可能在不同页/表上有锁，trx_locks变量将一个事务所有的锁信息进行链接，这样就可以快速查询一个事务所有锁信息。</p>
<p>un_member变量是一个结构共同体，它可以是表锁对象lock_table_t，也可以是页锁对象lock_rec_t，这根据type_mode来区分，type_mode控制了该锁结构（lock_struct）是属于什么类型的锁，已经目前处于的状态。</p>
<p>type_mode变量是一个无符号的4字节32位整型，从低位排列，</p>
<ol>
<li>第1个字节为lock_mode，定义如下； <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* Basic lock modes *&#x2F;</span><br><span class="line">enum lock_mode &#123;</span><br><span class="line">	LOCK_IS &#x3D; 0,    &#x2F;* intention shared *&#x2F;</span><br><span class="line">	LOCK_IX,    &#x2F;* intention exclusive *&#x2F;</span><br><span class="line">	LOCK_S,     &#x2F;* shared *&#x2F;</span><br><span class="line">	LOCK_X,     &#x2F;* exclusive *&#x2F;</span><br><span class="line">	LOCK_AUTO_INC,  &#x2F;* locks the auto-inc counter of a table</span><br><span class="line">			in an exclusive mode *&#x2F;</span><br><span class="line">	LOCK_NONE,  &#x2F;* this is used elsewhere to note consistent read *&#x2F;</span><br><span class="line">	LOCK_NUM &#x3D; LOCK_NONE, &#x2F;* number of lock modes *&#x2F;</span><br><span class="line">	LOCK_NONE_UNSET &#x3D; 255</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
<li>第2个字节为lock_type，目前只用前两位，大小为16和32，分别表示LOCK_TABLE 和LOCK_REC，这一个字节控制了lock_struct是表级锁还是行级锁。 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define LOCK_TABLE      16</span><br><span class="line">#define LOCK_REC        32</span><br></pre></td></tr></table></figure></li>
<li>剩下的高位bit表示行锁的类型record_lock_type <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#define LOCK_WAIT   256        &#x2F;* 表示正在等待锁 *&#x2F;</span><br><span class="line">#define LOCK_ORDINARY 0     &#x2F;* 表示 Next-Key Lock ，锁住记录本身和记录之前的 Gap*&#x2F;</span><br><span class="line">#define LOCK_GAP    512        &#x2F;* 表示锁住记录之前 Gap（不锁记录本身） *&#x2F;</span><br><span class="line">#define LOCK_REC_NOT_GAP 1024    &#x2F;* 表示锁住记录本身，不锁记录前面的 gap *&#x2F;</span><br><span class="line">#define LOCK_INSERT_INTENTION 2048    &#x2F;* 插入意向锁 *&#x2F;</span><br><span class="line">#define LOCK_CONV_BY_OTHER 4096        &#x2F;* 表示锁是由其它事务创建的(比如隐式锁转换) *&#x2F;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="1-4-2-行级锁的查询"><a href="#1-4-2-行级锁的查询" class="headerlink" title="1.4.2 行级锁的查询"></a>1.4.2 行级锁的查询</h3><p>有些时候，我们需要查询某个具体行记录的锁信息。<strong>比如行记录id=3是否有锁</strong>？</p>
<p>InnoDB使用一个哈希表映射行数据和锁信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">struct lock_sys_struct&#123;</span><br><span class="line">    hash_table_t* rec_hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>每次新建一个锁对象，都要插入到lock_sys_struct-&gt;rec_hash中。lock_sys_struct中的key通过页的space和page_no计算得到，而value则是页锁结构lock_rec_struct。</p>
<p>因此若需查询某一行记录是否有锁，首先则先要根据索引，定位到该行记录具体在哪一页。然后根据页的space和page_no进行哈希查询，得到lock_rec_struct，再根据lock_rec_struct里面的位图n_bits，最终得到该行记录是否有锁。</p>
<blockquote>
<p>正是因为行锁的查询需要根据页的space和page_no，而页的定位又基于索引，所以才说InnoDB的行锁是通过给索引项加锁实现的，这就意味着只有通过索引条件检索数据时，InnoDB才使用行锁，否则使用表锁。也就是说，<strong>如果批量update，如果条件的字段没有索引，将会锁表，如果有索引，则只会出现行锁</strong>。</p>
</blockquote>
<p>可以看出，根据页来查找行锁的查询并不是高效设计，但这种方式的资源开销非常小。某一事务对一个页任意行加锁开销都是一样的（不管锁住多少行）。因此也不需要支持锁升级的功能。</p>
<h2 id="1-5-死锁"><a href="#1-5-死锁" class="headerlink" title="1.5 死锁"></a>1.5 死锁</h2><p>死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种相互等待的现象。若无外力作用，他们都将无法推进下去。</p>
<p>解决死锁常用的两个方案：</p>
<ol>
<li><p>超时机制</p>
<ul>
<li>即两个事务互相等待时，当一个等待时间超过设置的某一阀值时，其中一个事务回滚，另一个事务继续执行。MySQL4.0版本开始，提供innodb_lock_wait_time用于设置等待超时时间。</li>
</ul>
</li>
<li><p>等待图（wait-for graph）</p>
<ul>
<li>较之超时的解决方案，这是一种更为主动的死锁检测方式。InnoDB通过锁的信息链表和事务等待链表，判断是否存在等待回路。如有，则存在死锁。每次加锁操作需要等待时都判断是否产生死锁，若有则回滚事务。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-279d2538466f15ae9ef9796f6a07cdb3e81.png" alt=""></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-eff83ca3d0abfed2f6c40dd447116b8ed61.png" alt=""></li>
</ul>
</li>
</ol>
<h2 id="1-6-锁的监控方式"><a href="#1-6-锁的监控方式" class="headerlink" title="1.6 锁的监控方式"></a>1.6 锁的监控方式</h2><p><code>show engine innodb status</code>命令可以获取最近一次的死锁日志。<br>MySQL8之前，可以通过<code>INFORMATION_SCHEMA</code>下<code>INNODB_TRX</code>,<code>INNODB_LOCKS</code>,<code>INNODB_LOCK_WAITS</code>查看事务和锁信息。<br>INNODB_TRX在MySQL8依然保留。</p>
<h1 id="2-InnoDB事务机制"><a href="#2-InnoDB事务机制" class="headerlink" title="2. InnoDB事务机制"></a>2. InnoDB事务机制</h1><p>在关系型数据库中，事务的重要性不言而喻，只要对数据库稍有了解的人都知道事务具有ACID四个基本特性。回顾一下事务的ACID特性，分别是原子性、一致性、隔离性、持久性， 一致性是事务的最终追求的目标，隔离性、原子性、持久性是达成一致性目标的手段。</p>
<ul>
<li><p>A : atomicity 原子性。原子性是我们对事务最直观的理解：事务就是一系列的操作，要么全部都执行，要么全部都不执行。</p>
</li>
<li><p>C : consistency 一致性。数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。它分为数据库外部的一致性和内部的一致性：</p>
<ul>
<li>数据库外部的一致性，例如对银行转帐事务，不管事务成功还是失败，应该保证事务结束后ACCOUNTS表中Tom和Jack的存款总和不变。这个由外部应用的编码来保证，即某个应用在执行转帐的数据库操作时，必须在同一个事务内部调用对帐户A和帐户B的操作。</li>
<li>数据库内部的一致性，这是数据库层面去保证的，体现在我们利用事务将账户A和账户B的操作绑定时，要么一起成功，要么一起失败（原子性）。同时，如果在并发场景下，还要保证其他事务的操作不会影响当前事务（隔离性）。</li>
</ul>
</li>
<li><p>I : isolation 隔离性。在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。</p>
</li>
<li><p>D : durability 持久性。只要事务成功结束，它对数据库所做的更新就必须永久保存下来。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态。</p>
</li>
</ul>
<p>事务的 ACID 特性概念简单，但需要注意的是这几个特性不是一种平级关系：</p>
<ol>
<li>只有满足一致性，事务的执行结果才是正确的。</li>
<li>在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。</li>
<li>事务满足持久化是为了能应对数据库崩溃的情况。</li>
</ol>
<p>所以他们的关系如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f5ac61c75c660df67f8e210a7db7fc834b2.png" alt=""></p>
<p><strong>接下来就让我们来探究一下InnoDB是如何实现事务的——如何保证事务的ACID特性</strong>。</p>
<h2 id="2-1-InnoDB事务原子性的保证"><a href="#2-1-InnoDB事务原子性的保证" class="headerlink" title="2.1 InnoDB事务原子性的保证"></a>2.1 InnoDB事务原子性的保证</h2><p>原子性，核心要点是，<strong>要么全部都执行成功，要么全部都不执行</strong>：</p>
<ol>
<li>要么全部都执行成功：修改后的数据的新状态也是原子的，如果执行成功，那新状态（可能涉及到多个行的变更）应该就像一个操作那样同时全部生效。而不是这一秒3个行被更新完成，下一秒剩下2个行才被更新完成。</li>
<li>要么全部都不执行：也就是如果失败了，要可回滚，将一切都恢复原样。</li>
</ol>
<p><strong>前者通过MVCC来实现</strong>，前文我们已经介绍过MVCC了，同一个事务而产生的新的数据行都带有相同的版本号，配合上一致性非锁定读，可以实现统一事务的变更同时在一个瞬间（也就是同一个系统版本）生效。</p>
<p><strong>而后者，则通过undo日志来实现</strong>，undo日志的详细介绍可见本站博客《【InnoDB详解四】redo log和undo log》，这里简单介绍一下：</p>
<p>在对数据库进行修改时，InnoDB存储引擎会产生一定量的undo log，它记录了事务中每一步操作的<strong>反向逻辑操作</strong>：</p>
<ol>
<li>如果是一个INSERT操作，那么undo log会对应产生一条DELETE操作。</li>
<li>如果是一个DELETE操作，那么undo log会对应产生一条INSERT操作。</li>
<li>如果是一个UPDATE操作，假设是将行A的值从a变更为b，那么undo log会对应产生一条UPDATE操作，将行A的值从b变更为a。</li>
</ol>
<p>这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。</p>
<blockquote>
<p>前者我们说过，MVCC也是通过undo日志实现的，所以本质上，InnoDB事务原子性的保证（undo log + MVCC），其实全都是依赖于undo日志。</p>
</blockquote>
<h2 id="2-3-InnoDB事务持久性的保证"><a href="#2-3-InnoDB事务持久性的保证" class="headerlink" title="2.3 InnoDB事务持久性的保证"></a>2.3 InnoDB事务持久性的保证</h2><p>持久性的核心在于已经提交的修改必须永久的保存下来，对于数据库而言，也就是要写入磁盘中，这才能做到真正的数据持久化。</p>
<p>InnoDB事务持久性的保证依赖于redo日志，redo日志由两部分组成：</p>
<ol>
<li>内存中的重做日志缓冲（redo log buffr），其是易失的;</li>
<li>重做日志文件（redo log file），其是持久的。</li>
</ol>
<blockquote>
<p>redo日志的详细介绍可见本站博客《【InnoDB详解四】redo log和undo log》</p>
</blockquote>
<p>redo日志是物理日志，它的内容和undo日志那样的逻辑日志不一样，它记录的是数据页的物理变更信息，对于事务中的任何操作，都会产生redo日志，用来记录其对数据页的物理变动信息。</p>
<p>InnoDB通过<strong>Force Log at Commit</strong>机制实现事务的持久性，即当事务提交（COMMIT）时，<strong>必须先将该事务产生的所有redo日志写入到重做日志文件（redo log file）进行持久化</strong>，这样就能保证<strong>就算数据的变更还在缓冲池中（在脏页里面），如果系统崩溃了，也可以通过已经持久化的redo日志进行数据恢复</strong>。</p>
<p>将redo日志写入重做日志文件（redo log file）的操作叫做fsync操作，理论上为了保证持久性，每一次事务提交前，InnoDB应该都要执行一次fsync操作，不过很显然，频繁的fsync操作会影响并发性能。</p>
<p>InnoDB存储引擎允许用户手工设置fsync操作的频率，以此提高数据库的性能。参数<code>innodb_flush_log_at_trx_commit</code>用来控制重做日志刷新到磁盘的策略：</p>
<ol>
<li>该参数的默认值为1，表示事务提交时必须调用一次 fsync操作。<ul>
<li>这是最安全的持久化策略，不会发生更新丢失的情况。</li>
</ul>
</li>
<li>还可以设置该参数的值为0，表示事务提交时不进行写人重做日志操作，这个操作仅在master thread中完成，而在master thread中每1秒会进行一次重做日志文件的fsync操作。<ul>
<li>此时如果发生宕机，<strong>最多会丢失1秒的那部分更新</strong>。</li>
</ul>
</li>
<li>还可以设置该参数的值为2，表示事务提交时将重做日志写入重做日志文件，但仅写入文件系统的缓存中，不进行fsync操作。<ul>
<li>在这个设置下，当MySQL数据库发生宕机而操作系统不发生宕机时，并不会导致事务的丢失。而当操作系统宕机时，重启数据库后会丢失<strong>未从文件系统缓存刷新到重做日志文件那部分更新</strong>。</li>
</ul>
</li>
</ol>
<h2 id="2-3-InnoDB事务隔离性的保证"><a href="#2-3-InnoDB事务隔离性的保证" class="headerlink" title="2.3 InnoDB事务隔离性的保证"></a>2.3 InnoDB事务隔离性的保证</h2><p>在本站博客《MySQL核心要点汇总》一文中，我们简单了解过MySQL中事务的隔离级别：</p>
<p>SQL 标准定义了四个隔离级别：</p>
<ul>
<li><strong>READ-UNCOMMITTED(读未提交)</strong>： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。</li>
<li><strong>READ-COMMITTED(读已提交)</strong>： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。</li>
<li><strong>REPEATABLE-READ(可重复读)</strong>： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生（这是针对Oracle，SQL server等数据库而言，InnoDB采用Next-Key Lock，在可重复读级别下就可以避免幻读）。</li>
<li><strong>SERIALIZABLE(串行化)</strong>： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。</li>
</ul>
<p>同样的，我们回顾一下 脏读/不可重复读/幻读 这三类并发的问题。</p>
<ul>
<li><strong>脏读</strong>：指的是在不同的事务下，当前事务可以读到另外事务<strong>未提交的数据</strong>，简单来说就是可以读到脏数据。</li>
<li><strong>不可重复读</strong>：是指在事务A中多次读取同一批数据。在这个多次访问之间，事务B也访问该批数据，并做了一些DML操作，并且提交（如果没提交就是脏读了）。因此，在事务A中的两次读数据之间，由于事务B的修改，导致事务A两次读到的数据可能是不一样的。不可重复读和脏读的区别是脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据。</li>
<li><strong>幻读</strong>：是指在同一事务（事务A）下，连续执行两次同样的SQL语句可能搜出不同的结果，<strong>第二次的SQL语句可能会返回之前不存在的行，就像产生了幻觉一样</strong>。也就是说，在两次查询之间，其他事务insert并且提交的行，如果满足事务A查询的where条件，那么也会被查出来。幻读和不可重复读的区别在于幻读是查询的行数量变多（因为其他事务insert），不可重复读是行数据不一致（因为其他事务update）。</li>
</ul>
<p><strong>那么，各个隔离级别是如何实现的呢？他们分别是如何解决脏读/不可重复读/幻读问题的呢</strong>？</p>
<p>我们可以先来个开门见山的总结：</p>
<ul>
<li><strong>READ-UNCOMMITTED(读未提交)</strong><ul>
<li>无锁</li>
<li>无并发控制协议</li>
</ul>
</li>
<li><strong>READ-COMMITTED(读已提交)</strong><ul>
<li>使用乐观锁MVCC，其<code>非一致性读取</code>，可以避免事务读取被上锁的行记录（防止脏读），只能读取快照数据。</li>
<li>但在该级别下，所有事务的<code>非一致性读</code>都会<strong>读取最新版本的快照</strong>，即便这个最新版本是在事务开启之后才提交的，这就可能产生<code>不可重复读</code>问题。</li>
</ul>
</li>
<li><strong>REPEATABLE-READ(可重复读)</strong><ul>
<li>使用乐观锁MVCC，并且所有事务的<code>非一致性读</code>都会<strong>读取当前事务开启时最新版本的快照</strong>，这样就能避免<code>不可重复读</code>的发送。</li>
<li>使用Next-Key Lock，给事务查询的where条件涵盖的行记录加上范围锁，防止其他事务在这些行数据间隙插入新的记录，从而避免幻读问题。</li>
</ul>
</li>
<li><strong>SERIALIZABLE(串行化)</strong><ul>
<li>使用悲观锁LBCC。<code>一致性读取</code>会在操作的每一行数据上都加上锁，读取加S锁，其余加X锁。</li>
</ul>
</li>
</ul>
<p>其中MVCC和LBCC我们在前文已经介绍过了，这里不再赘述。</p>
<p>不过需要注意的是，各个隔离级别的加锁，其实是加在索引上的，而且在不同的情况下，加锁逻辑也不太相同，比如我们执行一条delete语句：<code>delete from t1 where id=10;</code>，那么在执行这条语句前，我们需要确定：</p>
<ol>
<li>id列是不是主键？</li>
<li>事务的隔离级别是什么？</li>
<li>id非主键的话，其上有建立索引吗？</li>
<li>建立的索引是唯一索引吗？</li>
<li>该SQL的执行计划是什么？索引扫描？全表扫描？</li>
</ol>
<p>不同场景的不同实现，我们逐一来看下：</p>
<h3 id="2-3-1-READ-UNCOMMITTED的加锁方式"><a href="#2-3-1-READ-UNCOMMITTED的加锁方式" class="headerlink" title="2.3.1 READ-UNCOMMITTED的加锁方式"></a>2.3.1 READ-UNCOMMITTED的加锁方式</h3><p>无锁，没有什么实现，忽略。</p>
<h3 id="2-3-2-READ-COMMITTED的加锁方式"><a href="#2-3-2-READ-COMMITTED的加锁方式" class="headerlink" title="2.3.2 READ-COMMITTED的加锁方式"></a>2.3.2 READ-COMMITTED的加锁方式</h3><h4 id="2-3-2-1-id列是主键"><a href="#2-3-2-1-id列是主键" class="headerlink" title="2.3.2.1 id列是主键"></a>2.3.2.1 id列是主键</h4><p>当id是主键的时候，我们只需要在该id=10的记录上加上x锁即可。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ca2458bf61c1ae996c19d02fdde2db595a0.png" alt=""></p>
<h4 id="2-3-2-2-id列是辅助唯一索引"><a href="#2-3-2-2-id列是辅助唯一索引" class="headerlink" title="2.3.2.2 id列是辅助唯一索引"></a>2.3.2.2 id列是辅助唯一索引</h4><p>当id列不是主键，但是为辅助唯一索引时，辅助索引和聚集索引都会加X锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cb574ee9a9fdd4fcdfefb3a51340e84f729.png" alt=""></p>
<h4 id="2-3-2-3-id列是辅助非唯一索引"><a href="#2-3-2-3-id列是辅助非唯一索引" class="headerlink" title="2.3.2.3 id列是辅助非唯一索引"></a>2.3.2.3 id列是辅助非唯一索引</h4><p>当id列不是主键，如果id是非唯一索引，那么所对应的<strong>所有的辅佐索引和聚集索引记录</strong>上都会上x锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a65e9c01d5eec8ee913abdebd626bc2315b.png" alt=""></p>
<h4 id="2-3-2-4-id列上没有索引"><a href="#2-3-2-4-id列上没有索引" class="headerlink" title="2.3.2.4 id列上没有索引"></a>2.3.2.4 id列上没有索引</h4><p>由于id列上没有索引，因此只能走聚簇索引，进行全表扫描。因此聚集索引上的每条记录，无论是否满足条件，都会被加上X锁。</p>
<p>但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，<strong>会在判断后放锁</strong>，最终持有的，是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不会省略。同时，优化也违背了2PL约束（同时加锁同时放锁）。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0af0e86bcea7ffd644e3639c095cea54f0c.png" alt=""></p>
<p>最后只有id=10的锁留下了。</p>
<h3 id="2-3-3-REPEATABLE-READ的加锁方式"><a href="#2-3-3-REPEATABLE-READ的加锁方式" class="headerlink" title="2.3.3 REPEATABLE-READ的加锁方式"></a>2.3.3 REPEATABLE-READ的加锁方式</h3><h4 id="2-3-3-1-id列是主键"><a href="#2-3-3-1-id列是主键" class="headerlink" title="2.3.3.1 id列是主键"></a>2.3.3.1 id列是主键</h4><p>与id列是主键，RC隔离级别的情况，完全相同。因为只有一条结果记录，只能在上面加锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ca2458bf61c1ae996c19d02fdde2db595a0.png" alt=""></p>
<blockquote>
<p>RR级别是需要同时加间隙锁的，但因为id列是唯一主键，且delete的where条件是id=10，这种情况不会发生幻读，所以此例没加。但如果delete语句不是id=10，而是id&gt;10 and id &lt; 15，那么就要加间隙锁了。</p>
</blockquote>
<h4 id="2-3-3-2-id列是辅助唯一索引"><a href="#2-3-3-2-id列是辅助唯一索引" class="headerlink" title="2.3.3.2 id列是辅助唯一索引"></a>2.3.3.2 id列是辅助唯一索引</h4><p>与id列是辅助唯一索引，RC隔离级别的情况，完全相同。因为只有一条结果记录，只能在上面加锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cb574ee9a9fdd4fcdfefb3a51340e84f729.png" alt=""></p>
<blockquote>
<p>RR级别是需要同时加间隙锁的，但因为id列是唯一索引，且delete的where条件是id=10，这种情况不会发生幻读，所以此例没加。但如果delete语句不是id=10，而是id&gt;10 and id &lt; 15，那么就要加间隙锁了。</p>
</blockquote>
<h4 id="2-3-3-3-id列是辅助非唯一索引"><a href="#2-3-3-3-id列是辅助非唯一索引" class="headerlink" title="2.3.3.3 id列是辅助非唯一索引"></a>2.3.3.3 id列是辅助非唯一索引</h4><p>在RR隔离级别下，为了防止幻读的发生，会使用间隙锁（GAP锁）。</p>
<p>首先，通过辅助索引定位到第一条满足查询条件的记录，加记录上的X锁，加GAP上的GAP锁，然后加聚簇索引上的记录X锁，然后返回；</p>
<p>然后读取下一条，重复进行。直至进行到第一条不满足条件的记录<code>[11,f]</code>，此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-12f73d7997a01391c31de0c36df7bcb90dd.png" alt=""></p>
<h4 id="2-3-3-4-id列上没有索引"><a href="#2-3-3-4-id列上没有索引" class="headerlink" title="2.3.3.4 id列上没有索引"></a>2.3.3.4 id列上没有索引</h4><p>在这种情况下，聚集索引上的所有记录，都被加上了X锁。其次，聚集索引每条记录间的间隙(GAP)，也同时被加上了GAP锁。</p>
<p>但是，InnoDB也做了相关的优化，就是所谓的semi-consistent read。semi-consistent read开启的情况下，<strong>对于不满足查询条件的记录，MySQL会提前放锁，同时也不会添加Gap锁</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0805e613bf1d63f1919bf5224e5ffb01cb8.png" alt=""></p>
<h3 id="2-3-4-SERIALIZABLE的加锁方式"><a href="#2-3-4-SERIALIZABLE的加锁方式" class="headerlink" title="2.3.4 SERIALIZABLE的加锁方式"></a>2.3.4 SERIALIZABLE的加锁方式</h3><p>因为这是DML（delete）操作，<strong>所以与REPEATABLE-READ级别的各种情况下表现完全相同</strong>。但如果是select操作，会有所不同：</p>
<ul>
<li><p>REPEATABLE-READ级别默认是一致性非锁定读，在行记录有锁的情况下可以不用阻塞，而是去读取快照，除非SQL中主动加锁进行一致性锁定读（lock in share mode 或 for update）；</p>
</li>
<li><p>而Serializable级别下，会对每条select语句，自动加上lock in share mode，进行一致性锁定读，即如果行上有锁，只能阻塞。</p>
</li>
</ul>
<h2 id="2-4-InnoDB事务一致性的保证"><a href="#2-4-InnoDB事务一致性的保证" class="headerlink" title="2.4 InnoDB事务一致性的保证"></a>2.4 InnoDB事务一致性的保证</h2><p>前文我们已经阐述过了，数据库外的数据一致性，需要通过外部编码来实现，而数据库内的数据一致性，则依赖于原子性和隔离性。在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f5ac61c75c660df67f8e210a7db7fc834b2.png" alt=""></p>
<p>所以InnoDB实现了原子性和隔离性，也就自然而然实现了一致性。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/" itemprop="url">【图论】拓扑排序详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-15T21:36:36+08:00">
                2020-09-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%9B%BE/" itemprop="url" rel="index">
                    <span itemprop="name">图</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/15/【图论】拓扑排序详解/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在正文开始前，我们先来了解一下<strong>有向无环图(Directed Acyclic Graph简称DAG)</strong></p>
<p>如下图就是一个DAG图，DAG图是我们讨论拓扑排序的基础。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8f6717028963b3bea2b37a3ce72eae8f784.png" alt=""></p>
<blockquote>
<p>AOV网：数据在顶点 可以理解为面向对象<br>AOE网：数据在边上，可以理解为面向过程！</p>
</blockquote>
<h1 id="1-什么是拓扑排序"><a href="#1-什么是拓扑排序" class="headerlink" title="1. 什么是拓扑排序"></a>1. 什么是拓扑排序</h1><p><strong>拓扑排序（Topological Order）</strong>，很多人听说过，但是不了解的一种算法。或许很多人只知道它是图论的一种排序，至于干什么的不清楚。又或许很多人可能还会认为它是一种啥排序。</p>
<p>而实质上<strong>它只是将DAG图的顶点排成一个线性序列，得到一个顶点的全序集合</strong>。其排序的顺序依据就是节点的指向关系。比如前言的DAG图：</p>
<ul>
<li>…</li>
<li>节点5在节点4和节点3的后面</li>
<li>节点9在节点6和节点7的后面</li>
<li>…</li>
</ul>
<p>那么最后得到的节点的线性序列结果,也一定要满足上面的指向顺序。</p>
<p>每一个节点都拥有<strong>入度</strong>（有多少点导向它，也就是开始它有多少前提）和<strong>出度</strong>（它导向多少点，也就是它是多少其他节点开始的前提）。例如节点5的入度为3和4，出度为7。</p>
<p><strong>拓扑排序的结果不是唯一的</strong>，只要符合上面的条件，那么它就是拓扑序列，比如<code>1 2 4 3 6 5 7 9</code>和<code>2 1 3 4 5 6 7 9</code>，这两个结果都是可行的。</p>
<blockquote>
<p>官方一点的定义：将有向图中的节点以线性方式进行排序。即对于任何连接自节点u到节点v的有向边uv，在最后的排序结果中，节点u总是在节点v的前面。</p>
</blockquote>
<h1 id="2-现实案例"><a href="#2-现实案例" class="headerlink" title="2. 现实案例"></a>2. 现实案例</h1><p>看了上面关于拓扑排序的概念如果还觉得十分抽象的话，那么不妨考虑一个非常非常经典的例子——选课。</p>
<p>假设我非常想学习一门《jsp入门》的课程，但是在修这么课程之前，我们必须要学习一些基础课程，比如《JAVA语言程序设计》，《HTML指南》等等。那么这个制定选修课程顺序的过程，实际上就是一个拓扑排序的过程，每门课程相当于有向图中的一个顶点，而连接顶点之间的有向边就是课程学习的先后关系。</p>
<p>只不过这个过程不是那么复杂，从而很自然的在我们的大脑中完成了。将这个过程以算法的形式描述出来的结果，就是拓扑排序。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ed6f21ce9608d461a3bccfea80f57b48fa6.png" alt=""></p>
<p>可以看到，上图中的学习顺序，就是拓扑序列，其不止一个结果。</p>
<p>拓扑排序算法在工程学中十分重要。</p>
<blockquote>
<p>节点成环的图，无法被拓扑排序，因为这在工程上本身没有意义，比如A——&gt;B——&gt;C——&gt;A，那么这个工程永远无法被开始。</p>
</blockquote>
<h1 id="3-算法实现"><a href="#3-算法实现" class="headerlink" title="3. 算法实现"></a>3. 算法实现</h1><p>拓扑排序的<strong>最优时间复杂度是O(m+n)</strong>,其中m和n是DAG图中节点数和边数。因为拓扑排序<strong>至少</strong>要对DAG图的节点和边进行一次完整的遍历。</p>
<p>拓扑排序的<strong>最优空间复杂度是O(m+n)</strong>,其中m和n是DAG图中节点数和边数。我们一般使用邻接表来存储DAG图，因此空间复杂度是O(m+n)。</p>
<h2 id="3-1-广度优先搜索法（BFS）"><a href="#3-1-广度优先搜索法（BFS）" class="headerlink" title="3.1 广度优先搜索法（BFS）"></a>3.1 广度优先搜索法（BFS）</h2><h3 id="3-1-1-BFS实现拓扑排序"><a href="#3-1-1-BFS实现拓扑排序" class="headerlink" title="3.1.1 BFS实现拓扑排序"></a>3.1.1 BFS实现拓扑排序</h3><p>广度优先搜索法的思路很简单：</p>
<ol>
<li>从DAG图中找到<strong>入度为0</strong>的节点A（也就是没有箭头指向它的节点），将其放入拓扑序列的结果集。</li>
<li>同时删除由节点A出发的所有边。</li>
<li>在剩下的DAG图中重复1-2两步。</li>
<li>如果最后可以把全部的节点都删除并加入到结果集，那表示DAG图可以被拓扑排序；否则，如果最后有节点被剩下，那说明该图是有环图，无法被拓扑排序。</li>
</ol>
<p>如下图</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3391dd5692b37d49a3f885971f434cf5a02.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-60263c4c74b83269df50907f42790bb5234.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-77d989dca380e2eba9c57d1e815326edc56.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fe6e6c396e5c66160ca7a86e6bde5c3c5b3.png" alt=""></p>
<h3 id="3-1-2-BFS实现拓扑排序的优化"><a href="#3-1-2-BFS实现拓扑排序的优化" class="headerlink" title="3.1.2 BFS实现拓扑排序的优化"></a>3.1.2 BFS实现拓扑排序的优化</h3><p>如果有时候，我们只需要知道某个DAG图是否可以拓扑排序，而不需要真正得到拓扑排序后的结果，那么可以不需要结果集列表，<strong>只需要统计被删除的节点的数量即可，如果该数量等于DAG图的节点数，那么DAG图可以被拓扑排序</strong>。</p>
<h2 id="3-2-深度优先搜索法（DFS）"><a href="#3-2-深度优先搜索法（DFS）" class="headerlink" title="3.2 深度优先搜索法（DFS）"></a>3.2 深度优先搜索法（DFS）</h2><h3 id="3-2-1-DFS实现拓扑排序"><a href="#3-2-1-DFS实现拓扑排序" class="headerlink" title="3.2.1 DFS实现拓扑排序"></a>3.2.1 DFS实现拓扑排序</h3><p>深度优先搜索法是广度优先搜索法的逆向思路，它的步骤如下：</p>
<ol>
<li>选取图中任意一个节点A，将其状态标记为“搜索中”</li>
<li>寻找节点A的邻接点（沿着箭头指向寻找相邻的节点）<ol>
<li>如果A存在邻接点<ol>
<li>如果A的邻接点中存在状态为“搜索中”的邻接点，那么表示DAG图有环路，不可拓扑排序。</li>
<li>否则，那么任意选择一个状态为“未搜索”的邻接点B，使用递归对B重复做1和2操作，注意此时B的邻接点判断不包含来路（也就是A节点）。等到A的所有邻接点都被搜索到，递归回溯回A节点的时候，那么A节点也会被标记为“已搜索”，并压入结果栈。</li>
</ol>
</li>
<li>如果A不存在邻接点，那么将节点A的状态改为“已完成”，并且将其压入一个结果集的栈中。</li>
</ol>
</li>
<li>A节点及其相邻节点都搜索完毕后，如果还有未搜索的节点，那么任意选取一个节点当做出发点，继续重复1,2,3步骤。</li>
<li>直到所有的节点都被搜索并压入栈，那么此时结果栈中，从栈顶到栈底的顺序，就是拓扑排序的顺序。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-4c28b181876a97519a71c906921c05e9a8a.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8527f61ef65f2e3bde9e47f8b7a22481fae.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f6b9acea12ae9b5876b792b3394a4b0b480.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a70c8606a0f12ed549991a6a6fd584d5030.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-788b9456add4b59dc890a12950e0efdd024.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2cbe7ded9481877300dbf1a2e519a85f8fc.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8be9445aae16147097ac42f8bc08002a114.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4386e32bbe6db3348a0b5051aac0114cacb.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-102c038f31cec5cbdea7102f2e612f06b67.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c091a2e5694ff8708a1884c9492c8cdf551.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-50cc6d8c4050ac9c0b8114c2bb3a49e809d.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-59af3a05a56757f166044305474cf42922f.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-700d02c9347cef22f44ce631a6b088a2011.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8445591c7013e1633e194c4f4f71a31eb71.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ee05cf7512bfb71807f9b3ad8d91b026685.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5a462ba6ac4e920c4cc444eef497fd02d62.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6d626a51209e2c008ff9a1f7008f196a4a4.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-46b3b2f1532c08a3c29aa71b97b049ef3b9.png" alt=""></p>
<h3 id="3-2-2-DFS实现拓扑排序的优化"><a href="#3-2-2-DFS实现拓扑排序的优化" class="headerlink" title="3.2.2 DFS实现拓扑排序的优化"></a>3.2.2 DFS实现拓扑排序的优化</h3><p>如果有时候，我们只需要知道某个DAG图是否可以拓扑排序，而不需要真正得到拓扑排序后的结果，那么可以不需要结果栈，只需要判断整个深度优先搜索过程，没有发生“搜索中”节点的相邻节点（不包含来路的节点）也是“搜索中”就行。</p>
<h1 id="4-算法题解"><a href="#4-算法题解" class="headerlink" title="4 算法题解"></a>4 算法题解</h1><h2 id="4-1-课程表I"><a href="#4-1-课程表I" class="headerlink" title="4.1 课程表I"></a>4.1 课程表I</h2><p><a href="https://leetcode-cn.com/problems/course-schedule/" target="_blank" rel="noopener" title="leetcode-207. 课程表">leetcode-207. 课程表I</a></p>
<h2 id="4-2-课程表II"><a href="#4-2-课程表II" class="headerlink" title="4.2 课程表II"></a>4.2 课程表II</h2><p><a href="https://leetcode-cn.com/problems/course-schedule-ii/" target="_blank" rel="noopener" title="leetcode-210.课程表II">leetcode-210.课程表II</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/" itemprop="url">【图论】广度/深度优先搜索算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-15T21:29:34+08:00">
                2020-09-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%9B%BE/" itemprop="url" rel="index">
                    <span itemprop="name">图</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/15/【图论】广度-深度优先搜索算法/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我们首次接触<strong>广度优先搜索</strong>和<strong>深度优先搜索</strong>时，应该是在数据结构课上讲的 “图的遍历”。还有就是刷题的时候，遍历二叉树/拓扑排序我们会经常用到这两种遍历方法。</p>
<p><strong>广度优先搜索算法（Breadth-First-Search，缩写为 BFS）</strong>，是一种利用<strong>队列</strong>实现的搜索算法。简单来说，其搜索过程和 “湖面丢进一块石头激起层层涟漪” 类似。</p>
<p><strong>深度优先搜索算法（Depth-First-Search，缩写为 DFS）</strong>，是一种利用<strong>递归</strong>实现的搜索算法。简单来说，其搜索过程和 “不撞南墙不回头” 类似。</p>
<p><strong>BFS 的重点在于队列，而 DFS 的重点在于递归。这是它们的本质区别。</strong></p>
<h1 id="1-广度优先搜索法"><a href="#1-广度优先搜索法" class="headerlink" title="1. 广度优先搜索法"></a>1. 广度优先搜索法</h1><p>广度优先搜索，也叫做广度优先遍历，其主要思想类似于树的层序遍历。</p>
<ol>
<li>从任意一个节点A开始，遍历它的全部的邻接点B,C</li>
<li>然后再以它其中一个邻接点B为起点，遍历B的所有的邻接点D，F。</li>
<li>然后再以它另外一个邻接点C为起点，遍历C的所有的邻接点G，H。</li>
<li>然后再以它其中一个邻接点D为起点，遍历D的所有的邻接点…。</li>
<li>以此类推….</li>
</ol>
<p>伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;queue：结果集，queue队列</span><br><span class="line">&#x2F;&#x2F;nodeA：开始节点</span><br><span class="line">public void bfsSearch(List&lt;Node&gt; queue ,Node StrartNode)&#123;</span><br><span class="line">    &#x2F;&#x2F;先选择一个出发点，加入队列。</span><br><span class="line">    queue.add(StrartNode);</span><br><span class="line">    int size &#x3D; queue.getSize();</span><br><span class="line">    for(int index&#x3D;0;index&lt;size;index++)&#123;</span><br><span class="line">        &#x2F;&#x2F;BFS的重点在于队列，它的思路就是沿着queue的添加顺序，依次遍历他们的邻接点。</span><br><span class="line">        for(Node node : queue.get(index).getNeighbor())&#123;</span><br><span class="line">            &#x2F;&#x2F;没被搜索过，那么加入结果集</span><br><span class="line">            if(!queue.contain(node))&#123;</span><br><span class="line">                queue.add(node);</span><br><span class="line">                size &#x3D; queue.getSize();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void main()&#123;</span><br><span class="line">    &#x2F;&#x2F;定义一个结果集，queue队列</span><br><span class="line">    List&lt;Node&gt; queue &#x3D; new LinkedList&lt;Node&gt;();</span><br><span class="line">    &#x2F;&#x2F;先选择一个节点作为开始节点。</span><br><span class="line">    Node startNode&#x3D;nodeA;</span><br><span class="line">    bfsSearch(queue,startNode);</span><br><span class="line">    while(queue.size()不等于节点总数)&#123;</span><br><span class="line">        &#x2F;&#x2F;说明可能因为边有向的问题，有些节点没有被遍历到</span><br><span class="line">        &#x2F;&#x2F;此时需要在剩下的节点中另找一个出发点（假设为B）</span><br><span class="line">        startNode &#x3D; nodeB;&#x2F;&#x2F;省略找出B的过程</span><br><span class="line">        bfsSearch(queue,startNode);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>BFS比较适合判断二分图，以及用于实现寻找最小生成树（MST），如在BFS基础上的Kruskal算法。还有寻找最短路径问题（如Dijkstra算法）。</p>
<p><img src="https://cuijiahua.com/wp-content/uploads/2018/01/alogrithm_10_2.gif" alt="image"></p>
<h2 id="1-1-无向图的广度优先遍历"><a href="#1-1-无向图的广度优先遍历" class="headerlink" title="1.1 无向图的广度优先遍历"></a>1.1 无向图的广度优先遍历</h2><p>我们先给出一个图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-251c89eb3165548739c5acd6ea271c41554.png" alt=""></p>
<ol>
<li>先找到A，这是第一层。</li>
<li>再找到A的邻接点，遍历到B，C，D，F。</li>
<li>再找到B，C，D，F的邻接点，遍历到G，E，H</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-3b6c768580717218780d806bc60e913008b.png" alt=""></p>
<h2 id="1-2-有向图的广度优先遍历"><a href="#1-2-有向图的广度优先遍历" class="headerlink" title="1.2 有向图的广度优先遍历"></a>1.2 有向图的广度优先遍历</h2><p><img src="https://oscimg.oschina.net/oscnet/up-aa815c87267ef276969876712cfccf33128.png" alt=""></p>
<p>思路和与无向图类似，只不过需要考虑边的走向问题。</p>
<ol>
<li>先找到A，这是第一层。</li>
<li>再找到A的邻接点，遍历到B，C，F。</li>
<li>再找到B，C，F的邻接点，遍历到D，H</li>
<li>再找到D，H的邻接点，遍历到E，G</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-684db1b8e0400316ab9d8a86a457489f9fa.png" alt=""></p>
<h1 id="2-深度优先搜索法"><a href="#2-深度优先搜索法" class="headerlink" title="2. 深度优先搜索法"></a>2. 深度优先搜索法</h1><p>深度优先搜索，也叫做深度优先遍历，其主要思想是回溯法，它的核心是使用递归。</p>
<p>例如这张图，从1开始到2，之后到5，5不能再走了，退回2，到6，退回2退回1，到3，以此类推；</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-45757424adba38157c8d3c14ffb0dd6f61a.png" alt=""></p>
<p>伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;stack：定义的结果集stack栈</span><br><span class="line">&#x2F;&#x2F;currentNode：本次递归搜索的当前node</span><br><span class="line">public void dfsSearch(Stack&lt;Node&gt; stack,Node currentNode)&#123;</span><br><span class="line">    if(currentNode没有邻接点 &amp;&amp; !stack.contain(currentNode))&#123;</span><br><span class="line">        &#x2F;&#x2F;压入结果栈</span><br><span class="line">        stack.push(currentNode);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;node有邻接点，那么遍历邻接点，依次深搜</span><br><span class="line">    for(Node node : currentNode.getNeighbor())&#123;</span><br><span class="line">        if(node.isVisited() || stack.contain(currentNode))&#123;</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line">        node.setVisited(true);</span><br><span class="line">        dfsSearch(stack,node);</span><br><span class="line">        node.setVisited(false);</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;currentNode的邻接点都已经遍历过了，现在逻辑回溯回currentNode</span><br><span class="line">    &#x2F;&#x2F;那么需要将currentNode压入结果栈</span><br><span class="line">    stack.push(currentNode);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void main()&#123;</span><br><span class="line">    &#x2F;&#x2F;定义一个结果集</span><br><span class="line">    Stack&lt;Node&gt; stack &#x3D; new Stack&lt;Node&gt;();</span><br><span class="line">    &#x2F;&#x2F;先选择一个节点作为开始节点。</span><br><span class="line">    Node startNode&#x3D;nodeA;</span><br><span class="line">    dfsSearch(stack,startNode);</span><br><span class="line">    while(queue.size()不等于节点总数)&#123;</span><br><span class="line">        &#x2F;&#x2F;说明可能因为边有向的问题，有些节点没有被遍历到</span><br><span class="line">        &#x2F;&#x2F;此时需要在剩下的节点中另找一个出发点（假设为B）</span><br><span class="line">        startNode &#x3D; nodeB;&#x2F;&#x2F;省略找出B的过程</span><br><span class="line">        dfsSearch(stack,startNode);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><img src="https://cuijiahua.com/wp-content/uploads/2018/01/alogrithm_10_3.gif" alt="image"></p>
<h2 id="2-1-无向图的深度优先遍历"><a href="#2-1-无向图的深度优先遍历" class="headerlink" title="2.1 无向图的深度优先遍历"></a>2.1 无向图的深度优先遍历</h2><p>我们先给出一个图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-74f1f6bfb457012ec8d3b5e0dd1cd05fcc1.png" alt=""></p>
<p>对上无向图进行深度优先遍历，从A开始：</p>
<p><strong>第1步</strong>：访问A。</p>
<p><strong>第2步</strong>：访问B(A的邻接点)。 在第1步访问A之后，接下来应该访问的是A的邻接点，即”B,D,F”中的一个。但在本文的实现中，顶点ABCDEFGH是按照顺序存储，B在”D和F”的前面，因此，先访问B。</p>
<p><strong>第3步</strong>：访问G(B的邻接点)。 和B相连只有”G”(A已经访问过了)  </p>
<p><strong>第4步</strong>：访问E(G的邻接点)。 在第3步访问了B的邻接点G之后，接下来应该访问G的邻接点，即”E和H”中一个(B已经被访问过，就不算在内)。而由于E在H之前，先访问E。</p>
<p><strong>第5步</strong>：访问C(E的邻接点)。 和E相连只有”C”(G已经访问过了)。</p>
<p><strong>第6步</strong>：访问D(C的邻接点)。 </p>
<p><strong>第7步</strong>：访问H。因为D没有未被访问的邻接点；因此，一直回溯到访问G的另一个邻接点H。</p>
<p><strong>第8步</strong>：访问(H的邻接点)F。</p>
<p>因此访问顺序是：<strong>A -&gt; B -&gt; G -&gt; E -&gt; C -&gt; D -&gt; H</strong> <strong>-&gt;</strong> <strong>F</strong></p>
<h2 id="2-2-有向图的深度优先遍历"><a href="#2-2-有向图的深度优先遍历" class="headerlink" title="2.2 有向图的深度优先遍历"></a>2.2 有向图的深度优先遍历</h2><p><img src="https://oscimg.oschina.net/oscnet/up-c270810594e5678e4b97eedac94bd900bbf.png" alt=""></p>
<p>对上有向图进行深度优先遍历，从A开始：</p>
<p><strong>第1步</strong>：访问A。</p>
<p><strong>第2步</strong>：访问(A的出度对应的字母)B。 在第1步访问A之后，接下来应该访问的是A的出度对应字母，即”B,C,F”中的一个。但在本文的实现中，顶点ABCDEFGH是按照顺序存储，B在”C和F”的前面，因此，先访问B。</p>
<p><strong>第3步</strong>：访问(B的出度对应的字母)F。 B的出度对应字母只有F。 </p>
<p><strong>第4步</strong>：访问H(F的出度对应的字母)。 F的出度对应字母只有H。 </p>
<p><strong>第5步</strong>：访问(H的出度对应的字母)G。</p>
<p><strong>第6步</strong>：访问(G的出度对应字母)E。 在第5步访问G之后，接下来应该访问的是G的出度对应字母，即”B,C,E”中的一个。但在本文的实现中，顶点B已经访问了，由于C在E前面，所以先访问C。</p>
<p><strong>第7步</strong>：访问(C的出度对应的字母)D。</p>
<p><strong>第8步</strong>：访问(C的出度对应字母)D。 在第7步访问C之后，接下来应该访问的是C的出度对应字母，即”B,D”中的一个。但在本文的实现中，顶点B已经访问了，所以访问D。</p>
<p><strong>第9步</strong>：访问E。D无出度，所以一直回溯到G对应的另一个出度E。</p>
<p>因此访问顺序是：<strong>A -&gt; B -&gt; F -&gt; H -&gt; G -&gt; C -&gt; D</strong> <strong>-&gt; E</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/" itemprop="url">【InnoDB详解二】MySQL文件系统和InnoDB存储结构</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-08T21:47:43+08:00">
                2020-09-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/08/【InnoDB详解二】MySQL文件系统和InnoDB存储结构/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  10.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  38
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-MySQL文件系统"><a href="#1-MySQL文件系统" class="headerlink" title="1 MySQL文件系统"></a>1 MySQL文件系统</h1><p>本章节将分析构成MySQL数据库和InnoDB存储引擎表的各种类型文件。这些文件有以下这些。</p>
<ol>
<li>参数文件∶告诉MySQL实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数，这些参数定义了某种内存结构的大小等设置，还会介绍各种参数的类型。</li>
<li>日志文件∶用来记录MySQL实例对某种条件做出响应时写人的文件，如错误日志文件、二进制日志文件、慢查询日志文件、查询日志文件等。</li>
<li>socket文件∶当用UNIX域套接字方式进行连接时需要的文件。</li>
<li>pid文件∶MySQL实例的进程 ID文件。</li>
<li>MySQL表结构文件∶用来存放 MySQL表结构定义文件。</li>
<li>存储引擎文件∶因为MySQL表存储引擎的关系，每个存储引擎都会有自己的文件来保存各种数据。这些存储引擎真正存储了记录和索引等数据。本章主要介绍与 InnoDB有关的存储引擎文件。</li>
</ol>
<h2 id="1-1-参数文件"><a href="#1-1-参数文件" class="headerlink" title="1.1 参数文件"></a>1.1 参数文件</h2><p>当 MySQL实例启动时，数据库会先去读取一个配置参数文件，用来寻找数据库的各种文件所在位置以及指定某些初始化参数，这些参数通常定义了某种内存结构有多大等。</p>
<p>在默认情况下，MySQL实例会按照一定的顺序在指定的位置进行读取，用户只需通过命令<code>mysql--help | grep my.cnf</code>来寻找即可。</p>
<p>MySQL数据库参数文件的作用和Oracle数据库的参数文件极其类似，不同的是，Oracle实例在启动时若找不到参数文件，是不能进行装载（mount）操作的。MySQL稍微有所不同，MySQL实例可以不需要参数文件，这时所有的参数值取决于编译MySQL时指定的默认值和源代码中指定参数的默认值。</p>
<p>MySQL数据库的参数文件是以文本方式进行存储的。用户可以直接通过一些常用的文本编辑软件（如vi和emacs）进行参数的修改。</p>
<p>MySQL数据库参数是一个键/值（key/value）对。如innodb_buffer_pool_size=1G。</p>
<p>可以通过命令 SHOW VARIABLES查看数据库中的所有参数，也可以通过LIKE来过滤参数名。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-829069acf66ead1907d807695b02b7bc6cd.png" alt=""></p>
<h2 id="1-1-参数的类型"><a href="#1-1-参数的类型" class="headerlink" title="1.1 参数的类型"></a>1.1 参数的类型</h2><p>MySQL数据库中的参数可以分为两类∶</p>
<ol>
<li>动态（dynamic）参数</li>
<li>静态（static）参数</li>
</ol>
<p>动态参数意味着可以在MySQL实例运行中进行更改，静态参数说明在整个实例生命周期内都不得进行更改，就好像是只读（read only）的。可以通过SET命令对动态的参数值进行修改，SET 的语法如下∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b80574245a07a91e0ffdcac095ec1c0f029.png" alt=""></p>
<p>这里可以看到global和session关键字，它们表明该参数的修改是基于当前会话还是整个实例的生命周期。</p>
<p>有些动态参数只能在会话中进行修改，如autocommit;</p>
<p>而有些参数修改完后，在整个实例生命周期中都会生效，如binlog_cache_size;</p>
<p>而有些参数既可以在会话中又可以在整个实例的生命周期内生效，如 read_buffer_size。</p>
<p>举例如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4dae9240c84d8f5ccdb2a89b83c8d3c2c35.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-be3d687886cb98ef05ae7ba432b35e1ae1e.png" alt=""></p>
<p>上述示例中将当前会话的参数read_buffer_size从2MB调整为了512KB，而用户可以看到全局的read_buffer_size的值仍然是2MB，也就是说如果有另一个会话登录到MySQL实例，它的read_buffer_size的值是2MB，而不是512KB。这里使用了set global | session来改变动态变量的值。用户同样可以直接使用SET@@global | @@session来更改，如下所示∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9eb8d6ca15b99a9b523638d9573f069bdbe.png" alt=""></p>
<p>这次把read_buffer_size全局值更改为IMB，而当前会话的read bufer_size的值还是512KB。</p>
<p><strong>这里需要注意的是，对变量的全局值进行了修改，仅在这次的实例生命周期内都有效，但MySQL实例本身并不会对参数文件中的该值进行修改</strong>。也就是说，在下次启动时MySQL实例还是会读取参数文件。若想在数据库实例下一次启动时该参数还是保留为当前修改的值，那么用户必须去修改参数文件。</p>
<h2 id="1-2-日志文件"><a href="#1-2-日志文件" class="headerlink" title="1.2 日志文件"></a>1.2 日志文件</h2><p>日志文件相关介绍详见本站文章《MySQL日志体系详解》</p>
<h2 id="1-3-socket文件"><a href="#1-3-socket文件" class="headerlink" title="1.3 socket文件"></a>1.3 socket文件</h2><p>之前的文章中我们提到过，在UNIX系统下本地连接MySQL可以采用UNIX域套接字方式，这种方式需要一个套接字（socket）文件。套接字文件可由参数socket控制。一般在/tmp 目录下，名为mysql.sock∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-27971b64ed5d9b0d3d21735b54082076be9.png" alt=""></p>
<h2 id="1-4-pid文件"><a href="#1-4-pid文件" class="headerlink" title="1.4 pid文件"></a>1.4 pid文件</h2><p>当MySQL实例启动时，会将自己的进程ID写入一个文件中——该文件即为pid文件。该文件可由参数pid_file控制，默认位于数据库目录下，文件名为主机名.pid∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5d5410fd7723a267507026c3c8aea14ad95.png" alt=""></p>
<h2 id="1-5-表结构定义文件"><a href="#1-5-表结构定义文件" class="headerlink" title="1.5 表结构定义文件"></a>1.5 表结构定义文件</h2><p>MySQL数据的存储是根据表进行的，但因为MySQL插件式存储引擎的体系结构的关系，所以MySQL要在存储引擎之上将表信息记录下来，于是，MySQL为每个表都定义与之对应的文件。不论表采用何种存储引擎，MySQL都有一个以frm为后缀名的文件，这个文件记录了该表的表结构定义。</p>
<p>frm还用来存放视图的定义，如用户创建了一个va视图，那么对应地会产生一个v_a.frm文件，用来记录视图的定义，该文件是文本文件，可以直接使用cat命令进行查看∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-da9b95f3bb49699a68f530e23797414618a.png" alt=""></p>
<h2 id="1-6-InnoDB存储引擎文件"><a href="#1-6-InnoDB存储引擎文件" class="headerlink" title="1.6 InnoDB存储引擎文件"></a>1.6 InnoDB存储引擎文件</h2><p>之前介绍的文件都是MySQL数据库本身的文件，和存储引擎无关。除了这些文件外，每个表存储引擎还有其自己独有的文件。本节将具体介绍与InnoDB存储引擎密切相关的文件，这些文件包括重做日志文件、表空间文件。</p>
<h3 id="1-6-1-表空间文件"><a href="#1-6-1-表空间文件" class="headerlink" title="1.6.1 表空间文件"></a>1.6.1 表空间文件</h3><p>InnoDB采用将存储的数据按表空间（tablespace）进行存放的设计。在默认配置下会有一个初始大小为10MB，名为ibdata1的文件。该文件就是默认的表空间文件（tablespace file），又称作<strong>共享表空间</strong>，用户可以通过参数innodb_data_file_path对其进行设置，格式如下∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7a23c3bfaca6805e33740c49fa5ab0eb7dc.png" alt=""></p>
<p>用户可以通过多个文件组成一个表空间，同时制定文件的属性，如∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e51162c902e23c04cbcf254b852dda4502f.png" alt=""></p>
<p>这里将/db/ibdata1和/dr2/db/ibdata2两个文件用来组成表空间。若这两个文件位于不同的磁盘上，磁盘的负载可能被平均，因此可以提高数据库的整体性能。同时，两个文件的文件名后都跟了属性，表示文件idbdata1的大小为2000MB，文件ibdata2的大小为2000MB，如果用完了这2000MB，该文件可以自动增长（autoextend）。</p>
<p>设置<code>innodb_data_file_path</code>参数后，所有基于InnoDB存储引擎的表的数据都会记录到该<strong>共享表空间</strong>中。若设置了参数<code>innodb_file_per_table</code>，则用户可以将每个基于InnoDB存储引擎的表产生一个独立表空间。独立表空间的命名规则为∶表名.ibd。通过这样的方式，用户不用将所有数据都存放于共享表空间中。</p>
<p>下面这台MySQL数据库服务器设置了<code>innodb_file_per_table</code>，故可以观察到∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a9dd36b64935cb056ec5b1b365e10efb40d.png" alt=""></p>
<p>表Profile、t1和t2都是基于InnoDB存储的表，由于设置参数<code>innodb_file_per_table=ON</code>，因此产生了单独的.ibd独立表空间文件。</p>
<p>直到这里，我们知道了表空间有两种：</p>
<ol>
<li>共享表文件：<code>innodb_data_file_path</code>参数指向的ibdata1这种文件。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-7c5ac8a6a59f66a5069f82358a7d6cc7a8d.png" alt=""></li>
</ul>
</li>
<li>单独表文件：由于设置参数<code>innodb_file_per_table=ON</code>，因此产生了单独的.ibd独立表空间文件。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-f47d86f905134c1cff8100e6e9ff99140e9.png" alt=""></li>
</ul>
</li>
</ol>
<blockquote>
<p>需要注意的是，这些单独的表空间文件（tableName.ibd）仅存储该表的数据、索引和插入缓冲Bitmap等信息，其余信息，如回滚（undo）信息，插入缓冲索引页、系统事务信息，二次写缓冲（Double write buffer）等信息，还是存放在共享表空间（ibdata1文件）中。</p>
</blockquote>
<p>下图显示了InnoDB存储引擎对于文件的存储方式</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f63c067633b130643ee0baf138d33fc5376.png" alt=""></p>
<h3 id="1-6-2-redo-log文件"><a href="#1-6-2-redo-log文件" class="headerlink" title="1.6.2 redo log文件"></a>1.6.2 redo log文件</h3><p>在默认情况下，在InnoDB存储引擎的数据目录下会有两个名为ib_logfile0和ib_logfile1的文件。在MySQL官方手册中将其称为InnoDB存储引擎的日志文件，不过更准确的定义应该是重做日志文件（redo log file）。为什么强调是重做日志文件呢?因为重做日志文件对于InnoDB存储引擎至关重要，它们记录了对于InnoDB存储引擎的事务日志。</p>
<p>当实例或介质失败（media failure）时，重做日志文件就能派上用场。例如，数据库由于所在主机掉电导致实例失败，InnoDB存储引擎会使用重做日志恢复到掉电前的时刻，以此来保证数据的完整性。</p>
<p>每个InoDB存储引擎至少有1个重做日志文件组（group），每个文件组下至少有2个重做日志文件，如默认的ib_logfile0和ib_logfile1。为了得到更高的可靠性，用户可以设置多个的镜像日志组（mirored log groups），将不同的文件组放在不同的磁盘上，以此提高重做日志的高可用性。在日志组中每个重做日志文件的大小一致，并以循环写入的方式运行。</p>
<p>InnoDB存储引擎先写重做日志文件1，当达到文件的最后时会切换至重做日志文件2，再当重做日志文件2也被写满时，会再切换到重做日志文件1中。</p>
<p>redo log文件详情，可见本站文章《【InnoDB详解四】redo log和undo log》</p>
<h1 id="2-InnoDB存储结构"><a href="#2-InnoDB存储结构" class="headerlink" title="2 InnoDB存储结构"></a>2 InnoDB存储结构</h1><p>我们接下来将从InnoDB存储引擎表的逻辑存储及实现开始进行介绍，然后将重点分析表的物理存储特征，即数据在表中是如何组织和存放的。简单来说，表就是关于特定实体的数据集合，这也是关系型数据库模型的核心。</p>
<p>在InnoDB存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表（index organized table）。在InnoDB存储引擎表中，每张表都有个主键（Primary Key），如果在创建表时没有显式地定义主键，则InnoDB存储引擎会按如下方式选择或创建主键∶</p>
<ol>
<li>首先判断表中是否有非空的唯一索引（Unique NOTNULL），如果有，则该列即为主键。</li>
<li>如果不符合上述条件，InnoDB存储引擎自动创建一个6字节大小的指针。当表中有多个非空唯一索引时，InnoDB存储引擎将选择建表时第一个定义的非空唯一索引为主键。这里需要非常注意的是，<strong>主键的选择根据的是定义索引的顺序，而不是建表时列的顺序</strong>。</li>
</ol>
<h2 id="2-1-InnoDB逻辑存储结构"><a href="#2-1-InnoDB逻辑存储结构" class="headerlink" title="2.1 InnoDB逻辑存储结构"></a>2.1 InnoDB逻辑存储结构</h2><p>从 InnoDB存储引擎的<strong>逻辑</strong>存储结构看，所有数据都被<strong>逻辑地</strong>存放在一个空间中，称之为表空间（tablespace）。表空间又由段（segment）、区（extent）、页（page）组成。页在一些文档中有时也称为块（block），InnoDB存储引擎的逻辑存储结构大致如图4-1所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-dde687244bd19181c20420210e6075394e6.png" alt=""></p>
<p>表空间可以看做是InnoDB存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。前文我们已经介绍了表空间，并且知道了表空间分为共享表空间和独立表空间（若有），这里就不再赘述了。</p>
<h3 id="2-1-1-段"><a href="#2-1-1-段" class="headerlink" title="2.1.1 段"></a>2.1.1 段</h3><p>图4-1中显示了表空间是由各个段组成的，常见的段有<strong>数据段、索引段、回滚段</strong>等。</p>
<p>因为前面已经介绍过了InnoDB存储引擎表是索引组织的（index organized），因此数据即索引，索引即数据。那么数据段即为B+树的叶子节点（图4-1的Leafnode segment），索引段即为B+树的非索引节点（图4-1的Non-leaf node segment）。</p>
<p>回滚段较为特殊，将会在后面的章节进行单独的介绍。</p>
<p>在InnoDB存储引擎中，对段的管理都是由引擎自身所完成，DBA不能也没有必要对其进行控制。这和Oracle数据库中的自动段空间管理（ASSM）类似，从一定程度上简化了DBA 对于段的管理。</p>
<h3 id="2-1-2-区"><a href="#2-1-2-区" class="headerlink" title="2.1.2 区"></a>2.1.2 区</h3><p>区是由连续页组成的空间，在任何情况下每个区的大小都为1MB。为了保证区中页的连续性，InnoDB存储引擎一次从磁盘申请4～5个区。在默认情况下，InnoDB存储引擎页的大小为16KB，即一个区中一共有64个连续的页。</p>
<p>InnoDB1.0.x版本开始引入压缩页，即每个页的大小可以通过参数KEY_BLOCK_SIZE设置为2K、4K、8K，因此每个区对应页的数量就应该为512、256、128。</p>
<p>InnoDB 1.2.x版本新增了参数 innodb_page_size，通过该参数可以将默认页的大小设置为4K、8K，但是页中的数据库不是压缩。这时区中页的数量同样也为256、128。总之，不论页的大小怎么变化，区的大小总是为1M。</p>
<p>但是，这里还有这样一个问题∶在用户启用了参数innodb_file_per_talbe后，创建的表默认大小是96KB。区中是64个连续的页，创建的表的大小至少是1MB才对啊，这是什么原因呢?</p>
<p>其实这是因为在每个段开始时，<strong>先用32个页大小的碎片页（fragment page）来存放数据，在使用完这些页之后才是64个连续页的申请</strong>。这样做的目的是，对于一些小表，或者是undo这类的段，可以在开始时申请较少的空间，节省磁盘容量的开销。</p>
<h3 id="2-1-3-页"><a href="#2-1-3-页" class="headerlink" title="2.1.3 页"></a>2.1.3 页</h3><p>同大多数数据库一样，InnoDB有页（Page）的概念（也可以称为块），页是InnoDB磁盘管理的最小单位。在InnoDB存储引擎中，默认每个页的大小为16KB。而从InnoDB 1.2.x版本开始，可以通过参数innodb_page_size将页的大小设置为4K、8K、16K。</p>
<p>若设置完成，则所有表中页的大小都为innodb_page_size，不可以对其再次进行修改。除非通过mysqldump导入和导出操作来产生新的库。</p>
<p>页是InnoDB磁盘管理的最小单位：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4b9e083e4419ed6d4a329215524a2d2a4b7.png" alt=""></p>
<blockquote>
<p>在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，InnoDB存储引擎一个页的大小是16K。</p>
</blockquote>
<h4 id="2-1-3-1-页的类型"><a href="#2-1-3-1-页的类型" class="headerlink" title="2.1.3.1 页的类型"></a>2.1.3.1 页的类型</h4><p>在InnoDB存储引擎中，常见的页类型有∶</p>
<ol>
<li>数据页（B-tree Node）</li>
<li>undo页（undo Log Page）</li>
<li>系统页（System Page）</li>
<li>事务数据页（Transaction system Page）</li>
<li>插入缓冲bitmap页（Insert Buffer Bitmap）</li>
<li>插入缓冲空闲列表页（Insert Buffer Free List）</li>
<li>未压缩的二进制大对象页（Uncompressed BLOB Page）</li>
<li>压缩的二进制大对象页（compressed BLOB Page）</li>
</ol>
<p>在页的File Header结构中，FIL_PAGE_TYPE字段被用来区分数据页的类型（后文会介绍），他们的值如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-96b64aa4d0334ea009a815bc45dd48924ab.png" alt=""></p>
<h3 id="2-1-4-行"><a href="#2-1-4-行" class="headerlink" title="2.1.4 行"></a>2.1.4 行</h3><p>InnoDB存储引擎是面向列的（row-oriented），也就说数据是按行进行存放的。每个页存放的行记录也是有硬性定义的，最多允许存放16KB/2-200行的记录，即7992行记录。</p>
<blockquote>
<p>这里提到了row-oriented的数据库，也就是说，存在有colum-riented的数据库。MySQL infobright存储引擎就是按列来存放数据的，这对于数据仓库下的分析类 SQL语句的执行及数据压缩非常有帮助。类似的数据库还有Sybase IQ、Google Big Table。面向列的数据库是当前数据库发展的一个方向，但这超出了本书涵盖的内容，有兴趣的读者可以在网上寻找相关资料。</p>
</blockquote>
<h2 id="2-2-InnoDB存储格式"><a href="#2-2-InnoDB存储格式" class="headerlink" title="2.2 InnoDB存储格式"></a>2.2 InnoDB存储格式</h2><h3 id="2-2-1-InnoDB行记录格式"><a href="#2-2-1-InnoDB行记录格式" class="headerlink" title="2.2.1 InnoDB行记录格式"></a>2.2.1 InnoDB行记录格式</h3><p>InnoDB存储引擎和大多数数据库一样（如 Oracle和Microsof SQL Server数据库），记录是以行的形式存储的。这意味着页中保存着表中一行行的数据。在InmoDB1.0x版本之前，InnoDB存储引擎提供了Compact和Redundant两种格式来存放行记录数据，这也是目前使用最多的一种格式。</p>
<p>Redundant格式是为兼容之前版本而保留的，如果阅读过InnoDB的源代码，用户会发现源代码中是用PHYSICALRECORD（NEW STYLE）和PHYSICALRECORD（OLD STYLE）来区分两种格式的。</p>
<p>在MySQL5.1版本中，默认设置为Compact行格式。用户可以通过命令SHOW TABLE STATUS LIKE’table_name’来查看当前表使用的行格式，其中row_format 属性表示当前所使用的行记录结构类型。如∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-52ac4e4b7bd5e8d753a861b5a795d430c68.png" alt=""></p>
<p>可以看到，这里的mytest表是Compact的行格式，mytest2表是Redundant的行格式。</p>
<h4 id="2-2-1-1-Compact类型格式"><a href="#2-2-1-1-Compact类型格式" class="headerlink" title="2.2.1.1 Compact类型格式"></a>2.2.1.1 Compact类型格式</h4><p>Compact行记录是在MySQL5.0中引入的，其设计目标是高效地存储数据。简单来说，一个页中存放的行数据越多，其性能就越高。下图显示了Compact行记录的存储方式∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9f530fbc68f17136efaced7cf23194a2e62.png" alt=""></p>
<ol>
<li>变长字段长度列表<ul>
<li>这部分用来记录该行中每个varchar字段的长度（注意，只记录varchar字段的长度，单位是字节），假设数据行中会有n个varchar列，所以该部分也会对应存储n个长度值。</li>
<li><strong>每个varchar列的长度一般用一个字节（对应字段真正长度 &lt; 128字节），最多只能用两个字节（16 bit）（对应字段真正长度 &gt;= 128字节）表示</strong>，所以在MySQL数据库中varchar类型的最大长度限制为65535字节（2的16次方）。</li>
<li>不过这里就有问题了，如果a列的长度占用1个字节，b列的长度占用两个字节，那解析的时候如何知道这三个字节的分界线呢？InnoDB规定如果某个字节最高位为0，那么这个字节就是独立的字节；如果某个字节最高位为1，那么就和它后面的字节共同表示一个长度（第二个字节可以用所有位表示长度）。<strong>也正是因为字节首位另有用处，所以一个字节最多表示长度为小于128</strong>。</li>
<li>所以如果a，b两列长度紧密排列，如<code>01111111 10000000 10000000</code>，那就可以知道分界线是<code>01111111 | 10000000 10000000</code>。需要注意的是，MySQL采取 Little Endian 的计数方式，低位在前，高位在后，所以129用两个字节表示就是 <code>10000001 10000000</code>。</li>
<li>变长字段长度列表中每个长度值的排序，和行中varchar列的顺序是相反的，也就是长度值在变长字段长度列表中是倒序存放</li>
</ul>
</li>
</ol>
<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 假如有三个字段 id,name,desc,age。其中name,desc是变长类型（Varchar）</span><br><span class="line">|id|name|desc|age|</span><br><span class="line">|1|wang|shuaige|18|</span><br><span class="line">|2|li|meinv|20|</span><br><span class="line">	</span><br><span class="line">则磁盘里的存储为：</span><br><span class="line">0x07 0x04 null值列表 数据头 1 wang shuaige 18 0x05 0x02 null值列表 数据头 2 li meinv 20</span><br><span class="line"># 其中0x04表示name长度为4 ,0x07表示desc的长度为7，以此类推。</span><br></pre></td></tr></table></figure></code></pre><ol start="2">
<li><p>NULL标志位</p>
<ul>
<li>该部分用来标记该行中哪些列的值是NULL值。</li>
<li>它是一个bitmap，一般占用1个字节（8 bit），它的每一位位指示了该行数据中对应的列是否是NULL值，有则用1表示。</li>
<li>比如NULL标志位如果为0x06，二进制是00000110，很显然第2位和第3位的值是1，那么就表示该行的第二列和第三列当前值为NULL。</li>
<li>NULL标志位一般是占用1个字节，但如果列的数量大于8个，那么会多扩充一个字节，直到能涵盖所有的列。</li>
</ul>
</li>
<li><p>记录头信息（record header）</p>
<ul>
<li>固定占用5字节（40位），每位的含义见下图：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-516d623552830ed65906b93d067e5754855.png" alt=""></li>
<li>值得注意的是RecordHeader的最后两个字节，这16 bit是next_recorder，代表下一个记录的偏移量，假设该值为0x2c，那么它表示当前记录的位置加上偏移量0x2c就是下条记录的起始位置。所以InnoDB存储引擎在页内部是通过一种链表的结构来串连各个行记录的。</li>
</ul>
</li>
<li><p>列数据</p>
<ul>
<li>最后的部分就是实际存储每个列的数据。需要特别注意的是，NULL不占该部分任何空间，即NULL除了占有NULL标志位，实际存储不占有任何空间。</li>
<li>另外有一点需要注意的是，每行数据除了用户定义的列外，还有两个隐藏列，事务ID列和回滚指针列，分别为6字节和7字节的大小，这两个部分与InnoDB实现MVCC有关，版本控制、事务回滚等内容，这里不详述。若InnoDB表没有定义主键，每行还会增加一个6字节的rowid列。</li>
</ul>
</li>
</ol>
<p>我们来用一个实际的例子分析Compact行记录格式吧：</p>
<p>我们先定义一个表mytest，其中t1，t2，t4是变长的varchar类型，t3是固定长度的char类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;mytest&#96; (</span><br><span class="line">&#96;t1&#96; varchar(10) DEFAULT NULL,</span><br><span class="line">&#96;t2&#96; varchar(10) DEFAULT NULL,</span><br><span class="line">&#96;t3&#96; char(10) DEFAULT NULL,</span><br><span class="line">&#96;t4&#96; varchar(10) DEFAULT NULL</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latin1 ROW_FORMAT&#x3D;COMPACT</span><br></pre></td></tr></table></figure>

<p>我们插入如下记录（其中–表示NULL）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from mytest;</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| t1 | t2 | t3 |  t4 |</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| a  | bb | bb | ccc |</span><br><span class="line">| d  | ee | ee | fff |</span><br><span class="line">| d  | -- | -- | fff |</span><br><span class="line">+----+----+----+-----+</span><br></pre></td></tr></table></figure>

<p>然后将打开表空间文件mytest.ibd（这里启用了innodb_file_per_table，若没有启用该选项，打开默认的共享表空间文件 ibdata1）。</p>
<p>在Windows操作系统下，可以选择通过程序UltraEdit打开该二进制文件。在Linux 环境下，使用命令<code>hexdump-C-v mytest.ibd&gt;mytest.txt</code>。这里将结果重定向到了文件mytes.txt，打开 mytest.txt文件，找到如下内容∶</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0000c070 73 75 70 72 65 6d 75 6d 03 02 01 00 00 00 10 00|supremum……</span><br><span class="line">0000c080 2c 00 00 00 2b 68 00 00 00 00 00 06 05 80 00 00|，……+h……</span><br><span class="line">0000c090 00 32 01 10 61 62 62 62 62 20 20 20 20 20 20 20|.2..abbbb</span><br><span class="line">0000c0a0 20 63 63 63 03 02 01 00 00 00 18 00 2b 00 00 00|ccc……+……</span><br><span class="line">0000c0b0 2b 68 01 00 00 00 00 06 06 80 00 00 00 32 01 10|+h……2..</span><br><span class="line">0000c0c0 64 65 65 65 65 20 20 20 20 20 20 20 20 66 66 66|deeeefff</span><br><span class="line">0000c0d0 03 01 06 00 00 20 ff 98 00 00 00 2b 68 02 00 00|……+h……</span><br><span class="line">0000c0e0 00 00 06 07 80 00 00 00 32 01 10 64 66 66 66 00|……2..dfff.</span><br></pre></td></tr></table></figure>

<p>第一行记录（a,bb,bb,ccc）从0000c078开始，我们整理一下，下面都是16进制数，如03就是0x03：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">03 02 01&#x2F;*变长字段长度列表，分别记录t1，t2，t4的长度，逆序*&#x2F;</span><br><span class="line">00&#x2F;*NULL标志位，第一行没有NULL值*&#x2F;</span><br><span class="line">00 00 10 00 2c&#x2F;*记录头信息，固定5字节长度*&#x2F;</span><br><span class="line">00 00 00 2b 68 00&#x2F;*RowID我们建的表没有主键，因此会有RowID*&#x2F;</span><br><span class="line">00 00 00 00 06 05&#x2F;*TransactionID*&#x2F;</span><br><span class="line">80 00 00 00 32 01 10&#x2F;*Roll Pointer*&#x2F;</span><br><span class="line">61&#x2F;*t1数据&#39;a&#39;*&#x2F;</span><br><span class="line">62 62&#x2F;*t2&#39;bb&#39;*&#x2F;</span><br><span class="line">62 62 20 20 20 20 20 20 20 20&#x2F;*t3数据&#39;bb&#39;，因为t3列是固定长度的char类型，所以可以看到，未占用的地方，char用0x20（空格）补全*&#x2F;</span><br><span class="line">63 63 63&#x2F;*t4数据&#39;ccc&#39;*&#x2F;</span><br></pre></td></tr></table></figure>

<p>我们再来看有NULL值的第三行记录（d,NULL,NULL,fff），</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">03 01&#x2F;*变长字段长度列表，逆序*&#x2F;</span><br><span class="line">06&#x2F;*NULL标志位，06的二进制是00000110，很显然第2位和第3位的值是1，所以t2和t3是NULL*&#x2F;</span><br><span class="line">00 00 20 ff 98&#x2F;*记录头信息*&#x2F;</span><br><span class="line">00 00 00 2b 68 02&#x2F;*RowID*&#x2F;</span><br><span class="line">00 00 00 00 06 07&#x2F;*TransactionID*&#x2F;</span><br><span class="line">80 00 00 00 32 01 10&#x2F;*Roll Pointer*&#x2F;</span><br><span class="line">64&#x2F;*t1数据&#39;d&#39;*&#x2F;</span><br><span class="line">66 66 66&#x2F;*t4数据&#39;fff&#39;*&#x2F;</span><br></pre></td></tr></table></figure>

<p>可以发现不管是char还是varchar，NULL都不占用任何空间。</p>
<h4 id="2-2-1-2-Redundant类型格式"><a href="#2-2-1-2-Redundant类型格式" class="headerlink" title="2.2.1.2 Redundant类型格式"></a>2.2.1.2 Redundant类型格式</h4><p>Redundant是MySQL 5.0版本之前InnoDB的行记录存储方式，MySQL 5.0支持Redundant是为了兼容之前版本的页格式。Redundant行记录采用如下所示的方式存储。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8eac0bc22f7a4dbd8dca7ef7491b534d190.png" alt=""></p>
<ol>
<li>字段长度偏移列表<ul>
<li>不同于Compact行记录格式，Redundant行记录格式的首部是一个字段长度<strong>偏移</strong>列表，同样是按照列的顺序<strong>逆序</strong>放置的。</li>
<li>注意该列表记录的是每个列长度的偏移量，而不是长度值本身，比如某个字段长度偏移列表经整理后为<code>23 20 16 14 13 0c 06</code>，因为是逆序排布，所以我们先翻为正序<code>06，0c，13，14，16，20，23</code>，那么这表示：第一列的长度是6，第二列的长度是6（6+6=0x0C），第三列的长度为7（6+6+7=0x13），第四列的长度是1（6+6+7+1=0x14），第五列的长度是2（6+6+7+1+2=0x16），第六列的长度是10（6+6+7+1+2+10=0x20），第七列的长度是3（6+6+7+1+2+10+3=0x23）。</li>
<li>同样的，长度列表中每个列的长度的偏移值一般用一个字节，最多用两个字节来存储。不过不同于compact格式，compact格式允许a列使用1个字节，b列使用两个字节，但是Redundant的话，<strong>要么所有列的偏移值都占用1字节，要么都占用2字节</strong>。</li>
<li>到底每个偏移使用1字节还是2字节，是根据整行记录的长度决定，如果<strong>整行长度</strong>小于 128，则用1字节存储，否则，用2字节。<ul>
<li>如果是1字节存储的情况，那么每个字节最高的那个bit用来标记对应字段值是否为 NULL，如果为NULL，则最高位为1，否则为0。剩下的7位用来存储长度偏移量，所以最多是127。</li>
<li>对于两字节存储，首个字节的最高位还是用来标记对应字段值是否为NULL。最高的第二位则用来标记这条记录是否在同一页，如果在则为0，如果不在则为1，这其实就涉及到了后面要说的溢出页。剩下的连同第二个字节完整8bit在内的14bit表示长度，所以最多是16383</li>
</ul>
</li>
</ul>
</li>
<li>记录头信息（record header）<ul>
<li>不同于Compact行记录格式，Redundant行记录格式的记录头占用6字节（48 位），每位的含义见下表</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-c935a4248a4f545e00e0a7d004ac8d1d5ed.png" alt=""></li>
<li>从中可以发现，n_fields值代表一行中列的数量，占用10位。同时这也很好地解释了为什么MySQL数据库一行支持最多的列为1023。因为2的10次方为1024</li>
<li>另一个需要注意的值为1byte_offs_flag，该值定义了字段长度偏移列表占用的是1字节还是2字节。</li>
</ul>
</li>
<li>列数据<ul>
<li>最后的部分就是实际存储每个列的数据。需要特别注意的是，varchar类型的NULL不占该部分任何空间，char类型的NULL占用固定空间。</li>
<li>另外有一点需要注意的是，每行数据除了用户定义的列外，还有两个隐藏列，事务ID列和回滚指针列，分别为6字节和7字节的大小，这两个部分与InnoDB实现MVCC有关，版本控制、事务回滚等内容，这里不详述。若InnoDB表没有定义主键，每行还会增加一个6字节的rowid列。</li>
</ul>
</li>
</ol>
<p>好，我们也来看下Redundant格式的例子，还是那张表和那些记录：</p>
<p>其中t1，t2，t4是变长的varchar类型，t3是固定长度的char类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from mytest;</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| t1 | t2 | t3 |  t4 |</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| a  | bb | bb | ccc |</span><br><span class="line">| d  | ee | ee | fff |</span><br><span class="line">| d  | -- | -- | fff |</span><br><span class="line">+----+----+----+-----+</span><br></pre></td></tr></table></figure>

<p>我们直接来看有NULL的第三行（下面都是16进制表示）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a1 9e 94 14 13 0c 06&#x2F;*长度偏移列表，逆序*&#x2F;</span><br><span class="line">00 00 20 0f 00 74&#x2F;*记录头信息，固定6个字节*&#x2F;</span><br><span class="line">00 00 00 2b 68 0d&#x2F;*RowID*&#x2F;</span><br><span class="line">00 00 00 00 06 53&#x2F;*TransactionID*&#x2F;</span><br><span class="line">80 00 00 00 32 01 10&#x2F;*Roll Point*&#x2F;</span><br><span class="line">64&#x2F;*t1数据&#39;d&#39;*&#x2F;</span><br><span class="line">00 00 00 00 00 00 00 00 00 00&#x2F;*t3数据NULL*&#x2F;</span><br><span class="line">66 66 66&#x2F;*t4数据&#39;fff&#39;*&#x2F;</span><br></pre></td></tr></table></figure>

<p>可以看到：</p>
<ol>
<li>来看长度偏移列表，<code>21 9e 94 14 13 0c 06</code>翻转为正序是<code>06 0c 13 14 94 9e 21</code>，我们前面说过，每个字节中首位用来表示字段是否为NULL，后面7位才表示偏移值，这里需要将每个字节分成两部分（1bit | 7bit），并转化为十进制是<code>0|6 0|12 0|19 0|20 1|20 1|30 0|33</code></li>
<li>该行中varchar类型的t2列，因为值为NULL，故而在Redundant格式中没有占用任何空间，所以我们看不到t2，t2位NULL的信息其实旨在长度偏移列表中体现了，也就是上文说到的<code>1|20</code>这个字节。但同样为NULL值的t3数据，除了在偏移列表中体现外，却真的占用了10个字节，可见，<strong>在Redundant格式中，varchar类型的NULL不占用空间，char类型的NULL固定占用10字节空间</strong>。</li>
<li>记录头信息中应该注意48位中22～32位（n_fields），为0000000111，表示表共有7个列（包含了隐藏的3列），接下去的33位（1byte_offs_flag）为1，代表偏移列表中每个偏移量占用一个字节。</li>
</ol>
<blockquote>
<p>当前表mytest的字符集为Latin1，每个字符最多只占用1个字节。若这里将表mytest的字符集转换为utf8，则第三列char固定长度类型就不再是只占用10个字节了，而是10×3=30个字节，Redundant行格式下char固定字符类型将会占据可能存放的最大值字节数。</p>
</blockquote>
<h4 id="2-2-1-3-行溢出数据"><a href="#2-2-1-3-行溢出数据" class="headerlink" title="2.2.1.3 行溢出数据"></a>2.2.1.3 行溢出数据</h4><p>InnoDB存储引擎可以将一条记录中的某些数据存储在数据页之外，而不是存放在行记录所在的当前页中，这类数据就叫行溢出数据。什么情况下会出现行溢出数据呢？答案是一个页（16K）放不下的时候，一些数据必然要溢出。</p>
<p>于是我们可以想到BLOB、LOB这类的大对象列类型的存储，InnoDB应该会把数据存放在数据页面之外。但是，这个理解有点偏差，其实BLOB、LOB这类的大对象并不一定非要溢出，而常见的varchar类型也并不一定不会溢出。</p>
<p>那么什么时候会产生行溢出数据呢？这个阈值是多少呢？</p>
<p>前文我们说过，<strong>数据页会被InnoDB以B+树的形式给整理起来</strong>，这就要求了：<strong>一个数据页中应该至少能存两条行记录</strong>（如果一个页只能存一行，那B+树就没有意义了，数据结构就成链表了）</p>
<p>基于这个要求，我们知道一个页为16KB，即16384字节，那么扣除掉页中如header，tail，dictionary等固定字段外，再对半分，则可以得出一行记录不发生行溢出的最大长度上限：<strong>8098字节</strong>。</p>
<p>那么，如果一行记录长度超过了8098字节，InnoDB又会如何存储呢？</p>
<p>在一般情况下，InnoDB存储引擎的数据都是存放在页类型为B-tree node（也就是数据页）的页中。但是当发生行溢出时，数据溢出部分存放在页类型为Uncompress BLOB的页中：</p>
<p>假设我们创建一个列a长度为65532的表t，并插入一条数据</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3164ed940f9d57e06258f6a7c4f77c38145.png" alt=""></p>
<p>通过工具可以观察到表空间中有一个数据页节点B-tree Node，另外有4个未压缩的二进制大对象页Uncompressed BLOB Page，在这些页中才真正存放了65532字节的数据。既然实际存放的数据都在BLOB页中，那数据页中又存放了些什么内容呢?同样通过之前的 hexdump来读取表空间文件，从数据页c000开始查看∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d9bed37dbfbb79292b1af2f46fa441bc2f6.png" alt=""></p>
<p>可以看到，从0x0000c093到0x000c392数据页面其实只保存了VARCHAR（65532）的<strong>前768字节的前缀</strong>（prefix）数据（这里都是a）。然后之后是行溢出页指针（20字节），指向行溢出页，也就是前面用户看到的Uncompressed BLOB Page。因此，对于行溢出数据，其存放采用下图的方式。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-098ad59f67bb0fd52b16d1d84dcfb0809dc.png" alt=""></p>
<h4 id="2-2-1-4-Compressed-Dynamic类型格式"><a href="#2-2-1-4-Compressed-Dynamic类型格式" class="headerlink" title="2.2.1.4 Compressed/Dynamic类型格式"></a>2.2.1.4 Compressed/Dynamic类型格式</h4><p>InnoDB Plugin引入了新的文件格式（file format，可以理解为新的页格式），对于以前支持的Compact和Redundant格式将其称为Antelope文件格式，新的文件格式称为Barracuda。</p>
<p>Barracuda文件格式下拥有两种新的行记录格式Compressed和Dynamic两种。新的两种格式对于存放BLOB的数据采用了完全的行溢出的方式，在数据页中只存放20个字节的指针，实际的数据都存放在BLOB Page中，而之前的Compact和Redundant两种格式会存放768个前缀字节。</p>
<p>下图是Barracuda文件格式的溢出行：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7647fad5539a242a7fdf54a7f1b531af2f2.png" alt=""></p>
<p>Compressed行记录格式的另一个功能就是，存储在其中的行数据会以<strong>zlib的算法</strong>进行压缩，因此对于BLOB、TEXT、VARCHAR这类大长度类型的数据能够进行非常有效的存储。</p>
<h4 id="2-2-1-5-CHAR类型字段的存储"><a href="#2-2-1-5-CHAR类型字段的存储" class="headerlink" title="2.2.1.5 CHAR类型字段的存储"></a>2.2.1.5 CHAR类型字段的存储</h4><p>通常理解 VARCHAR是存储变长长度的字符类型，CHAR是存储固定长度的字符类型。而在前面的小节中，用户已经了解行结构的内部的存储，并可以发现每行的变长字段长度的列表都没有存储CHAR类型的长度。</p>
<p>然而，值得注意的是之前给出的两个例子中的字符集都是单字节的latin1格式。从MySQL4.1版本开始，CHAR（N）中的N指的是字符的个数，而不是之前版本的字节长度。也就说在不同的字符集下，CHAR类型列内部存储的可能不是定长的数据。</p>
<p>例如，对于UTF-8下CHAR（10）类型的列，其最小可以存储10字节的字符（都是拉丁字母），而最大可以存储30字节的字符（10个字符都是汉字）。因此，对于多字节字符编码的CHAR数据类型的存储，<strong>InnoDB存储引擎在内部将其视为VARCHAR变长字符类型</strong>。这也就意味着在变长长度列表中会记录CHAR 数据类型的长度。</p>
<p><strong>因此可以认为在多字节字符集的情况下，CHAR和VARCHAR的实际行存储基本是没有区别的</strong>。</p>
<h3 id="2-2-2-数据页的存储格式"><a href="#2-2-2-数据页的存储格式" class="headerlink" title="2.2.2 数据页的存储格式"></a>2.2.2 数据页的存储格式</h3><p>我们已经知道页是InnoDB存储引擎管理数据库的最小磁盘单位。类型为B-tree Node的页存放的即是表中行的实际数据了。页的结构如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c831f98dd011f807e7100bca08e9c01a305.png" alt=""></p>
<h4 id="2-2-2-1-File-Header"><a href="#2-2-2-1-File-Header" class="headerlink" title="2.2.2.1 File Header"></a>2.2.2.1 File Header</h4><p><strong>File Header</strong> 字段用于记录 Page 的头信息。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b844420e80d52e767ccff0e0a6ef7ebbe0f.png" alt=""></p>
<p>其中比较重要的是 FIL_PAGE_PREV 和 FIL_PAGE_NEXT 字段，它们分别是B+树叶子节点双向链表的前驱和后驱，通过这两个字段，我们可以找到该页的上一页和下一页，实际上所有页通过两个字段可以形成一条双向链表。</p>
<h4 id="2-2-2-2-Page-Header"><a href="#2-2-2-2-Page-Header" class="headerlink" title="2.2.2.2 Page Header"></a>2.2.2.2 Page Header</h4><p><strong>Page Header</strong> 字段用于记录页的状态信息。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-8cfcdf1e3da990c1f0e4164467457bd9da5.png" alt=""></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-e398686bcf847a72564b954a18f4acd5608.png" alt=""></li>
</ul>
<h4 id="2-2-2-3-Infimum-和-Supremum"><a href="#2-2-2-3-Infimum-和-Supremum" class="headerlink" title="2.2.2.3 Infimum 和 Supremum"></a>2.2.2.3 Infimum 和 Supremum</h4><p><strong>Infimum 和 Supremum</strong> 是两个虚拟的行记录，用来确定真实的行记录的边界。</p>
<p>Infimum（下确界）记录比该页中任何主键值都要小的值，Supremum （上确界）记录比该页中任何主键值都要大的值，这个虚拟记录分别构成了页中记录的边界。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f5a741681f7bda057e0743abc1605d5ee30.png" alt=""></p>
<h4 id="2-2-2-4-User-Records"><a href="#2-2-2-4-User-Records" class="headerlink" title="2.2.2.4 User Records"></a>2.2.2.4 User Records</h4><p><strong>User Records</strong> 中存放的是<strong>实际的数据行记录</strong>，行记录的格式，我们在上文中已经介绍过了，有compact/redundant等格式。</p>
<p>我们再来复习一下，不论是什么格式，行记录都有一个记录头信息部分（record header）</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9f530fbc68f17136efaced7cf23194a2e62.png" alt=""></p>
<p>记录头中各个字段如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-516d623552830ed65906b93d067e5754855.png" alt=""></p>
<p>值得注意的是Record Header的最后两个字节，这16 bit是next_recorder，代表下一个记录的偏移量，假设该值为0x2c，那么它表示当前记录的位置加上偏移量0x2c就是下条记录的起始位置。<strong>所以行记录在User Records中是通过一种链表的结构来串连起来的</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-11431516dbe26aa0eb8739349aa5f33dec4.png" alt=""></p>
<p>排序顺序一般是根据primary key升序放置。</p>
<h4 id="2-2-2-5-Free-Space"><a href="#2-2-2-5-Free-Space" class="headerlink" title="2.2.2.5 Free Space"></a>2.2.2.5 Free Space</h4><p><strong>Free Space</strong> 中存放的是空闲空间，当一条行记录被删除后，它的空间会被加入到空闲列表中。</p>
<h4 id="2-2-2-6-Page-Directory"><a href="#2-2-2-6-Page-Directory" class="headerlink" title="2.2.2.6 Page Directory"></a>2.2.2.6 Page Directory</h4><p><strong>Page Directory</strong> 页目录，记录着与二叉查找相关的信息。</p>
<p>前面我们介绍了User Records是有序的，那么维护User Records的记录有序是为了做什么呢？没错，还是为了性能。行记录之间以链表串联，链表的查询性能是O(n)，这显然是不够理想的，为了提升性能，Page Directory应运而生。</p>
<p>我们可以打个比方，我们在看书的时候，如果要找到某一节，而这一节我们并不知道在哪一页，我们是不是就要从前往后，一节一节地去寻找我们需要的内容的页码呢？</p>
<p>答案是否定的，因为在书的前面，存在目录，它会告诉你这一节在哪一页，例如，第一节在第1页、第二节在第13页。在数据库的页中，实际上也使用了这种目录的结构，这就是页目录。</p>
<p>那么引入页目录之后，我们所理解的页结构，就变成了这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fd4a712ed26ec34941484e0d70c742fe25d.png" alt=""></p>
<p>页目录是一个稀疏目录，它有限的目录项会离散的指向整个User Records列表的各个锚点，比如上图的目录项1指向id=1，目录项2指向id=3。</p>
<p>如此一来，假设我们要寻找id=5的数据，就不需要遍历一遍整个User Records列表了，只要通过页目录（假设是<code>[1,3,7,10,...]</code>）定位到id=9是在7-10之间，那么就可以直接跳到id=7，之后再后溯两个行，就能定位到id=9。</p>
<h4 id="2-2-2-7-File-Trailer"><a href="#2-2-2-7-File-Trailer" class="headerlink" title="2.2.2.7 File Trailer"></a>2.2.2.7 File Trailer</h4><p><strong>File Trailer</strong> 存储用于检测数据完整性的校验和等数据。</p>
<p>为了检测页是否已经完整地写人磁盘（如可能发生的写人过程中磁盘损坏、机器关机等），InnoDB存储引擎的页中设置了File Trailer部分。</p>
<p>File Trailer只有一个FIL_PAGE_END_LSN部分，占用8字节。前4字节代表该页的checksum值，最后4字节和File Header中的FIL_PAGELSN相同。将这两个值与File Header中的FIL_PAGE_SPACE_OR_CHKSUM和FIL_PAGELSN值进行比较，看是否一致（checksum的比较需要通过InnoDB的checksum函数来进行比较，不是简单的等值比较），以此来保证页的完整性（not corrupted）。</p>
<h3 id="2-2-3-索引和页的联系"><a href="#2-2-3-索引和页的联系" class="headerlink" title="2.2.3 索引和页的联系"></a>2.2.3 索引和页的联系</h3><p>我们已经知道InnoDB的索引采用B+树来实现，B+树中的叶子节点和非叶子节点，其实它们也都是页，只不过叶子结点的页（我们称为索引页）只存放键值和指向非叶子节点（我们称为数据页）的偏移量：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d56be3c294a4f3897605f7817f60a37d900.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-03e38ce46f0b73c2a688a808d2f8424ea26.png" alt=""></p>
<p>如上图可以看到，page 4/5/6都是叶子节点的数据页，他们存放实际的行记录。除此以外还有存放索引键值和指针的页，比如图中page number=3的页，该页存放键值和指向数据页的指针。这只是一个实例，实际上我们完整的B+树应该长这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3351c306d86845e280dadb774a97ded1de8.png" alt=""></p>
<p>这些页都是被各种指针给<strong>逻辑地</strong>组成了一个B+树，<strong>他们实际上都离散的存放在磁盘上</strong>，也就是我们之前说的独立表空间文件中（tableName.idb文件中）。</p>
<p>当我们需要对某个页做读写的时候，再将某个页从磁盘载入缓冲池，缓冲池大小有限，所以会通过LRU List做淘汰机制，将不常用的页从缓冲池删除。</p>
<p>那么，假设现在要查找一条数据，该怎么查，比如：</p>
<p>select * from t1 where id=6;</p>
<p>在这里我们假设t1表选择自增id来做主键，这时要通过B+树来查找：</p>
<ol>
<li><p>首先查找根页。一般来说，每个表的根页位置在表空间（t1.ibd）中都是不变的，在这里也就是page number=3的页，将page number=3的页载入缓冲池。</p>
<blockquote>
<p>其实一般来说，根页只要进入缓冲池，就基本上都是热点数据，很难被LRU算法淘汰掉，因为基本上所有走t1表索引的查询，都要访问t1表的根页，即便是走非聚簇索引，也会定位到聚簇索引上来。</p>
</blockquote>
</li>
<li><p>找到根页后通过二分查找法，定位到id=6的页应该在指针P5指向的页中。</p>
<blockquote>
<p><strong>需要牢记的是，B+树索引本身并不能找到具体的一条记录，能找到只是该记录所在的页</strong>。</p>
</blockquote>
</li>
<li><p>如果P5指向的页（page number=5）不在缓冲池中，那么把页载入到缓冲池。</p>
</li>
<li><p>发现page number=5的页是非叶子节点了，然后通过Page Directory再进行二叉查找，即可查找到id=6的对应记录了。</p>
<blockquote>
<p>Page Directory二叉查找的时间复杂度很低，同时在缓冲池（也就是内存）中的查找很快，因此通常忽略这部分查找所用的时间。</p>
</blockquote>
</li>
</ol>
<p>再看一张类似的图</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d468bc450e8055f95de04f818faaf23432d.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-hand-o-right" aria-label="accessibility.next_page"></i></a>
  </nav>

          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png"
                alt="cherish-ls" />
            
              <p class="site-author-name" itemprop="name">cherish-ls</p>
              <p class="site-description motion-element" itemprop="description">纸上得来终觉浅</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">54</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">94</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="git@github.com:cherish-ls/cherish-ls.github.io.git" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">cherish-ls</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">376.6k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"cherish"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  
















  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: 'TQhjcmooFXWGQ3qgqUroDKsD-gzGzoHsz',
        appKey: 'zjA9PvG5eljY1JErig8WVQQD',
        placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  

  
  

  

  

  

</body>
</html>
