<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="纸上得来终觉浅，绝知此事要躬行" />










<meta name="description" content="纸上得来终觉浅">
<meta property="og:type" content="website">
<meta property="og:title" content="cherish">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="cherish">
<meta property="og:description" content="纸上得来终觉浅">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="cherish-ls">
<meta property="article:tag" content="纸上得来终觉浅，绝知此事要躬行">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>cherish</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">cherish</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">返朴归真</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/03/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/03/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%AF%BB/" itemprop="url">文章导读</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-12-03T22:56:59+08:00">
                2019-12-03
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/12/03/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%AF%BB/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/12/03/文章导读/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  530
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  2
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="JAVA"><a href="#JAVA" class="headerlink" title="JAVA"></a>JAVA</h1><ul>
<li><h2 id="JAVA-JVM"><a href="#JAVA-JVM" class="headerlink" title="JAVA  JVM"></a>JAVA  JVM</h2><ul>
<li><a href="https://cherish-ls.github.io/2019/10/17/JAVA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/" target="_blank" rel="noopener" title="JAVA内存模型">JAVA内存模型</a></li>
<li><a href="https://cherish-ls.github.io/2019/10/23/JAVA%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E5%92%8C%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/" target="_blank" rel="noopener" title="JAVA内存结构和内存管理">JAVA内存结构和内存管理</a></li>
<li><a href="https://cherish-ls.github.io/2019/11/21/JAVA%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/" target="_blank" rel="noopener" title="JAVA垃圾回收器">JAVA垃圾回收器</a></li>
<li><a href="https://cherish-ls.github.io/2019/12/03/Class%E6%96%87%E4%BB%B6%E5%92%8C%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/" target="_blank" rel="noopener" title="Class文件和类加载机制">Class文件和类加载机制</a></li>
<li><a href="https://cherish-ls.github.io/2019/11/25/JAVA%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/" target="_blank" rel="noopener" title="JAVA对象的创建和内存分配策略">JAVA对象的创建和内存分配策略</a></li>
<li><a href="https://cherish-ls.github.io/2020/05/07/JVM%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%E4%B9%8B%E3%80%8E%E4%B8%80%E4%B8%AA%E7%B1%BB%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%E3%80%8F/" target="_blank" rel="noopener" title="JVM学习总结之『一个类的前世今生』">JVM学习总结之『一个类的前世今生』</a></li>
</ul>
</li>
<li><h2 id="线程与并发控制"><a href="#线程与并发控制" class="headerlink" title="线程与并发控制"></a>线程与并发控制</h2><ul>
<li><a href="https://cherish-ls.github.io/2018/03/27/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-ThreadPoolExecutor/" target="_blank" rel="noopener" title="线程池源码分析——ThreadPoolExecutor">线程池源码分析——ThreadPoolExecutor</a></li>
<li><a href="https://cherish-ls.github.io/2019/08/29/JAVA%E4%B8%AD%E6%96%AD%E6%9C%BA%E5%88%B6/" target="_blank" rel="noopener" title="JAVA中断机制">JAVA中断机制</a></li>
<li><a href="https://cherish-ls.github.io/2019/08/23/JAVA%E5%B9%B6%E5%8F%91%E4%B9%8BAQS%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener" title="JAVA并发之AQS详解">JAVA并发之AQS详解</a></li>
<li><a href="https://cherish-ls.github.io/2019/09/26/AQS%E5%AE%9E%E7%8E%B0%E4%B9%8BCountDownLatch-Semaphore-CyclicBarrier/" target="_blank" rel="noopener" title="AQS实现之CountDownLatch/Semaphore/CyclicBarrier">AQS实现之CountDownLatch/Semaphore/CyclicBarrier</a></li>
<li><a href="https://cherish-ls.github.io/2019/10/15/synchronized%E5%8E%9F%E7%90%86%E5%92%8C%E9%94%81%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5-%E5%81%8F%E5%90%91-%E8%BD%BB%E9%87%8F%E7%BA%A7-%E9%87%8D%E9%87%8F%E7%BA%A7/" target="_blank" rel="noopener" title="synchronized原理和锁优化策略(偏向/轻量级/重量级)">synchronized原理和锁优化策略(偏向/轻量级/重量级)</a></li>
<li><a href="https://cherish-ls.github.io/2020/08/05/JAVA%E7%9A%84CAS%E5%8F%8A%E5%85%B6ABA%E9%97%AE%E9%A2%98/" target="_blank" rel="noopener" title="JAVA的CAS及其ABA问题">JAVA的CAS及其ABA问题</a></li>
<li><a href="https://cherish-ls.github.io/2020/08/07/volatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener" title="volatile关键字详解">volatile关键字详解</a></li>
</ul>
</li>
<li><h2 id="JAVA实现或特性"><a href="#JAVA实现或特性" class="headerlink" title="JAVA实现或特性"></a>JAVA实现或特性</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/07/26/JAVA%E9%9D%99%E6%80%81-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/" target="_blank" rel="noopener" title="JAVA静态/动态代理">JAVA静态/动态代理</a></li>
<li><a href="https://cherish-ls.github.io/2020/10/14/JAVA%E5%86%85%E7%BD%AE%E6%8E%92%E5%BA%8FArrays-sort%E5%AE%9E%E7%8E%B0%E7%AE%80%E8%BF%B0/" target="_blank" rel="noopener" title="JAVA内置排序Arrays.sort实现简述">JAVA内置排序Arrays.sort实现简述</a></li>
</ul>
</li>
<li><h2 id="JAVA监控和调优"><a href="#JAVA监控和调优" class="headerlink" title="JAVA监控和调优"></a>JAVA监控和调优</h2><ul>
<li><a href="https://cherish-ls.github.io/2019/08/27/dump%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%92%8C%E5%88%86%E6%9E%90%E6%9F%A5%E7%9C%8B/" target="_blank" rel="noopener" title="dump文件生成和分析查看">dump文件生成和分析查看</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="数据结构与算法"><a href="#数据结构与算法" class="headerlink" title="数据结构与算法"></a>数据结构与算法</h1><ul>
<li><h2 id="树"><a href="#树" class="headerlink" title="树"></a>树</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/04/28/B%E6%A0%91-B-%E6%A0%91%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="B树/B+树分析">B树/B+树分析</a></li>
</ul>
</li>
<li><h2 id="图"><a href="#图" class="headerlink" title="图"></a>图</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/" target="_blank" rel="noopener" title="【图论】广度/深度优先搜索算法">【图论】广度/深度优先搜索算法</a></li>
<li><a href="https://cherish-ls.github.io/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener" title="【图论】拓扑排序详解">【图论】拓扑排序详解</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="计算机协议和技术"><a href="#计算机协议和技术" class="headerlink" title="计算机协议和技术"></a>计算机协议和技术</h1><ul>
<li><h2 id="网络协议"><a href="#网络协议" class="headerlink" title="网络协议"></a>网络协议</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/03/17/TCP-IP%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%A7%88/" target="_blank" rel="noopener" title="TCP-IP协议学习导览">TCP-IP协议学习导览</a></li>
<li><a href="https://cherish-ls.github.io/2020/03/18/UDP%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="UDP协议分析">UDP协议分析</a></li>
<li><a href="https://cherish-ls.github.io/2020/04/08/TCP%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="TCP协议分析">TCP协议分析</a> </li>
</ul>
</li>
<li><h2 id="Linux相关"><a href="#Linux相关" class="headerlink" title="Linux相关"></a>Linux相关</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/08/13/%E8%AF%A6%E8%A7%A3IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%92%8C%E5%85%B6%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94select-poll-epoll/" target="_blank" rel="noopener" title="详解IO多路复用和其三种模式——select/poll/epoll">详解IO多路复用和其三种模式——select/poll/epoll</a></li>
<li><a href="https://cherish-ls.github.io/2019/07/21/%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4%E5%AF%BC%E8%88%AA/" target="_blank" rel="noopener" title="常用shell命令导航">常用shell命令导航</a></li>
<li><a href="https://cherish-ls.github.io/2019/07/17/shell-notes-tips/" target="_blank" rel="noopener" title="shell notes&amp;tips">shell notes&amp;tips</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h1><ul>
<li><h2 id="spring"><a href="#spring" class="headerlink" title="spring"></a>spring</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/05/25/Spring-IoC%E6%A6%82%E5%BF%B5%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="Spring-IoC概念分析">Spring-IoC概念分析</a></li>
<li><a href="https://cherish-ls.github.io/2020/06/29/Spring-Resource%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6%E4%BD%93%E7%B3%BB/" target="_blank" rel="noopener" title="Spring-Resource资源文件体系">Spring-Resource资源文件体系</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h1><ul>
<li><h2 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h2><ul>
<li><a href="https://cherish-ls.github.io/2019/08/20/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1zookeeper%E7%AE%80%E8%AE%BA/" target="_blank" rel="noopener" title="分布式协调服务zookeeper简论">分布式协调服务zookeeper简论</a></li>
</ul>
</li>
<li><h2 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/02/20/ElasticSearch%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E8%AF%A6%E8%A7%A3%EF%BC%88index-type-doc-node-shard-replica-segment%EF%BC%89/" target="_blank" rel="noopener" title="ElasticSearch核心概念详解（index/type/doc/node/shard/replica/segment）">ElasticSearch核心概念详解（index/type/doc/node/shard/replica/segment）</a></li>
<li><a href="https://cherish-ls.github.io/2020/02/18/ElasticSearch-Master%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6%E6%B5%85%E6%9E%90/" target="_blank" rel="noopener" title="ElasticSearch Master选举机制浅析">ElasticSearch Master选举机制浅析</a></li>
<li><a href="https://cherish-ls.github.io/2018/08/02/ElasticSearch%E5%8D%87%E7%BA%A7%E8%AE%B0%E5%BD%95-ver-1-4-5%E2%86%92ver-5-2-0/" target="_blank" rel="noopener" title="ElasticSearch升级记录 ver.1.4.5→ver.5.2.0">ElasticSearch升级记录 ver.1.4.5→ver.5.2.0</a></li>
</ul>
</li>
<li><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><ul>
<li><a href="https://cherish-ls.github.io/2019/12/19/Redis%E7%9A%845%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/" target="_blank" rel="noopener" title="Redis的5种数据类型">Redis的5种数据类型</a></li>
<li><a href="https://cherish-ls.github.io/2019/12/19/Redis%E7%9A%848%E7%A7%8D%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" target="_blank" rel="noopener" title="Redis的8种底层数据结构">Redis的8种底层数据结构</a></li>
<li><a href="https://cherish-ls.github.io/2020/01/08/Redis%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%9E%8B-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/" target="_blank" rel="noopener" title="Redis事件模型-主从复制-哨兵模型-集群模式">Redis事件模型-主从复制-哨兵模型-集群模式</a></li>
<li><a href="https://cherish-ls.github.io/2019/12/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%93%E6%9E%84-%E9%94%AE%E7%A9%BA%E9%97%B4-%E8%BF%87%E6%9C%9F%E5%AD%97%E5%85%B8-%E4%BA%8B%E5%8A%A1-%E9%94%81-%E6%8C%81%E4%B9%85%E5%8C%96/" target="_blank" rel="noopener" title="Redis数据库结构/键空间/过期字典/事务/锁/持久化">Redis数据库结构/键空间/过期字典/事务/锁/持久化</a></li>
<li><a href="https://cherish-ls.github.io/2020/04/09/Redis%E7%9A%84%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E4%BB%8B%E7%BB%8D/" target="_blank" rel="noopener" title="Redis的缓存雪崩/缓存穿透/缓存预热+布隆过滤器介绍">Redis的缓存雪崩/缓存穿透/缓存预热+布隆过滤器介绍</a></li>
<li><a href="https://cherish-ls.github.io/2020/08/04/Redis%E4%B8%ADLRU%E5%92%8CLFU%E7%AE%97%E6%B3%95%E5%92%8C%E5%AE%9E%E7%8E%B0/" target="_blank" rel="noopener" title="LRU和LFU算法以及其在Redis中的实现">LRU和LFU算法以及其在Redis中的实现</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h1><ul>
<li><h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/05/06/MySQL%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%B1%87%E6%80%BB/" target="_blank" rel="noopener" title="MySQL核心要点汇总">MySQL核心要点汇总</a></li>
<li><a href="https://cherish-ls.github.io/2020/09/30/MySQL%E6%97%A5%E5%BF%97%E4%BD%93%E7%B3%BB%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener" title="MySQL日志体系详解">MySQL日志体系详解</a></li>
<li><a href="https://cherish-ls.github.io/2020/08/31/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%80%E3%80%91%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%92%8C%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7/" target="_blank" rel="noopener" title="【InnoDB详解一】体系架构和关键特性">【InnoDB详解一】体系架构和关键特性</a></li>
<li><a href="https://cherish-ls.github.io/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/" target="_blank" rel="noopener" title="【InnoDB详解二】MySQL文件系统和InnoDB存储结构">【InnoDB详解二】MySQL文件系统和InnoDB存储结构</a></li>
<li><a href="https://cherish-ls.github.io/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/" target="_blank" rel="noopener" title="【InnoDB详解三】锁和事务">【InnoDB详解三】锁和事务</a></li>
<li><a href="https://cherish-ls.github.io/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/" target="_blank" rel="noopener" title="【InnoDB详解四】redo log和undo log">【InnoDB详解四】redo log和undo log</a></li>
</ul>
</li>
<li><h2 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/05/06/%E7%90%86%E8%A7%A3sql%E4%B8%AD%E7%9A%84group-by%E5%92%8Chaving/" target="_blank" rel="noopener" title="理解sql中的group by和having">理解sql中的group by和having</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="分布式算法-amp-理论"><a href="#分布式算法-amp-理论" class="headerlink" title="分布式算法&amp;理论"></a>分布式算法&amp;理论</h1><ul>
<li><h2 id="分布式一致性算法"><a href="#分布式一致性算法" class="headerlink" title="分布式一致性算法"></a>分布式一致性算法</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/01/21/Raft%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="Raft算法分析">Raft算法分析</a></li>
<li><a href="https://cherish-ls.github.io/2019/08/12/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%90%86%E8%AE%BA%E5%92%8Cpaxos%E7%AE%97%E6%B3%95/" target="_blank" rel="noopener" title="分布式一致性理论和paxos算法">分布式一致性理论和paxos算法</a></li>
<li><a href="https://cherish-ls.github.io/2020/07/26/ZAB%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/" target="_blank" rel="noopener" title="ZAB协议分析">ZAB协议分析</a></li>
</ul>
</li>
<li><h2 id="负载均衡算法"><a href="#负载均衡算法" class="headerlink" title="负载均衡算法"></a>负载均衡算法</h2><ul>
<li><a href="https://cherish-ls.github.io/2020/07/26/%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95/" target="_blank" rel="noopener" title="一致性hash算法">一致性hash算法</a></li>
</ul>
</li>
</ul>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/09/JAVA%E7%9B%91%E6%8E%A7%E5%92%8C%E8%B0%83%E4%BC%98%E5%B7%A5%E5%85%B7%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%88%E6%AD%A4%E5%9D%91%E6%9C%AA%E5%A1%AB%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/09/JAVA%E7%9B%91%E6%8E%A7%E5%92%8C%E8%B0%83%E4%BC%98%E5%B7%A5%E5%85%B7%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%88%E6%AD%A4%E5%9D%91%E6%9C%AA%E5%A1%AB%EF%BC%89/" itemprop="url">JAVA监控和调优工具操作指南</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-09T20:39:02+08:00">
                2020-11-09
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/11/09/JAVA%E7%9B%91%E6%8E%A7%E5%92%8C%E8%B0%83%E4%BC%98%E5%B7%A5%E5%85%B7%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%88%E6%AD%A4%E5%9D%91%E6%9C%AA%E5%A1%AB%EF%BC%89/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/11/09/JAVA监控和调优工具操作指南（此坑未填）/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  5.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  22
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我们在日常的开发和维护工作中，免不了需要对JAVA程序进行监控、调优以及问题排查。</p>
<p>给一个系统定位问题的时候，知识、经验是关键基础，数据是依据，工具是运用知识处理数据的手段。这里说的数据包括∶运行日志、异常堆栈、GC日志、线程快照（thread dump/java core文件）、堆转储快照（heap dump/hprof文件）等。</p>
<p>经常使用适当的监控和分析工具可以加快我们分析数据、定位解决问题的速度，但在学习工具前，也应当意识到工具永远都是知识技能的一层包装，没有什么工具是”秘密武器”，不可能学会了就能包治百病。</p>
<h2 id="进程id的获取"><a href="#进程id的获取" class="headerlink" title="进程id的获取"></a>进程id的获取</h2><p>许多工具或者命令需要用到java进程的进程id，有必要回顾一下。</p>
<blockquote>
<ol>
<li>查看当前运行的所有的java进程：<code>ps -ef|grep java</code>；</li>
<li>准确获取定位到tomcat下正在运行的java进程的PID命令：<code>ps -ef|grep java | grep catalina | awk &#39;{print $2}&#39;</code></li>
<li>准确定位到tomcat下正在运行的java进程相关信息：<code>ps -ef|grep java | grep catalina</code>.</li>
</ol>
</blockquote>
<h2 id="jinfo-jmap访问受限的解决"><a href="#jinfo-jmap访问受限的解决" class="headerlink" title="jinfo/jmap访问受限的解决"></a>jinfo/jmap访问受限的解决</h2><p>一般情况下，我们使用jinfo命令，可能会遇到如下的报错：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3bcb4835de13ba36eadb8b19630a824973f.png" alt=""></p>
<p>这是因为新版的Linux系统加入了 ptrace-scope 机制,该机制的目的是防止用户访问正在执行的进程的内存，但是如jinfo,jmap这些调试类工具本身就是利用ptrace来获取执行进程的内存等信息。</p>
<p><strong>解决：</strong></p>
<ol>
<li>临时解决，该方法在下次重启前有效：<code>echo 0 | sudo tee /proc/sys/kernel/yama/ptrace_scope</code></li>
<li>永久解决，直接修改内核参数：<code>sudo vi /etc/sysctl.d/10-ptrace.conf</code><ul>
<li>编辑这行: <code>kernel.yama.ptrace_scope = 1</code></li>
<li>修改为: <code>kernel.yama.ptrace_scope = 0</code></li>
<li>重启系统，使修改生效。</li>
</ul>
</li>
</ol>
<blockquote>
<p>参数名：kernel.yama.ptrace_scope（值为１：表示禁止用户访问正在执行的进程的内存；０表示可以访问）</p>
</blockquote>
<h1 id="1-程序数据"><a href="#1-程序数据" class="headerlink" title="1. 程序数据"></a>1. 程序数据</h1><h2 id="1-1-【命令】jps（显示java进程）"><a href="#1-1-【命令】jps（显示java进程）" class="headerlink" title="1.1 【命令】jps（显示java进程）"></a>1.1 【命令】jps（显示java进程）</h2><p>jps (Java Virtual Machine Process Status Tool)，是java提供的一个显示当前所有JAVA进程pid的命令，适合在linux/unix平台上简单察看当前java进程的一些简单情况。</p>
<p>我们常常会用到unix系统里的ps命令，这个命令主要是用来显示当前系统的进程情况，有哪些进程以及进程id。</p>
<p><strong>jps就是java程序版本的ps命令，它的作用是显示当前系统的java进程情况及进程id。</strong></p>
<p><strong>格式：<code>jps [-命令选项]</code></strong></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2c4c5b7173045d72f971624168e8cb70e73.png" alt=""></p>
<h3 id="1-1-1-jps的选项"><a href="#1-1-1-jps的选项" class="headerlink" title="1.1.1 jps的选项"></a>1.1.1 jps的选项</h3><p>jps默认只会打印进程id和java类名，如果要更具体的信息，则要借助更多的选项：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-16840d91b4bfcceb7cfb57aacb4b7f4e3b3.png" alt=""></p>
<ol>
<li><p>jps -q</p>
<ul>
<li>只显示pid，不显示class名称,jar文件名和传递给main方法的参数</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-62cd627d9ee93c1fe76cb2474e5b75dbba4.png" alt=""></li>
</ul>
</li>
<li><p>jps -m</p>
<ul>
<li>输出传递给main方法的参数，在嵌入式jvm上可能是null</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-a56eedc39b84a2f57451b3f7c5172fc7d32.png" alt=""></li>
</ul>
</li>
<li><p>jps -l</p>
<ul>
<li>输出应用程序main class的完整package名或者应用程序的jar文件完整路径名</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-7bf94c1599ea21d939c982c152f76125f6b.png" alt=""></li>
</ul>
</li>
<li><p>jps -v</p>
<ul>
<li>输出传递给JVM的参数</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-17e285a83ecb8b6d0aedd6efe5b5e3c91eb.png" alt=""></li>
</ul>
</li>
<li><p>jps -V</p>
<ul>
<li>隐藏输出传递给JVM的参数</li>
</ul>
</li>
</ol>
<h2 id="1-2-【命令】jinfo（显示JVM配置信息）"><a href="#1-2-【命令】jinfo（显示JVM配置信息）" class="headerlink" title="1.2 【命令】jinfo（显示JVM配置信息）"></a>1.2 【命令】jinfo（显示JVM配置信息）</h2><p>jinfo 是 JDK 自带的命令，可以用来查看正在运行的 java 应用程序的扩展参数，包括Java System属性和JVM命令行参数；也可以动态的修改正在运行的JVM一些参数。当系统崩溃时，jinfo也可以从core文件里面知道崩溃的Java应用程序的配置信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Usage:</span><br><span class="line">    jinfo [option] &lt;pid&gt;</span><br><span class="line">        (to connect to running process)</span><br><span class="line">    jinfo [option] &lt;executable &lt;core&gt;</span><br><span class="line">        (to connect to a core file)</span><br><span class="line">    jinfo [option] [server_id@]&lt;remote server IP or hostname&gt;</span><br><span class="line">        (to connect to remote debug server)</span><br><span class="line"></span><br><span class="line">where &lt;option&gt; is one of:</span><br><span class="line">    -flag &lt;name&gt;         to print the value of the named VM flag</span><br><span class="line">    -flag [+|-]&lt;name&gt;    to enable or disable the named VM flag</span><br><span class="line">    -flag &lt;name&gt;&#x3D;&lt;value&gt; to set the named VM flag to the given value</span><br><span class="line">    -flags               to print VM flags</span><br><span class="line">    -sysprops            to print Java system properties</span><br><span class="line">    &lt;no option&gt;          to print both of the above</span><br><span class="line">    -h | -help           to print this help message</span><br></pre></td></tr></table></figure>

<p><strong>格式：<code>jinfo [-命令选项] &lt;pid&gt;</code> 或 <code>jinfo [-命令选项] &lt;executable core&gt;</code> 或 <code>jinfo [-命令选项] [server_id@] &lt;remote ip or hostname&gt;</code></strong></p>
<ul>
<li><code>pid</code>：对应jvm的进程id</li>
<li><code>executable core</code>：产生core dump文件</li>
<li><code>remote server IP or hostname</code>：远程调试服务的ip或者hostname</li>
<li><code>server-id</code>：唯一id,假如一台主机上多个远程debug服务;</li>
</ul>
<blockquote>
<p>Javacore，也可以称为“threaddump”或是“javadump”，它是 Java 提供的一种诊断特性，能够提供一份可读的当前运行的 JVM 中线程使用情况的快照。即在某个特定时刻，JVM 中有哪些线程在运行，每个线程执行到哪一个类，哪一个方法。<br>应用程序如果出现不可恢复的错误或是内存泄露，就会自动触发 Javacore 的生成。</p>
</blockquote>
<p>jinfo工具特别强大，有众多的可选命令选项，比如：</p>
<h3 id="1-2-1-输出JVM进程的参数和属性"><a href="#1-2-1-输出JVM进程的参数和属性" class="headerlink" title="1.2.1 输出JVM进程的参数和属性"></a>1.2.1 输出JVM进程的参数和属性</h3><p><code>jinfo &lt;pid&gt;</code></p>
<p>不带任何选项的情况下，输出当前 jvm 进程的全部参数和系统属性</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3d8f5e1a88b7882699b13e00bf379611362.png" alt=""></p>
<h3 id="1-2-2-打印JVM特定参数的值"><a href="#1-2-2-打印JVM特定参数的值" class="headerlink" title="1.2.2 打印JVM特定参数的值"></a>1.2.2 打印JVM特定参数的值</h3><p><code>jinfo -flag &lt;name&gt; &lt;pid&gt;</code></p>
<p>用于打印虚拟机标记参数的值，name表示虚拟机标记参数的名称。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4ea5b8737fb9011c4030aa2c2d57e242811.png" alt=""></p>
<h3 id="1-2-3-开启或关闭JVM特定参数"><a href="#1-2-3-开启或关闭JVM特定参数" class="headerlink" title="1.2.3 开启或关闭JVM特定参数"></a>1.2.3 开启或关闭JVM特定参数</h3><p><code>jinfo -flag [+|-]&lt;name&gt; &lt;pid&gt;</code></p>
<p>用于开启或关闭虚拟机标记参数。+表示开启，-表示关闭。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9379bda74d5e129a548ffe7cfd724167ab1.png" alt=""></p>
<h3 id="1-2-4-设置JVM特定参数的值"><a href="#1-2-4-设置JVM特定参数的值" class="headerlink" title="1.2.4 设置JVM特定参数的值"></a>1.2.4 设置JVM特定参数的值</h3><p><code>jinfo -flag &lt;name&gt;=&lt;value&gt; &lt;pid&gt;</code></p>
<p>用于设置虚拟机标记参数，但并不是每个参数都可以被动态修改的。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-adb15a8f73ef408099cbee2110bc9879f02.png" alt=""></p>
<h3 id="1-2-5-打印所有JVM参数"><a href="#1-2-5-打印所有JVM参数" class="headerlink" title="1.2.5 打印所有JVM参数"></a>1.2.5 打印所有JVM参数</h3><p><code>jinfo -flags &lt;pid&gt;</code></p>
<p>打印虚拟机参数。什么是虚拟机参数呢？如<code>-XX:NewSize,-XX:OldSize</code>等就是虚拟机参数。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b79b41e6b74426fa258da530dcfd256847b.png" alt=""></p>
<h3 id="1-2-6-打印所有系统参数"><a href="#1-2-6-打印所有系统参数" class="headerlink" title="1.2.6 打印所有系统参数"></a>1.2.6 打印所有系统参数</h3><p><code>jinfo -sysprops &lt;pid&gt;</code></p>
<p>打印所有系统参数</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e4bb4b35ac7fed34239fc2785067e3e7574.png" alt=""></p>
<h1 id="2-快照采集"><a href="#2-快照采集" class="headerlink" title="2. 快照采集"></a>2. 快照采集</h1><h2 id="2-1-【命令】jmap（生成内存快照文件）"><a href="#2-1-【命令】jmap（生成内存快照文件）" class="headerlink" title="2.1 【命令】jmap（生成内存快照文件）"></a>2.1 【命令】jmap（生成内存快照文件）</h2><p>jmap命令是一个可以输出所有内存中对象的工具，甚至可以将VM 中的heap，以二进制输出成文本。打印出某个java进程（使用pid）内存内的，所有‘对象’的情况（如：产生那些对象，及其数量）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Usage:</span><br><span class="line">    jmap [option] &lt;pid&gt;</span><br><span class="line">        (to connect to running process)</span><br><span class="line">    jmap [option] &lt;executable &lt;core&gt;</span><br><span class="line">        (to connect to a core file)</span><br><span class="line">    jmap [option] [server_id@]&lt;remote server IP or hostname&gt;</span><br><span class="line">        (to connect to remote debug server)</span><br><span class="line"></span><br><span class="line">where &lt;option&gt; is one of:</span><br><span class="line">    &lt;none&gt;               to print same info as Solaris pmap</span><br><span class="line">    -heap                to print java heap summary</span><br><span class="line">    -histo[:live]        to print histogram of java object heap; if the &quot;live&quot;</span><br><span class="line">                         suboption is specified, only count live objects</span><br><span class="line">    -clstats             to print class loader statistics</span><br><span class="line">    -finalizerinfo       to print information on objects awaiting finalization</span><br><span class="line">    -dump:&lt;dump-options&gt; to dump java heap in hprof binary format</span><br><span class="line">                         dump-options:</span><br><span class="line">                           live         dump only live objects; if not specified,</span><br><span class="line">                                        all objects in the heap are dumped.</span><br><span class="line">                           format&#x3D;b     binary format</span><br><span class="line">                           file&#x3D;&lt;file&gt;  dump heap to &lt;file&gt;</span><br><span class="line">                         Example: jmap -dump:live,format&#x3D;b,file&#x3D;heap.bin &lt;pid&gt;</span><br><span class="line">    -F                   force. Use with -dump:&lt;dump-options&gt; &lt;pid&gt; or -histo</span><br><span class="line">                         to force a heap dump or histogram when &lt;pid&gt; does not</span><br><span class="line">                         respond. The &quot;live&quot; suboption is not supported</span><br><span class="line">                         in this mode.</span><br><span class="line">    -h | -help           to print this help message</span><br><span class="line">    -J&lt;flag&gt;             to pass &lt;flag&gt; directly to the runtime system</span><br></pre></td></tr></table></figure>

<p>64位机上使用需要使用如下方式：<code>jmap -J-d64 -heap pid</code></p>
<p><strong>格式：<code>jmap [option] &lt;pid&gt;</code> 或 <code>jmap [option] &lt;executable &lt;core&gt;</code> 或 <code>jmap [option] [server_id@]&lt;remote server IP or hostname&gt;</code></strong></p>
<ul>
<li><code>pid</code>：对应jvm的进程id</li>
<li><code>executable core</code>：产生core dump文件</li>
<li><code>remote server IP or hostname</code>：远程调试服务的ip或者hostname</li>
<li><code>server-id</code>：唯一id,假如一台主机上多个远程debug服务;</li>
</ul>
<p>jinfo工具特别强大，有众多的可选命令选项，比如：</p>
<h3 id="2-1-1-输出hprof二进制格式的heap文件"><a href="#2-1-1-输出hprof二进制格式的heap文件" class="headerlink" title="2.1.1 输出hprof二进制格式的heap文件"></a>2.1.1 输出hprof二进制格式的heap文件</h3><p><code>jmap -dump:live,format=b,file=myjmapfile.txt  &lt;pid&gt;</code><br>或<br><code>jmap -dump:file=myjmapfile.hprof,format=b &lt;pid&gt;</code></p>
<p>使用hprof二进制形式,输出jvm的heap内容到文件，file=可以指定文件存放的目录。live子选项是可选的，假如指定live选项，那么只输出活的对象到文件。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-35d57224bda3c1ce43daa4eed065ae0e0a2.png" alt=""></p>
<h3 id="2-1-2-打印正等候回收的对象的信息"><a href="#2-1-2-打印正等候回收的对象的信息" class="headerlink" title="2.1.2 打印正等候回收的对象的信息"></a>2.1.2 打印正等候回收的对象的信息</h3><p><code>jmap -finalizerinfo  &lt;pid&gt;</code></p>
<p>打印正等候回收的对象的信息。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f2d9d9dfa286b51df4e3575ae27423cd93e.png" alt=""></p>
<p>Number of objects pending for finalization: 0 表示等候回收的对象为0个</p>
<h3 id="2-1-3-打印heap的概要信息"><a href="#2-1-3-打印heap的概要信息" class="headerlink" title="2.1.3 打印heap的概要信息"></a>2.1.3 打印heap的概要信息</h3><p><code>jmap -heap  &lt;pid&gt;</code></p>
<p>打印heap的概要信息，GC使用的算法，heap（堆）的配置及JVM堆内存的使用情况。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-992e8f7a9ced2b305f6a16d2184c77a5686.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">Attaching to process ID 2805, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 25.181-b13</span><br><span class="line"></span><br><span class="line">using thread-local object allocation.</span><br><span class="line">Parallel GC with 4 thread(s)   ##GC 方式</span><br><span class="line"></span><br><span class="line">Heap Configuration:  ##堆配置情况，也就是JVM参数配置的结果[平常说的tomcat配置JVM参数，就是在配置这些]</span><br><span class="line">   MinHeapFreeRatio         &#x3D; 0  ##最小堆使用比例</span><br><span class="line">   MaxHeapFreeRatio         &#x3D; 100  ##最大堆可用比例</span><br><span class="line">   MaxHeapSize              &#x3D; 734003200 (700.0MB)  ##最大堆空间大小</span><br><span class="line">   NewSize                  &#x3D; 21495808 (20.5MB)  ##新生代分配大小</span><br><span class="line">   MaxNewSize               &#x3D; 244318208 (233.0MB)  ##最大可新生代分配大小</span><br><span class="line">   OldSize                  &#x3D; 43515904 (41.5MB)  ##老年代大小</span><br><span class="line">   NewRatio                 &#x3D; 2  ##新生代比例</span><br><span class="line">   SurvivorRatio            &#x3D; 8  ##新生代与suvivor的比例</span><br><span class="line">   MetaspaceSize            &#x3D; 21807104 (20.796875MB)  ## 元数据空间大小</span><br><span class="line">   CompressedClassSpaceSize &#x3D; 1073741824 (1024.0MB)  ## 压缩空间大小</span><br><span class="line">   MaxMetaspaceSize         &#x3D; 17592186044415 MB  ## 最大元数据空间大小</span><br><span class="line">   G1HeapRegionSize         &#x3D; 0 (0.0MB)  ## G1的对region空间大小</span><br><span class="line"></span><br><span class="line">Heap Usage:  ##堆使用情况【堆内存实际的使用情况】</span><br><span class="line">PS Young Generation  ##新生代（伊甸区Eden区 + 幸存区survior(1+2)空间）</span><br><span class="line">Eden Space:   ##伊甸区</span><br><span class="line">   capacity &#x3D; 32505856 (31.0MB)</span><br><span class="line">   used     &#x3D; 0 (0.0MB)</span><br><span class="line">   free     &#x3D; 32505856 (31.0MB)</span><br><span class="line">   0.0% used</span><br><span class="line">From Space:  ##survior1区</span><br><span class="line">   capacity &#x3D; 2621440 (2.5MB)</span><br><span class="line">   used     &#x3D; 0 (0.0MB)</span><br><span class="line">   free     &#x3D; 2621440 (2.5MB)</span><br><span class="line">   0.0% used</span><br><span class="line">To Space:  ##survior2 区</span><br><span class="line">   capacity &#x3D; 4194304 (4.0MB)</span><br><span class="line">   used     &#x3D; 0 (0.0MB)</span><br><span class="line">   free     &#x3D; 4194304 (4.0MB)</span><br><span class="line">   0.0% used</span><br><span class="line">PS Old Generation  ##老年代使用情况</span><br><span class="line">   capacity &#x3D; 21495808 (20.5MB)</span><br><span class="line">   used     &#x3D; 3738528 (3.565338134765625MB)</span><br><span class="line">   free     &#x3D; 17757280 (16.934661865234375MB)</span><br><span class="line">   17.391893340320124% used</span><br><span class="line"></span><br><span class="line">4524 interned Strings occupying 360168 bytes.</span><br></pre></td></tr></table></figure>

<h3 id="2-1-4-打印每个class的实例信息"><a href="#2-1-4-打印每个class的实例信息" class="headerlink" title="2.1.4 打印每个class的实例信息"></a>2.1.4 打印每个class的实例信息</h3><p><code>jmap -histo:live &lt;pid&gt;</code><br>或<br><code>jmap -histo: &lt;pid&gt;</code></p>
<p>打印每个class的实例数目，内存占用,类全名信息，VM的内部类名字开头会加上前缀”*”。如果live子参数加上后，只统计活的对象数量</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-67f49e0ba5cdbfe3ac02c26aaa396f42648.png" alt=""></p>
<blockquote>
<p>采用jmap -histo pid&gt;a.log日志将其保存，在一段时间后，使用文本对比工具，可以对比出GC回收了哪些对象。</p>
</blockquote>
<blockquote>
<p>jmap -dump:format=b,file=outfile 3024可以将3024进程的内存heap输出出来到outfile文件里，再配合MAT（内存分析工具）。</p>
</blockquote>
<h3 id="2-1-5-打印类加载器的数据"><a href="#2-1-5-打印类加载器的数据" class="headerlink" title="2.1.5 打印类加载器的数据"></a>2.1.5 打印类加载器的数据</h3><p><code>jmap -clstats &lt;pid&gt;</code></p>
<p>-clstats是-permstat的替代方案，在JDK8之前，-permstat用来打印类加载器的数据。打印Java堆内存的永久保存区域的类加载器的智能统计信息。</p>
<p>对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、它所加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4f07b6ea610226208c0791082ab70ce0689.png" alt=""></p>
<h3 id="2-1-6-指定传递给运行jmap的JVM的参数"><a href="#2-1-6-指定传递给运行jmap的JVM的参数" class="headerlink" title="2.1.6 指定传递给运行jmap的JVM的参数"></a>2.1.6 指定传递给运行jmap的JVM的参数</h3><p><code>jmap -J&lt;flag&gt; &lt;pid&gt;</code></p>
<p>指定传递给运行jmap的JVM的参数</p>
<p>如<code>jmap -J-d64 -heap pid</code>表示在64位机上使用<code>jmap -heap</code></p>
<h2 id="2-3-【命令】jstack（输出线程快照）"><a href="#2-3-【命令】jstack（输出线程快照）" class="headerlink" title="2.3 【命令】jstack（输出线程快照）"></a>2.3 【命令】jstack（输出线程快照）</h2><p>jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息（也就是线程），如果是在64位机器上，需要指定选项”-J-d64”，Windows的jstack使用方式只支持以下的这种方式：<code>jstack [-l] pid</code></p>
<p>如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。</p>
<p>另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息，如果现在运行的java程序呈现hung的状态，jstack是非常有用的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Usage:</span><br><span class="line">    jstack [-l] &lt;pid&gt;</span><br><span class="line">        (to connect to running process)</span><br><span class="line">    jstack -F [-m] [-l] &lt;pid&gt;</span><br><span class="line">        (to connect to a hung process)</span><br><span class="line">    jstack [-m] [-l] &lt;executable&gt; &lt;core&gt;</span><br><span class="line">        (to connect to a core file)</span><br><span class="line">    jstack [-m] [-l] [server_id@]&lt;remote server IP or hostname&gt;</span><br><span class="line">        (to connect to a remote debug server)</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">    -F  to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung)</span><br><span class="line">    -m  to print both java and native frames (mixed mode)</span><br><span class="line">    -l  long listing. Prints additional information about locks</span><br><span class="line">    -h or -help to print this help message</span><br></pre></td></tr></table></figure>

<p><strong>格式：<code>jstack [option] &lt;pid&gt;</code> 或 <code>jstack [option] &lt;executable &lt;core&gt;</code> 或 <code>jstack [option] [server_id@]&lt;remote server IP or hostname&gt;</code></strong></p>
<ul>
<li><code>pid</code>：对应jvm的进程id</li>
<li><code>executable core</code>：产生core dump文件</li>
<li><code>remote server IP or hostname</code>：远程调试服务的ip或者hostname</li>
<li><code>server-id</code>：唯一id,假如一台主机上多个远程debug服务;</li>
</ul>
<p>jstack工具特别强大，有众多的可选命令选项和适用场景，比如：</p>
<h3 id="2-3-1-程序没有响应时强制打印线程"><a href="#2-3-1-程序没有响应时强制打印线程" class="headerlink" title="2.3.1 程序没有响应时强制打印线程"></a>2.3.1 程序没有响应时强制打印线程</h3><p><code>jstack -F &lt;pid&gt;</code></p>
<p>当pid对应的程序没有响应时，强制打印线程堆栈信息。</p>
<h3 id="2-3-2-打印完整的堆栈信息"><a href="#2-3-2-打印完整的堆栈信息" class="headerlink" title="2.3.2 打印完整的堆栈信息"></a>2.3.2 打印完整的堆栈信息</h3><p><code>jstack -l &lt;pid&gt;</code></p>
<p>长列表，打印关于锁的附加信息，例如属于java.util.concurrent的ownable synchronizers列表。</p>
<h3 id="2-3-3-打印java-native框架的所有堆栈"><a href="#2-3-3-打印java-native框架的所有堆栈" class="headerlink" title="2.3.3 打印java/native框架的所有堆栈"></a>2.3.3 打印java/native框架的所有堆栈</h3><p><code>jstack -m &lt;pid&gt;</code></p>
<p>打印java和native c/c++框架的所有栈信息。</p>
<h3 id="2-3-4"><a href="#2-3-4" class="headerlink" title="2.3.4"></a>2.3.4</h3><p><a href="https://www.jianshu.com/p/8d5782bc596e" target="_blank" rel="noopener">https://www.jianshu.com/p/8d5782bc596e</a></p>
<h1 id="3-监控跟踪"><a href="#3-监控跟踪" class="headerlink" title="3. 监控跟踪"></a>3. 监控跟踪</h1><h2 id="3-1-【命令】jstat（收集JVM运行数据）"><a href="#3-1-【命令】jstat（收集JVM运行数据）" class="headerlink" title="3.1 【命令】jstat（收集JVM运行数据）"></a>3.1 【命令】jstat（收集JVM运行数据）</h2><p>Jstat是JDK自带的一个轻量级小工具。全称“Java Virtual Machine statistics monitoring tool”，它位于java的bin目录下，主要利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了堆内存各部分的使用量，以及加载类的数量，还有垃圾回收状况的监控。</p>
<p>可见，Jstat是轻量级的、专门针对JVM的工具。</p>
<p><strong>格式：<code>jstat [-命令选项] &lt;pid&gt;</code></strong></p>
<p>jstat工具特别强大，有众多的可选项，详细查看堆内各个部分的使用量，以及加载类的数量。使用时，需加上查看进程的进程id，和所选参数。参考格式如下：</p>
<h3 id="3-1-1-类加载统计"><a href="#3-1-1-类加载统计" class="headerlink" title="3.1.1 类加载统计"></a>3.1.1 类加载统计</h3><p><code>jstat –class &lt;pid&gt;</code></p>
<p>显示加载class的数量，及所占空间等信息。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2e60bd64a892a063c76037f7fbaa5ceb196.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>Loaded</td>
<td>装载的类的数量</td>
</tr>
<tr>
<td>Bytes</td>
<td>装载类所占用的字节数</td>
</tr>
<tr>
<td>Unloaded</td>
<td>卸载类的数量</td>
</tr>
<tr>
<td>Bytes</td>
<td>卸载类的字节数</td>
</tr>
<tr>
<td>Time</td>
<td>装载和卸载类所花费的时间</td>
</tr>
</tbody></table>
<h3 id="3-1-2-编译统计"><a href="#3-1-2-编译统计" class="headerlink" title="3.1.2 编译统计"></a>3.1.2 编译统计</h3><p><code>jstat -compiler &lt;pid&gt;</code></p>
<p>显示VM实时编译的数量等信息。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-452f7c3598597bea5efd6a2596c52f13228.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>Compiled</td>
<td>编译任务执行数量</td>
</tr>
<tr>
<td>Failed</td>
<td>编译任务执行失败数量</td>
</tr>
<tr>
<td>Invalid</td>
<td>编译任务执行失效数量</td>
</tr>
<tr>
<td>Time</td>
<td>编译任务消耗时间</td>
</tr>
<tr>
<td>FailedType</td>
<td>最后一个编译失败任务的类型</td>
</tr>
<tr>
<td>FailedMethod</td>
<td>最后一个编译失败任务所在的类及方法</td>
</tr>
</tbody></table>
<h3 id="3-1-3-垃圾回收统计"><a href="#3-1-3-垃圾回收统计" class="headerlink" title="3.1.3 垃圾回收统计"></a>3.1.3 垃圾回收统计</h3><p><code>jstat -gc &lt;pid&gt;</code></p>
<p>显示gc的信息，查看gc的次数，及时间。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6c7772ec1a693d7702905d45950f2a661d0.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>S0C</td>
<td>年轻代中第一个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S1C</td>
<td>年轻代中第二个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S0U</td>
<td>年轻代中第一个survivor（幸存区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>S1U</td>
<td>年轻代中第二个survivor（幸存区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>EC</td>
<td>年轻代中Eden（伊甸区）的容量 (字节)</td>
</tr>
<tr>
<td>EU</td>
<td>年轻代中Eden（伊甸区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>OC</td>
<td>Old代的容量 (字节)</td>
</tr>
<tr>
<td>OU</td>
<td>Old代目前已使用空间 (字节)</td>
</tr>
<tr>
<td>PC</td>
<td>Perm(持久代)的容量 (字节)</td>
</tr>
<tr>
<td>PU</td>
<td>Perm(持久代)目前已使用空间 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>YGCT</td>
<td>从应用程序启动到采样时年轻代中gc所用时间(s)</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
<tr>
<td>FGCT</td>
<td>从应用程序启动到采样时old代(full gc)gc所用时间(s)</td>
</tr>
<tr>
<td>GCT</td>
<td>从应用程序启动到采样时gc用的总时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-4-堆内存统计"><a href="#3-1-4-堆内存统计" class="headerlink" title="3.1.4 堆内存统计"></a>3.1.4 堆内存统计</h3><p><code>jstat -gccapacity &lt;pid&gt;</code></p>
<p>显示VM内存中三代（young，old，perm）对象的使用和占用大小</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c3cb2a0c165067a785f1e82eac8e86d5d6a.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>NGCMN</td>
<td>年轻代(young)中初始化(最小)的大小(字节)</td>
</tr>
<tr>
<td>NGCMX</td>
<td>年轻代(young)的最大容量 (字节)</td>
</tr>
<tr>
<td>NGC</td>
<td>年轻代(young)中当前的容量 (字节)</td>
</tr>
<tr>
<td>S0C</td>
<td>年轻代中第一个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S1C</td>
<td>年轻代中第二个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>EC</td>
<td>年轻代中Eden（伊甸区）的容量 (字节)</td>
</tr>
<tr>
<td>OGCMN</td>
<td>old代中初始化(最小)的大小 (字节)</td>
</tr>
<tr>
<td>OGCMX</td>
<td>old代的最大容量(字节)</td>
</tr>
<tr>
<td>OGC</td>
<td>old代当前新生成的容量 (字节)</td>
</tr>
<tr>
<td>OC</td>
<td>old代的容量 (字节)</td>
</tr>
<tr>
<td>PGCMN</td>
<td>perm代中初始化(最小)的大小 (字节)</td>
</tr>
<tr>
<td>PGCMX</td>
<td>perm代的最大容量 (字节)</td>
</tr>
<tr>
<td>PGC</td>
<td>perm代当前新生成的容量 (字节)</td>
</tr>
<tr>
<td>PC</td>
<td>Perm(持久代)的容量 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
</tbody></table>
<h3 id="3-1-5-新生代垃圾回收统计"><a href="#3-1-5-新生代垃圾回收统计" class="headerlink" title="3.1.5 新生代垃圾回收统计"></a>3.1.5 新生代垃圾回收统计</h3><p><code>jstat -gcnew &lt;pid&gt;</code></p>
<p>统计年轻代对象的信息</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ba28e19bd75231959a868d3fa24644cb3ef.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>S0C</td>
<td>年轻代中第一个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S1C</td>
<td>年轻代中第二个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S0U</td>
<td>年轻代中第一个survivor（幸存区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>S1U</td>
<td>年轻代中第二个survivor（幸存区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>TT</td>
<td>持有次数限制</td>
</tr>
<tr>
<td>MTT</td>
<td>最大持有次数限制</td>
</tr>
<tr>
<td>DSS</td>
<td>期望的幸存区大小</td>
</tr>
<tr>
<td>EC</td>
<td>年轻代中Eden（伊甸区）的容量 (字节)</td>
</tr>
<tr>
<td>EU</td>
<td>年轻代中Eden（伊甸区）目前已使用空间 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>YGCT</td>
<td>从应用程序启动到采样时年轻代中gc所用时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-6-新生代内存统计"><a href="#3-1-6-新生代内存统计" class="headerlink" title="3.1.6 新生代内存统计"></a>3.1.6 新生代内存统计</h3><p><code>jstat -gcnewcapacity &lt;pid&gt;</code></p>
<p>统计年轻代对象的信息及其占用量。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-be84ee14d1f8990973fbfffa1f014827082.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>NGCMN</td>
<td>年轻代(young)中初始化(最小)的大小(字节)</td>
</tr>
<tr>
<td>NGCMX</td>
<td>年轻代(young)的最大容量 (字节)</td>
</tr>
<tr>
<td>NGC</td>
<td>年轻代(young)中当前的容量 (字节)</td>
</tr>
<tr>
<td>S0CMX</td>
<td>年轻代中第一个survivor（幸存区）的最大容量 (字节)</td>
</tr>
<tr>
<td>S0C</td>
<td>年轻代中第一个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>S1CMX</td>
<td>年轻代中第二个survivor（幸存区）的最大容量 (字节)</td>
</tr>
<tr>
<td>S1C</td>
<td>年轻代中第二个survivor（幸存区）的容量 (字节)</td>
</tr>
<tr>
<td>ECMX</td>
<td>年轻代中Eden（伊甸区）的最大容量 (字节)</td>
</tr>
<tr>
<td>EC</td>
<td>年轻代中Eden（伊甸区）的容量 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
</tbody></table>
<h3 id="3-1-7-老年代垃圾回收统计"><a href="#3-1-7-老年代垃圾回收统计" class="headerlink" title="3.1.7 老年代垃圾回收统计"></a>3.1.7 老年代垃圾回收统计</h3><p><code>jstat -gcold &lt;pid&gt;</code></p>
<p>统计老年代对象的信息</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-44a6d03fa59ee3d179a5352c3f8c17c15b7.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>MC</td>
<td>方法区大小</td>
</tr>
<tr>
<td>MU</td>
<td>方法区使用大小</td>
</tr>
<tr>
<td>CCSC</td>
<td>压缩类空间大小</td>
</tr>
<tr>
<td>CCSU</td>
<td>压缩类空间使用大小</td>
</tr>
<tr>
<td>OC</td>
<td>Old代的容量 (字节)</td>
</tr>
<tr>
<td>OU</td>
<td>Old代目前已使用空间 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
<tr>
<td>YGCT</td>
<td>从应用程序启动到采样时年轻代中gc所用时间(s)</td>
</tr>
<tr>
<td>GCT</td>
<td>从应用程序启动到采样时gc用的总时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-8-老年代内存统计"><a href="#3-1-8-老年代内存统计" class="headerlink" title="3.1.8 老年代内存统计"></a>3.1.8 老年代内存统计</h3><p><code>jstat -gcoldcapacity &lt;pid&gt;</code></p>
<p>统计老年代对象的信息及其占用量</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fcb6eca9c1dd7c229a8833e66412f56fe94.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>OGCMN</td>
<td>old代中初始化(最小)的大小 (字节)</td>
</tr>
<tr>
<td>OGCMX</td>
<td>old代的最大容量(字节)</td>
</tr>
<tr>
<td>OGC</td>
<td>old代当前新生成的容量 (字节)</td>
</tr>
<tr>
<td>OC</td>
<td>Old代的容量 (字节)</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
<tr>
<td>YGCT</td>
<td>从应用程序启动到采样时年轻代中gc所用时间(s)</td>
</tr>
<tr>
<td>GCT</td>
<td>从应用程序启动到采样时gc用的总时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-9-元数据空间统计"><a href="#3-1-9-元数据空间统计" class="headerlink" title="3.1.9 元数据空间统计"></a>3.1.9 元数据空间统计</h3><p><code>jstat -gcmetacapacity &lt;pid&gt;</code></p>
<p>统计元数据空间容量</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b99529bc7810a586ef2d23f874cc9519a9f.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>MCMN</td>
<td>最小元数据容量</td>
</tr>
<tr>
<td>MCMX</td>
<td>最大元数据容量</td>
</tr>
<tr>
<td>MC</td>
<td>方法区大小</td>
</tr>
<tr>
<td>CCSMN</td>
<td>最小压缩类空间大小</td>
</tr>
<tr>
<td>CCSMX</td>
<td>最大压缩类空间大小</td>
</tr>
<tr>
<td>CCSC</td>
<td>压缩类空间大小</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
<tr>
<td>FGCT</td>
<td>从应用程序启动到采样时old代(full gc)gc所用时间(s)</td>
</tr>
<tr>
<td>GCT</td>
<td>从应用程序启动到采样时gc用的总时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-10-总结垃圾回收统计"><a href="#3-1-10-总结垃圾回收统计" class="headerlink" title="3.1.10 总结垃圾回收统计"></a>3.1.10 总结垃圾回收统计</h3><p><code>jstat -gcutil &lt;pid&gt;</code></p>
<p>统计gc容量占比信息</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e9c3e67acc4d4e817d3c206512b067d181e.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>S0</td>
<td>年轻代中第一个survivor（幸存区）已使用的占当前容量百分比</td>
</tr>
<tr>
<td>S1</td>
<td>年轻代中第二个survivor（幸存区）已使用的占当前容量百分比</td>
</tr>
<tr>
<td>E</td>
<td>年轻代中Eden（伊甸区）已使用的占当前容量百分比</td>
</tr>
<tr>
<td>O</td>
<td>old代已使用的占当前容量百分比</td>
</tr>
<tr>
<td>P</td>
<td>perm代已使用的占当前容量百分比</td>
</tr>
<tr>
<td>YGC</td>
<td>从应用程序启动到采样时年轻代中gc次数</td>
</tr>
<tr>
<td>YGCT</td>
<td>从应用程序启动到采样时年轻代中gc所用时间(s)</td>
</tr>
<tr>
<td>FGC</td>
<td>从应用程序启动到采样时old代(full gc)gc次数</td>
</tr>
<tr>
<td>FGCT</td>
<td>从应用程序启动到采样时old代(full gc)gc所用时间(s)</td>
</tr>
<tr>
<td>GCT</td>
<td>从应用程序启动到采样时gc用的总时间(s)</td>
</tr>
</tbody></table>
<h3 id="3-1-11-JVM编译方法统计"><a href="#3-1-11-JVM编译方法统计" class="headerlink" title="3.1.11 JVM编译方法统计"></a>3.1.11 JVM编译方法统计</h3><p><code>jstat -printcompilation &lt;pid&gt;</code></p>
<p>统计 JVM编译方法的信息</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-918c3cea79f7a31ccdf12b7a0aa75eb461a.png" alt=""></p>
<table>
<thead>
<tr>
<th>显示列名</th>
<th>具体描述</th>
</tr>
</thead>
<tbody><tr>
<td>Compiled</td>
<td>最近编译方法的数量</td>
</tr>
<tr>
<td>Size</td>
<td>最近编译方法的字节码数量</td>
</tr>
<tr>
<td>Type</td>
<td>最近编译方法的编译类型。</td>
</tr>
<tr>
<td>Method</td>
<td>方法名标识</td>
</tr>
</tbody></table>
<h2 id="3-2-jconsole（可视化监控控制台）"><a href="#3-2-jconsole（可视化监控控制台）" class="headerlink" title="3.2 jconsole（可视化监控控制台）"></a>3.2 jconsole（可视化监控控制台）</h2><h2 id="3-3-jhat（用于分析内存快照文件）"><a href="#3-3-jhat（用于分析内存快照文件）" class="headerlink" title="3.3 jhat（用于分析内存快照文件）"></a>3.3 jhat（用于分析内存快照文件）</h2><h1 id="4-分析工具"><a href="#4-分析工具" class="headerlink" title="4. 分析工具"></a>4. 分析工具</h1><h2 id="4-1-visualvm（故障分析工具）"><a href="#4-1-visualvm（故障分析工具）" class="headerlink" title="4.1 visualvm（故障分析工具）"></a>4.1 visualvm（故障分析工具）</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/14/JAVA%E5%86%85%E7%BD%AE%E6%8E%92%E5%BA%8FArrays-sort%E5%AE%9E%E7%8E%B0%E7%AE%80%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/14/JAVA%E5%86%85%E7%BD%AE%E6%8E%92%E5%BA%8FArrays-sort%E5%AE%9E%E7%8E%B0%E7%AE%80%E8%BF%B0/" itemprop="url">JAVA内置排序Arrays.sort实现简述</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-10-14T21:29:28+08:00">
                2020-10-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/JAVA%E5%AE%9E%E7%8E%B0%E6%88%96%E7%89%B9%E6%80%A7/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA实现或特性</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/10/14/JAVA%E5%86%85%E7%BD%AE%E6%8E%92%E5%BA%8FArrays-sort%E5%AE%9E%E7%8E%B0%E7%AE%80%E8%BF%B0/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/10/14/JAVA内置排序Arrays-sort实现简述/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  8
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在JAVA开发中，我们经常需要操作数组和集合，其中数组和链表的排序是重中之重。</p>
<p>Arrays.sort方法用来对数组排序。Collections.sort()方法用来对链表排序，而Collections.sort()的底层，其实使用的也是Arrays.sort方法。</p>
<p>所以JAVA内置排序的核心类，都在于Arrays工具类，接下来我们也重点剖析该类。</p>
<h1 id="1-Arrays工具类"><a href="#1-Arrays工具类" class="headerlink" title="1. Arrays工具类"></a>1. Arrays工具类</h1><p>我们先来看下Arrays工具类对外暴露的sort方法列表。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-53f7ef7792c0b7ceae71ba767016263106b.png" alt=""></p>
<p><strong>A：从排序范围角度划分，sort方法分为了</strong></p>
<ol>
<li>针对数组的整体做排序的方法，如<ul>
<li><code>sort(int[] a)</code></li>
<li><code>sort(Object[] a)</code></li>
<li><code>sort(T[] a, Comparator&lt;? super T&gt; c)</code></li>
</ul>
</li>
<li>针对数组的局部做排序的方法，如<ul>
<li><code>sort(int[] a, int fromIndex, int toIndex)</code></li>
<li><code>sort(Object[] a , int fromIndex, int toIndex)</code></li>
<li><code>sort(T[] a, int fromIndex, int toIndex,Comparator&lt;? super T&gt; c)</code></li>
</ul>
</li>
</ol>
<p><strong>B：从排序类型角度划分，sort方法分为了</strong></p>
<ol>
<li>对数组按照默认升序的方式进行排序的方法，如<ul>
<li><code>sort(int[] a)</code></li>
<li><code>sort(Object[] a)</code></li>
<li><code>sort(int[] a, int fromIndex, int toIndex)</code></li>
<li><code>sort(Object[] a , int fromIndex, int toIndex)</code></li>
</ul>
</li>
<li>对数组按照自定义排序类型进行排序的方法，如<ul>
<li><code>sort(T[] a, Comparator&lt;? super T&gt; c)</code></li>
<li><code>sort(T[] a, int fromIndex, int toIndex,Comparator&lt;? super T&gt; c)</code></li>
</ul>
</li>
</ol>
<p><strong>C：从操作对象角度划分，sort方法分为了</strong></p>
<ol>
<li>对基本类型（byte，int，char等）数组操作的方法<ul>
<li><code>sort(int[] a)</code></li>
<li><code>sort(int[] a, int fromIndex, int toIndex)</code></li>
</ul>
</li>
<li>对对象类型（object）数组操作的方法<ul>
<li><code>sort(Object[] a)</code></li>
<li><code>sort(Object[] a , int fromIndex, int toIndex)</code></li>
<li><code>sort(T[] a, Comparator&lt;? super T&gt; c)</code></li>
<li><code>sort(T[] a, int fromIndex, int toIndex,Comparator&lt;? super T&gt; c)</code></li>
</ul>
</li>
</ol>
<p>这里最重要的划分是C：从操作对象角度划分，因为JAVA对不同类型的数组，定义了不同的实现方法（以常用的JDK 1.8版本为例），我们先来开门见山的总结一下：</p>
<h1 id="2-基本类型数组的排序"><a href="#2-基本类型数组的排序" class="headerlink" title="2. 基本类型数组的排序"></a>2. 基本类型数组的排序</h1><p>对于基本数据类型的数组，假设数组长度为length：</p>
<ol>
<li>如果length&lt;47，那么采用<strong>插入排序算法</strong>。</li>
<li>如果47&lt;=length&lt;286，或者286&lt;=length，但数组不具备特定结构，那么使用<strong>快速排序的一种优化形式：双轴快排算法</strong>。</li>
<li>如果286&lt;=length，并且数组具备特定结构，那么使用<strong>归并排序算法</strong>。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-205a0fbd3c9218e765bbbd1a17947a400d9.png" alt=""></p>
<h2 id="2-1-数组是否具备特定结构"><a href="#2-1-数组是否具备特定结构" class="headerlink" title="2.1 数组是否具备特定结构"></a>2.1 数组是否具备特定结构</h2><p>在判断是否使用归并排序前，要先判断数组是否具备特定结构，这是一个什么意思呢？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Check if the array is nearly sorted</span><br><span class="line">    for (int k &#x3D; left; k &lt; right; run[count] &#x3D; k) &#123;        if (a[k] &lt; a[k + 1]) &#123; &#x2F;&#x2F; ascending</span><br><span class="line">            while (++k &lt;&#x3D; right &amp;&amp; a[k - 1] &lt;&#x3D; a[k]);</span><br><span class="line">        &#125; else if (a[k] &gt; a[k + 1]) &#123; &#x2F;&#x2F; descending</span><br><span class="line">            while (++k &lt;&#x3D; right &amp;&amp; a[k - 1] &gt;&#x3D; a[k]);            for (int lo &#x3D; run[count] - 1, hi &#x3D; k; ++lo &lt; --hi; ) &#123;                int t &#x3D; a[lo]; a[lo] &#x3D; a[hi]; a[hi] &#x3D; t;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123; &#x2F;&#x2F; equal</span><br><span class="line">            for (int m &#x3D; MAX_RUN_LENGTH; ++k &lt;&#x3D; right &amp;&amp; a[k - 1] &#x3D;&#x3D; a[k]; ) &#123;                if (--m &#x3D;&#x3D; 0) &#123;</span><br><span class="line">                    sort(a, left, right, true);                    return;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;        &#x2F;*</span><br><span class="line">         * The array is not highly structured,</span><br><span class="line">         * use Quicksort instead of merge sort.</span><br><span class="line">         *&#x2F;</span><br><span class="line">        if (++count &#x3D;&#x3D; MAX_RUN_COUNT) &#123;</span><br><span class="line">            sort(a, left, right, true);            return;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>这里主要作用是看他数组具不具备结构：实际逻辑是分组排序，每个降序序列为一个组，像1,9,8,7,6,8。9到6是降序，为一个组，然后把降序的一组排成升序：1,6,7,8,9,8。然后再从最后的8开始继续往后面找。</p>
<p>每遇到这样一个降序组，++count，当count大于<code>MAX_RUN_COUNT（67）</code>，被判断为这个数组不具备结构，也就是说这数据时而升时而降，波峰波谷太多，排列太过陡峭，说明不适合采用归并排序，还是使用快速排序为宜。</p>
<p>如果count少于MAX_RUN_COUNT（67）的，说明这个数组还有点结构，就继续往下走下面的归并排序。</p>
<h2 id="2-2-双轴快排"><a href="#2-2-双轴快排" class="headerlink" title="2.2 双轴快排"></a>2.2 双轴快排</h2><p>双轴快排（DualPivotQuickSort）是快排的一种优化版本。双轴快速排序，顾名思义，取两个中心点pivot1，pivot2，且pivot≤pivot2，可将序列分成三段：x&lt;pivot1、pivot1≤x≤pivot2，x&lt;pivot2，然后分别对三段进行递归。基本过程如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b5a42087e1f49243697d3cd080bdfb1b949.png" alt=""></p>
<p>具体详细内容可见博客<a href="https://blog.csdn.net/Holmofy/article/details/71168530" target="_blank" rel="noopener" title="单轴快排（SinglePivotQuickSort）和双轴快排（DualPivotQuickSort）及其JAVA实现">单轴快排（SinglePivotQuickSort）和双轴快排（DualPivotQuickSort）及其JAVA实现</a></p>
<h1 id="3-对象类型数组的排序"><a href="#3-对象类型数组的排序" class="headerlink" title="3. 对象类型数组的排序"></a>3. 对象类型数组的排序</h1><p>对于对象类型的数组，假设数组长度为length：</p>
<ul>
<li><ol>
<li>如果length&lt;32，那么采用<strong>不包含合并操作的mini-TimSort算法</strong>。</li>
</ol>
</li>
<li><ol start="2">
<li>如果32&lt;=length，那么采用<strong>完整TimSort排序算法（一种结合了归并排序和插入排序的算法）</strong>。</li>
</ol>
</li>
</ul>
<h2 id="3-1-TimSort"><a href="#3-1-TimSort" class="headerlink" title="3.1 TimSort"></a>3.1 TimSort</h2><p>TimSort算法是一种起源于归并排序和插入排序的混合排序算法，设计初衷是为了在真实世界中的各种数据中可以有较好的性能。</p>
<p>基本工作过程是：</p>
<ol>
<li>扫描数组，确定其中的单调上升段和严格单调下降段，将严格下降段反转。我们将这样的段称之为run。 </li>
<li>定义最小run长度，短于此的run通过插入排序合并为长度高于最小run长度； </li>
<li>反复归并一些相邻run，过程中需要避免归并长度相差很大的run，直至整个排序完成； </li>
<li>如何避免归并长度相差很大run呢， 依次将run压入栈中，若栈顶run X，run Y，run Z 的长度违反了X&gt;Y+Z 或 Y&gt;Z 则Y run与较小长度的run合并，并再次放入栈中。 依据这个法则，能够尽量使得大小相同的run合并，以提高性能。注意Timsort是稳定排序故只有相邻的run才能归并。</li>
<li>Merge操作还可以辅之以galloping，具体细节可以自行研究。</li>
</ol>
<p>总之，timsort是工业级算法，其混用插入排序与归并排序，二分搜索等算法，亮点是充分利用待排序数据可能部分有序的事实，并且依据待排序数据内容动态改变排序策略——选择性进行归并以及galloping。</p>
<p>具体内容我们不展开，可详见<a href="https://www.imooc.com/article/257268" target="_blank" rel="noopener" title="Collections.sort()源码分析(基于JAVA8)">Collections.sort()源码分析(基于JAVA8)</a></p>
<h1 id="4-为什么要采用不同的算法？"><a href="#4-为什么要采用不同的算法？" class="headerlink" title="4. 为什么要采用不同的算法？"></a>4. 为什么要采用不同的算法？</h1><p>对于长度较小的数组使用插入排序这很好理解，虽然插入排序的时间复杂度为O(n^2)，但在n较小的情况下，插入排序性能要高于快速排序。</p>
<p>其次我们要知道，在n的数量较大时，归并排序和快速排序，都是性能最优的排序算法，他们的时间复杂度平均都在O(nlogn)左右，只不过区别在于归并排序是稳定的，快速排序是不稳定的。</p>
<blockquote>
<p>稳定是指相等的数据在排序之后仍然按照排序之前的前后顺序排列。</p>
</blockquote>
<p>对于基本数据类型，稳定性没有意义，所以它可以使用不稳定的快排（当然它也使用了归并排序）</p>
<p>而对于对象类型，稳定性是比较重要的，因为对象相等的判断比较复杂，我们无法寄希望于每个程序员都会重写准确的equal方法，故而稳妥起见，最好相等对象尽量保持排序前的顺序，故而我们使用都是稳定算法的<strong>归并排序和插入排序结合而成的TimSort算法</strong>。</p>
<p>另外一个原因是归并排序的比较次数比快排少，移动（对象引用的移动）次数比快排多，而对于对象来说，比较是相对耗时的操作，所以它不适合使用快排。</p>
<p>而对于基本数据类型来说，比较和移动都不怎么耗时，所以它用归并或者快排都可以</p>
<p>总结：</p>
<ol>
<li><p>基本数据类型数组使用快排+归并是因为：</p>
<ul>
<li>基本数据类型无所谓稳定性，可以采用非稳定的快排。</li>
<li>对于基本数据类型来说，比较和移动都不怎么耗时，所以它用归并或者快排都可以。</li>
</ul>
</li>
<li><p>对象数据类型数组使用TimSort排序是因为（或者换句话说，对象数据类型不使用快排是因为）：</p>
<ul>
<li>对象数据类型要求稳定性，需要采用稳定的归并+插入。</li>
<li>对于对象来说，比较操作相对耗时，所以用比较操作较少的归并排序可以扬长避短。</li>
</ul>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/30/MySQL%E6%97%A5%E5%BF%97%E4%BD%93%E7%B3%BB%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/30/MySQL%E6%97%A5%E5%BF%97%E4%BD%93%E7%B3%BB%E8%AF%A6%E8%A7%A3/" itemprop="url">MySQL日志体系详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-30T23:44:48+08:00">
                2020-09-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/30/MySQL%E6%97%A5%E5%BF%97%E4%BD%93%E7%B3%BB%E8%AF%A6%E8%A7%A3/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/30/MySQL日志体系详解/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  8.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  34
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>日志是MySQL数据库的重要组成部分。日志文件中记录着MySQL数据库运行期间发生的变化；也就是说用来记录MySQL数据库的客户端连接状况、SQL语句的执行情况和错误信息等。当数据库遭到意外的损坏时，可以通过日志查看文件出错的原因，并且可以通过日志文件进行数据恢复。</p>
<p>MySQL的日志体系有如下几种分类：</p>
<ol>
<li>错误日志</li>
<li>查询日志</li>
<li>慢查询日志</li>
<li><strong>事务日志(Redo log/undo log)</strong></li>
<li><strong>二进制日志</strong></li>
<li>中继日志</li>
</ol>
<p>其中标粗的事务日志和二进制日志，是重中之重。</p>
<h1 id="1-错误日志"><a href="#1-错误日志" class="headerlink" title="1 错误日志"></a>1 错误日志</h1><p>在默认情况下，MySQL的错误日志是开启的，且无法被禁止。在没有指定的情况下，它一般是存储在数据库的数据文件目录中，名称为hostname.err，其中，hostname为服务器主机名。</p>
<h2 id="1-1-错误日志的内容"><a href="#1-1-错误日志的内容" class="headerlink" title="1.1 错误日志的内容"></a>1.1 错误日志的内容</h2><ol>
<li>服务器启动和关闭过程中的信息，未必是错误信息，比如mysql是如何去初始化存储引擎的过程记录在错误日志里等等</li>
<li>服务器运行过程中的错误信息（或者告警信息），比如sock文件找不到，无法加载mysql数据库的数据文件，如果忘记初始化mysql或data dir路径找不到，或权限不正确等 都会记录在此</li>
<li>事件调度器运行一个事件时产生的信息，一旦mysql调度启动一个计划任务（event scheduler）的时候，它也会将相关信息记录在错误日志中</li>
<li>在从服务器上启动从服务器进程时产生的信息，在复制环境下，从服务器进程的信息也会被记录进错误日志</li>
</ol>
<h2 id="1-2-配置相关"><a href="#1-2-配置相关" class="headerlink" title="1.2 配置相关"></a>1.2 配置相关</h2><h3 id="1-2-1-开启错误日志"><a href="#1-2-1-开启错误日志" class="headerlink" title="1.2.1 开启错误日志"></a>1.2.1 开启错误日志</h3><ol>
<li><p>在/etc/my.cnf配置文件中设置：</p>
<ul>
<li>如果需要手动指定错误日志路径的话只需要在<code>[mysqld]</code>字段中增加相关配置：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-cecfbe4ae32adc82200e726bfcee974be9f.png" alt=""></li>
</ul>
</li>
<li><p>如果没有在my.cnf配置文件中指定错误日志</p>
<ul>
<li>MySQL会自动将错误日志文件存放在datadir（数据目录）下，名为hostname.err（hostname根据实际主机名变化）。</li>
</ul>
</li>
<li><p>如果是通过YUM源进行安装</p>
<ul>
<li>错误日志会被配置在/var/log/mysqld.log中，这个也是由自动创建出的/etc/my.cnf所指定的。</li>
</ul>
</li>
</ol>
<h3 id="1-2-2-设置错误日志时区"><a href="#1-2-2-设置错误日志时区" class="headerlink" title="1.2.2 设置错误日志时区"></a>1.2.2 设置错误日志时区</h3><p>错误日志默认是使用utc时间，可以修改为系统时间方便查看</p>
<p><code>mysql &gt; set global log_timestamps=&#39;SYSTEM&#39;`</code></p>
<h3 id="1-2-3-删除错误日志"><a href="#1-2-3-删除错误日志" class="headerlink" title="1.2.3 删除错误日志"></a>1.2.3 删除错误日志</h3><p>在mysql5.5.7之前：数据库管理员可以删除很长时间之前的错误日志，以保证mysql服务器上的硬盘空间。mysql数据库中，可以使用mysqladmin命令开启新的错误日志。mysqladmin命令的语法如下：</p>
<p><code>mysqladmin –u root –pflush-logs</code></p>
<p>也可以使用登录mysql数据库中使用FLUSHLOGS语句来开启新的错误日志。</p>
<p>在mysql5.5.7之后：服务器将关闭此项功能。只能使用重命名原来的错误日志文件，手动冲洗日志创建一个新的：方式如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@stu18 data]<span class="comment"># mv stu18.magedu.com.err  stu18.magedu.com.err.old</span></span><br><span class="line">[root@stu18 data]<span class="comment">#  mysqladmin flush-logs</span></span><br><span class="line">[root@stu18 data]<span class="comment"># ls</span></span><br><span class="line">hellodb  myclass  mysql-bin.000003  mysql-bin.index           stu18.magedu.com.pid     ibda</span><br></pre></td></tr></table></figure>

<p>或者手动清理掉错误日志</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &gt; &#x2F;var&#x2F;log&#x2F;mysqld.log</span><br></pre></td></tr></table></figure>

<h2 id="1-3-查看错误日志和配置"><a href="#1-3-查看错误日志和配置" class="headerlink" title="1.3 查看错误日志和配置"></a>1.3 查看错误日志和配置</h2><p>查看log_error的配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;log_error&#39;;</span><br><span class="line">+---------------+---------------------+</span><br><span class="line">| Variable_name | Value               |</span><br><span class="line">+---------------+---------------------+</span><br><span class="line">| log_error     | &#x2F;var&#x2F;log&#x2F;mysqld.log |</span><br><span class="line">+---------------+---------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>查看错误日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql]# tailf &#x2F;var&#x2F;log&#x2F;mysqld.log</span><br><span class="line">130813  15:30:50  InnoDB: Starting shutdown...</span><br><span class="line">130813  15:30:51  InnoDB: Shutdown completed;  log sequence number 1630920</span><br><span class="line">130813 15:30:51  [Note] &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysqld: Shutdown complete</span><br><span class="line">130813 15:30:52  mysqld_safe mysqld from pid file &#x2F;mydata&#x2F;data&#x2F;stu18.magedu.com.pid ended</span><br><span class="line">130813 15:30:53  mysqld_safe Starting mysqld daemon with databases from &#x2F;mydata&#x2F;data</span><br><span class="line">130813 15:30:54  InnoDB: The InnoDB memory heap is disabled     #禁用了InnoDB memory的堆功能。</span><br><span class="line">130813 15:30:54  InnoDB: Mutexes and rw_locks use GCC atomic builtins #Mutexes（互斥量）和rw_locks（行级锁）是GCC编译的是InnoDB内置的。</span><br><span class="line">130813 15:30:54  InnoDB: Compressed tables use zlib 1.2.3     #默认压缩工具是zlib</span><br><span class="line">130813 15:30:55  InnoDB: Initializing buffer pool, size &#x3D; 128.0M    #InnoDB引擎的缓冲池（buffer pool）的值大小</span><br><span class="line">130813 15:30:55  InnoDB: Completed initialization of buffer pool</span><br><span class="line">130813 15:30:55  InnoDB: highest supported file format is Barracuda.</span><br><span class="line">130813  15:30:57  InnoDB: Waiting for the  background threads to start</span><br><span class="line">130813 15:30:58  InnoDB: 5.5.33 started; log sequence number 1630920</span><br><span class="line">130813 15:30:58  [Note] Server hostname (bind-address): &#39;0.0.0.0&#39;; port: 3306</span><br><span class="line">130813 15:30:58  [Note]   - &#39;0.0.0.0&#39; resolves to  &#39;0.0.0.0&#39;;  #0.0.0.0会反解主机名，这里反解失败</span><br><span class="line">130813 15:30:58  [Note] Server socket created on IP: &#39;0.0.0.0&#39;.</span><br><span class="line">130813 15:30:58  [Note] Event Scheduler: Loaded 0 events    #事件调度器没有任何事件，因为没有装载。</span><br><span class="line">130813 15:30:58  [Note] &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysqld: ready for connections. #mysql启动完成等待客户端的请求。</span><br><span class="line">Version:  &#39;5.5.33-log&#39;  socket:  &#39;&#x2F;tmp&#x2F;mysql.sock&#39;  port: 3306  Source distribution  #创建一个本地sock用于本地连接。</span><br></pre></td></tr></table></figure>

<h1 id="2-查询日志"><a href="#2-查询日志" class="headerlink" title="2 查询日志"></a>2 查询日志</h1><p>查询日志在MySQL中被称为general log(通用日志)，查询日志里的内容不要被”查询日志”误导，认为里面只存储select语句，其实不然，查询日志里面记录了数据库执行的<strong>所有命令</strong>，不管语句是否正确，都会被记录，因为本质上insert/update/delete语句中，都包含了查询操作:</p>
<ul>
<li>insert的查询是为了避免数据冲突，如果此前插入过数据，当前插入的数据如果跟主键或唯一键的数据重复那肯定会报错</li>
<li>update时也会查询，因为更新的时候是更新某一块数据，要先根据where定位到更新的记录。</li>
<li>delete查询，只删除符合条件的数据，同样是根据where定位。</li>
</ul>
<p>因此增删改查都会产生日志，在并发操作非常多的场景下，查询信息会非常多，那么如果都记录下来会导致IO非常大，影响MySQL性能，因此如果不是在调试环境下，是不建议开启查询日志功能的。</p>
<p>查询日志的开启有助于帮助我们分析哪些语句执行密集，执行密集的select语句对应的数据是否能够被缓存，同时也可以帮助我们分析问题，所以，我们可以根据自己的实际情况来决定是否开启查询日志。</p>
<h2 id="2-1-查询日志配置相关"><a href="#2-1-查询日志配置相关" class="headerlink" title="2.1 查询日志配置相关"></a>2.1 查询日志配置相关</h2><h3 id="2-1-1-查看配置"><a href="#2-1-1-查看配置" class="headerlink" title="2.1.1 查看配置"></a>2.1.1 查看配置</h3><p>所以如果你要判断MySQL数据库是否开启了查询日志，可以使用下面命令。general_log为ON表示开启查询日志，OFF表示关闭查询日志。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;%general_log%&#39; or variables like &#39;%log_output%&#39;;</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">| Variable_name    | Value                        |</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">| general_log      | OFF                          |</span><br><span class="line">| general_log_file | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log |</span><br><span class="line">| log_output       | FILE                         |</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>参数general_log用来控制开启、关闭MySQL查询日志</li>
<li>参数general_log_file用来控制查询日志的位置</li>
<li>如果开启了查询日志，参数log_output控制着查询日志的存储方式，log_output可以设置为以下4种值:<ol>
<li>FILE : 表示日志存储在文件中</li>
<li>TABLE : 表示日志存储在mysql库中的general_log表中</li>
<li>FILE, TABLE : 表示将日志同时存储在文件和general_log表中，改值会徒增很多IO压力，一般不会这样设置</li>
<li>NONE : 表示不记录日志，即使general_log设置为ON， 如果log_output设置为NONE，也不会记录查询日志</li>
</ol>
</li>
</ul>
<blockquote>
<p>log_output不仅控制查询日志的输出，也控制着慢查询日志的输出，即: log_output设置为FILE，就表示查询日志和慢查询日志都存放在文件中，设置为TABLE，查询日志和慢查询日志都存放在mysql库中的general_log表中</p>
</blockquote>
<h3 id="2-1-2-开启或关闭查询日志"><a href="#2-1-2-开启或关闭查询日志" class="headerlink" title="2.1.2 开启或关闭查询日志"></a>2.1.2 开启或关闭查询日志</h3><ul>
<li>方法1: 在配置文件中设置(不推荐)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#可以在my.cnf里添加,1开启（0关闭）,当然了,这样要重启才能生效,有点多余了</span><br><span class="line">general-log &#x3D; 1</span><br><span class="line">log_output&#x3D;&#39;table&#39;</span><br></pre></td></tr></table></figure>

<p>然后重启MySQL实例</p>
<ul>
<li>方法2 : 通过命令设置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#也可以设置变量那样更改,1开启（0关闭）,即时生效,不用重启,首选当然是这样的了</span><br><span class="line">set global general_log&#x3D;1</span><br><span class="line">set global log_output&#x3D;&#39;table&#39;;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>通过该方式设置，MySQL实例重启后，相关配置又恢复到默认值。如果只是短暂时间内使用，推荐使用命令行方式</p>
</blockquote>
<h3 id="2-1-3-修改查询日志名称或位置"><a href="#2-1-3-修改查询日志名称或位置" class="headerlink" title="2.1.3 修改查询日志名称或位置"></a>2.1.3 修改查询日志名称或位置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;general_log%&#39;;</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">| Variable_name    | Value                        |</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">| general_log      | ON                           |</span><br><span class="line">| general_log_file | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log |</span><br><span class="line">+------------------+------------------------------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set global general_log&#x3D;&#39;OFF&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set global general_log_file&#x3D;&#39;&#x2F;u02&#x2F;mysql_log.log&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set global general_log&#x3D;&#39;ON&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br></pre></td></tr></table></figure>

<h2 id="2-2-查询日志的查看"><a href="#2-2-查询日志的查看" class="headerlink" title="2.2 查询日志的查看"></a>2.2 查询日志的查看</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from mysql.general_log;</span><br><span class="line">+---------------------+---------------------------+-----------+-----------+--------------+----------------------------------+</span><br><span class="line">| event_time          | user_host                 | thread_id | server_id | command_type | argument                         |</span><br><span class="line">+---------------------+---------------------------+-----------+-----------+--------------+----------------------------------+</span><br><span class="line">| 2017-07-06 12:32:05 | root[root] @ localhost [] |         1 |         1 | Query        | show variables like &#39;general%&#39;   |</span><br><span class="line">| 2017-07-06 12:32:28 | root[root] @ localhost [] |         1 |         1 | Query        | show variables like &#39;log_output&#39; |</span><br><span class="line">| 2017-07-06 12:32:41 | root[root] @ localhost [] |         1 |         1 | Query        | select * from MyDB.test          |</span><br><span class="line">| 2017-07-06 12:34:36 | [root] @ localhost []     |         3 |         1 | Connect      | root@localhost on                |</span><br><span class="line">| 2017-07-06 12:34:36 | root[root] @ localhost [] |         3 |         1 | Query        | KILL QUERY 1                     |</span><br><span class="line">| 2017-07-06 12:34:36 | root[root] @ localhost [] |         3 |         1 | Quit         |                                  |</span><br><span class="line">| 2017-07-06 12:34:51 | root[root] @ localhost [] |         1 |         1 | Query        | select * from mysql.general_log  |</span><br><span class="line">+---------------------+---------------------------+-----------+-----------+--------------+----------------------------------+</span><br><span class="line">7 rows in set (0.02 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure>

<h2 id="2-3-查询日志的归档"><a href="#2-3-查询日志的归档" class="headerlink" title="2.3 查询日志的归档"></a>2.3 查询日志的归档</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; system mv &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log  &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log.20170706</span><br><span class="line"></span><br><span class="line">mysql&gt; system mysqladmin flush-logs -p</span><br><span class="line"></span><br><span class="line">Enter password:</span><br></pre></td></tr></table></figure>

<p>或者你在shell中执行下面命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@DB-Server mysql]# mv &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log  &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;DB-Server.log.20170706</span><br><span class="line"></span><br><span class="line">[root@DB-Server mysql]# mysqladmin flush-logs -p</span><br><span class="line"></span><br><span class="line">Enter password:</span><br></pre></td></tr></table></figure>

<h1 id="3-慢查询日志"><a href="#3-慢查询日志" class="headerlink" title="3 慢查询日志"></a>3 慢查询日志</h1><p>慢查询会导致CPU，IOPS，内存消耗过高。当数据库遇到性能瓶颈时，大部分时间都是由于慢查询导致的。 开启慢查询日志，可以让MySQL记录下查询超过指定时间的语句，之后运维人员通过定位分析，能够很好的优化数据库性能。</p>
<p>慢查询日志记录的慢查询不仅仅是执行比较慢的SELECT语句，还有INSERT，DELETE，UPDATE，CALL等DML操作，只要超过了指定时间，都可以称为”慢查询”，被记录到慢查询日志中。</p>
<p>默认情况下，慢查询日志是不开启的，只有手动开启了，慢查询才会被记录到慢查询日志中。</p>
<h2 id="3-1-慢查询日志配置相关"><a href="#3-1-慢查询日志配置相关" class="headerlink" title="3.1 慢查询日志配置相关"></a>3.1 慢查询日志配置相关</h2><h3 id="3-1-1-查看配置"><a href="#3-1-1-查看配置" class="headerlink" title="3.1.1 查看配置"></a>3.1.1 查看配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &quot;%slow%&quot; or variables like &quot;%log_queries_not_using_indexes%&quot;;</span><br><span class="line">+-------------------------------+-------------------------------------------------+</span><br><span class="line">| Variable_name                 | Value                                           |</span><br><span class="line">+-------------------------------+-------------------------------------------------+</span><br><span class="line">| log_slow_admin_statements     | OFF                                             |</span><br><span class="line">| log_slow_slave_statements     | OFF                                             |</span><br><span class="line">| slow_launch_time              | 2                                               |</span><br><span class="line">| slow_query_log                | OFF                                             |</span><br><span class="line">| slow_query_log_file           | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;iz2zeaf3cg1099kiidi06mz-slow.log |</span><br><span class="line">| log_queries_not_using_indexes | ON                                              |</span><br><span class="line">+-------------------------------+-------------------------------------------------+</span><br><span class="line">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>其中</p>
<ul>
<li>slow_query_log：慢查询开关，表示是否打开慢查询日志</li>
<li>long_query_time：慢查询指定时间设置，表示”多长时间的查询”被认定为”慢查询”，单位是秒(s)，默认是10s，即超过10s的查询都被认定为慢查询。</li>
<li>log_queries_not_using_indexes：表示如果运行的SQL语句没有使用到索引，是否也被当作慢查询语句记录到慢查询记录中，OFF表示不记录，ON表示记录。</li>
<li>如果开启了查询日志，参数log_output控制着查询日志的存储方式，log_output可以设置为以下4种值:<ol>
<li>FILE : 表示日志存储在文件中</li>
<li>TABLE : 表示日志存储在mysql库中的general_log表中</li>
<li>FILE, TABLE : 表示将日志同时存储在文件和general_log表中，改值会徒增很多IO压力，一般不会这样设置</li>
<li>NONE : 表示不记录日志，即使general_log设置为ON， 如果log_output设置为NONE，也不会记录查询日志</li>
</ol>
</li>
<li>slow_query_log_file：当使用文件存储慢查询日志时(log_output设置为”FILE”或者”FILE,TABLE”时)，制定慢查询日志存储在哪个文件中，默认的文件名是”主机名-slow.log”，存储目录为数据目录</li>
<li>log_throttle_queries_not_using_indexes: MySQL5.6.5版本新引入的参数，用来限制没有使用索引的语句每分钟记录到慢查询日志中的次数。在生产环境中，有可能有很多没有使用索引的语句，可能会导致慢查询日志快速增长。</li>
</ul>
<blockquote>
<p>log_output不仅控制查询日志的输出，也控制着慢查询日志的输出，即: log_output设置为FILE，就表示查询日志和慢查询日志都存放在文件中，设置为TABLE，查询日志和慢查询日志都存放在mysql库中的general_log表中</p>
</blockquote>
<h3 id="3-1-2-开启或关闭慢查询日志"><a href="#3-1-2-开启或关闭慢查询日志" class="headerlink" title="3.1.2 开启或关闭慢查询日志"></a>3.1.2 开启或关闭慢查询日志</h3><ul>
<li>方法1: 在配置文件中设置(不推荐)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#可以在my.cnf里添加,1开启（0关闭）,当然了,这样要重启才能生效,有点多余了</span><br><span class="line">slow_query_log&#x3D;1</span><br></pre></td></tr></table></figure>

<p>然后重启MySQL实例</p>
<ul>
<li>方法2 : 通过命令设置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#也可以设置变量那样更改,ON开启（OFF关闭）,即时生效,不用重启,首选当然是这样的了</span><br><span class="line">mysql&gt; set global slow_query_log&#x3D;&#39;ON&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"># 设置慢查询时间</span><br><span class="line">mysql&gt; set global long_query_time&#x3D;0.05;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"># 关闭慢查询</span><br><span class="line">mysql&gt; set global slow_query_log&#x3D;&#39;OFF&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>通过该方式设置，MySQL实例重启后，相关配置又恢复到默认值。如果只是短暂时间内使用，推荐使用命令行方式</p>
</blockquote>
<blockquote>
<p>设置long_query_time这个阈值之后，MySQL数据库会记录运行时间超过该值的所有SQL语句，但对于运行时间正好等于 long_query_time 的情况，并不会被记录下。可以设置 long_query_time为0来捕获所有的查询</p>
</blockquote>
<h3 id="3-1-3-查看当前有多少条慢日志"><a href="#3-1-3-查看当前有多少条慢日志" class="headerlink" title="3.1.3 查看当前有多少条慢日志"></a>3.1.3 查看当前有多少条慢日志</h3><p>如果你想查询有多少条慢查询记录，可以使用系统变量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global status like &#39;%slow_queries%&#39;;</span><br><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| Slow_queries  | 0     |</span><br><span class="line">+---------------+-------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; &#96;</span><br></pre></td></tr></table></figure>

<h2 id="3-2-慢查询日志分析工具pt-query-digest"><a href="#3-2-慢查询日志分析工具pt-query-digest" class="headerlink" title="3.2 慢查询日志分析工具pt-query-digest"></a>3.2 慢查询日志分析工具pt-query-digest</h2><h3 id="3-2-1-pt-query-digest的使用"><a href="#3-2-1-pt-query-digest的使用" class="headerlink" title="3.2.1 pt-query-digest的使用"></a>3.2.1 pt-query-digest的使用</h3><p>pt-query-digest 是分析MySQL查询日志最有力的工具，该工具功能强大，它可以分析binlog，Generallog，slowlog，也可以通过show processlist或者通过 tcpdump 抓取的MySQL协议数据来进行分析，比 mysqldumpslow 更具体，更完善。</p>
<p>下载安装 <a href="https://www.percona.com/downloads/percona-toolkit/LATEST/" target="_blank" rel="noopener">https://www.percona.com/downloads/percona-toolkit/LATEST/</a></p>
<p>在windows下，下载tar.gz包，解压之后，使用perl命令运行</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9f38776eb1af0452f182405bcc051088b47.png" alt=""></p>
<p>其命令格式如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">pt-query-digest [OPTIONS] [FILES] [DSN]</span><br><span class="line">--create-review-table  当使用--review参数把分析结果输出到表中时，如果没有表就自动创建。</span><br><span class="line">--create-history-table  当使用--history参数把分析结果输出到表中时，如果没有表就自动创建。</span><br><span class="line">--filter  对输入的慢查询按指定的字符串进行匹配过滤后再进行分析</span><br><span class="line">--limit    限制输出结果百分比或数量，默认值是20,即将最慢的20条语句输出，如果是50%则按总响应时间占比从大到小排序，输出到总和达到50%位置截止。</span><br><span class="line">--host  mysql服务器地址</span><br><span class="line">--user  mysql用户名</span><br><span class="line">--password  mysql用户密码</span><br><span class="line">--history 将分析结果保存到表中，分析结果比较详细，下次再使用--history时，如果存在相同的语句，且查询所在的时间区间和历史表中的不同，则会记录到数据表中，可以通过查询同一CHECKSUM来比较某类型查询的历史变化。</span><br><span class="line">--review 将分析结果保存到表中，这个分析只是对查询条件进行参数化，一个类型的查询一条记录，比较简单。当下次使用--review时，如果存在相同的语句分析，就不会记录到数据表中。</span><br><span class="line">--output 分析结果输出类型，值可以是report(标准分析报告)、slowlog(Mysql slow log)、json、json-anon，一般使用report，以便于阅读。</span><br><span class="line">--since 从什么时间开始分析，值为字符串，可以是指定的某个”yyyy-mm-dd [hh:mm:ss]”格式的时间点，也可以是简单的一个时间值：s(秒)、h(小时)、m(分钟)、d(天)，如12h就表示从12小时前开始统计。</span><br><span class="line">--until 截止时间，配合—since可以分析一段时间内的慢查询。</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-pt-query-digest的结果"><a href="#3-2-2-pt-query-digest的结果" class="headerlink" title="3.2.2 pt-query-digest的结果"></a>3.2.2 pt-query-digest的结果</h3><p>输出结果分为三部分</p>
<ol>
<li>总体统计结果</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 该工具执行日志分析的用户时间，系统时间，物理内存占用大小，虚拟内存占用大小</span><br><span class="line"># 343ms user time, 78ms system time, 0 rss, 0 vsz</span><br><span class="line"># 工具执行时间</span><br><span class="line"># Current date: Thu Mar 29 15:51:38 2018</span><br><span class="line"># 运行分析工具的主机名</span><br><span class="line"># Hostname: NB2015041602</span><br><span class="line"># 被分析的文件名</span><br><span class="line"># Files: &#x2F;d&#x2F;xampp&#x2F;mysql&#x2F;data&#x2F;NB2015041602-slow.log</span><br><span class="line"># 语句总数量，唯一的语句数量，QPS，并发数</span><br><span class="line"># Overall: 5 total, 3 unique, 0.00 QPS, 0.05x concurrency ________________</span><br><span class="line"># 日志记录的时间范围</span><br><span class="line"># Time range: 2018-03-28 14:02:06 to 14:22:10</span><br><span class="line"># 属性               总计      最小    最大    平均    95%  标准    中等</span><br><span class="line"># Attribute          total     min     max     avg     95%  stddev  median</span><br><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;     &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"># 语句执行时间</span><br><span class="line"># Exec time            60s     10s     17s     12s     17s      3s     11s</span><br><span class="line"># 锁占用时间</span><br><span class="line"># Lock time            1ms       0   500us   200us   490us   240us       0</span><br><span class="line"># 发送到客户端的行数</span><br><span class="line"># Rows sent             50      10      10      10      10       0      10</span><br><span class="line"># select语句扫描行数</span><br><span class="line"># Rows examine     629.99k  45.43k 146.14k 126.00k 143.37k  39.57k 143.37k</span><br><span class="line"># 查询的字符数</span><br><span class="line"># Query size         2.81k     235   1.36k  575.40   1.33k  445.36  234.30</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>查询分组统计结果</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># rank：所有语句的排序，默认按照查询时间降序排序，通过--order-by指定</span><br><span class="line"># # query id：语句的id，（去掉多余空格和文本字符，计算hash值）</span><br><span class="line"># response：总的响应时间</span><br><span class="line"># time：该查询在本次分析中总的时间占比</span><br><span class="line"># calls：执行次数，即本次分析总共有多少条这种类型的查询语句</span><br><span class="line"># r&#x2F;call：平均每次执行的响应时间</span><br><span class="line"># v&#x2F;m：响应时间variance-to-mean的比率</span><br><span class="line"># item：查询对象</span><br><span class="line"></span><br><span class="line"># Profile</span><br><span class="line"># Rank Query ID           Response time Calls R&#x2F;Call  V&#x2F;M   Item</span><br><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">#    1 0x96112A601F7BCCC0 32.9042 55.0%     3 10.9681  0.01 SELECT affiliatemerchant_list user_list</span><br><span class="line">#    2 0x70885F9703A0E38D 17.2162 28.8%     1 17.2162  0.00 SELECT normalmerchant merchant_mapping normalmerchant_addinfo merchant_search_filter affiliatemerchant_list user_list</span><br><span class="line">#    3 0x43D8527285567FC4  9.7367 16.3%     1  9.7367  0.00 SELECT affiliatemerchant_list user_list affiliatemerchant_list user_list</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>每一种查询的详细统计结果</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"># id：查询的id号，和上面的query id对应</span><br><span class="line"># # databases：数据库名</span><br><span class="line"># users：各个用户执行的次数（占比）</span><br><span class="line"># query_time_distribution：查询时间分布，长短体现区间占比</span><br><span class="line"># tables：查询中设计到的表</span><br><span class="line"># explain：sql语句</span><br><span class="line"></span><br><span class="line"># Query 1: 0.00 QPS, 0.03x concurrency, ID 0x96112A601F7BCCC0 at byte 2647</span><br><span class="line"># This item is included in the report because it matches --limit.</span><br><span class="line"># Scores: V&#x2F;M &#x3D; 0.01</span><br><span class="line"># Time range: 2018-03-28 14:03:31 to 14:19:54</span><br><span class="line"># Attribute    pct   total     min     max     avg     95%  stddev  median</span><br><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"># Count         60       3</span><br><span class="line"># Exec time     54     33s     11s     11s     11s     11s   243ms     11s</span><br><span class="line"># Lock time     50   500us       0   500us   166us   490us   231us       0</span><br><span class="line"># Rows sent     60      30      10      10      10      10       0      10</span><br><span class="line"># Rows examine  69 438.42k 146.14k 146.14k 146.14k 146.14k       0 146.14k</span><br><span class="line"># Query size    24     707     235     236  235.67  234.30       0  234.30</span><br><span class="line"># String:</span><br><span class="line"># Databases    database_base</span><br><span class="line"># Hosts        localhost</span><br><span class="line"># Users        root</span><br><span class="line"># Query_time distribution</span><br><span class="line">#   1us</span><br><span class="line">#  10us</span><br><span class="line"># 100us</span><br><span class="line">#   1ms</span><br><span class="line">#  10ms</span><br><span class="line"># 100ms</span><br><span class="line">#    1s</span><br><span class="line">#  10s+  ################################################################</span><br><span class="line"># Tables</span><br><span class="line">#    SHOW TABLE STATUS FROM &#96;database_base&#96; LIKE &#39;table_list1&#39;\G</span><br><span class="line">#    SHOW CREATE TABLE &#96;database_base&#96;.&#96;table_list1&#96;\G</span><br><span class="line">#    SHOW TABLE STATUS FROM &#96;database_base&#96; LIKE &#39;user_list&#39;\G</span><br><span class="line">#    SHOW CREATE TABLE &#96;database_base&#96;.&#96;user_list&#96;\G</span><br><span class="line"># EXPLAIN &#x2F;*!50100 PARTITIONS*&#x2F;</span><br><span class="line">select SQL_CALC_FOUND_ROWS al.*, ul.Alias as userName</span><br><span class="line">        FROM table_list1 al</span><br><span class="line">        LEFT JOIN user_list ul ON ul.ID &#x3D; al.UserId</span><br><span class="line">         WHERE TRUE  AND (al.SupportCountrys LIKE &#39;%%&#39;)</span><br><span class="line">         limit 80, 10\G</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3-pt-query-digest的命令"><a href="#3-2-3-pt-query-digest的命令" class="headerlink" title="3.2.3 pt-query-digest的命令"></a>3.2.3 pt-query-digest的命令</h3><p>以下是使用pt-query-digest的示例:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;直接分析慢查询文件</span><br><span class="line">pt-query-digest  slow.log &gt; slow_report.log</span><br><span class="line"></span><br><span class="line">分析最近12小时内的查询</span><br><span class="line">pt-query-digest  --since&#x3D;12h  slow.log &gt; slow_report2.log</span><br><span class="line"></span><br><span class="line">分析指定时间范围内的查询</span><br><span class="line">pt-query-digest slow.log --since &#39;2017-01-07 09:30:00&#39; --until &#39;2017-01-07 10:00:00&#39;&gt; &gt; slow_report3.log</span><br><span class="line"></span><br><span class="line">分析含有select语句的慢查询</span><br><span class="line">pt-query-digest --filter &#39;$event-&gt;&#123;fingerprint&#125; &#x3D;~ m&#x2F;^select&#x2F;i&#39; slow.log&gt; slow_report4.log</span><br><span class="line"></span><br><span class="line">针对某个用户的慢查询</span><br><span class="line">pt-query-digest --filter &#39;($event-&gt;&#123;user&#125; || &quot;&quot;) &#x3D;~ m&#x2F;^root&#x2F;i&#39; slow.log&gt; slow_report5.log</span><br><span class="line"></span><br><span class="line">查询所有全表扫描或full join的慢查询</span><br><span class="line">pt-query-digest --filter &#39;(($event-&gt;&#123;Full_scan&#125; || &quot;&quot;) eq &quot;yes&quot;) ||(($event-&gt;&#123;Full_join&#125; || &quot;&quot;) eq &quot;yes&quot;)&#39; slow.log&gt; slow_report6.log</span><br><span class="line"></span><br><span class="line">把查询保存到query_review表</span><br><span class="line">pt-query-digest --user&#x3D;root –password&#x3D;abc123 --review  h&#x3D;localhost,D&#x3D;test,t&#x3D;query_review--create-review-table  slow.log</span><br><span class="line"></span><br><span class="line">把查询保存到query_history表</span><br><span class="line">pt-query-digest  --user&#x3D;root –password&#x3D;abc123 --review  h&#x3D;localhost,D&#x3D;test,t&#x3D;query_history--create-review-table  slow.log_0001</span><br><span class="line">pt-query-digest  --user&#x3D;root –password&#x3D;abc123 --review  h&#x3D;localhost,D&#x3D;test,t&#x3D;query_history--create-review-table  slow.log_0002</span><br><span class="line"></span><br><span class="line">通过tcpdump抓取的tcp协议数据，然后分析</span><br><span class="line">tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 &gt; mysql.tcp.txt</span><br><span class="line">pt-query-digest --type tcpdump mysql.tcp.txt&gt; slow_report9.log</span><br><span class="line"></span><br><span class="line">分析biglog</span><br><span class="line">mysqlbinlog mysql-bin.000093 &gt; mysql-bin000093.sql</span><br><span class="line">pt-query-digest  --type&#x3D;binlog  mysql-bin000093.sql &gt; slow_report10.log</span><br><span class="line"></span><br><span class="line">分析general log</span><br><span class="line">pt-query-digest  --type&#x3D;genlog  localhost.log &gt; slow_report11.log</span><br></pre></td></tr></table></figure>

<p>该工具可以将查询的剖析报告打印出来，可以分析结果输出到文件中，分析过程是先对查询语句的条件进行参数化，然后对参数化以后的查询进行分组统计，统计出各查询的执行时间，次数，占比等，可以借助分析结果找出问题进行优化。</p>
<h2 id="3-3-慢查询日志分析工具mysqldumpslow"><a href="#3-3-慢查询日志分析工具mysqldumpslow" class="headerlink" title="3.3 慢查询日志分析工具mysqldumpslow"></a>3.3 慢查询日志分析工具mysqldumpslow</h2><p>mysqldumpslow是mysql自身提供的日志分析工具，一般在mysql的bin目录下</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4485cce5b262eea9f252ec10f4ce6b93f8b.png" alt=""></p>
<p>帮助信息如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">$ mysqldumpslow.pl --help</span><br><span class="line">Usage: mysqldumpslow [ OPTS... ] [ LOGS... ]</span><br><span class="line"></span><br><span class="line">Parse and summarize the MySQL slow query log. Options are</span><br><span class="line"></span><br><span class="line">  --verbose    verbose</span><br><span class="line">  --debug      debug</span><br><span class="line">  --help       write this text to standard output</span><br><span class="line"></span><br><span class="line">  -v           verbose</span><br><span class="line">  -d           debug</span><br><span class="line"></span><br><span class="line"> -s, 是表示按照何种方式排序</span><br><span class="line">    c: 访问计数</span><br><span class="line"></span><br><span class="line">    l: 锁定时间</span><br><span class="line"></span><br><span class="line">    r: 返回记录</span><br><span class="line"></span><br><span class="line">    t: 查询时间</span><br><span class="line"></span><br><span class="line">    al:平均锁定时间</span><br><span class="line"></span><br><span class="line">    ar:平均返回记录数</span><br><span class="line"></span><br><span class="line">    at:平均查询时间</span><br><span class="line"></span><br><span class="line">-t, 是top n的意思，即为返回前面多少条的数据；</span><br><span class="line">-g, 后边可以写一个正则匹配模式，大小写不敏感的；</span><br><span class="line"></span><br><span class="line">比如:</span><br><span class="line">得到返回记录集最多的10个SQL。</span><br><span class="line">mysqldumpslow -s r -t 10 &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log</span><br><span class="line"></span><br><span class="line">得到访问次数最多的10个SQL</span><br><span class="line">mysqldumpslow -s c -t 10 &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log</span><br><span class="line"></span><br><span class="line">得到按照时间排序的前10条里面含有左连接的查询语句。</span><br><span class="line">mysqldumpslow -s t -t 10 -g “left join” &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log</span><br><span class="line"></span><br><span class="line">另外建议在使用这些命令时结合 | 和more 使用 ，否则有可能出现刷屏的情况。</span><br><span class="line">mysqldumpslow -s r -t 20 &#x2F;mysqldata&#x2F;mysql&#x2F;mysql06-slow.log | more</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果不能执行，可以先安装perl，然后通过perl mysqldumpslow xxx.log</p>
</blockquote>
<h1 id="4-事务日志"><a href="#4-事务日志" class="headerlink" title="4 事务日志"></a>4 事务日志</h1><p>事务日志包括redo log和undo log，在阐述二者之前，我们必须明确，redo log是InnoDB引擎的一类日志，而不是MySQL服务端的日志。它是InnoDB实现事务的重要机制。</p>
<p>具体内容详见本博客文章《【InnoDB详解四】redo log和undo log》</p>
<h1 id="5-二进制日志"><a href="#5-二进制日志" class="headerlink" title="5 二进制日志"></a>5 二进制日志</h1><p>MySQL的二进制日志（binary log，简称binlog）是一个二进制文件，主要记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的所有操作。二进制日志（binary log）中记录了对MySQL数据库执行更改的所有操作，并且记录了语句发生时间、执行时长、操作数据等其它额外信息，但是它不记录SELECT、SHOW等那些不修改数据的SQL语句。</p>
<p>它和InnoDB的redo log很像，但注意redo log是InnoDB的，是引擎级别的，binlog是MySQL级别的，换言之，不论MySQL使用什么存储引擎，它都会产生binlog。</p>
<h2 id="5-1-binlog的作用"><a href="#5-1-binlog的作用" class="headerlink" title="5.1 binlog的作用"></a>5.1 binlog的作用</h2><ol>
<li><p>恢复（recovery）：某些数据的恢复需要二进制日志。例如，在一个数据库全备文件恢复后，用户可以通过二进制日志进行point-in-time的恢复。</p>
</li>
<li><p>复制（replication）：其原理与恢复类似，通过复制和执行二进制日志使一台远程的MySQL数据库（一般称为slave或者standby）与一台MySQL数据库（一般称为master或者primary）进行实时同步。</p>
</li>
<li><p>审计（audit）：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击。</p>
</li>
</ol>
<p>除了上面介绍的几个作用外，binlog对于事务存储引擎的崩溃恢复也有非常重要的作用。</p>
<p>在开启binlog的情况下，为了保证binlog与redo的一致性，MySQL将采用事务的两阶段提交协议。当MySQL系统发生崩溃时，事务在存储引擎内部的状态可能为prepared和commit两种。对于prepared状态的事务，是进行提交操作还是进行回滚操作，这时需要参考binlog：如果事务在binlog中存在，那么将其提交；如果不在binlog中存在，那么将其回滚，这样就保证了数据在主库和从库之间的一致性。</p>
<h2 id="5-2-binlog的存储"><a href="#5-2-binlog的存储" class="headerlink" title="5.2 binlog的存储"></a>5.2 binlog的存储</h2><p>为了管理所有的binlog文件，MySQL额外创建了一个base-name.index文件，它按顺序记录了MySQL使用的所有binlog文件。如果你想自定义index文件的名称，可以设置log_bin_index=file参数。千万不要在mysqld运行的时候手动修改index文件的内容，这样会使mysqld产生混乱。</p>
<h2 id="5-3-binlog的开启"><a href="#5-3-binlog的开启" class="headerlink" title="5.3 binlog的开启"></a>5.3 binlog的开启</h2><p>binlog默认关闭，如果想开启binlog，可以在MySQL配置文件中通过配置参数<code>log-bin = [base-name]</code>启动二进制日志。如果不指定base-name，则默认以主机名为二进制日志的文件名，并以自增的数字作为后缀，例如<code>mysql-bin.000001</code>，所在目录为数据库所在目录（datadir）。</p>
<p>顺序说一下，对于二进制文件当满足下面三种情况时会创建新的文件，文件后缀会自增。</p>
<ol>
<li>文件大小达到<code>max_binlog_size</code>参数设置值时。</li>
<li>执行flush logs命令。</li>
<li>重启mysqld进程。</li>
</ol>
<blockquote>
<p>你可能会有顾虑，当文件后缀从000001增长到999999时会怎样？有网友测试过，当文件达到999999时又会回到000001，并不会有什么异常。</p>
</blockquote>
<h2 id="5-4-binlog格式"><a href="#5-4-binlog格式" class="headerlink" title="5.4 binlog格式"></a>5.4 binlog格式</h2><p>binlog格式分为: STATEMENT、ROW和MIXED三种，详情如下:</p>
<ol>
<li><p>STATEMENT</p>
<ul>
<li>STATEMENT格式的binlog记录的是数据库上执行的原生SQL语句。</li>
<li>这种方式有好处：<ul>
<li>好处就是相当简单，简单地记录和执行这些语句，能够让主备保持同步，在主服务器上执行的SQL语句，在从服务器上执行同样的语句。</li>
<li>另一个好处是二进制日志里的时间更加紧凑，所以相对而言，基于语句的复制模式不会使用太多带宽，同时也节约磁盘空间。并且通过mysqlbinlog工具容易读懂其中的内容。</li>
</ul>
</li>
<li>这种方式也有坏处：<ul>
<li>坏处就是同一条SQL在主库和从库上执行的时间可能稍微或很大不相同，因此在传输的二进制日志中，除了查询语句，还包括了一些元数据信息，如当前的时间戳。<ul>
<li>即便如此，还存在着一些无法被正确复制的SQL。例如，使用INSERT INTO TB1 VALUE(CUURENT_DATE())这一条使用函数的语句插入的数据复制到当前从服务器上来就会发生变化。存储过程和触发器在使用基于语句的复制模式时也可能存在问题。</li>
<li>另外一个问题就是基于语句的复制必须是串行化的。这要求大量特殊的代码，配置，例如InnoDB的next-key锁等。并不是所有的存储引擎都支持基于语句的复制。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>ROW</p>
<ul>
<li>从MySQL5.1开始支持基于行的复制，也就是基于数据的复制，基于行的更改。这种方式会将实际数据记录在二进制日志中。</li>
<li>这种方式有好处：<ul>
<li>最大的好处是可以正确地复制每一行数据。一些语句可以被更加有效地复制</li>
<li>另外就是几乎没有基于行的复制模式无法处理的场景，对于所有的SQL构造、触发器、存储过程等都能正确执行。</li>
</ul>
</li>
<li>这种方式也有坏处：<ul>
<li>主要的缺点就是二进制日志可能会很大，而且不直观，所以，你不能使用mysqlbinlog来查看二进制日志。也无法通过看二进制日志判断当前执行到那一条SQL语句了。</li>
</ul>
</li>
</ul>
</li>
</ol>
<blockquote>
<p>现在对于ROW格式的二进制日志基本是标配了，主要是因为它的优势远远大于缺点。并且由于ROW格式记录行数据，所以可以基于这种模式做一些DBA工具，比如数据恢复，不同数据库之间数据同步等。</p>
</blockquote>
<ol start="3">
<li><p>MIXED</p>
<ul>
<li>MIXED也是MySQL默认使用的二进制日志记录方式，但MIXED格式默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。比如用到UUID()、USER()、CURRENT_USER()、ROW_COUNT()等无法确定的函数。</li>
</ul>
</li>
</ol>
<h1 id="6-中继日志"><a href="#6-中继日志" class="headerlink" title="6 中继日志"></a>6 中继日志</h1><p>relay log是复制过程中产生的日志，很多方面都跟binary log差不多，区别是: relay log是从库服务器I/O线程将<strong>主库服务器</strong>的二进制日志读取过来记录到<strong>从库服务器</strong>本地文件，然后<strong>从库</strong>的SQL线程会读取relay-log日志的内容并应用到<strong>从库服务器</strong>上。</p>
<h2 id="6-1-中继日志参数"><a href="#6-1-中继日志参数" class="headerlink" title="6.1 中继日志参数"></a>6.1 中继日志参数</h2><ul>
<li><p>max_relay_log_size<br>标记relay log 允许的最大值，如果该值为0，则默认值为max_binlog_size(1G)；如果不为0，则max_relay_log_size则为最大的relay_log文件大小；</p>
</li>
<li><p>relay_log<br>定义relay_log的位置和名称，如果值为空，则默认位置在数据文件的目录，文件名为host_name-relay-bin.nnnnnn（By default, relay log file names have the form host_name-relay-bin.nnnnnn in the data directory）；</p>
</li>
<li><p>relay_log_index<br>同relay_log，定义relay_log的位置和名称；</p>
</li>
<li><p>relay_log_info_file<br>设置<code>http://relay-log.info</code>的位置和名称（<a href="http://relay-log.info记录MASTER的binary_log的恢复位置和relay_log的位置）" target="_blank" rel="noopener">http://relay-log.info记录MASTER的binary_log的恢复位置和relay_log的位置）</a></p>
</li>
<li><p>relay_log_purge<br>是否自动清空不再需要中继日志时。默认值为1(启用)。</p>
</li>
<li><p>relay_log_recovery<br>当slave从库宕机后，假如relay-log损坏了，导致一部分中继日志没有处理，则自动放弃所有未执行的relay-log，并且重新从master上获取日志，这样就保证了relay-log的完整性。默认情况下该功能是关闭的，将relay_log_recovery的值设置为 1时，可在slave从库上开启该功能，建议开启。</p>
</li>
<li><p>relay_log_space_limit<br>防止中继日志写满磁盘，这里设置中继日志最大限额。但此设置存在主库崩溃，从库中继日志不全的情况，不到万不得已，不推荐使用；</p>
</li>
<li><p>sync_relay_log<br>这个参数和sync_binlog是一样的，当设置为1时，slave的I/O线程每次接收到master发送过来的binlog日志都要写入系统缓冲区，然后刷入relay log中继日志里，这样是最安全的，因为在崩溃的时候，你最多会丢失一个事务，但会造成磁盘的大量I/O。当设置为0时，并不是马上就刷入中继日志里，而是由操作系统决定何时来写入，虽然安全性降低了，但减少了大量的磁盘I/O操作。这个值默认是0，可动态修改。</p>
</li>
<li><p>sync_relay_log_info<br>这个参数和sync_relay_log参数一样，当设置为1时，slave的I/O线程每次接收到master发送过来的binlog日志都要写入系统缓冲区，然后刷入<code>http://relay-log.info</code>里，这样是最安全的，因为在崩溃的时候，你最多会丢失一个事务，但会造成磁盘的大量I/O。当设置为0时，并不是马上就刷入<code>http://relay-log.info</code> 里，而是由操作系统决定何时来写入，虽然安全性降低了，但减少了大量的磁盘I/O操作。这个值默认是0，可动态修改。</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/" itemprop="url">【InnoDB详解四】redo log和undo log</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-27T23:36:33+08:00">
                2020-09-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/27/【InnoDB详解四】redo-log和undo-log/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  12.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  45
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-redo-log"><a href="#1-redo-log" class="headerlink" title="1 redo log"></a>1 redo log</h1><p>首先我们先明确一下InnoDB的修改数据的基本流程，当我们想要修改DB上某一行数据的时候，InnoDB是把数据从磁盘读取到内存的缓冲池上进行修改。这个时候数据在内存中被修改，与磁盘中相比就存在了差异，我们称这种有差异的数据为脏页。</p>
<p>InnoDB对脏页的处理不是每次生成脏页就将脏页刷新回磁盘，<strong>这样会产生海量的IO操作，严重影响InnoDB的处理性能</strong>。对于此，InnoDB有一套完善的处理策略，与我们这次主题关系不大，表过不提。既然脏页与磁盘中的数据存在差异，那么如果在这期间DB出现故障就会造成数据的丢失（持久性问题产生了）。为了解决这个问题，redo log就应运而生了。</p>
<h2 id="1-1-redo-log的特点"><a href="#1-1-redo-log的特点" class="headerlink" title="1.1 redo log的特点"></a>1.1 redo log的特点</h2><ul>
<li><p>redo log在<strong>数据库重启恢复的时候被使用</strong>。</p>
</li>
<li><p>redo日志占用的空间非常小，存储表空间ID、页号、偏移量以及需要更新的值所需的存储空间是很小的。</p>
</li>
<li><p>redo log属于物理日志，他可以将已提交事务修改的记录记录下来，即某个表空间中某页的某个偏移量的值更新为多少。因为其属于<strong>物理日志</strong>的特性，恢复速度远快于逻辑日志。而我们下文即将介绍的binlog和undo log就属于典型的逻辑日志。</p>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-e43816535e5b18dcd0b5bb54be94f21344a.png" alt=""></p>
<ul>
<li><p>redo日志不止记录索引插入/更新记录等操作，还有执行这个操作影响到的其他动作，如页分裂新增目录项记录，修改页信息等对数据页做的任何修改等等。</p>
</li>
<li><p>redo日志记录的是物理页的情况，它具有幂等性，因此记录日志的方式极其简练。幂等性的意思是多次操作前后状态是一样的，例如新插入一行后又删除该行，前后状态没有变化。</p>
</li>
<li><p>redo日志是顺序写入磁盘的，在执行事务的过程中，每执行一条语句，就可能产生若干条redo日志，这些日志是按照产生的顺序写入磁盘的，也就是使用顺序IO，这比随机IO的性能要高得多。</p>
</li>
</ul>
<h2 id="1-2-redo-log的工作机制简述"><a href="#1-2-redo-log的工作机制简述" class="headerlink" title="1.2 redo log的工作机制简述"></a>1.2 redo log的工作机制简述</h2><p>redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的，并且事务的记录是顺序追加的，性能非常高(磁盘的<strong>顺序写</strong>性能比内存的写性能差不了太多)。</p>
<p>InnoDB使用日志+缓存的策略来减少提交事务时的开销。因为日志中已经记录了事务，所以就无须为了保证持久性而在每个事务提交时都把缓冲池的脏数据刷新(flush)到磁盘中。</p>
<p>事务修改的数据和索引通常会映射到表空间的随机位置，所以刷新这些变更到磁盘需要很多随机IO。InnoDB假设使用常规磁盘，随机IO比顺序IO昂贵得多，因为一个IO请求需要时间把磁头移到正确的位置，然后等待磁盘上读出需要的部分，再转到开始位置。</p>
<p>InnoDB用日志把随机IO变成顺序IO。一旦日志安全写到磁盘，事务就持久化了，即使断电了，InnoDB可以重放日志并且恢复已经提交的事务。</p>
<p>为了确保每次日志数据都能写入到磁盘的事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作(即fsync()系统调用)。</p>
<p>因为MySQL是工作在用户空间的，MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中(也就是redo的ib_logfileN文件，undo的share tablespace或.ibd文件，后面讲undo log时会讲到)，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将OS buffer中的日志刷到磁盘上的log file中。</p>
<p>也就是说，从redo log buffer写日志到磁盘的redo log file中，过程如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c1152ce0028d1f668da73cbc4b28b1794a3.png" alt=""></p>
<h2 id="1-3-redo-log的数据结构（log-block）"><a href="#1-3-redo-log的数据结构（log-block）" class="headerlink" title="1.3 redo log的数据结构（log block）"></a>1.3 redo log的数据结构（log block）</h2><p>InnoDB存储引擎中，redo log以块为单位进行存储的，每个块占512字节（同磁盘扇区大小一致，可以保证块的写入是原子操作。），这称为redo log block。<strong>所以不管是log buffer中还是os buffer中以及redo log file on disk中，都是这样以512字节的块存储的</strong>。</p>
<p>每个redo log block由3部分组成：header、tailer和body。其中日志块头header占用12字节，日志块尾tailer占用8字节，所以每个redo log block的日志主体部分body只有512-12-8=492字节。</p>
<p>因为redo log记录的是数据页的变化，当一个数据页产生的变化需要使用超过492字节的redo log来记录，那么就会使用多个redo log block来记录该数据页的变化。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c6ca3a15d7c42bf5fa449dbe802b692605b.png" alt=""></p>
<p>上面所说的是一个日志块的内容，在redo log buffer或者redo log file on disk中，由很多log block组成。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e7ea51e63422a5719c70835176b989e073e.png" alt=""></p>
<h3 id="1-3-1-block-header"><a href="#1-3-1-block-header" class="headerlink" title="1.3.1 block header"></a>1.3.1 block header</h3><p>header包含4部分：</p>
<ul>
<li>log_block_hdr_no：(4字节)该日志块在redo log buffer/os buffer/log file中的位置ID。log buffer/redo log file on disk是由log block组成，在log buffer内部就好似一个数组，因此LOG_BLOCK HDR_NO用来标记这个数组中的位置。其是递增并且循环使用的。</li>
<li>log_block_hdr_data_len：(2字节)该log block中<strong>已记录</strong>的log大小。写满该log block时为0x200，表示512字节。</li>
<li>log_block_first_rec_group：(2字节)该log block中新的数据页对应的log的开始偏移位置。</li>
<li>lock_block_checkpoint_no：(4字节)写入checkpoint信息的位置。</li>
</ul>
<p>关于log block块头的第三部分<code>log_block_first_rec_group</code>，因为有时候一个数据页产生的日志量<strong>超出了一个日志块</strong>，这时需要用多个日志块来记录该页的相关日志。</p>
<p>例如，某一T1事务产生了792个字节的日志量，那么需要占用两个日志块，第一个日志块占用492字节，第二个日志块需要占用270个字节，那么对于第二个日志块来说，它记录的关于下一个数据页B的第一个log的开始位置就是282字节(270+12)。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fa477acf42ce4e51969e8127c867d22560e.png" alt=""></p>
<p>如果<code>log_block_first_rec_group</code>的值和<code>log_block_hdr_data_len</code>相等，则说明该log block中没有新开始记录下一个数据页的日志，即<strong>表示该日志块用来延续前一个日志块</strong>。</p>
<h3 id="1-3-2-block-tailer"><a href="#1-3-2-block-tailer" class="headerlink" title="1.3.2 block tailer"></a>1.3.2 block tailer</h3><p>tailer只有一个部分：</p>
<ul>
<li><code>log_block_trl_no</code> ，该值和块头的 <code>log_block_hdr_no</code> 相等。</li>
</ul>
<h3 id="1-3-3-block-body"><a href="#1-3-3-block-body" class="headerlink" title="1.3.3 block body"></a>1.3.3 block body</h3><p>因为innodb存储引擎存储数据的单元是页(和SQL Server中一样)，所以redo log也是基于页的格式来存放的。默认情况下，innodb的页大小是16KB(由<code>innodb_page_size</code>变量控制)，一个页内可以存放非常多的log block(每个512字节)，而log block中记录的又是数据页的变化。</p>
<p>其中log block中492字节的部分是block body，<strong>block body存储了很多条的redo日志，每条redo日志的格式分为4部分</strong>：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-952af4bd6ec616062dc8b8ce0a9ec050c1d.png" alt=""></p>
<ul>
<li><p>type：占用1个字节，8bit，其中高位的一个bit另做它用，剩下7个bit表示redo log的日志类型，其值有很多，在MySQL 5.7.21这个版本中，InnoDB一共为redo日志设计了53种不同的类型，下文将详细分析。</p>
</li>
<li><p>space ID：表示表空间的ID，采用压缩的方式后，占用的空间可能小于4字节。</p>
</li>
<li><p>page number：表示页的偏移量，同样是压缩过的。</p>
</li>
<li><p>data：表示每个redo日志的数据部分，恢复时会调用相应的函数进行解析。例如insert语句和delete语句写入redo log的内容是不一样的。</p>
</li>
</ul>
<h3 id="1-3-4-redo-log的类型"><a href="#1-3-4-redo-log的类型" class="headerlink" title="1.3.4 redo log的类型"></a>1.3.4 redo log的类型</h3><p>type字段的低位7个bit用来区分redo log的日志类型，我们来看下简单的场景和复杂的场景下，redo日志的不同类型。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c6af77a689edc02a3cafabd97c02942128c.png" alt=""></p>
<h4 id="1-3-4-1-简单的redo日志类型"><a href="#1-3-4-1-简单的redo日志类型" class="headerlink" title="1.3.4.1 简单的redo日志类型"></a>1.3.4.1 简单的redo日志类型</h4><p>我们前边介绍InnoDB的记录行格式的时候说过，如果我们没有为某个表显式的定义主键，并且表中也没有定义Unique键，那么InnoDB会自动的为表添加一个称之为row_id的隐藏列作为主键。</p>
<p>这时服务器会在内存中维护一个全局变量，每当向某个包含隐藏的row_id列的表中插入一条记录时，就会把该变量的当前值当作新记录的row_id列的值，并且把该变量自增1。</p>
<p>每当这个变量的值为256的倍数时，就会将该变量的值刷新到系统表空间的页号为7的页中一个称之为Max Row ID的属性处。</p>
<p>这是Max Row ID的持久化，即Max Row ID每增加256，就持久化一次，如果期间发生了系统宕机，那么重新启动后，服务器会将持久化的最大的Max Row ID取出，并加上256，当做新的Max Row ID。</p>
<blockquote>
<p>比如Max Row ID自增到800的时候，系统已经持久化了Max Row ID的三个值256，512，768。这时，系统崩溃了，重新启动后，系统取出了最新的768，但不能直接从768开始用，为了防止重复，新的Max Row ID=768+256=1024。</p>
</blockquote>
<p>这个Max Row ID属性占用的存储空间是8个字节，当某个事务向某个包含row_id隐藏列的表插入一条记录，并且为该记录分配的row_id值刚好为256的倍数时，就会向系统表空间页号为7的页面的相应偏移量处写入8个字节的值。</p>
<p>但是我们要知道，这个写入实际上是在Buffer Pool中完成的，我们需要为这个页的修改记录一条redo日志，以便在系统奔溃后能将已经提交的该事务对该页面所做的修改恢复出来。这种情况下对页的修改是极其简单的，<strong>redo日志中只需要记录一下页号为7的页面的某个偏移量处修改了几个字节的值，以及具体被修改的内容是啥就好了</strong>。</p>
<p>这种简单的redo日志，InnoDB定义了如下的type的值，来表示对应字节的redo日志的产生。</p>
<ul>
<li>MLOG_1BYTE(type字段对应的⼗进制数字为1)：表示在⻚⾯的某个偏移量处写⼊1个字节的redo⽇志类型。</li>
<li>MLOG_2BYTE(type字段对应的⼗进制数字为2)：表示在⻚⾯的某个偏移量处写⼊2个字节的redo⽇志类型。</li>
<li>MLOG_4BYTE(type字段对应的⼗进制数字为4)：表示在⻚⾯的某个偏移量处写⼊4个字节的redo⽇志类型。</li>
<li>MLOG_8BYTE(type字段对应的⼗进制数字为8)：表示在⻚⾯的某个偏移量处写⼊8个字节的redo⽇志类型。</li>
<li>MLOG_WRITE_STRING(type字段对应的⼗进制数字为30)：表示在⻚⾯的某个偏移量处写⼊⼀串数据。</li>
</ul>
<p>我们上边提到的Max Row ID属性实际占用8个字节的存储空间，所以在修改页面中的该属性时，会记录一条类型为MLOG_8BYTE的redo日志，MLOG_8BYTE的redo日志结构如下所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c32188a1f15479176b8ec9188c67c622f21.png" alt=""></p>
<p>其余MLOG_1BYTE、MLOG_2BYTE、MLOG_4BYTE类型的redo日志结构和MLOG_8BYTE的类似，只不过具体数据中包含对应个字节的数据罢了。MLOG_WRITE_STRING类型的redo日志表示写入一串数据，但是因为不能确定写入的具体数据占用多少字节，所以需要在日志结构中添加一个len字段：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-554313fb140cc3234089d0f76ff3c927c36.png" alt=""></p>
<blockquote>
<p>其实只要将MLOG_WRITE_STRING类型的redo日志的len字段填充上1、2、4、8这些数字，就可以分别替代MLOG_1BYTE、MLOG_2BYTE、MLOG_4BYTE、MLOG_8BYTE这些类型的redo日志，为啥还要多此一举设计这么多类型呢？还不是因为省空间啊，能不写len字段就不写len字段，省一个字节算一个字节。</p>
</blockquote>
<h4 id="1-3-4-2-复杂的redo日志类型"><a href="#1-3-4-2-复杂的redo日志类型" class="headerlink" title="1.3.4.2 复杂的redo日志类型"></a>1.3.4.2 复杂的redo日志类型</h4><p>有时候执行一条语句会修改非常多的页面，包括系统数据页面（比如上文提到的全局变量Max Row ID的更新）和用户数据页面（用户数据指的就是聚簇索引和二级索引对应的B+树）。</p>
<p>以一条INSERT语句为例，它除了要向B+树的页面中插入数据，也可能更新系统数据Max Row ID的值，不过对于我们用户来说，平时更关心的是语句对B+树所做更新：</p>
<ul>
<li>表中包含多少个索引，一条INSERT语句就可能更新多少棵B+树。</li>
<li>针对某一棵B+树来说，既可能更新叶子节点页面，也可能更新内节点页面，也可能创建新的页面（在该记录插入的叶子节点的剩余空间比较少，不足以存放该记录时，会进行页面的分裂）。</li>
<li>对于B+树上的页来说，新的行被插入，页中的<code>Page Directory</code>的槽信息、<code>Page Header</code>中的各种统计信息，行记录链表的后驱<code>next_record</code>等都要随之更新。</li>
</ul>
<p>画一个简易的示意图就像是这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3371ed59e2f4a43841d84d37c5e6f0d35c5.png" alt=""></p>
<p>说了这么多，就是想表达：把一条记录插入到一个页面时需要更改的地方非常多。这时我们如果使用上边介绍的简单的物理redo日志来记录这些修改时，可以有两种解决方案：</p>
<ul>
<li><p>方案一：在每个修改的地方都记录一条redo日志。</p>
<ul>
<li>也就是如上图所示，有多少个加粗的块，就写多少条物理redo日志。这样子记录redo日志的缺点是显而易见的，因为被修改的地方是在太多了，可能记录的redo日志占用的空间都比整个页面占用的空间都多了。</li>
</ul>
</li>
<li><p>方案二：将整个页面的第一个被修改的字节到最后一个修改的字节之间所有的数据当成是一条物理redo日志中的具体数据。</p>
<ul>
<li>从图中也可以看出来，第一个被修改的字节到最后一个修改的字节之间仍然有许多没有修改过的数据，我们把这些没有修改的数据也加入到redo日志中去岂不是太浪费了。</li>
</ul>
</li>
</ul>
<p>正因为上述两种使用物理redo日志的方式来记录某个页面中做了哪些修改比较浪费，InnoDB的设计者本着勤俭节约的初心，提出了一些新的redo日志类型，比如：</p>
<ul>
<li>MLOG_REC_INSERT(type字段对应的十进制数字为9)：表示插入一条使用非紧凑行格式记录时的redo日志类型（如redundant）</li>
<li>MLOG_COMP_REC_INSERT(type字段对应的十进制数字为38)：表示插入一条使用紧凑行格式记录时的redo日志类型（如compact/dynamic/compressed）</li>
<li>MLOG_COMP_PAGE_CREATE（type字段对应的十进制数字为58）：表示创建一个存储紧凑行格式记录的页面的redo日志类型。</li>
<li>MLOG_COMP_REC_DELET(type字段对应的十进制数字为42)：表示删除一条使用紧凑行格式记录的redo日志类型</li>
<li>MLOG_COMP_LIST_START_DELETE（type字段对应的十进制数字为44）：表示从某条给定记录开始删除页面中的一系列使用紧凑行格式记录的redo日志类型。</li>
<li>MLOG_ZIP_PAGE_COMPRESS（type字段对应的十进制数字为51）：表示压缩一个数据页的redo日志类型。</li>
<li>MLOG_COMP_LIST_END_DELETE（type字段对应的十进制数字为43）：与MLOG_COMP_LIST_START_DELETE类型的redo日志呼应，表示删除一系列记录直到MLOG_COMP_LIST_END_DELETE类型的redo日志对应的记录为止。</li>
</ul>
<p>那这些新类型和旧的类型有什么区别呢？如果还是简单的把所有的物理层面的数据变动都记录下来，那岂不是没什么区别？</p>
<p>区别就是，新的日志类型，除了能体现物理层面的变动，还包含了逻辑层面的变动，它主要是搭配系统恢复的函数的来使用的。</p>
<ol>
<li>物理层面：修改的是哪个表空间，哪个页，以及页的偏移量。</li>
<li>逻辑层面：是插入操作还是删除操作；操作对象是行记录还是其他？如果是行记录，那是什么格式的行记录？紧凑的还是非紧凑的。</li>
</ol>
<p>这样有什么好处呢？？我们以插入一条使用紧凑行格式的记录时的redo日志（MLOG_COMP_REC_INSERT）为例，直接看一下这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志的结构，橙色部分都是block body：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-eda1ea874ed13e2c18c96c51b3c426d2bac.png" alt=""></p>
<p>这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志结构有几个地方需要大家注意：</p>
<ol>
<li>在一个数据页里，行记录都是按照索引列从小到大的顺序排序的。对于二级索引来说，当索引列的值相同时，记录还需要按照主键值进行排序。图中n_uniques的值的含义是在一条记录中，需要几个字段的值才能确保记录的唯一性，这样当插入一条记录时就可以按照记录的前n_uniques个字段进行排序。对于聚簇索引来说，n_uniques的值为主键的列数，对于其他二级索引来说，该值为索引列数+主键列数。这里需要注意的是，唯一二级索引的值可能为NULL，所以该值仍然为索引列数+主键列数。</li>
<li>field1_len ~ fieldn_len代表着该记录若干个字段占用存储空间的大小，需要注意的是，这里不管该字段的类型是固定长度大小的（比如INT），还是可变长度大小（比如VARCHAR(M)）的，该字段占用的大小始终要写入redo日志中。</li>
<li>offset代表的是该记录的前一条记录在页面中的地址。为啥要记录前一条记录的地址呢？这是因为每向数据页插入一条记录，都需要修改该页面中维护的记录链表，每条记录的记录头信息中都包含一个称为next_record的属性，所以在插入新记录时，需要修改前一条记录的next_record属性。</li>
</ol>
<p>很显然这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志并没有记录PAGE_N_DIR_SLOTS的值修改为了啥，PAGE_HEAP_TOP的值修改为了啥，PAGE_N_HEAP的值修改为了啥等等这些信息，<strong>而只是把在本页面中插入一条记录所有必备的要素记了下来</strong>，之后系统奔溃重启时，<strong>服务器会调用相关向某个页面插入一条记录的那个函数，而redo日志中的那些数据就可以被当成是调用这个函数所需的参数</strong>，在调用完该函数后，页面中的PAGE_N_DIR_SLOTS、PAGE_HEAP_TOP、PAGE_N_HEAP等等的值也就都被恢复到系统奔溃前的样子了。这就是所谓的逻辑日志的意思。</p>
<p>如下图，分别是insert和delete大致的记录方式。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1c95c4a1e07f6afdf1f7f9bdb9c5cfa80c2.png" alt=""></p>
<h2 id="1-4-redo日志的原子性（Mini-Transaction）"><a href="#1-4-redo日志的原子性（Mini-Transaction）" class="headerlink" title="1.4  redo日志的原子性（Mini-Transaction）"></a>1.4  redo日志的原子性（Mini-Transaction）</h2><p>前文说到执行一条INSERT的SQL语句，InnoDB在向某个B+树中插入新的记录的过程，会产生许多条的redo日志，因为可能涉及页的分裂，各种段的修改、区的统计信息，各种链表的统计信息等等。</p>
<p>我们知道向某个索引对应的B+树中插入一条记录的这个过程必须是原子的，不能说插了一半之后就停止了。在B+树上插入一个新的行，触发的页的分裂，这时新的页面已经分配好了，数据也复制过去了，新的记录也插入到页面中了，可是没有向数据节点中插入一条目录项记录，那么这个插入过程就是不完整的，这样会形成一棵不正确的B+树。</p>
<p>我们知道redo日志是为了在系统奔溃重启时恢复崩溃前的状态，如果在INSERT的过程中只记录了一部分redo日志，那么在系统奔溃重启时会将索引对应的B+树恢复成一种不正确的状态，这是InnoDB设计者们所不能忍受的。</p>
<p>MySQL把这种<strong>不容许分割的，对底层页面中的一次原子操作的过程</strong>称之为一个<strong>Mini-Transaction</strong>，简称mtr，比如上边所说的修改一次Max Row ID的值算是一个Mini-Transaction，向某个索引对应的B+树中插入一条记录的过程也算是一个Mini-Transaction。</p>
<p>一个mtr可能产生单条或者多条redo日志，就像对redo日志进行编组一样，在进行奔溃恢复时这一组redo日志将作为一个不可分割的整体，要么一起恢复，要么都不恢复。</p>
<blockquote>
<p>一个事务可以包含若干条语句，每一条语句其实是由若干个mtr组成，每一个mtr又可以包含若干条redo日志，画个图表示它们的关系就是这样：</p>
</blockquote>
<p><img src="https://oscimg.oschina.net/oscnet/up-391c80e95bda8d4ae7b97e571b2a5a77e33.png" alt=""></p>
<p>那么如何对一个mtr产生的redo日志进行编组呢？这得分情况讨论：</p>
<ol>
<li>有的操作会生成多条redo日志，比如向某个索引对应的B+树中进行一次插入就需要生成许多条redo日志。</li>
<li>有的需要保证原子性的操作只生成一条redo日志，比如更新全局变量Max Row ID属性的操作就只会生成一条redo日志。</li>
</ol>
<h3 id="1-4-1-原子操作生成多条redo日志"><a href="#1-4-1-原子操作生成多条redo日志" class="headerlink" title="1.4.1 原子操作生成多条redo日志"></a>1.4.1 原子操作生成多条redo日志</h3><p><strong>针对第一种情况</strong>，InnoDB定义了一种新的类型（<code>MLOG_MULTI_REC_END</code>，type字段对应的十进制数字为31）的redo log结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-020bd4a48f5f5c3000bd25452a3b8c4a5cb.png" alt=""></p>
<p>所以某个需要保证原子性的操作产生的一系列redo日志必须要以一个类型为<code>MLOG_MULTI_REC_END</code>结尾，就像这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b10b12fd333ba38b1faf25732f1669596a2.png" alt=""></p>
<p>这样在系统奔溃重启进行恢复时，只有当解析到类型为MLOG_MULTI_REC_END的redo日志，才认为解析到了一组完整的redo日志，才会进行恢复。否则的话直接放弃前边解析到的不完整部分的redo日志。</p>
<h3 id="1-4-2-原子操作生成单条redo日志"><a href="#1-4-2-原子操作生成单条redo日志" class="headerlink" title="1.4.2 原子操作生成单条redo日志"></a>1.4.2 原子操作生成单条redo日志</h3><p><strong>针对第二种情况</strong>，其实在一条日志后边跟一个类型为MLOG_MULTI_REC_END的redo日志也是可以的，但这比较浪费。</p>
<p>别忘了虽然redo日志的类型比较多，但撑死了也就是几十种，是小于127这个数字的，也就是说我们用7个比特位就足以包括所有的redo日志类型，而type字段其实是占用1个字节8比特位的，也就是说我们可以省出来一个比特位用来表示该需要保证原子性的操作只产生单一的一条redo日志，示意图如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c6af77a689edc02a3cafabd97c02942128c.png" alt=""></p>
<p>如果type字段的第一个比特为为1，代表该需要保证原子性的操作只产生了单一的一条redo日志，否则表示该需要保证原子性的操作产生了一系列的redo日志。</p>
<h2 id="1-5-redo日志的写入"><a href="#1-5-redo日志的写入" class="headerlink" title="1.5 redo日志的写入"></a>1.5 redo日志的写入</h2><p>我们前边说过，InnoDB为了解决磁盘速度过慢的问题而引入了Buffer Pool。同理，写入redo日志时也不能直接直接写到磁盘上，实际上在服务器启动时就向操作系统申请了一大片称之为redo log buffer的连续内存空间，翻译成中文就是redo日志缓冲区，我们也可以简称为log buffer。这片内存空间被划分成若干个连续的redo log block，就像这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3166883a72a3121c950bc3e38a1ad5ac71c.png" alt=""></p>
<p>向log buffer中写入redo日志的过程是顺序的，也就是先往前边的block中写，当该block的空闲空间用完之后再往下一个block中写。当我们想往log buffer中写入redo日志时，第一个遇到的问题就是应该写在哪个block的哪个偏移量处，所以InnoDB特意提供了一个称之为<code>buf_free</code>的全局变量，该变量指明后续写入的redo日志应该写入到log buffer中的哪个位置，如图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-34ddf107ece3e7f268d7097b01a4bc312f8.png" alt=""></p>
<p>我们前边说过一个mtr执行过程中可能产生若干条redo日志，这些redo日志是一个不可分割的组，所以其实并不是每生成一条redo日志，就将其插入到log buffer中，<strong>而是每个mtr运行过程中产生的日志先暂时存到一个地方，当该mtr结束的时候，将过程中产生的一组redo日志再全部复制到log buffer中（所以同一mtr的一组log都是一起连续出现）</strong>。</p>
<p>我们现在假设有两个名为T1、T2的事务，每个事务都包含2个mtr，每个mtr都产生若干个redo log：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-19d955d351169129ad49610058aa3f07fcd.png" alt=""></p>
<p>不同的事务可能是并发执行的，所以T1、T2之间的mtr可能是交替执行的。</p>
<p>每当一个mtr执行完成时，伴随该mtr生成的一组redo日志就需要被复制到log buffer中，也就是说不同事务的mtr可能是交替写入log buffer的，我们画个示意图（为了美观，我们把一个mtr中产生的所有的redo日志当作一个整体来画）：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-687b270013902ff1f4d3d65701700de0ef5.png" alt=""></p>
<p>从示意图中我们可以看出来，不同的mtr产生的一组redo日志占用的存储空间可能不一样，有的mtr产生的redo日志量很少，比如mtr_t1_1、mtr_t2_1就被放到同一个block中存储，有的mtr产生的redo日志量非常大，比如mtr_t1_2产生的redo日志甚至占用了3个block来存储。</p>
<h2 id="1-6-redo日志的持久化"><a href="#1-6-redo日志的持久化" class="headerlink" title="1.6 redo日志的持久化"></a>1.6 redo日志的持久化</h2><p>前面我们说过，和InnoDB的数据修改一样，redo log也是借助了日志缓冲区来调节磁盘和CPU的矛盾，提升了性能。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0c9e8dfa4efc1da25a6055de1a9232833db.png" alt=""></p>
<h3 id="1-6-1-redo日志的持久化文件"><a href="#1-6-1-redo日志的持久化文件" class="headerlink" title="1.6.1 redo日志的持久化文件"></a>1.6.1 redo日志的持久化文件</h3><p>我们知道数据页持久化后，是保存在ibdata1（没有开启<code>innodb_file_per_table</code>时的共享表空间文件）或者.ibd（开启 <code>innodb_file_per_table</code>时）文件中的。</p>
<p>InnoDB定义了一个组（log group）的概念，一个组内由多个<strong>大小完全相同</strong>的redo log file组成。组内redo log file的数量由变量<code>innodb_log_files_group</code>决定，默认值为2，即两个redo log file。</p>
<blockquote>
<p>log group为redo日志组，其中有多个redo log file。虽然源码中已支持log group 的镜像功能，但是在ha_innobase.cc 文件中禁止了该功能。因此InnoDB存储引擎实际只有一个log group。</p>
</blockquote>
<p>这个组是一个逻辑的概念，并没有真正的文件来表示这是一个组，但是可以通过变量<code>innodb_log_group_home_dir</code>来定义组的目录，redo log file都放在这个目录下，默认是在datadir下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global variables like &quot;innodb_log%&quot;;</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">| Variable_name               | Value    |</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">| innodb_log_buffer_size      | 8388608  |</span><br><span class="line">| innodb_log_compressed_pages | ON       |</span><br><span class="line">| innodb_log_file_size        | 50331648 |</span><br><span class="line">| innodb_log_files_in_group   | 2        |</span><br><span class="line">| innodb_log_group_home_dir   | .&#x2F;       |</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">[root@xuexi data]# ll &#x2F;mydata&#x2F;data&#x2F;ib*</span><br><span class="line">-rw-rw---- 1 mysql mysql 79691776 Mar 30 23:12 &#x2F;mydata&#x2F;data&#x2F;ibdata1</span><br><span class="line">-rw-rw---- 1 mysql mysql 50331648 Mar 30 23:12 &#x2F;mydata&#x2F;data&#x2F;ib_logfile0</span><br><span class="line">-rw-rw---- 1 mysql mysql 50331648 Mar 30 23:12 &#x2F;mydata&#x2F;data&#x2F;ib_logfile1</span><br></pre></td></tr></table></figure>
<p>可以看到在默认的数据目录下，有两个ib_logfile开头的文件，它们就是log group中的redo log file，而且它们的大小完全一致且等于变量<code>innodb_log_file_size</code>定义的值。</p>
<p>在innodb将log buffer中的redo log block刷到这些log file中时，会以追加写入的方式循环轮训写入。即先在ib_logfile0的尾部追加写，直到满了之后向ib_logfile1追加写。<strong>当ib_logfile1满了，则又重新向ib_logfile0进行覆盖写</strong>。</p>
<p>由于是将log buffer中的日志刷到log file，所以在log file中记录日志的方式也是log block的方式。在每个组的第一个redo log file中，前2KB负责记录4个特定的部分，从2KB之后才开始记录log block。除了第一个redo log file中会记录这2KB的部分外，<strong>log group中的其他log file不会记录这2KB，但是却会腾出这2KB的空间</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0e974f07531a01ac0003212eab079cea38b.png" alt=""></p>
<blockquote>
<p>redo log file的大小对innodb的性能影响非常大，设置的太大，恢复的时候就会时间较长，设置的太小，就会导致在写redo log的时候循环切换redo log file。</p>
</blockquote>
<h3 id="1-6-1-redo日志的持久化策略"><a href="#1-6-1-redo日志的持久化策略" class="headerlink" title="1.6.1 redo日志的持久化策略"></a>1.6.1 redo日志的持久化策略</h3><p>那么，log buffer里面的日志，什么时候刷到log file中呢？</p>
<ol>
<li>事务提交时</li>
<li>当log buffer中有一半的内存空间已经被使用时</li>
<li>log checkpoint 时</li>
</ol>
<p>其中<code>1. 事务提交时</code>是InnoDB事务的持久性的保证，但就像我们在《【InnoDB详解三】锁和事务》一文中介绍的那样，为了性能，InnoDB允许牺牲一定的持久性，允许执行不同的redo日志持久化策略。</p>
<p>MySQL支持用户自定义在事务提交时是否将log buffer中的日志刷log file中。这种控制通过变量 <code>innodb_flush_log_at_trx_commit</code> 的值来决定。该变量有3种值：0、1、2，默认为1。</p>
<ul>
<li>当设置为0的时候，<strong>事务提交时</strong>不会将log buffer中日志写入到os buffer。那什么时候写入呢？由master thread通过每秒一次的频率来异步写入。该值为0时性能较好，但是会丢失掉master thread还没刷新进磁盘部分的数据。<blockquote>
<p>这里我想简单介绍一下master thread，这是InnoDB一个在后台运行的主线程，从名字就能看出这个线程相当的重要。它做的主要工作包括但不限于：刷新日志缓冲，合并插入缓冲，刷新脏页等。master thread大致分为每秒运行一次的操作和每10秒运行一次的操作。master thread中刷新数据，属于checkpoint的一种。</p>
</blockquote>
</li>
<li>当设置为1的时候，当然是最安全的，即每次commit都会强迫flush到log file，但是数据库性能会受一定影响。</li>
<li>当设置为2的时候，每次提交都仅写入到操作系统的内核空间os buffer，然后由操作系统异步每秒调用一次fsync()将os buffer中的日志写入到log file。</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-29558eb65234c525c09f9651c104f0f9bb1.png" alt=""></p>
<h3 id="1-6-3-redo日志持久化策略的性能"><a href="#1-6-3-redo日志持久化策略的性能" class="headerlink" title="1.6.3 redo日志持久化策略的性能"></a>1.6.3 redo日志持久化策略的性能</h3><p>选择刷日志的策略会严重影响数据修改时的性能，特别是刷到磁盘的过程。下例就测试了<code>innodb_flush_log_at_trx_commit</code>分别为0、1、2时的差距。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#创建测试表</span><br><span class="line">drop table if exists test_flush_log;</span><br><span class="line">create table test_flush_log(id int,name char(50))engine&#x3D;innodb;</span><br><span class="line"></span><br><span class="line">#创建插入指定行数的记录到测试表中的存储过程</span><br><span class="line">drop procedure if exists proc;</span><br><span class="line">delimiter $$</span><br><span class="line">create procedure proc(i int)</span><br><span class="line">begin</span><br><span class="line">    declare s int default 1;</span><br><span class="line">    declare c char(50) default repeat(&#39;a&#39;,50);</span><br><span class="line">    while s&lt;&#x3D;i do</span><br><span class="line">        start transaction;</span><br><span class="line">        insert into test_flush_log values(null,c);</span><br><span class="line">        commit;</span><br><span class="line">        set s&#x3D;s+1;</span><br><span class="line">    end while;</span><br><span class="line">end$$</span><br><span class="line">delimiter ;</span><br></pre></td></tr></table></figure>

<p>当前环境下， <code>innodb_flush_log_at_trx_commit</code> 的值为1，即每次提交都刷日志到磁盘。测试此时插入10W条记录的时间。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; call proc(100000);</span><br><span class="line">Query OK, 0 rows affected (15.48 sec)</span><br></pre></td></tr></table></figure>

<p>结果是15.48秒。</p>
<p>再测试值为2的时候，即每次提交都刷新到os buffer，但每秒才刷入磁盘中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set @@global.innodb_flush_log_at_trx_commit&#x3D;2;</span><br><span class="line">mysql&gt; truncate test_flush_log;</span><br><span class="line"></span><br><span class="line">mysql&gt; call proc(100000);</span><br><span class="line">Query OK, 0 rows affected (3.41 sec)</span><br></pre></td></tr></table></figure>

<p>结果插入时间大减，只需3.41秒。</p>
<p>最后测试值为0的时候，即每秒才刷到os buffer和磁盘。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set @@global.innodb_flush_log_at_trx_commit&#x3D;0;</span><br><span class="line">mysql&gt; truncate test_flush_log;</span><br><span class="line"></span><br><span class="line">mysql&gt; call proc(100000);</span><br><span class="line">Query OK, 0 rows affected (2.10 sec)</span><br></pre></td></tr></table></figure>

<p>结果只有2.10秒。</p>
<p>最后可以发现，其实值为2和0的时候，它们的差距并不太大，但2却比0要安全的多。它们都是每秒从os buffer刷到磁盘，它们之间的时间差体现在log buffer刷到os buffer上。因为将log buffer中的日志刷新到os buffer只是内存数据的转移，并没有太大的开销，所以每次提交和每秒刷入差距并不大。可以测试插入更多的数据来比较，以下是插入100W行数据的情况。从结果可见，值为2和0的时候差距并不大，但值为1的性能却差太多。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5a84cadbc4f69368f44b55bbb5b8c4cb33b.png" alt=""></p>
<p>尽管设置为0和2可以大幅度提升插入性能，但是在故障的时候可能会丢失1秒钟数据，这1秒钟很可能有大量的数据，从上面的测试结果看，100W条记录也只消耗了20多秒，1秒钟大约有4W-5W条数据，尽管上述插入的数据简单，但却说明了数据丢失的大量性。<strong>更好的插入数据的做法是将值设置为1，然后修改存储过程，将每次循环都提交修改为只提交一次，这样既能保证数据的一致性，也能提升性能</strong>，修改如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">drop procedure if exists proc;</span><br><span class="line">delimiter $$</span><br><span class="line">create procedure proc(i int)</span><br><span class="line">begin</span><br><span class="line">    declare s int default 1;</span><br><span class="line">    declare c char(50) default repeat(&#39;a&#39;,50);</span><br><span class="line">    start transaction;</span><br><span class="line">    while s&lt;&#x3D;i DO</span><br><span class="line">        insert into test_flush_log values(null,c);</span><br><span class="line">        set s&#x3D;s+1;</span><br><span class="line">    end while;</span><br><span class="line">    commit;</span><br><span class="line">end$$</span><br><span class="line">delimiter ;</span><br></pre></td></tr></table></figure>

<p>测试值为1时的情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set @@global.innodb_flush_log_at_trx_commit&#x3D;1;</span><br><span class="line">mysql&gt; truncate test_flush_log;</span><br><span class="line"></span><br><span class="line">mysql&gt; call proc(1000000);</span><br><span class="line">Query OK, 0 rows affected (11.26 sec)</span><br></pre></td></tr></table></figure>


<h2 id="1-7-利用redo日志做系统恢复"><a href="#1-7-利用redo日志做系统恢复" class="headerlink" title="1.7 利用redo日志做系统恢复"></a>1.7 利用redo日志做系统恢复</h2><h3 id="1-7-1-LSN和Checkpoint"><a href="#1-7-1-LSN和Checkpoint" class="headerlink" title="1.7.1 LSN和Checkpoint"></a>1.7.1 LSN和Checkpoint</h3><p>说到恢复，就不得不提LSN，我们在《【InnoDB详解一】体系架构和关键特性》一文中已经有过介绍，为方便计，我们粘贴过来。</p>
<p>对于InnoDB存储引擎而言，是通过LSN（Log Sequence Number）来标记版本的。LSN是一个一直递增的8字节整型数字，<strong>表示事务写入到redo日志的字节总量（注意LSN的含义是日志的字节总量）</strong>。每个页都有LSN字段，重做日志中也有LSN，Checkpoint也有LSN。</p>
<p>在每个数据页头部的LSN字段，记录当前页最后一次数据修改所对应的重做日志的LSN值，用于在recovery时对比重做日志LSN值，以决定是否对该页进行恢复数据。前面说的checkpoint也是有LSN号记录的，checkpoint的LSN表示已刷新到磁盘的最新的数据所对应的重做日志的LSN，LSN号串联起一个事务开始到恢复的过程。</p>
<blockquote>
<p>比如redo日志的文件是600M，LSN的值已经为1G了，也就是LSN=1000000000。因为redo日志是循环使用的，所以我们可以知道LSN=1G=600M+400M，所以redo日志已经重复使用过一整遍后，目前最新的可写入点，在redo日志偏移量400M的位置。</p>
</blockquote>
<blockquote>
<p>我们执行了一个update语句，产生了一个事务t，这次数据的修改，假设产生了512个字节的日志量，那么LSN就会增加到1000000512，而事务t的修改使得A、B、C三个数据页成为了脏页，那么A、B、C三个数据页的LSN值就会更新为1000000512。如果这时，触发了checkpoint，刚刚好将事务t为止的修改刷新到磁盘，那么此时checkpoint LSN也是1000000512。</p>
</blockquote>
<p>除了LSN之外，我们还要知道Checkpoint，同样在《【InnoDB详解一】体系架构和关键特性》一文中已经有过介绍。简单来说就是Checkpoint会定时将buffer里面的redo日志持久化到磁盘。</p>
<h3 id="1-7-2-恢复过程"><a href="#1-7-2-恢复过程" class="headerlink" title="1.7.2 恢复过程"></a>1.7.2 恢复过程</h3><p>InnoDB存储引擎在启动时<strong>不管上次数据库运行时是否正常关闭，都会尝试进行恢复</strong>。因为重做日志记录的是物理日志，因此恢复的速度比逻辑日志，如二进制日毒要快很多。与此同时，InnoDB存储引擎自身也对恢复进行了一定程度的优化，如顺序读取及并行应用重做日志，这样可以进一步地提高数据库恢复的速度。</p>
<p>由于checkpoint会记录已经刷新到磁盘页上的LSN，因此在恢复过程中仅需恢复checkpoint开始的日志部分。假设当数据库在checkpoint的LSN为10000时发生宕机，恢复操作仅恢复LSN10000～13000范围内的日志。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f46c3e46759e30a6596ccab8491f2c7c8af.png" alt=""></p>
<p>恢复的过程中，系统会根据redo日志的类型，调用相关的恢复函数进行恢复，而redo日志中的那些数据就可以被当成是调用这个函数所需的参数。从而使数据库恢复原样。</p>
<p>注意，调用相关的恢复函数的结果是幂等的，即便是insert一条行记录的redo日志，即便多次被恢复函数调用，其结果也是幂等的。</p>
<h1 id="2-undo-log"><a href="#2-undo-log" class="headerlink" title="2 undo log"></a>2 undo log</h1><p>undo log有两个作用：</p>
<ol>
<li>提供回滚<ul>
<li>InnoDB在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。</li>
</ul>
</li>
<li>多个行版本控制(MVCC)<ul>
<li>有时候应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而根据事务的版本和行记录的版本匹配，让用户实现非锁定一致性读取。</li>
</ul>
</li>
</ol>
<p>undo log和redo log记录物理日志不一样，<strong>它是逻辑日志</strong>。因此只是将数据库<strong>逻辑地</strong>恢复到原来的样子。所有修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能大不相同。</p>
<p>这是因为在多用户并发系统中，可能会有数十、数百甚至数千个并发事务。数据库的主要任务就是协调对数据记录的并发访问。比如，一个事务在修改当前一个页中某几条记录，同时还有别的事务在对同一个页中另几条记录进行修改。因此，不能将一个页回滚到事务开始的样子，<strong>因为这样会影响其他事务正在进行的工作</strong>。</p>
<p>例如，用户执行了一个INSERT 10W条记录的事务，这个事务会导致分配一个新的段，即表空间会增大。在用户执行ROLLBACK时，会将插入的事务进行回滚，但是表空间的大小<strong>并不会因此而收缩</strong>。因此，当InnoDB存储引擎回滚时，它实际上做的是与先前相反的工作。</p>
<p><strong>可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录</strong>。</p>
<p><strong>undo log是采用段(segment)的方式来记录的</strong>，每个undo操作在记录的时候占用一个undo log segment。</p>
<p><strong>另外，undo log也会产生redo log，因为undo log也要实现持久性保护</strong>。</p>
<h2 id="2-1-purge线程"><a href="#2-1-purge线程" class="headerlink" title="2.1 purge线程"></a>2.1 purge线程</h2><p>在详述undo log之前，我们需要了解一个前置知识点：purge线程</p>
<p>delete和update操作可能并不直接删除原有的数据。例如表t（a,b）如下的SQL语句∶</p>
<p><code>DELETE FROM t WHERE a=1;</code></p>
<p>表t上列a有聚集索引，列b上有辅助索引。</p>
<p>对于上述的delete操作，在MVCC的章节介绍已经知道仅是将主键列等于1的记录delete flag设置为1，记录并没有被删除，即记录还是存在于B+树中。其次，对辅助索引上a等于1，b等于1的记录同样没有做任何处理，甚至没有产生undo log。而真正删除这行记录的操作其实被”延时”了，最终在 purge操作中完成。</p>
<p>purge用于最终完成delete和 update操作。这样设计是因为InnoDB存储引擎支持MVCC，所以记录不能在事务提交时立即进行处理。这时其他事物可能正在引用这行，故InnoDB存储引擎需要保存记录之前的版本。而是否可以删除该条记录通过purge来进行判断。若该行记录已不被任何其他事务引用，那么就可以进行真正的delete操作。</p>
<p>可见，purge操作是清理之前的delete和update操作，将上述操作”最终”完成。而实际执行的操作为delete操作，清理之前行记录的版本。</p>
<p>为了节省存储空间，InnoDB存储引擎的undo log设计是这样的：</p>
<ol>
<li>一个页上允许多个事务的undo log存在。虽然这不代表事务在全局过程中提交的顺序，但是后面的事务产生的undo log总在最后。</li>
<li>此外，ImnoDB存储引擎还有一个history列表，它根据事务提交的顺序，将undo log进行链接。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-88c56db52cf6ad7facfd77561eae1e1e56b.png" alt=""></p>
<p>在图7-17的例子中，history list表示<strong>按照事务提交的顺序</strong>将undo log进行组织。在InnoDB存储引擎的设计中，先提交的事务总在尾端。</p>
<p>undo page存放了undo log，由于可以重用，因此一个undo page中可能存放了<strong>多个不同事务</strong>的undo log。tx5的灰色阴影表示该 undo log还被其他事务引用。</p>
<p>执行 purge的过程中，InnoDB存储引擎首先从history list中找到第一个需要被清理的记录，这里为trx1，清理之后InnoDB存储引擎会在trx1的undo log所在的页中继续寻找是否存在可以被清理的记录，这里会找到事务trx3，接着找到trx5，但是发现trx5被其他事务所引用而不能清理，故去再次去history list中查找，发现这时最尾端的记录为trx2，接着找到trx2所在的页，然后依次再把事务trx6、trx4的记录进行清理。</p>
<p>InnoDB存储引擎这种先从history list中找undo log，然后再从undo page中找undo log的设计模式是<strong>为了避免大量的随机读取操作，从而提高 purge的效率</strong>。</p>
<h2 id="2-2-undo-log的存储方式"><a href="#2-2-undo-log的存储方式" class="headerlink" title="2.2 undo log的存储方式"></a>2.2 undo log的存储方式</h2><p>Innodb存储引擎对undo的管理采用段（segment）的方式。rollback segment称为回滚段，每个回滚段中有1024个undo log segment。</p>
<p>在以前老版本，只支持1个rollback segment，这样就只能记录1024个undo log segment。后来MySQL5.5可以支持128个rollback segment，即支持<code>128*1024</code>个undo操作，还可以通过变量 <code>innodb_undo_logs</code> (5.6版本以前该变量是 innodb_rollback_segments )自定义多少个rollback segment，默认值为128。</p>
<p>undo log默认存放在共享表空间中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xuexi data]# ll &#x2F;mydata&#x2F;data&#x2F;ibda*</span><br><span class="line">-rw-rw---- 1 mysql mysql 79691776 Mar 31 01:42 &#x2F;mydata&#x2F;data&#x2F;ibdata1</span><br></pre></td></tr></table></figure>

<p>同样的，如果开启了 innodb_file_per_table ，将放在每个表的.ibd文件中。</p>
<p>在MySQL5.6中，undo的存放位置还可以通过变量 <code>innodb_undo_directory</code> 来自定义存放目录，默认值为”.”表示datadir。</p>
<p>默认rollback segment全部写在一个文件中，但可以通过设置变量 <code>innodb_undo_tablespaces</code> 平均分配到多少个文件中。该变量默认值为0，即全部写入一个表空间文件。该变量为静态变量，只能在数据库示例停止状态下修改，如写入配置文件或启动时带上对应参数。但是innodb存储引擎在启动过程中提示，不建议修改为非0的值，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: Expected to open 3 undo tablespaces but was able</span><br><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: to find only 0 undo tablespaces.</span><br><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: Set the innodb_undo_tablespaces parameter to the</span><br><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: correct value and retry. Suggested value is 0</span><br></pre></td></tr></table></figure>
<h2 id="2-3-undo-log的数据结构"><a href="#2-3-undo-log的数据结构" class="headerlink" title="2.3 undo log的数据结构"></a>2.3 undo log的数据结构</h2><p>InnoDB采用回滚段的方式来维护undo log是为了保证事务并发操作时，在写各自的undo log时不产生冲突。回滚段实际上是一种 Undo 文件组织方式，每个回滚段又有多个undo log slot。具体的文件组织方式如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a25c818ad84c7493b4eb9f92c1c8ea108b8.png" alt=""></p>
<p>当事务开启时，会给它指定使用哪个rollback segment，然后在真正执行操作时，分配具体的slot，通常会有两种slot：</p>
<ul>
<li>insert_undo：只用于事务内的insert语句<ul>
<li>insert undo log是指在insert操作中产生的undo log。因为insert操作的记录，只对事务本身可见，对其他事务不可见（这是事务隔离性的要求），故该undo log不会被其他事务引用，不用进行purge操作，可以在事务提交后直接删除（事务提交后就没有回滚需求了）。</li>
</ul>
</li>
<li>update_undo: 只用于事务内的update语句<ul>
<li>update undo log记录的是对delete和 update操作产生的undo log。该undo log可能需要提供MVCC机制，因此不能在事务提交时就进行删除。提交时放入undo log链表，等待 purge线程进行最后的删除。</li>
</ul>
</li>
</ul>
<p>通常如果事务内只包含一种操作类型，则只使用一个slot。但也有例外，例如insert操作，如果insert的记录在page上已经存在了，但是是无效的，那么就可以直接通过更新这条无效记录的方式来实现插入，这时候使用的是update_undo。</p>
<h3 id="2-3-1-insert-undo的数据结构"><a href="#2-3-1-insert-undo的数据结构" class="headerlink" title="2.3.1 insert_undo的数据结构"></a>2.3.1 insert_undo的数据结构</h3><p>insert undo log的数据结构如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1886e6ec7203188f0fa788d3d6d5c1b6c40.png" alt=""></p>
<p>其中<code>*</code>表示对存储的字段进行了压缩。</p>
<ol>
<li>insete undo log开始的前两个字节next 记录的是下一个undo log的位置，通过该next的字节可以知道一个undo log所占的空间字节数。</li>
<li>类似地，尾部的两个字节记录的是undo log的开始位置。</li>
<li>type_cmpl占用一个字节，记录的是undo的类型，对于insert undo log，该值总是为11。</li>
<li>undo_no记录事务的ID，table_id记录undo log所对应的表对象。这两个值都是在压缩后保存的。</li>
<li>接着的部分记录了所有主键的列和值。在进行 rollback操作时，根据这些值可以定位到具体的记录，然后进行删除即可。</li>
</ol>
<h3 id="2-3-2-update-undo的数据结构"><a href="#2-3-2-update-undo的数据结构" class="headerlink" title="2.3.2 update_undo的数据结构"></a>2.3.2 update_undo的数据结构</h3><p>update undo log的结构如图所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1add9223f47f7e189d289b96332cf7f655e.png" alt=""></p>
<p>update undo log相对于之前介绍的insert undo log，记录的内容更多，所需点用的空间也更大。</p>
<ol>
<li>next、start、undo_no、table_id与之前介绍的insert undo log部分相同。</li>
<li>这里的 type_cmpl，由于update undo log本身还有分类，故其可能的值如下∶<ul>
<li>12 TRXUNDO_UPD_EXIST_REC更新 non-delete-mark的记录</li>
<li>13 TRX_UNDO_UPD_DEL_REC将delete的记录标记为not delete </li>
<li>14 TRX_UNDO_DEL_MARK_REC将记录标记为delete</li>
</ul>
</li>
<li>接着的部分记录 update_vector信息，update_vector表示update操作导致发生改变的列。每个修改的列信息都要记录的undo log中。</li>
</ol>
<p>对于不同的undo log类型，可能还需要记录对索引列所做的修改。</p>
<h2 id="2-4-相关参数"><a href="#2-4-相关参数" class="headerlink" title="2.4 相关参数"></a>2.4 相关参数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global variables like &#39;%undo%&#39;;</span><br><span class="line">+--------------------------+------------+</span><br><span class="line">| Variable_name            | Value      |</span><br><span class="line">+--------------------------+------------+</span><br><span class="line">| innodb_max_undo_log_size | 1073741824 |</span><br><span class="line">| innodb_undo_directory    | .&#x2F;         |</span><br><span class="line">| innodb_undo_log_truncate | OFF        |</span><br><span class="line">| innodb_undo_logs         | 128        |</span><br><span class="line">| innodb_undo_tablespaces  | 3          |</span><br><span class="line">+--------------------------+------------+</span><br><span class="line"> </span><br><span class="line">mysql&gt; show global variables like &#39;%truncate%&#39;;</span><br><span class="line">+--------------------------------------+-------+</span><br><span class="line">| Variable_name                        | Value |</span><br><span class="line">+--------------------------------------+-------+</span><br><span class="line">| innodb_purge_rseg_truncate_frequency | 128   |</span><br><span class="line">| innodb_undo_log_truncate             | OFF   |</span><br><span class="line">+--------------------------------------+-------+</span><br></pre></td></tr></table></figure>
<ul>
<li>innodb_undo_directory<ul>
<li>变量 <code>innodb_undo_directory</code> 来自定义存放目录，默认值为”.”表示datadir。</li>
</ul>
</li>
<li>innodb_max_undo_log_size<ul>
<li>控制最大undo tablespace文件的大小，当启动了innodb_undo_log_truncate 时，undo tablespace 超过innodb_max_undo_log_size 阀值时才会去尝试truncate。该值默认大小为1G，truncate后的大小默认为10M。</li>
</ul>
</li>
<li>innodb_undo_tablespaces<ul>
<li>设置undo独立表空间个数，范围为0-128， 默认为0，0表示表示不开启独立undo表空间，且 undo日志存储在ibdata文件中。该参数只能在最开始初始化MySQL实例的时候指定，如果实例已创建，这个参数是不能变动的，如果在数据库配置文件 .cnf 中指定innodb_undo_tablespaces 的个数大于实例创建时的指定个数，则会启动失败，提示该参数设置有误。</li>
<li>设置该参数后，会在路径inodb_undo_directory看到undo为前缀的文件，该文件就代表rollback segment文件。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-dfb2af1207e6212f287c7518853aae22234.png" alt=""></li>
</ul>
</li>
<li><strong>innodb_undo_log_truncate</strong><ul>
<li>InnoDB的purge线程，根据innodb_undo_log_truncate设置开启或关闭、innodb_max_undo_log_size的参数值，以及truncate的频率来进行空间回收和undo file的重新初始化。</li>
<li>该参数生效的前提是，已设置独立表空间且独立表空间个数大于等于2个。</li>
<li>purge线程在truncate undo log file的过程中，需要检查该文件上是否还有活动事务，如果没有，需要把该undo log file标记为不可分配，这个时候，undo log 都会记录到其他文件上，所以至少需要2个独立表空间文件，才能进行truncate 操作。</li>
<li>标注不可分配后，会创建一个独立的文件undo__trunc.log，记录现在正在truncate 某个undo log文件，然后开始初始化undo log file到10M，操作结束后，删除表示truncate动作的 undo__trunc.log 文件，这个文件保证了即使在truncate过程中发生了故障重启数据库服务，重启后，服务发现这个文件，也会继续完成truncate操作，删除文件结束后，标识该undo log file可分配。</li>
</ul>
</li>
<li>innodb_purge_rseg_truncate_frequency<ul>
<li>用于控制purge回滚段的频度，默认为128。假设设置为n，则说明，当Innodb Purge操作的协调线程 purge事务128次时，就会触发一次History purge，检查当前的undo log 表空间状态是否会触发truncate。</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/" itemprop="url">【InnoDB详解三】锁和事务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-21T21:26:54+08:00">
                2020-09-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/21/【InnoDB详解三】锁和事务/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  9.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  34
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-InnoDB锁机制"><a href="#1-InnoDB锁机制" class="headerlink" title="1. InnoDB锁机制"></a>1. InnoDB锁机制</h1><p>锁是数据库系统区别于文件系统的一个关键特性。锁机制用于管理对共享资源的并发访问。InnoDB存储引擎会在行级别上对表数据上锁，这固然不错。不过InnoDB存储引擎也会在数据库内部其他多个地方使用锁，从而允许对多种不同资源提供并发访问。例如，操作缓冲池中的LRU列表，删除、添加、移动LRU列表中的元素，为了保证一致性，必须有锁的介入。数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。</p>
<p>InnoDB存储引擎锁的实现和Oracle数据库非常类似，提供一致性的非锁定读、行级锁支持。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。</p>
<h2 id="1-1-InnoDB中锁的类型"><a href="#1-1-InnoDB中锁的类型" class="headerlink" title="1.1 InnoDB中锁的类型"></a>1.1 InnoDB中锁的类型</h2><h3 id="1-1-1-共享锁和排他锁"><a href="#1-1-1-共享锁和排他锁" class="headerlink" title="1.1.1 共享锁和排他锁"></a>1.1.1 共享锁和排他锁</h3><p>InoDB存储引擎实现了如下两种标准的锁∶</p>
<ol>
<li>共享锁（S Lock），S是Share的缩写，也叫作<strong>读锁</strong>，允许事务读取共享资源的数据。</li>
<li>排他锁（X Lock），X是Exclusive的缩写，也叫作<strong>写锁</strong>，允许事务删除或更新资源的数据。</li>
</ol>
<p>InnoDB存储引擎支持多粒度（granular）锁定，S Lock和X Lock锁定的对象可以是行，也可以是页，也可以是表。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a9dd75ae92e3c9b415c077c8106a7bc91be.png" alt=""></p>
<p>如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r 的共享锁，因为读取并没有改变行r的数据，我们称这种情况为锁兼容（Lock Compatible）。</p>
<p>但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁才行——这种情况称为锁不兼容。</p>
<p>下图显示了共享锁和排他锁的兼容性：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-98ab6eecdfd147396fad62b458bc3021d40.png" alt=""></p>
<blockquote>
<p>总结为一句话，只有二者都是共享锁的时候才会兼容。</p>
</blockquote>
<h3 id="1-1-2-意向锁"><a href="#1-1-2-意向锁" class="headerlink" title="1.1.2 意向锁"></a>1.1.2 意向锁</h3><p>我们之前说过，S/X锁针对的对象可以是行，也可以是表。这种多粒度（granular）锁定是InnoDB锁机制的特点，但多粒度锁定会不可避免的带来一种问题：</p>
<ul>
<li>假设事务A锁住了表中的一行，让这一行只能读，不能写。</li>
<li>之后，事务B申请整个表的写锁。</li>
<li>如果事务B申请成功，那么理论上它就能修改表中的任意一行，这与A持有的行锁是冲突的。</li>
</ul>
<p>数据库需要避免这种冲突，就是说要让B的申请被阻塞，直到A释放了行锁。那么数据库要怎么判断这个冲突呢？</p>
<ol>
<li>step1：判断表是否已被其他事务用表锁锁表</li>
<li>step2：判断表中的每一行是否已被行锁锁住。</li>
</ol>
<p>注意step2，这样的判断方法需要遍历整个表，效率实在不高，于是就有了意向锁。</p>
<p>在意向锁存在的情况下，<strong>事务A必须先申请表的意向共享锁，成功后才能申请表中行的行锁</strong>。于是上面的判断可以改成：</p>
<ol>
<li>step1：判断表是否已被其他事务用表锁锁表</li>
<li>step2：发现表上有意向锁：<ol>
<li>如果是意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。</li>
<li>如果是意向排他锁，说明表中有些行被排他行锁锁住了，因此，事务B申请表的写锁会被阻塞。</li>
</ol>
</li>
</ol>
<p>是的没错，InnoDB的意向锁也支持如下两种，不过意向锁不是多粒度的，<strong>它只支持表级锁定</strong>：</p>
<ol>
<li>意向共享锁（IS Lock），表示事务已经获得一张表中某几行的共享锁。</li>
<li>意向排他锁（IX Lock），表示事务已经获得一张表中某几行的排他锁。</li>
</ol>
<blockquote>
<p>IS和IX的I是intention的缩写，意向的意思可以理解为：一个事务在申请行级锁前，先宣称对行所在表的读/写的意向，宣称之后，在不兼容的情况，其他锁就会冲突了。</p>
</blockquote>
<p>因为意向锁是表级锁，所以也不存在和行级锁/页级锁的兼容性问题，但意向锁之间，以及意向锁和表级共享/排他锁之间是存在不兼容的情况的，具体兼容性如下表（注意下标的S和X是表级锁）：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7b141535385456447ca04fd14e64f38744b.png" alt=""></p>
<blockquote>
<p>一句话：意向锁内部都兼容，除此之外，意向共享锁只和表级共享锁兼容。</p>
</blockquote>
<h3 id="1-1-3-自增锁"><a href="#1-1-3-自增锁" class="headerlink" title="1.1.3 自增锁"></a>1.1.3 自增锁</h3><p>自增长在数据库中是非常常见的一种属性，也是很多DBA或开发人员首选的主键方式。在InnoDB存储引擎的内存结构中，对每个含有自增长值的表都有一个自增长计数器（auto-increment counter）。当对含有自增长的计数器的表进行插入操作时，这个计数器会被初始化，执行如下的语句来得到计数器的值∶</p>
<p><code>SELECT MAX(auto_inc_col) FROM t FOR UPDATE;</code></p>
<p>插入操作会依据这个自增长的计数器值加1赋予自增长列。这个实现方式称做AUTO-INC Locking。<strong>这种锁其实是采用一种特殊的表锁机制，为了提高插人的性能，锁不是在一个事务完成后才释放，而是在完成对自增长值插人的SQL语句后立即释放</strong>。</p>
<h2 id="1-2-行锁的加锁方式"><a href="#1-2-行锁的加锁方式" class="headerlink" title="1.2 行锁的加锁方式"></a>1.2 行锁的加锁方式</h2><p>前面我们说过，InnoDB存储引擎支持多粒度（granular）锁定，S Lock和X Lock锁定的对象可以是行，也可以是页，也可以是表。</p>
<p>不过当锁定的对象是<strong>行记录</strong>的时候，InnoDB有三种加锁方式，或者说，有三种锁的算法：</p>
<ol>
<li>Record Lock：锁单条行记录；</li>
<li>Gap Lock：间隙锁，锁定一个范围，但不包含记录本身</li>
<li>Next-Key Lock：Gap Lock+RecordLock，记录锁和间隙锁的组合，锁定一个范围，并且锁定记录本身</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-a52d4cd7eca7873d81b9ba93bd670e0ba7d.png" alt=""></p>
<p><strong>这里需要重点注意间隙锁，它可以解决幻读</strong>，因为MySQL默认的事务隔离级别是<code>可重复读</code>，其底层就是使用Next-Key Lock，也就是说Next-Key Lock是目前InnoDB对行锁默认的加锁方式。下文我们再对各个事务隔离级别的底层实现做描述。</p>
<blockquote>
<p>InnoDB的行锁是通过给索引项加锁实现的（这个我们后面会说到），这就意味着只有通过索引条件检索数据时，InnoDB才使用行锁，否则使用表锁。也就是说，<strong>如果批量update，如果条件的字段没有索引，将会锁表，如果有索引，则只会出现行锁</strong>。</p>
</blockquote>
<h2 id="1-3-并发控制协议"><a href="#1-3-并发控制协议" class="headerlink" title="1.3 并发控制协议"></a>1.3 并发控制协议</h2><h3 id="1-3-1-MVCC和一致性非锁定读"><a href="#1-3-1-MVCC和一致性非锁定读" class="headerlink" title="1.3.1 MVCC和一致性非锁定读"></a>1.3.1 MVCC和一致性非锁定读</h3><p>MVCC全称Multi-Version Concurrent Control，即多版本并发控制，是一种乐观锁的实现。它最大的特点是：读可不加锁，读写不冲突。并发性能很高。</p>
<p>MVCC中默认的读是<strong>非锁定的一致性读</strong>，也称快照读。读取的是记录的可见版本，当读取的的记录正在被别的事务并发修改时，会读取记录的历史版本。读取过程中不对记录加锁。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-03b0ae53e0ab9979a20a7de00545fa3a388.png" alt=""></p>
<p>如上图，如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB存储引擎会去读取行的一个快照数据。之所以称其为非锁定读，因为不需要等待访问的行上X锁的释放。</p>
<p>那么快照数据如何产生呢？</p>
<p>在InnoDB的行记录的列数据中有两个隐藏的列：当前行<strong>创建时的版本号</strong>和<strong>删除时的版本号</strong>（可能为空，其实还有一列称为回滚指针，用于事务回滚，这里暂不讨论）。这里的版本号并不是实际的时间值，而是系统版本号。每开始新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询每行记录的版本号进行比较。</p>
<p>每个事务又有自己的版本号，这样事务内执行CRUD操作时，就通过版本号的比较来达到数据版本控制的目的。</p>
<p>MVCC的实现依赖于undo日志（undo日志具体可见本站博客《【InnoDB详解四】redo log和undo log》），该日志通过回滚指针把一个数据行（Record）的所有快照数据（也都是数据行）连接起来：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cd6044f25be571296c160c23277dc144dc8.png" alt=""></p>
<blockquote>
<p>后文会讲到，MVCC主要用于<strong>可重复读</strong>和<strong>读已提交</strong>这两种事务隔离级别的实现中。</p>
</blockquote>
<p>那么MVCC下InnoDB的增删查改是怎么运作的呢？</p>
<h4 id="1-3-1-1-MVCC下的insert"><a href="#1-3-1-1-MVCC下的insert" class="headerlink" title="1.3.1.1 MVCC下的insert"></a>1.3.1.1 MVCC下的insert</h4><p>插入时，记录的版本号即当前事务的版本号。我们执行一条数据语句：</p>
<p><code>insert into testmvcc values(1,&quot;test&quot;);</code></p>
<p>假设事务id为1，那么插入后的数据行如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-893019c4b35d3863e2820831cd3236e0d37.png" alt=""></p>
<h4 id="1-3-1-2-MVCC下的update"><a href="#1-3-1-2-MVCC下的update" class="headerlink" title="1.3.1.2 MVCC下的update"></a>1.3.1.2 MVCC下的update</h4><p>在更新操作的时候，采用的是先标记旧的那行记录为已删除，并且删除版本号是事务版本号，然后插入一行新的记录的方式。</p>
<p>比如，针对上面那行记录，把name字段更新：</p>
<p><code>update table set name= &#39;new_value&#39; where id=1;</code></p>
<p>假设事务id为2，那么更新后的结果如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-18f88aa062b8044a6961d63c28231563dc3.png" alt=""></p>
<h4 id="1-3-1-3-MVCC下的delete"><a href="#1-3-1-3-MVCC下的delete" class="headerlink" title="1.3.1.3 MVCC下的delete"></a>1.3.1.3 MVCC下的delete</h4><p>在删除操作的时候，就把事务版本号作为删除版本号。比如</p>
<p><code>delete from table where id=1;</code></p>
<p>假设事务id为3，那么删除后的结果如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-37153c8fa1ea12e85f2cfd6f4d1b46c6bec.png" alt=""></p>
<h4 id="1-3-1-4-MVCC下的select"><a href="#1-3-1-4-MVCC下的select" class="headerlink" title="1.3.1.4 MVCC下的select"></a>1.3.1.4 MVCC下的select</h4><p>综合上文，我们可以知道，在查询时要<strong>符合以下两个条件的记录</strong>才能被事务查询出来：</p>
<ol>
<li><p>删除版本号<strong>未指定</strong>或者<strong>大于当前事务版本号</strong>，即要确保查询事务开启时，要读取的行未被删除。(比如上述事务id为2的事务查询时，依然能读取到被id=3的事务所删除的数据行)</p>
</li>
<li><p>创建版本号<strong>小于</strong>或者<strong>等于</strong>当前事务版本号 ，即要确保查询事务开启时，要读取的行记录<strong>正在</strong>（等于的情况）或者<strong>已经</strong>（小于的情况）被创建。(比如上述事务id为2的事务查询时，只能读取到被id=1或者id=2的事务所创建的行)</p>
</li>
</ol>
<h3 id="1-3-2-LBCC和一致性锁定读"><a href="#1-3-2-LBCC和一致性锁定读" class="headerlink" title="1.3.2 LBCC和一致性锁定读"></a>1.3.2 LBCC和一致性锁定读</h3><p>在前文中我们说到，默认配置下，即事务的隔离级别为<code>可重复读</code>模式下，InnoDB存储引擎的SELECT操作使用一致性非锁定读。但是在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。而这要求数据库支持加锁语句，即使是对于SELECT的只读操作。</p>
<p>LBCC全称Lock-Based Concurrent Control，即基于锁的并发控制，是一种悲观锁的实现。LBCC中的读是<strong>一致性锁定读</strong>，也称当前读：读取的是记录的最新版本，并且会对记录加锁。</p>
<p>InnoDB存储引擎对于SELECT语句支持两种一致性的锁定读（locking read）操作∶</p>
<ol>
<li>SELECT…FOR UPDATE<ul>
<li>SELECT…FOR UPDATE 对读取的行记录加一个X锁，其他事务不能对已锁定的行加上任何锁。</li>
</ul>
</li>
<li>SELECT…LOCK IN SHARE MODE<ul>
<li>SELECT.·…LOCKIN SHARE MODE对读取的行记录加一个S锁，其他事务可以向被锁定的行加S锁，但是如果加X锁，则会被阻塞。</li>
</ul>
</li>
</ol>
<blockquote>
<p>对于一致性非锁定读，即使读取的行已被执行了SELECT…FOR UPDATE，也是可以进行读取的，这和之前讨论的情况一样。</p>
</blockquote>
<blockquote>
<p>此外，SELECT.…FOR UPDATE，SELECT.…·LOCK IN SHARE MODE必须在一个事务中，当事务提交了，锁也就释放了。因此在使用上述两句SELECT锁定语句时，务必加上BEGIN，STARTTRANSACTION或者SET AUTOCOMMIT=0。</p>
</blockquote>
<blockquote>
<p>LBCC被用在seraliable隔离级别中，seraliable级别会对每个select语句后面自动加上lock in share mode。</p>
</blockquote>
<h2 id="1-4-锁的数据结构"><a href="#1-4-锁的数据结构" class="headerlink" title="1.4 锁的数据结构"></a>1.4 锁的数据结构</h2><p>锁升级（Lock Escalation）是指将当前锁的粒度降低。举例来说，如果一个页中，有大量的行都被加了锁，那么维护这么多的锁对象，需要占用大量内存，那为了节约内存提高效率，数据库会将锁升级，从行锁升级为页锁。这样只需要维护一个页锁对象就可以替代可能是几千个行锁对象了。同理，页锁升级为表锁也是同样的道理。</p>
<p>如果在数据库的设计中认为锁是一种稀有资源，而且想避免锁的开销，那数据库中会频繁出现锁升级现象，虽然这种做法会降低并发性能。</p>
<p>这种升级保护了系统资源，防止系统使用太多的内存来维护锁，在一定程度上提高了效率。</p>
<p><strong>然而，InnoDB不需要锁升级机制，因为InnoDB对锁对象的维护十分特殊</strong>，InnoDB并非将行锁维护在每一个行记录中，而是使用了位图+哈希表，前者保证了占用少量内存，后者保证了查询效率极高。</p>
<h3 id="1-4-1-锁对象和位图"><a href="#1-4-1-锁对象和位图" class="headerlink" title="1.4.1 锁对象和位图"></a>1.4.1 锁对象和位图</h3><p>InnoDB定义了<strong>页锁结构</strong>和<strong>表锁结构</strong>两种数据结构，来分别描述<strong>行级锁和表级锁</strong></p>
<h4 id="1-4-1-1-页锁结构"><a href="#1-4-1-1-页锁结构" class="headerlink" title="1.4.1.1 页锁结构"></a>1.4.1.1 页锁结构</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;页锁结构</span><br><span class="line">typedef struct lock_rec_struct        lock_rec_t</span><br><span class="line">struct lock_rec_struct&#123;</span><br><span class="line">    ulint space;    &#x2F;*space id*&#x2F;</span><br><span class="line">    ulint page_no;  &#x2F;*page number*&#x2F;</span><br><span class="line">    unint n_bits;   &#x2F;*number of bits in the lock bitmap*&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>space+page_no可以唯一定位一个页，所以InnoDB中有多少个数据页，就最多有多少个页锁对象。</li>
<li>n_bits是一个位图。如果要查看锁对象某行记录是否上锁，只需要根据space／page_no找到对应的页，然后根据位图中对应位置是否是1来决定此行记录是否上锁。</li>
</ul>
<p>假设页中有250条行记录，那么位图n_bit的占用空间为=250bit+64bit(额外预留的)=314bit，那么实际位图需要40个字节（320bit）用于位图的管理，若页中heap_no为2，3，4的记录都已经上锁，则对应的数据结构lock_rec_t 在内存中的关系如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a64fdbec884bcbc7141720cf86b5edf2092.png" alt=""></p>
<p>我们可以看到，行级锁并非维护在数据页的行记录里面，而是另外寻了一处空间来存放，这种锁的实现机制可以最大程度地重用锁对象，节省系统资源，不存在锁升级的问题。</p>
<p>可想而知，如果每个行锁都生成一个锁对象，将会导致严重的性能损耗，比如接近于全表扫描的查询就会生成大量的锁对象，内存开销将会很大。位图的方式很好地避免了这个问题。</p>
<h4 id="1-4-1-2-表锁结构"><a href="#1-4-1-2-表锁结构" class="headerlink" title="1.4.1.2 表锁结构"></a>1.4.1.2 表锁结构</h4><p>表级锁的数据结构（用于表的意向锁和自增锁）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">typedef struct lock_table_struct lock_table_t;</span><br><span class="line">struct lock_table_struct &#123;</span><br><span class="line">    dict_table_t*          table;   &#x2F;*database table in dictionary cache*&#x2F;</span><br><span class="line">    UT_LIST_NODE_T(lock_t) locks;   &#x2F;*list of locks on the same table*&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#define UT_LIST_NODE_T(TYPE)</span><br><span class="line">struct &#123;</span><br><span class="line">       TYPE *   prev;       &#x2F;* pointer to the previous node,NULL if start of list *&#x2F;</span><br><span class="line">       TYPE *   next;       &#x2F;* pointer to next node, NULL if end of list *&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一目了然，结构内的table变量是一个表结构（dict_table_t）的指针，它表示被锁住的是哪个表，一个表锁结构对应一张表。</p>
<p>然后locks变量是lock_struct结构（<code>typedef struct lock_struct  lock_t;</code>）组成的链表节点，UT_LIST_NODE_T是一个典型的链表节点结构，有前驱和后驱。</p>
<p>lock_struct是锁信息的整合结构，下面我们会介绍，locks所在的这个链表，连接了所有加在当前table上的锁对象，<strong>这样就能通过locks变量，遍历到当前表级锁对象所锁定的表上一共有哪些类型的锁</strong>。</p>
<h4 id="1-4-1-3-整合的锁结构"><a href="#1-4-1-3-整合的锁结构" class="headerlink" title="1.4.1.3 整合的锁结构"></a>1.4.1.3 整合的锁结构</h4><p>上面我们知道InnoDB定义了页锁结构和表锁结构，但通过这二者，我们只能知道哪些行记录或者表被加了锁，<strong>却不知道这锁是由哪个事务加的，加的是什么类型的锁</strong>，于是，InnoDB定义了一个新的锁结构，它就是我们前面看到的struct lock_struct  lock_t：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">typedef struct lock_struct  lock_t;</span><br><span class="line">struct lock_struct&#123;</span><br><span class="line">    trx_t*                  trx;       &#x2F;*这个锁属于哪个事务*&#x2F;</span><br><span class="line">    UT_LIST_NODE_T(lock_t)  trx_locks;  &#x2F;*该事务拥有的锁通过一个链表连接起来*&#x2F;</span><br><span class="line">    ulint                   type_mode;  &#x2F;* lock type, mode, gap flag, and wait flag, ORed *&#x2F;</span><br><span class="line">    hash_node_t             hash;       &#x2F;* hash chain node for a record lock *&#x2F;</span><br><span class="line">    dict_index_t*           index;      &#x2F;* 在该锁类型是行锁是有效，指向一个索引，因为行锁本质是索引记录锁。 *&#x2F;</span><br><span class="line">    union &#123;</span><br><span class="line">        lock_table_t    tab_lock; &#x2F;* table lock *&#x2F;</span><br><span class="line">        lock_rec_t      rec_lock; &#x2F;* record lock *&#x2F;</span><br><span class="line">    &#125; un_member;  &#x2F;*如果是表锁则un_member为lock_table_t，如果是记录锁则un_member为lock_rec_t，通过type_mode来判断类型*&#x2F;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>lock_struct是<code>&lt;事务，页/表&gt;</code>维度的结构，不同事务的每个页（或每个表）都要定义一个lock_struct结构。但一个事务可能在不同页/表上有锁，trx_locks变量将一个事务所有的锁信息进行链接，这样就可以快速查询一个事务所有锁信息。</p>
<p>un_member变量是一个结构共同体，它可以是表锁对象lock_table_t，也可以是页锁对象lock_rec_t，这根据type_mode来区分，type_mode控制了该锁结构（lock_struct）是属于什么类型的锁，已经目前处于的状态。</p>
<p>type_mode变量是一个无符号的4字节32位整型，从低位排列，</p>
<ol>
<li>第1个字节为lock_mode，定义如下； <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* Basic lock modes *&#x2F;</span><br><span class="line">enum lock_mode &#123;</span><br><span class="line">	LOCK_IS &#x3D; 0,    &#x2F;* intention shared *&#x2F;</span><br><span class="line">	LOCK_IX,    &#x2F;* intention exclusive *&#x2F;</span><br><span class="line">	LOCK_S,     &#x2F;* shared *&#x2F;</span><br><span class="line">	LOCK_X,     &#x2F;* exclusive *&#x2F;</span><br><span class="line">	LOCK_AUTO_INC,  &#x2F;* locks the auto-inc counter of a table</span><br><span class="line">			in an exclusive mode *&#x2F;</span><br><span class="line">	LOCK_NONE,  &#x2F;* this is used elsewhere to note consistent read *&#x2F;</span><br><span class="line">	LOCK_NUM &#x3D; LOCK_NONE, &#x2F;* number of lock modes *&#x2F;</span><br><span class="line">	LOCK_NONE_UNSET &#x3D; 255</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
<li>第2个字节为lock_type，目前只用前两位，大小为16和32，分别表示LOCK_TABLE 和LOCK_REC，这一个字节控制了lock_struct是表级锁还是行级锁。 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define LOCK_TABLE      16</span><br><span class="line">#define LOCK_REC        32</span><br></pre></td></tr></table></figure></li>
<li>剩下的高位bit表示行锁的类型record_lock_type <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#define LOCK_WAIT   256        &#x2F;* 表示正在等待锁 *&#x2F;</span><br><span class="line">#define LOCK_ORDINARY 0     &#x2F;* 表示 Next-Key Lock ，锁住记录本身和记录之前的 Gap*&#x2F;</span><br><span class="line">#define LOCK_GAP    512        &#x2F;* 表示锁住记录之前 Gap（不锁记录本身） *&#x2F;</span><br><span class="line">#define LOCK_REC_NOT_GAP 1024    &#x2F;* 表示锁住记录本身，不锁记录前面的 gap *&#x2F;</span><br><span class="line">#define LOCK_INSERT_INTENTION 2048    &#x2F;* 插入意向锁 *&#x2F;</span><br><span class="line">#define LOCK_CONV_BY_OTHER 4096        &#x2F;* 表示锁是由其它事务创建的(比如隐式锁转换) *&#x2F;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="1-4-2-行级锁的查询"><a href="#1-4-2-行级锁的查询" class="headerlink" title="1.4.2 行级锁的查询"></a>1.4.2 行级锁的查询</h3><p>有些时候，我们需要查询某个具体行记录的锁信息。<strong>比如行记录id=3是否有锁</strong>？</p>
<p>InnoDB使用一个哈希表映射行数据和锁信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">struct lock_sys_struct&#123;</span><br><span class="line">    hash_table_t* rec_hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>每次新建一个锁对象，都要插入到lock_sys_struct-&gt;rec_hash中。lock_sys_struct中的key通过页的space和page_no计算得到，而value则是页锁结构lock_rec_struct。</p>
<p>因此若需查询某一行记录是否有锁，首先则先要根据索引，定位到该行记录具体在哪一页。然后根据页的space和page_no进行哈希查询，得到lock_rec_struct，再根据lock_rec_struct里面的位图n_bits，最终得到该行记录是否有锁。</p>
<blockquote>
<p>正是因为行锁的查询需要根据页的space和page_no，而页的定位又基于索引，所以才说InnoDB的行锁是通过给索引项加锁实现的，这就意味着只有通过索引条件检索数据时，InnoDB才使用行锁，否则使用表锁。也就是说，<strong>如果批量update，如果条件的字段没有索引，将会锁表，如果有索引，则只会出现行锁</strong>。</p>
</blockquote>
<p>可以看出，根据页来查找行锁的查询并不是高效设计，但这种方式的资源开销非常小。某一事务对一个页任意行加锁开销都是一样的（不管锁住多少行）。因此也不需要支持锁升级的功能。</p>
<h2 id="1-5-死锁"><a href="#1-5-死锁" class="headerlink" title="1.5 死锁"></a>1.5 死锁</h2><p>死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种相互等待的现象。若无外力作用，他们都将无法推进下去。</p>
<p>解决死锁常用的两个方案：</p>
<ol>
<li><p>超时机制</p>
<ul>
<li>即两个事务互相等待时，当一个等待时间超过设置的某一阀值时，其中一个事务回滚，另一个事务继续执行。MySQL4.0版本开始，提供innodb_lock_wait_time用于设置等待超时时间。</li>
</ul>
</li>
<li><p>等待图（wait-for graph）</p>
<ul>
<li>较之超时的解决方案，这是一种更为主动的死锁检测方式。InnoDB通过锁的信息链表和事务等待链表，判断是否存在等待回路。如有，则存在死锁。每次加锁操作需要等待时都判断是否产生死锁，若有则回滚事务。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-279d2538466f15ae9ef9796f6a07cdb3e81.png" alt=""></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-eff83ca3d0abfed2f6c40dd447116b8ed61.png" alt=""></li>
</ul>
</li>
</ol>
<h2 id="1-6-锁的监控方式"><a href="#1-6-锁的监控方式" class="headerlink" title="1.6 锁的监控方式"></a>1.6 锁的监控方式</h2><p><code>show engine innodb status</code>命令可以获取最近一次的死锁日志。<br>MySQL8之前，可以通过<code>INFORMATION_SCHEMA</code>下<code>INNODB_TRX</code>,<code>INNODB_LOCKS</code>,<code>INNODB_LOCK_WAITS</code>查看事务和锁信息。<br>INNODB_TRX在MySQL8依然保留。</p>
<h1 id="2-InnoDB事务机制"><a href="#2-InnoDB事务机制" class="headerlink" title="2. InnoDB事务机制"></a>2. InnoDB事务机制</h1><p>在关系型数据库中，事务的重要性不言而喻，只要对数据库稍有了解的人都知道事务具有ACID四个基本特性。回顾一下事务的ACID特性，分别是原子性、一致性、隔离性、持久性， 一致性是事务的最终追求的目标，隔离性、原子性、持久性是达成一致性目标的手段。</p>
<ul>
<li><p>A : atomicity 原子性。原子性是我们对事务最直观的理解：事务就是一系列的操作，要么全部都执行，要么全部都不执行。</p>
</li>
<li><p>C : consistency 一致性。数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。它分为数据库外部的一致性和内部的一致性：</p>
<ul>
<li>数据库外部的一致性，例如对银行转帐事务，不管事务成功还是失败，应该保证事务结束后ACCOUNTS表中Tom和Jack的存款总和不变。这个由外部应用的编码来保证，即某个应用在执行转帐的数据库操作时，必须在同一个事务内部调用对帐户A和帐户B的操作。</li>
<li>数据库内部的一致性，这是数据库层面去保证的，体现在我们利用事务将账户A和账户B的操作绑定时，要么一起成功，要么一起失败（原子性）。同时，如果在并发场景下，还要保证其他事务的操作不会影响当前事务（隔离性）。</li>
</ul>
</li>
<li><p>I : isolation 隔离性。在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。</p>
</li>
<li><p>D : durability 持久性。只要事务成功结束，它对数据库所做的更新就必须永久保存下来。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态。</p>
</li>
</ul>
<p>事务的 ACID 特性概念简单，但需要注意的是这几个特性不是一种平级关系：</p>
<ol>
<li>只有满足一致性，事务的执行结果才是正确的。</li>
<li>在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。</li>
<li>事务满足持久化是为了能应对数据库崩溃的情况。</li>
</ol>
<p>所以他们的关系如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f5ac61c75c660df67f8e210a7db7fc834b2.png" alt=""></p>
<p><strong>接下来就让我们来探究一下InnoDB是如何实现事务的——如何保证事务的ACID特性</strong>。</p>
<h2 id="2-1-InnoDB事务原子性的保证"><a href="#2-1-InnoDB事务原子性的保证" class="headerlink" title="2.1 InnoDB事务原子性的保证"></a>2.1 InnoDB事务原子性的保证</h2><p>原子性，核心要点是，<strong>要么全部都执行成功，要么全部都不执行</strong>：</p>
<ol>
<li>要么全部都执行成功：修改后的数据的新状态也是原子的，如果执行成功，那新状态（可能涉及到多个行的变更）应该就像一个操作那样同时全部生效。而不是这一秒3个行被更新完成，下一秒剩下2个行才被更新完成。</li>
<li>要么全部都不执行：也就是如果失败了，要可回滚，将一切都恢复原样。</li>
</ol>
<p><strong>前者通过MVCC来实现</strong>，前文我们已经介绍过MVCC了，同一个事务而产生的新的数据行都带有相同的版本号，配合上一致性非锁定读，可以实现统一事务的变更同时在一个瞬间（也就是同一个系统版本）生效。</p>
<p><strong>而后者，则通过undo日志来实现</strong>，undo日志的详细介绍可见本站博客《【InnoDB详解四】redo log和undo log》，这里简单介绍一下：</p>
<p>在对数据库进行修改时，InnoDB存储引擎会产生一定量的undo log，它记录了事务中每一步操作的<strong>反向逻辑操作</strong>：</p>
<ol>
<li>如果是一个INSERT操作，那么undo log会对应产生一条DELETE操作。</li>
<li>如果是一个DELETE操作，那么undo log会对应产生一条INSERT操作。</li>
<li>如果是一个UPDATE操作，假设是将行A的值从a变更为b，那么undo log会对应产生一条UPDATE操作，将行A的值从b变更为a。</li>
</ol>
<p>这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。</p>
<blockquote>
<p>前者我们说过，MVCC也是通过undo日志实现的，所以本质上，InnoDB事务原子性的保证（undo log + MVCC），其实全都是依赖于undo日志。</p>
</blockquote>
<h2 id="2-3-InnoDB事务持久性的保证"><a href="#2-3-InnoDB事务持久性的保证" class="headerlink" title="2.3 InnoDB事务持久性的保证"></a>2.3 InnoDB事务持久性的保证</h2><p>持久性的核心在于已经提交的修改必须永久的保存下来，对于数据库而言，也就是要写入磁盘中，这才能做到真正的数据持久化。</p>
<p>InnoDB事务持久性的保证依赖于redo日志，redo日志由两部分组成：</p>
<ol>
<li>内存中的重做日志缓冲（redo log buffr），其是易失的;</li>
<li>重做日志文件（redo log file），其是持久的。</li>
</ol>
<blockquote>
<p>redo日志的详细介绍可见本站博客《【InnoDB详解四】redo log和undo log》</p>
</blockquote>
<p>redo日志是物理日志，它的内容和undo日志那样的逻辑日志不一样，它记录的是数据页的物理变更信息，对于事务中的任何操作，都会产生redo日志，用来记录其对数据页的物理变动信息。</p>
<p>InnoDB通过<strong>Force Log at Commit</strong>机制实现事务的持久性，即当事务提交（COMMIT）时，<strong>必须先将该事务产生的所有redo日志写入到重做日志文件（redo log file）进行持久化</strong>，这样就能保证<strong>就算数据的变更还在缓冲池中（在脏页里面），如果系统崩溃了，也可以通过已经持久化的redo日志进行数据恢复</strong>。</p>
<p>将redo日志写入重做日志文件（redo log file）的操作叫做fsync操作，理论上为了保证持久性，每一次事务提交前，InnoDB应该都要执行一次fsync操作，不过很显然，频繁的fsync操作会影响并发性能。</p>
<p>InnoDB存储引擎允许用户手工设置fsync操作的频率，以此提高数据库的性能。参数<code>innodb_flush_log_at_trx_commit</code>用来控制重做日志刷新到磁盘的策略：</p>
<ol>
<li>该参数的默认值为1，表示事务提交时必须调用一次 fsync操作。<ul>
<li>这是最安全的持久化策略，不会发生更新丢失的情况。</li>
</ul>
</li>
<li>还可以设置该参数的值为0，表示事务提交时不进行写人重做日志操作，这个操作仅在master thread中完成，而在master thread中每1秒会进行一次重做日志文件的fsync操作。<ul>
<li>此时如果发生宕机，<strong>最多会丢失1秒的那部分更新</strong>。</li>
</ul>
</li>
<li>还可以设置该参数的值为2，表示事务提交时将重做日志写入重做日志文件，但仅写入文件系统的缓存中，不进行fsync操作。<ul>
<li>在这个设置下，当MySQL数据库发生宕机而操作系统不发生宕机时，并不会导致事务的丢失。而当操作系统宕机时，重启数据库后会丢失<strong>未从文件系统缓存刷新到重做日志文件那部分更新</strong>。</li>
</ul>
</li>
</ol>
<h2 id="2-3-InnoDB事务隔离性的保证"><a href="#2-3-InnoDB事务隔离性的保证" class="headerlink" title="2.3 InnoDB事务隔离性的保证"></a>2.3 InnoDB事务隔离性的保证</h2><p>在本站博客《MySQL核心要点汇总》一文中，我们简单了解过MySQL中事务的隔离级别：</p>
<p>SQL 标准定义了四个隔离级别：</p>
<ul>
<li><strong>READ-UNCOMMITTED(读未提交)</strong>： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。</li>
<li><strong>READ-COMMITTED(读已提交)</strong>： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。</li>
<li><strong>REPEATABLE-READ(可重复读)</strong>： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生（这是针对Oracle，SQL server等数据库而言，InnoDB采用Next-Key Lock，在可重复读级别下就可以避免幻读）。</li>
<li><strong>SERIALIZABLE(串行化)</strong>： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。</li>
</ul>
<p>同样的，我们回顾一下 脏读/不可重复读/幻读 这三类并发的问题。</p>
<ul>
<li><strong>脏读</strong>：指的是在不同的事务下，当前事务可以读到另外事务<strong>未提交的数据</strong>，简单来说就是可以读到脏数据。</li>
<li><strong>不可重复读</strong>：是指在事务A中多次读取同一批数据。在这个多次访问之间，事务B也访问该批数据，并做了一些DML操作，并且提交（如果没提交就是脏读了）。因此，在事务A中的两次读数据之间，由于事务B的修改，导致事务A两次读到的数据可能是不一样的。不可重复读和脏读的区别是脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据。</li>
<li><strong>幻读</strong>：是指在同一事务（事务A）下，连续执行两次同样的SQL语句可能搜出不同的结果，<strong>第二次的SQL语句可能会返回之前不存在的行，就像产生了幻觉一样</strong>。也就是说，在两次查询之间，其他事务insert并且提交的行，如果满足事务A查询的where条件，那么也会被查出来。幻读和不可重复读的区别在于幻读是查询的行数量变多（因为其他事务insert），不可重复读是行数据不一致（因为其他事务update）。</li>
</ul>
<p><strong>那么，各个隔离级别是如何实现的呢？他们分别是如何解决脏读/不可重复读/幻读问题的呢</strong>？</p>
<p>我们可以先来个开门见山的总结：</p>
<ul>
<li><strong>READ-UNCOMMITTED(读未提交)</strong><ul>
<li>无锁</li>
<li>无并发控制协议</li>
</ul>
</li>
<li><strong>READ-COMMITTED(读已提交)</strong><ul>
<li>使用乐观锁MVCC，其<code>非一致性读取</code>，可以避免事务读取被上锁的行记录（防止脏读），只能读取快照数据。</li>
<li>但在该级别下，所有事务的<code>非一致性读</code>都会<strong>读取最新版本的快照</strong>，即便这个最新版本是在事务开启之后才提交的，这就可能产生<code>不可重复读</code>问题。</li>
</ul>
</li>
<li><strong>REPEATABLE-READ(可重复读)</strong><ul>
<li>使用乐观锁MVCC，并且所有事务的<code>非一致性读</code>都会<strong>读取当前事务开启时最新版本的快照</strong>，这样就能避免<code>不可重复读</code>的发送。</li>
<li>使用Next-Key Lock，给事务查询的where条件涵盖的行记录加上范围锁，防止其他事务在这些行数据间隙插入新的记录，从而避免幻读问题。</li>
</ul>
</li>
<li><strong>SERIALIZABLE(串行化)</strong><ul>
<li>使用悲观锁LBCC。<code>一致性读取</code>会在操作的每一行数据上都加上锁，读取加S锁，其余加X锁。</li>
</ul>
</li>
</ul>
<p>其中MVCC和LBCC我们在前文已经介绍过了，这里不再赘述。</p>
<p>不过需要注意的是，各个隔离级别的加锁，其实是加在索引上的，而且在不同的情况下，加锁逻辑也不太相同，比如我们执行一条delete语句：<code>delete from t1 where id=10;</code>，那么在执行这条语句前，我们需要确定：</p>
<ol>
<li>id列是不是主键？</li>
<li>事务的隔离级别是什么？</li>
<li>id非主键的话，其上有建立索引吗？</li>
<li>建立的索引是唯一索引吗？</li>
<li>该SQL的执行计划是什么？索引扫描？全表扫描？</li>
</ol>
<p>不同场景的不同实现，我们逐一来看下：</p>
<h3 id="2-3-1-READ-UNCOMMITTED的加锁方式"><a href="#2-3-1-READ-UNCOMMITTED的加锁方式" class="headerlink" title="2.3.1 READ-UNCOMMITTED的加锁方式"></a>2.3.1 READ-UNCOMMITTED的加锁方式</h3><p>无锁，没有什么实现，忽略。</p>
<h3 id="2-3-2-READ-COMMITTED的加锁方式"><a href="#2-3-2-READ-COMMITTED的加锁方式" class="headerlink" title="2.3.2 READ-COMMITTED的加锁方式"></a>2.3.2 READ-COMMITTED的加锁方式</h3><h4 id="2-3-2-1-id列是主键"><a href="#2-3-2-1-id列是主键" class="headerlink" title="2.3.2.1 id列是主键"></a>2.3.2.1 id列是主键</h4><p>当id是主键的时候，我们只需要在该id=10的记录上加上x锁即可。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ca2458bf61c1ae996c19d02fdde2db595a0.png" alt=""></p>
<h4 id="2-3-2-2-id列是辅助唯一索引"><a href="#2-3-2-2-id列是辅助唯一索引" class="headerlink" title="2.3.2.2 id列是辅助唯一索引"></a>2.3.2.2 id列是辅助唯一索引</h4><p>当id列不是主键，但是为辅助唯一索引时，辅助索引和聚集索引都会加X锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cb574ee9a9fdd4fcdfefb3a51340e84f729.png" alt=""></p>
<h4 id="2-3-2-3-id列是辅助非唯一索引"><a href="#2-3-2-3-id列是辅助非唯一索引" class="headerlink" title="2.3.2.3 id列是辅助非唯一索引"></a>2.3.2.3 id列是辅助非唯一索引</h4><p>当id列不是主键，如果id是非唯一索引，那么所对应的<strong>所有的辅佐索引和聚集索引记录</strong>上都会上x锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a65e9c01d5eec8ee913abdebd626bc2315b.png" alt=""></p>
<h4 id="2-3-2-4-id列上没有索引"><a href="#2-3-2-4-id列上没有索引" class="headerlink" title="2.3.2.4 id列上没有索引"></a>2.3.2.4 id列上没有索引</h4><p>由于id列上没有索引，因此只能走聚簇索引，进行全表扫描。因此聚集索引上的每条记录，无论是否满足条件，都会被加上X锁。</p>
<p>但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，<strong>会在判断后放锁</strong>，最终持有的，是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不会省略。同时，优化也违背了2PL约束（同时加锁同时放锁）。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0af0e86bcea7ffd644e3639c095cea54f0c.png" alt=""></p>
<p>最后只有id=10的锁留下了。</p>
<h3 id="2-3-3-REPEATABLE-READ的加锁方式"><a href="#2-3-3-REPEATABLE-READ的加锁方式" class="headerlink" title="2.3.3 REPEATABLE-READ的加锁方式"></a>2.3.3 REPEATABLE-READ的加锁方式</h3><h4 id="2-3-3-1-id列是主键"><a href="#2-3-3-1-id列是主键" class="headerlink" title="2.3.3.1 id列是主键"></a>2.3.3.1 id列是主键</h4><p>与id列是主键，RC隔离级别的情况，完全相同。因为只有一条结果记录，只能在上面加锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ca2458bf61c1ae996c19d02fdde2db595a0.png" alt=""></p>
<blockquote>
<p>RR级别是需要同时加间隙锁的，但因为id列是唯一主键，且delete的where条件是id=10，这种情况不会发生幻读，所以此例没加。但如果delete语句不是id=10，而是id&gt;10 and id &lt; 15，那么就要加间隙锁了。</p>
</blockquote>
<h4 id="2-3-3-2-id列是辅助唯一索引"><a href="#2-3-3-2-id列是辅助唯一索引" class="headerlink" title="2.3.3.2 id列是辅助唯一索引"></a>2.3.3.2 id列是辅助唯一索引</h4><p>与id列是辅助唯一索引，RC隔离级别的情况，完全相同。因为只有一条结果记录，只能在上面加锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cb574ee9a9fdd4fcdfefb3a51340e84f729.png" alt=""></p>
<blockquote>
<p>RR级别是需要同时加间隙锁的，但因为id列是唯一索引，且delete的where条件是id=10，这种情况不会发生幻读，所以此例没加。但如果delete语句不是id=10，而是id&gt;10 and id &lt; 15，那么就要加间隙锁了。</p>
</blockquote>
<h4 id="2-3-3-3-id列是辅助非唯一索引"><a href="#2-3-3-3-id列是辅助非唯一索引" class="headerlink" title="2.3.3.3 id列是辅助非唯一索引"></a>2.3.3.3 id列是辅助非唯一索引</h4><p>在RR隔离级别下，为了防止幻读的发生，会使用间隙锁（GAP锁）。</p>
<p>首先，通过辅助索引定位到第一条满足查询条件的记录，加记录上的X锁，加GAP上的GAP锁，然后加聚簇索引上的记录X锁，然后返回；</p>
<p>然后读取下一条，重复进行。直至进行到第一条不满足条件的记录<code>[11,f]</code>，此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-12f73d7997a01391c31de0c36df7bcb90dd.png" alt=""></p>
<h4 id="2-3-3-4-id列上没有索引"><a href="#2-3-3-4-id列上没有索引" class="headerlink" title="2.3.3.4 id列上没有索引"></a>2.3.3.4 id列上没有索引</h4><p>在这种情况下，聚集索引上的所有记录，都被加上了X锁。其次，聚集索引每条记录间的间隙(GAP)，也同时被加上了GAP锁。</p>
<p>但是，InnoDB也做了相关的优化，就是所谓的semi-consistent read。semi-consistent read开启的情况下，<strong>对于不满足查询条件的记录，MySQL会提前放锁，同时也不会添加Gap锁</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0805e613bf1d63f1919bf5224e5ffb01cb8.png" alt=""></p>
<h3 id="2-3-4-SERIALIZABLE的加锁方式"><a href="#2-3-4-SERIALIZABLE的加锁方式" class="headerlink" title="2.3.4 SERIALIZABLE的加锁方式"></a>2.3.4 SERIALIZABLE的加锁方式</h3><p>因为这是DML（delete）操作，<strong>所以与REPEATABLE-READ级别的各种情况下表现完全相同</strong>。但如果是select操作，会有所不同：</p>
<ul>
<li><p>REPEATABLE-READ级别默认是一致性非锁定读，在行记录有锁的情况下可以不用阻塞，而是去读取快照，除非SQL中主动加锁进行一致性锁定读（lock in share mode 或 for update）；</p>
</li>
<li><p>而Serializable级别下，会对每条select语句，自动加上lock in share mode，进行一致性锁定读，即如果行上有锁，只能阻塞。</p>
</li>
</ul>
<h2 id="2-4-InnoDB事务一致性的保证"><a href="#2-4-InnoDB事务一致性的保证" class="headerlink" title="2.4 InnoDB事务一致性的保证"></a>2.4 InnoDB事务一致性的保证</h2><p>前文我们已经阐述过了，数据库外的数据一致性，需要通过外部编码来实现，而数据库内的数据一致性，则依赖于原子性和隔离性。在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f5ac61c75c660df67f8e210a7db7fc834b2.png" alt=""></p>
<p>所以InnoDB实现了原子性和隔离性，也就自然而然实现了一致性。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/" itemprop="url">【图论】拓扑排序详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-15T21:36:36+08:00">
                2020-09-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%9B%BE/" itemprop="url" rel="index">
                    <span itemprop="name">图</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/15/【图论】拓扑排序详解/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在正文开始前，我们先来了解一下<strong>有向无环图(Directed Acyclic Graph简称DAG)</strong></p>
<p>如下图就是一个DAG图，DAG图是我们讨论拓扑排序的基础。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8f6717028963b3bea2b37a3ce72eae8f784.png" alt=""></p>
<blockquote>
<p>AOV网：数据在顶点 可以理解为面向对象<br>AOE网：数据在边上，可以理解为面向过程！</p>
</blockquote>
<h1 id="1-什么是拓扑排序"><a href="#1-什么是拓扑排序" class="headerlink" title="1. 什么是拓扑排序"></a>1. 什么是拓扑排序</h1><p><strong>拓扑排序（Topological Order）</strong>，很多人听说过，但是不了解的一种算法。或许很多人只知道它是图论的一种排序，至于干什么的不清楚。又或许很多人可能还会认为它是一种啥排序。</p>
<p>而实质上<strong>它只是将DAG图的顶点排成一个线性序列，得到一个顶点的全序集合</strong>。其排序的顺序依据就是节点的指向关系。比如前言的DAG图：</p>
<ul>
<li>…</li>
<li>节点5在节点4和节点3的后面</li>
<li>节点9在节点6和节点7的后面</li>
<li>…</li>
</ul>
<p>那么最后得到的节点的线性序列结果,也一定要满足上面的指向顺序。</p>
<p>每一个节点都拥有<strong>入度</strong>（有多少点导向它，也就是开始它有多少前提）和<strong>出度</strong>（它导向多少点，也就是它是多少其他节点开始的前提）。例如节点5的入度为3和4，出度为7。</p>
<p><strong>拓扑排序的结果不是唯一的</strong>，只要符合上面的条件，那么它就是拓扑序列，比如<code>1 2 4 3 6 5 7 9</code>和<code>2 1 3 4 5 6 7 9</code>，这两个结果都是可行的。</p>
<blockquote>
<p>官方一点的定义：将有向图中的节点以线性方式进行排序。即对于任何连接自节点u到节点v的有向边uv，在最后的排序结果中，节点u总是在节点v的前面。</p>
</blockquote>
<h1 id="2-现实案例"><a href="#2-现实案例" class="headerlink" title="2. 现实案例"></a>2. 现实案例</h1><p>看了上面关于拓扑排序的概念如果还觉得十分抽象的话，那么不妨考虑一个非常非常经典的例子——选课。</p>
<p>假设我非常想学习一门《jsp入门》的课程，但是在修这么课程之前，我们必须要学习一些基础课程，比如《JAVA语言程序设计》，《HTML指南》等等。那么这个制定选修课程顺序的过程，实际上就是一个拓扑排序的过程，每门课程相当于有向图中的一个顶点，而连接顶点之间的有向边就是课程学习的先后关系。</p>
<p>只不过这个过程不是那么复杂，从而很自然的在我们的大脑中完成了。将这个过程以算法的形式描述出来的结果，就是拓扑排序。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ed6f21ce9608d461a3bccfea80f57b48fa6.png" alt=""></p>
<p>可以看到，上图中的学习顺序，就是拓扑序列，其不止一个结果。</p>
<p>拓扑排序算法在工程学中十分重要。</p>
<blockquote>
<p>节点成环的图，无法被拓扑排序，因为这在工程上本身没有意义，比如A——&gt;B——&gt;C——&gt;A，那么这个工程永远无法被开始。</p>
</blockquote>
<h1 id="3-算法实现"><a href="#3-算法实现" class="headerlink" title="3. 算法实现"></a>3. 算法实现</h1><p>拓扑排序的<strong>最优时间复杂度是O(m+n)</strong>,其中m和n是DAG图中节点数和边数。因为拓扑排序<strong>至少</strong>要对DAG图的节点和边进行一次完整的遍历。</p>
<p>拓扑排序的<strong>最优空间复杂度是O(m+n)</strong>,其中m和n是DAG图中节点数和边数。我们一般使用邻接表来存储DAG图，因此空间复杂度是O(m+n)。</p>
<h2 id="3-1-广度优先搜索法（BFS）"><a href="#3-1-广度优先搜索法（BFS）" class="headerlink" title="3.1 广度优先搜索法（BFS）"></a>3.1 广度优先搜索法（BFS）</h2><h3 id="3-1-1-BFS实现拓扑排序"><a href="#3-1-1-BFS实现拓扑排序" class="headerlink" title="3.1.1 BFS实现拓扑排序"></a>3.1.1 BFS实现拓扑排序</h3><p>广度优先搜索法的思路很简单：</p>
<ol>
<li>从DAG图中找到<strong>入度为0</strong>的节点A（也就是没有箭头指向它的节点），将其放入拓扑序列的结果集。</li>
<li>同时删除由节点A出发的所有边。</li>
<li>在剩下的DAG图中重复1-2两步。</li>
<li>如果最后可以把全部的节点都删除并加入到结果集，那表示DAG图可以被拓扑排序；否则，如果最后有节点被剩下，那说明该图是有环图，无法被拓扑排序。</li>
</ol>
<p>如下图</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3391dd5692b37d49a3f885971f434cf5a02.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-60263c4c74b83269df50907f42790bb5234.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-77d989dca380e2eba9c57d1e815326edc56.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fe6e6c396e5c66160ca7a86e6bde5c3c5b3.png" alt=""></p>
<h3 id="3-1-2-BFS实现拓扑排序的优化"><a href="#3-1-2-BFS实现拓扑排序的优化" class="headerlink" title="3.1.2 BFS实现拓扑排序的优化"></a>3.1.2 BFS实现拓扑排序的优化</h3><p>如果有时候，我们只需要知道某个DAG图是否可以拓扑排序，而不需要真正得到拓扑排序后的结果，那么可以不需要结果集列表，<strong>只需要统计被删除的节点的数量即可，如果该数量等于DAG图的节点数，那么DAG图可以被拓扑排序</strong>。</p>
<h2 id="3-2-深度优先搜索法（DFS）"><a href="#3-2-深度优先搜索法（DFS）" class="headerlink" title="3.2 深度优先搜索法（DFS）"></a>3.2 深度优先搜索法（DFS）</h2><h3 id="3-2-1-DFS实现拓扑排序"><a href="#3-2-1-DFS实现拓扑排序" class="headerlink" title="3.2.1 DFS实现拓扑排序"></a>3.2.1 DFS实现拓扑排序</h3><p>深度优先搜索法是广度优先搜索法的逆向思路，它的步骤如下：</p>
<ol>
<li>选取图中任意一个节点A，将其状态标记为“搜索中”</li>
<li>寻找节点A的邻接点（沿着箭头指向寻找相邻的节点）<ol>
<li>如果A存在邻接点<ol>
<li>如果A的邻接点中存在状态为“搜索中”的邻接点，那么表示DAG图有环路，不可拓扑排序。</li>
<li>否则，那么任意选择一个状态为“未搜索”的邻接点B，使用递归对B重复做1和2操作，注意此时B的邻接点判断不包含来路（也就是A节点）。等到A的所有邻接点都被搜索到，递归回溯回A节点的时候，那么A节点也会被标记为“已搜索”，并压入结果栈。</li>
</ol>
</li>
<li>如果A不存在邻接点，那么将节点A的状态改为“已完成”，并且将其压入一个结果集的栈中。</li>
</ol>
</li>
<li>A节点及其相邻节点都搜索完毕后，如果还有未搜索的节点，那么任意选取一个节点当做出发点，继续重复1,2,3步骤。</li>
<li>直到所有的节点都被搜索并压入栈，那么此时结果栈中，从栈顶到栈底的顺序，就是拓扑排序的顺序。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-4c28b181876a97519a71c906921c05e9a8a.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8527f61ef65f2e3bde9e47f8b7a22481fae.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f6b9acea12ae9b5876b792b3394a4b0b480.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a70c8606a0f12ed549991a6a6fd584d5030.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-788b9456add4b59dc890a12950e0efdd024.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2cbe7ded9481877300dbf1a2e519a85f8fc.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8be9445aae16147097ac42f8bc08002a114.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4386e32bbe6db3348a0b5051aac0114cacb.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-102c038f31cec5cbdea7102f2e612f06b67.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c091a2e5694ff8708a1884c9492c8cdf551.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-50cc6d8c4050ac9c0b8114c2bb3a49e809d.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-59af3a05a56757f166044305474cf42922f.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-700d02c9347cef22f44ce631a6b088a2011.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8445591c7013e1633e194c4f4f71a31eb71.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ee05cf7512bfb71807f9b3ad8d91b026685.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5a462ba6ac4e920c4cc444eef497fd02d62.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6d626a51209e2c008ff9a1f7008f196a4a4.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-46b3b2f1532c08a3c29aa71b97b049ef3b9.png" alt=""></p>
<h3 id="3-2-2-DFS实现拓扑排序的优化"><a href="#3-2-2-DFS实现拓扑排序的优化" class="headerlink" title="3.2.2 DFS实现拓扑排序的优化"></a>3.2.2 DFS实现拓扑排序的优化</h3><p>如果有时候，我们只需要知道某个DAG图是否可以拓扑排序，而不需要真正得到拓扑排序后的结果，那么可以不需要结果栈，只需要判断整个深度优先搜索过程，没有发生“搜索中”节点的相邻节点（不包含来路的节点）也是“搜索中”就行。</p>
<h1 id="4-算法题解"><a href="#4-算法题解" class="headerlink" title="4 算法题解"></a>4 算法题解</h1><h2 id="4-1-课程表I"><a href="#4-1-课程表I" class="headerlink" title="4.1 课程表I"></a>4.1 课程表I</h2><p><a href="https://leetcode-cn.com/problems/course-schedule/" target="_blank" rel="noopener" title="leetcode-207. 课程表">leetcode-207. 课程表I</a></p>
<h2 id="4-2-课程表II"><a href="#4-2-课程表II" class="headerlink" title="4.2 课程表II"></a>4.2 课程表II</h2><p><a href="https://leetcode-cn.com/problems/course-schedule-ii/" target="_blank" rel="noopener" title="leetcode-210.课程表II">leetcode-210.课程表II</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/" itemprop="url">【图论】广度/深度优先搜索算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-15T21:29:34+08:00">
                2020-09-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%9B%BE/" itemprop="url" rel="index">
                    <span itemprop="name">图</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/15/【图论】广度-深度优先搜索算法/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我们首次接触<strong>广度优先搜索</strong>和<strong>深度优先搜索</strong>时，应该是在数据结构课上讲的 “图的遍历”。还有就是刷题的时候，遍历二叉树/拓扑排序我们会经常用到这两种遍历方法。</p>
<p><strong>广度优先搜索算法（Breadth-First-Search，缩写为 BFS）</strong>，是一种利用<strong>队列</strong>实现的搜索算法。简单来说，其搜索过程和 “湖面丢进一块石头激起层层涟漪” 类似。</p>
<p><strong>深度优先搜索算法（Depth-First-Search，缩写为 DFS）</strong>，是一种利用<strong>递归</strong>实现的搜索算法。简单来说，其搜索过程和 “不撞南墙不回头” 类似。</p>
<p><strong>BFS 的重点在于队列，而 DFS 的重点在于递归。这是它们的本质区别。</strong></p>
<h1 id="1-广度优先搜索法"><a href="#1-广度优先搜索法" class="headerlink" title="1. 广度优先搜索法"></a>1. 广度优先搜索法</h1><p>广度优先搜索，也叫做广度优先遍历，其主要思想类似于树的层序遍历。</p>
<ol>
<li>从任意一个节点A开始，遍历它的全部的邻接点B,C</li>
<li>然后再以它其中一个邻接点B为起点，遍历B的所有的邻接点D，F。</li>
<li>然后再以它另外一个邻接点C为起点，遍历C的所有的邻接点G，H。</li>
<li>然后再以它其中一个邻接点D为起点，遍历D的所有的邻接点…。</li>
<li>以此类推….</li>
</ol>
<p>伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;queue：结果集，queue队列</span><br><span class="line">&#x2F;&#x2F;nodeA：开始节点</span><br><span class="line">public void bfsSearch(List&lt;Node&gt; queue ,Node StrartNode)&#123;</span><br><span class="line">    &#x2F;&#x2F;先选择一个出发点，加入队列。</span><br><span class="line">    queue.add(StrartNode);</span><br><span class="line">    int size &#x3D; queue.getSize();</span><br><span class="line">    for(int index&#x3D;0;index&lt;size;index++)&#123;</span><br><span class="line">        &#x2F;&#x2F;BFS的重点在于队列，它的思路就是沿着queue的添加顺序，依次遍历他们的邻接点。</span><br><span class="line">        for(Node node : queue.get(index).getNeighbor())&#123;</span><br><span class="line">            &#x2F;&#x2F;没被搜索过，那么加入结果集</span><br><span class="line">            if(!queue.contain(node))&#123;</span><br><span class="line">                queue.add(node);</span><br><span class="line">                size &#x3D; queue.getSize();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void main()&#123;</span><br><span class="line">    &#x2F;&#x2F;定义一个结果集，queue队列</span><br><span class="line">    List&lt;Node&gt; queue &#x3D; new LinkedList&lt;Node&gt;();</span><br><span class="line">    &#x2F;&#x2F;先选择一个节点作为开始节点。</span><br><span class="line">    Node startNode&#x3D;nodeA;</span><br><span class="line">    bfsSearch(queue,startNode);</span><br><span class="line">    while(queue.size()不等于节点总数)&#123;</span><br><span class="line">        &#x2F;&#x2F;说明可能因为边有向的问题，有些节点没有被遍历到</span><br><span class="line">        &#x2F;&#x2F;此时需要在剩下的节点中另找一个出发点（假设为B）</span><br><span class="line">        startNode &#x3D; nodeB;&#x2F;&#x2F;省略找出B的过程</span><br><span class="line">        bfsSearch(queue,startNode);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>BFS比较适合判断二分图，以及用于实现寻找最小生成树（MST），如在BFS基础上的Kruskal算法。还有寻找最短路径问题（如Dijkstra算法）。</p>
<p><img src="https://cuijiahua.com/wp-content/uploads/2018/01/alogrithm_10_2.gif" alt="image"></p>
<h2 id="1-1-无向图的广度优先遍历"><a href="#1-1-无向图的广度优先遍历" class="headerlink" title="1.1 无向图的广度优先遍历"></a>1.1 无向图的广度优先遍历</h2><p>我们先给出一个图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-251c89eb3165548739c5acd6ea271c41554.png" alt=""></p>
<ol>
<li>先找到A，这是第一层。</li>
<li>再找到A的邻接点，遍历到B，C，D，F。</li>
<li>再找到B，C，D，F的邻接点，遍历到G，E，H</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-3b6c768580717218780d806bc60e913008b.png" alt=""></p>
<h2 id="1-2-有向图的广度优先遍历"><a href="#1-2-有向图的广度优先遍历" class="headerlink" title="1.2 有向图的广度优先遍历"></a>1.2 有向图的广度优先遍历</h2><p><img src="https://oscimg.oschina.net/oscnet/up-aa815c87267ef276969876712cfccf33128.png" alt=""></p>
<p>思路和与无向图类似，只不过需要考虑边的走向问题。</p>
<ol>
<li>先找到A，这是第一层。</li>
<li>再找到A的邻接点，遍历到B，C，F。</li>
<li>再找到B，C，F的邻接点，遍历到D，H</li>
<li>再找到D，H的邻接点，遍历到E，G</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-684db1b8e0400316ab9d8a86a457489f9fa.png" alt=""></p>
<h1 id="2-深度优先搜索法"><a href="#2-深度优先搜索法" class="headerlink" title="2. 深度优先搜索法"></a>2. 深度优先搜索法</h1><p>深度优先搜索，也叫做深度优先遍历，其主要思想是回溯法，它的核心是使用递归。</p>
<p>例如这张图，从1开始到2，之后到5，5不能再走了，退回2，到6，退回2退回1，到3，以此类推；</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-45757424adba38157c8d3c14ffb0dd6f61a.png" alt=""></p>
<p>伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;stack：定义的结果集stack栈</span><br><span class="line">&#x2F;&#x2F;currentNode：本次递归搜索的当前node</span><br><span class="line">public void dfsSearch(Stack&lt;Node&gt; stack,Node currentNode)&#123;</span><br><span class="line">    if(currentNode没有邻接点 &amp;&amp; !stack.contain(currentNode))&#123;</span><br><span class="line">        &#x2F;&#x2F;压入结果栈</span><br><span class="line">        stack.push(currentNode);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;node有邻接点，那么遍历邻接点，依次深搜</span><br><span class="line">    for(Node node : currentNode.getNeighbor())&#123;</span><br><span class="line">        if(node.isVisited() || stack.contain(currentNode))&#123;</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line">        node.setVisited(true);</span><br><span class="line">        dfsSearch(stack,node);</span><br><span class="line">        node.setVisited(false);</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;currentNode的邻接点都已经遍历过了，现在逻辑回溯回currentNode</span><br><span class="line">    &#x2F;&#x2F;那么需要将currentNode压入结果栈</span><br><span class="line">    stack.push(currentNode);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void main()&#123;</span><br><span class="line">    &#x2F;&#x2F;定义一个结果集</span><br><span class="line">    Stack&lt;Node&gt; stack &#x3D; new Stack&lt;Node&gt;();</span><br><span class="line">    &#x2F;&#x2F;先选择一个节点作为开始节点。</span><br><span class="line">    Node startNode&#x3D;nodeA;</span><br><span class="line">    dfsSearch(stack,startNode);</span><br><span class="line">    while(queue.size()不等于节点总数)&#123;</span><br><span class="line">        &#x2F;&#x2F;说明可能因为边有向的问题，有些节点没有被遍历到</span><br><span class="line">        &#x2F;&#x2F;此时需要在剩下的节点中另找一个出发点（假设为B）</span><br><span class="line">        startNode &#x3D; nodeB;&#x2F;&#x2F;省略找出B的过程</span><br><span class="line">        dfsSearch(stack,startNode);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><img src="https://cuijiahua.com/wp-content/uploads/2018/01/alogrithm_10_3.gif" alt="image"></p>
<h2 id="2-1-无向图的深度优先遍历"><a href="#2-1-无向图的深度优先遍历" class="headerlink" title="2.1 无向图的深度优先遍历"></a>2.1 无向图的深度优先遍历</h2><p>我们先给出一个图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-74f1f6bfb457012ec8d3b5e0dd1cd05fcc1.png" alt=""></p>
<p>对上无向图进行深度优先遍历，从A开始：</p>
<p><strong>第1步</strong>：访问A。</p>
<p><strong>第2步</strong>：访问B(A的邻接点)。 在第1步访问A之后，接下来应该访问的是A的邻接点，即”B,D,F”中的一个。但在本文的实现中，顶点ABCDEFGH是按照顺序存储，B在”D和F”的前面，因此，先访问B。</p>
<p><strong>第3步</strong>：访问G(B的邻接点)。 和B相连只有”G”(A已经访问过了)  </p>
<p><strong>第4步</strong>：访问E(G的邻接点)。 在第3步访问了B的邻接点G之后，接下来应该访问G的邻接点，即”E和H”中一个(B已经被访问过，就不算在内)。而由于E在H之前，先访问E。</p>
<p><strong>第5步</strong>：访问C(E的邻接点)。 和E相连只有”C”(G已经访问过了)。</p>
<p><strong>第6步</strong>：访问D(C的邻接点)。 </p>
<p><strong>第7步</strong>：访问H。因为D没有未被访问的邻接点；因此，一直回溯到访问G的另一个邻接点H。</p>
<p><strong>第8步</strong>：访问(H的邻接点)F。</p>
<p>因此访问顺序是：<strong>A -&gt; B -&gt; G -&gt; E -&gt; C -&gt; D -&gt; H</strong> <strong>-&gt;</strong> <strong>F</strong></p>
<h2 id="2-2-有向图的深度优先遍历"><a href="#2-2-有向图的深度优先遍历" class="headerlink" title="2.2 有向图的深度优先遍历"></a>2.2 有向图的深度优先遍历</h2><p><img src="https://oscimg.oschina.net/oscnet/up-c270810594e5678e4b97eedac94bd900bbf.png" alt=""></p>
<p>对上有向图进行深度优先遍历，从A开始：</p>
<p><strong>第1步</strong>：访问A。</p>
<p><strong>第2步</strong>：访问(A的出度对应的字母)B。 在第1步访问A之后，接下来应该访问的是A的出度对应字母，即”B,C,F”中的一个。但在本文的实现中，顶点ABCDEFGH是按照顺序存储，B在”C和F”的前面，因此，先访问B。</p>
<p><strong>第3步</strong>：访问(B的出度对应的字母)F。 B的出度对应字母只有F。 </p>
<p><strong>第4步</strong>：访问H(F的出度对应的字母)。 F的出度对应字母只有H。 </p>
<p><strong>第5步</strong>：访问(H的出度对应的字母)G。</p>
<p><strong>第6步</strong>：访问(G的出度对应字母)E。 在第5步访问G之后，接下来应该访问的是G的出度对应字母，即”B,C,E”中的一个。但在本文的实现中，顶点B已经访问了，由于C在E前面，所以先访问C。</p>
<p><strong>第7步</strong>：访问(C的出度对应的字母)D。</p>
<p><strong>第8步</strong>：访问(C的出度对应字母)D。 在第7步访问C之后，接下来应该访问的是C的出度对应字母，即”B,D”中的一个。但在本文的实现中，顶点B已经访问了，所以访问D。</p>
<p><strong>第9步</strong>：访问E。D无出度，所以一直回溯到G对应的另一个出度E。</p>
<p>因此访问顺序是：<strong>A -&gt; B -&gt; F -&gt; H -&gt; G -&gt; C -&gt; D</strong> <strong>-&gt; E</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/" itemprop="url">【InnoDB详解二】MySQL文件系统和InnoDB存储结构</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-08T21:47:43+08:00">
                2020-09-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/08/【InnoDB详解二】MySQL文件系统和InnoDB存储结构/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  10.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  38
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-MySQL文件系统"><a href="#1-MySQL文件系统" class="headerlink" title="1 MySQL文件系统"></a>1 MySQL文件系统</h1><p>本章节将分析构成MySQL数据库和InnoDB存储引擎表的各种类型文件。这些文件有以下这些。</p>
<ol>
<li>参数文件∶告诉MySQL实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数，这些参数定义了某种内存结构的大小等设置，还会介绍各种参数的类型。</li>
<li>日志文件∶用来记录MySQL实例对某种条件做出响应时写人的文件，如错误日志文件、二进制日志文件、慢查询日志文件、查询日志文件等。</li>
<li>socket文件∶当用UNIX域套接字方式进行连接时需要的文件。</li>
<li>pid文件∶MySQL实例的进程 ID文件。</li>
<li>MySQL表结构文件∶用来存放 MySQL表结构定义文件。</li>
<li>存储引擎文件∶因为MySQL表存储引擎的关系，每个存储引擎都会有自己的文件来保存各种数据。这些存储引擎真正存储了记录和索引等数据。本章主要介绍与 InnoDB有关的存储引擎文件。</li>
</ol>
<h2 id="1-1-参数文件"><a href="#1-1-参数文件" class="headerlink" title="1.1 参数文件"></a>1.1 参数文件</h2><p>当 MySQL实例启动时，数据库会先去读取一个配置参数文件，用来寻找数据库的各种文件所在位置以及指定某些初始化参数，这些参数通常定义了某种内存结构有多大等。</p>
<p>在默认情况下，MySQL实例会按照一定的顺序在指定的位置进行读取，用户只需通过命令<code>mysql--help | grep my.cnf</code>来寻找即可。</p>
<p>MySQL数据库参数文件的作用和Oracle数据库的参数文件极其类似，不同的是，Oracle实例在启动时若找不到参数文件，是不能进行装载（mount）操作的。MySQL稍微有所不同，MySQL实例可以不需要参数文件，这时所有的参数值取决于编译MySQL时指定的默认值和源代码中指定参数的默认值。</p>
<p>MySQL数据库的参数文件是以文本方式进行存储的。用户可以直接通过一些常用的文本编辑软件（如vi和emacs）进行参数的修改。</p>
<p>MySQL数据库参数是一个键/值（key/value）对。如innodb_buffer_pool_size=1G。</p>
<p>可以通过命令 SHOW VARIABLES查看数据库中的所有参数，也可以通过LIKE来过滤参数名。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-829069acf66ead1907d807695b02b7bc6cd.png" alt=""></p>
<h2 id="1-1-参数的类型"><a href="#1-1-参数的类型" class="headerlink" title="1.1 参数的类型"></a>1.1 参数的类型</h2><p>MySQL数据库中的参数可以分为两类∶</p>
<ol>
<li>动态（dynamic）参数</li>
<li>静态（static）参数</li>
</ol>
<p>动态参数意味着可以在MySQL实例运行中进行更改，静态参数说明在整个实例生命周期内都不得进行更改，就好像是只读（read only）的。可以通过SET命令对动态的参数值进行修改，SET 的语法如下∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b80574245a07a91e0ffdcac095ec1c0f029.png" alt=""></p>
<p>这里可以看到global和session关键字，它们表明该参数的修改是基于当前会话还是整个实例的生命周期。</p>
<p>有些动态参数只能在会话中进行修改，如autocommit;</p>
<p>而有些参数修改完后，在整个实例生命周期中都会生效，如binlog_cache_size;</p>
<p>而有些参数既可以在会话中又可以在整个实例的生命周期内生效，如 read_buffer_size。</p>
<p>举例如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4dae9240c84d8f5ccdb2a89b83c8d3c2c35.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-be3d687886cb98ef05ae7ba432b35e1ae1e.png" alt=""></p>
<p>上述示例中将当前会话的参数read_buffer_size从2MB调整为了512KB，而用户可以看到全局的read_buffer_size的值仍然是2MB，也就是说如果有另一个会话登录到MySQL实例，它的read_buffer_size的值是2MB，而不是512KB。这里使用了set global | session来改变动态变量的值。用户同样可以直接使用SET@@global | @@session来更改，如下所示∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9eb8d6ca15b99a9b523638d9573f069bdbe.png" alt=""></p>
<p>这次把read_buffer_size全局值更改为IMB，而当前会话的read bufer_size的值还是512KB。</p>
<p><strong>这里需要注意的是，对变量的全局值进行了修改，仅在这次的实例生命周期内都有效，但MySQL实例本身并不会对参数文件中的该值进行修改</strong>。也就是说，在下次启动时MySQL实例还是会读取参数文件。若想在数据库实例下一次启动时该参数还是保留为当前修改的值，那么用户必须去修改参数文件。</p>
<h2 id="1-2-日志文件"><a href="#1-2-日志文件" class="headerlink" title="1.2 日志文件"></a>1.2 日志文件</h2><p>日志文件相关介绍详见本站文章《MySQL日志体系详解》</p>
<h2 id="1-3-socket文件"><a href="#1-3-socket文件" class="headerlink" title="1.3 socket文件"></a>1.3 socket文件</h2><p>之前的文章中我们提到过，在UNIX系统下本地连接MySQL可以采用UNIX域套接字方式，这种方式需要一个套接字（socket）文件。套接字文件可由参数socket控制。一般在/tmp 目录下，名为mysql.sock∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-27971b64ed5d9b0d3d21735b54082076be9.png" alt=""></p>
<h2 id="1-4-pid文件"><a href="#1-4-pid文件" class="headerlink" title="1.4 pid文件"></a>1.4 pid文件</h2><p>当MySQL实例启动时，会将自己的进程ID写入一个文件中——该文件即为pid文件。该文件可由参数pid_file控制，默认位于数据库目录下，文件名为主机名.pid∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5d5410fd7723a267507026c3c8aea14ad95.png" alt=""></p>
<h2 id="1-5-表结构定义文件"><a href="#1-5-表结构定义文件" class="headerlink" title="1.5 表结构定义文件"></a>1.5 表结构定义文件</h2><p>MySQL数据的存储是根据表进行的，但因为MySQL插件式存储引擎的体系结构的关系，所以MySQL要在存储引擎之上将表信息记录下来，于是，MySQL为每个表都定义与之对应的文件。不论表采用何种存储引擎，MySQL都有一个以frm为后缀名的文件，这个文件记录了该表的表结构定义。</p>
<p>frm还用来存放视图的定义，如用户创建了一个va视图，那么对应地会产生一个v_a.frm文件，用来记录视图的定义，该文件是文本文件，可以直接使用cat命令进行查看∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-da9b95f3bb49699a68f530e23797414618a.png" alt=""></p>
<h2 id="1-6-InnoDB存储引擎文件"><a href="#1-6-InnoDB存储引擎文件" class="headerlink" title="1.6 InnoDB存储引擎文件"></a>1.6 InnoDB存储引擎文件</h2><p>之前介绍的文件都是MySQL数据库本身的文件，和存储引擎无关。除了这些文件外，每个表存储引擎还有其自己独有的文件。本节将具体介绍与InnoDB存储引擎密切相关的文件，这些文件包括重做日志文件、表空间文件。</p>
<h3 id="1-6-1-表空间文件"><a href="#1-6-1-表空间文件" class="headerlink" title="1.6.1 表空间文件"></a>1.6.1 表空间文件</h3><p>InnoDB采用将存储的数据按表空间（tablespace）进行存放的设计。在默认配置下会有一个初始大小为10MB，名为ibdata1的文件。该文件就是默认的表空间文件（tablespace file），又称作<strong>共享表空间</strong>，用户可以通过参数innodb_data_file_path对其进行设置，格式如下∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7a23c3bfaca6805e33740c49fa5ab0eb7dc.png" alt=""></p>
<p>用户可以通过多个文件组成一个表空间，同时制定文件的属性，如∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e51162c902e23c04cbcf254b852dda4502f.png" alt=""></p>
<p>这里将/db/ibdata1和/dr2/db/ibdata2两个文件用来组成表空间。若这两个文件位于不同的磁盘上，磁盘的负载可能被平均，因此可以提高数据库的整体性能。同时，两个文件的文件名后都跟了属性，表示文件idbdata1的大小为2000MB，文件ibdata2的大小为2000MB，如果用完了这2000MB，该文件可以自动增长（autoextend）。</p>
<p>设置<code>innodb_data_file_path</code>参数后，所有基于InnoDB存储引擎的表的数据都会记录到该<strong>共享表空间</strong>中。若设置了参数<code>innodb_file_per_table</code>，则用户可以将每个基于InnoDB存储引擎的表产生一个独立表空间。独立表空间的命名规则为∶表名.ibd。通过这样的方式，用户不用将所有数据都存放于共享表空间中。</p>
<p>下面这台MySQL数据库服务器设置了<code>innodb_file_per_table</code>，故可以观察到∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a9dd36b64935cb056ec5b1b365e10efb40d.png" alt=""></p>
<p>表Profile、t1和t2都是基于InnoDB存储的表，由于设置参数<code>innodb_file_per_table=ON</code>，因此产生了单独的.ibd独立表空间文件。</p>
<p>直到这里，我们知道了表空间有两种：</p>
<ol>
<li>共享表文件：<code>innodb_data_file_path</code>参数指向的ibdata1这种文件。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-7c5ac8a6a59f66a5069f82358a7d6cc7a8d.png" alt=""></li>
</ul>
</li>
<li>单独表文件：由于设置参数<code>innodb_file_per_table=ON</code>，因此产生了单独的.ibd独立表空间文件。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-f47d86f905134c1cff8100e6e9ff99140e9.png" alt=""></li>
</ul>
</li>
</ol>
<blockquote>
<p>需要注意的是，这些单独的表空间文件（tableName.ibd）仅存储该表的数据、索引和插入缓冲Bitmap等信息，其余信息，如回滚（undo）信息，插入缓冲索引页、系统事务信息，二次写缓冲（Double write buffer）等信息，还是存放在共享表空间（ibdata1文件）中。</p>
</blockquote>
<p>下图显示了InnoDB存储引擎对于文件的存储方式</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f63c067633b130643ee0baf138d33fc5376.png" alt=""></p>
<h3 id="1-6-2-redo-log文件"><a href="#1-6-2-redo-log文件" class="headerlink" title="1.6.2 redo log文件"></a>1.6.2 redo log文件</h3><p>在默认情况下，在InnoDB存储引擎的数据目录下会有两个名为ib_logfile0和ib_logfile1的文件。在MySQL官方手册中将其称为InnoDB存储引擎的日志文件，不过更准确的定义应该是重做日志文件（redo log file）。为什么强调是重做日志文件呢?因为重做日志文件对于InnoDB存储引擎至关重要，它们记录了对于InnoDB存储引擎的事务日志。</p>
<p>当实例或介质失败（media failure）时，重做日志文件就能派上用场。例如，数据库由于所在主机掉电导致实例失败，InnoDB存储引擎会使用重做日志恢复到掉电前的时刻，以此来保证数据的完整性。</p>
<p>每个InoDB存储引擎至少有1个重做日志文件组（group），每个文件组下至少有2个重做日志文件，如默认的ib_logfile0和ib_logfile1。为了得到更高的可靠性，用户可以设置多个的镜像日志组（mirored log groups），将不同的文件组放在不同的磁盘上，以此提高重做日志的高可用性。在日志组中每个重做日志文件的大小一致，并以循环写入的方式运行。</p>
<p>InnoDB存储引擎先写重做日志文件1，当达到文件的最后时会切换至重做日志文件2，再当重做日志文件2也被写满时，会再切换到重做日志文件1中。</p>
<p>redo log文件详情，可见本站文章《【InnoDB详解四】redo log和undo log》</p>
<h1 id="2-InnoDB存储结构"><a href="#2-InnoDB存储结构" class="headerlink" title="2 InnoDB存储结构"></a>2 InnoDB存储结构</h1><p>我们接下来将从InnoDB存储引擎表的逻辑存储及实现开始进行介绍，然后将重点分析表的物理存储特征，即数据在表中是如何组织和存放的。简单来说，表就是关于特定实体的数据集合，这也是关系型数据库模型的核心。</p>
<p>在InnoDB存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表（index organized table）。在InnoDB存储引擎表中，每张表都有个主键（Primary Key），如果在创建表时没有显式地定义主键，则InnoDB存储引擎会按如下方式选择或创建主键∶</p>
<ol>
<li>首先判断表中是否有非空的唯一索引（Unique NOTNULL），如果有，则该列即为主键。</li>
<li>如果不符合上述条件，InnoDB存储引擎自动创建一个6字节大小的指针。当表中有多个非空唯一索引时，InnoDB存储引擎将选择建表时第一个定义的非空唯一索引为主键。这里需要非常注意的是，<strong>主键的选择根据的是定义索引的顺序，而不是建表时列的顺序</strong>。</li>
</ol>
<h2 id="2-1-InnoDB逻辑存储结构"><a href="#2-1-InnoDB逻辑存储结构" class="headerlink" title="2.1 InnoDB逻辑存储结构"></a>2.1 InnoDB逻辑存储结构</h2><p>从 InnoDB存储引擎的<strong>逻辑</strong>存储结构看，所有数据都被<strong>逻辑地</strong>存放在一个空间中，称之为表空间（tablespace）。表空间又由段（segment）、区（extent）、页（page）组成。页在一些文档中有时也称为块（block），InnoDB存储引擎的逻辑存储结构大致如图4-1所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-dde687244bd19181c20420210e6075394e6.png" alt=""></p>
<p>表空间可以看做是InnoDB存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。前文我们已经介绍了表空间，并且知道了表空间分为共享表空间和独立表空间（若有），这里就不再赘述了。</p>
<h3 id="2-1-1-段"><a href="#2-1-1-段" class="headerlink" title="2.1.1 段"></a>2.1.1 段</h3><p>图4-1中显示了表空间是由各个段组成的，常见的段有<strong>数据段、索引段、回滚段</strong>等。</p>
<p>因为前面已经介绍过了InnoDB存储引擎表是索引组织的（index organized），因此数据即索引，索引即数据。那么数据段即为B+树的叶子节点（图4-1的Leafnode segment），索引段即为B+树的非索引节点（图4-1的Non-leaf node segment）。</p>
<p>回滚段较为特殊，将会在后面的章节进行单独的介绍。</p>
<p>在InnoDB存储引擎中，对段的管理都是由引擎自身所完成，DBA不能也没有必要对其进行控制。这和Oracle数据库中的自动段空间管理（ASSM）类似，从一定程度上简化了DBA 对于段的管理。</p>
<h3 id="2-1-2-区"><a href="#2-1-2-区" class="headerlink" title="2.1.2 区"></a>2.1.2 区</h3><p>区是由连续页组成的空间，在任何情况下每个区的大小都为1MB。为了保证区中页的连续性，InnoDB存储引擎一次从磁盘申请4～5个区。在默认情况下，InnoDB存储引擎页的大小为16KB，即一个区中一共有64个连续的页。</p>
<p>InnoDB1.0.x版本开始引入压缩页，即每个页的大小可以通过参数KEY_BLOCK_SIZE设置为2K、4K、8K，因此每个区对应页的数量就应该为512、256、128。</p>
<p>InnoDB 1.2.x版本新增了参数 innodb_page_size，通过该参数可以将默认页的大小设置为4K、8K，但是页中的数据库不是压缩。这时区中页的数量同样也为256、128。总之，不论页的大小怎么变化，区的大小总是为1M。</p>
<p>但是，这里还有这样一个问题∶在用户启用了参数innodb_file_per_talbe后，创建的表默认大小是96KB。区中是64个连续的页，创建的表的大小至少是1MB才对啊，这是什么原因呢?</p>
<p>其实这是因为在每个段开始时，<strong>先用32个页大小的碎片页（fragment page）来存放数据，在使用完这些页之后才是64个连续页的申请</strong>。这样做的目的是，对于一些小表，或者是undo这类的段，可以在开始时申请较少的空间，节省磁盘容量的开销。</p>
<h3 id="2-1-3-页"><a href="#2-1-3-页" class="headerlink" title="2.1.3 页"></a>2.1.3 页</h3><p>同大多数数据库一样，InnoDB有页（Page）的概念（也可以称为块），页是InnoDB磁盘管理的最小单位。在InnoDB存储引擎中，默认每个页的大小为16KB。而从InnoDB 1.2.x版本开始，可以通过参数innodb_page_size将页的大小设置为4K、8K、16K。</p>
<p>若设置完成，则所有表中页的大小都为innodb_page_size，不可以对其再次进行修改。除非通过mysqldump导入和导出操作来产生新的库。</p>
<p>页是InnoDB磁盘管理的最小单位：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4b9e083e4419ed6d4a329215524a2d2a4b7.png" alt=""></p>
<blockquote>
<p>在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，InnoDB存储引擎一个页的大小是16K。</p>
</blockquote>
<h4 id="2-1-3-1-页的类型"><a href="#2-1-3-1-页的类型" class="headerlink" title="2.1.3.1 页的类型"></a>2.1.3.1 页的类型</h4><p>在InnoDB存储引擎中，常见的页类型有∶</p>
<ol>
<li>数据页（B-tree Node）</li>
<li>undo页（undo Log Page）</li>
<li>系统页（System Page）</li>
<li>事务数据页（Transaction system Page）</li>
<li>插入缓冲bitmap页（Insert Buffer Bitmap）</li>
<li>插入缓冲空闲列表页（Insert Buffer Free List）</li>
<li>未压缩的二进制大对象页（Uncompressed BLOB Page）</li>
<li>压缩的二进制大对象页（compressed BLOB Page）</li>
</ol>
<p>在页的File Header结构中，FIL_PAGE_TYPE字段被用来区分数据页的类型（后文会介绍），他们的值如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-96b64aa4d0334ea009a815bc45dd48924ab.png" alt=""></p>
<h3 id="2-1-4-行"><a href="#2-1-4-行" class="headerlink" title="2.1.4 行"></a>2.1.4 行</h3><p>InnoDB存储引擎是面向列的（row-oriented），也就说数据是按行进行存放的。每个页存放的行记录也是有硬性定义的，最多允许存放16KB/2-200行的记录，即7992行记录。</p>
<blockquote>
<p>这里提到了row-oriented的数据库，也就是说，存在有colum-riented的数据库。MySQL infobright存储引擎就是按列来存放数据的，这对于数据仓库下的分析类 SQL语句的执行及数据压缩非常有帮助。类似的数据库还有Sybase IQ、Google Big Table。面向列的数据库是当前数据库发展的一个方向，但这超出了本书涵盖的内容，有兴趣的读者可以在网上寻找相关资料。</p>
</blockquote>
<h2 id="2-2-InnoDB存储格式"><a href="#2-2-InnoDB存储格式" class="headerlink" title="2.2 InnoDB存储格式"></a>2.2 InnoDB存储格式</h2><h3 id="2-2-1-InnoDB行记录格式"><a href="#2-2-1-InnoDB行记录格式" class="headerlink" title="2.2.1 InnoDB行记录格式"></a>2.2.1 InnoDB行记录格式</h3><p>InnoDB存储引擎和大多数数据库一样（如 Oracle和Microsof SQL Server数据库），记录是以行的形式存储的。这意味着页中保存着表中一行行的数据。在InmoDB1.0x版本之前，InnoDB存储引擎提供了Compact和Redundant两种格式来存放行记录数据，这也是目前使用最多的一种格式。</p>
<p>Redundant格式是为兼容之前版本而保留的，如果阅读过InnoDB的源代码，用户会发现源代码中是用PHYSICALRECORD（NEW STYLE）和PHYSICALRECORD（OLD STYLE）来区分两种格式的。</p>
<p>在MySQL5.1版本中，默认设置为Compact行格式。用户可以通过命令SHOW TABLE STATUS LIKE’table_name’来查看当前表使用的行格式，其中row_format 属性表示当前所使用的行记录结构类型。如∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-52ac4e4b7bd5e8d753a861b5a795d430c68.png" alt=""></p>
<p>可以看到，这里的mytest表是Compact的行格式，mytest2表是Redundant的行格式。</p>
<h4 id="2-2-1-1-Compact类型格式"><a href="#2-2-1-1-Compact类型格式" class="headerlink" title="2.2.1.1 Compact类型格式"></a>2.2.1.1 Compact类型格式</h4><p>Compact行记录是在MySQL5.0中引入的，其设计目标是高效地存储数据。简单来说，一个页中存放的行数据越多，其性能就越高。下图显示了Compact行记录的存储方式∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9f530fbc68f17136efaced7cf23194a2e62.png" alt=""></p>
<ol>
<li>变长字段长度列表<ul>
<li>这部分用来记录该行中每个varchar字段的长度（注意，只记录varchar字段的长度，单位是字节），假设数据行中会有n个varchar列，所以该部分也会对应存储n个长度值。</li>
<li><strong>每个varchar列的长度一般用一个字节（对应字段真正长度 &lt; 128字节），最多只能用两个字节（16 bit）（对应字段真正长度 &gt;= 128字节）表示</strong>，所以在MySQL数据库中varchar类型的最大长度限制为65535字节（2的16次方）。</li>
<li>不过这里就有问题了，如果a列的长度占用1个字节，b列的长度占用两个字节，那解析的时候如何知道这三个字节的分界线呢？InnoDB规定如果某个字节最高位为0，那么这个字节就是独立的字节；如果某个字节最高位为1，那么就和它后面的字节共同表示一个长度（第二个字节可以用所有位表示长度）。<strong>也正是因为字节首位另有用处，所以一个字节最多表示长度为小于128</strong>。</li>
<li>所以如果a，b两列长度紧密排列，如<code>01111111 10000000 10000000</code>，那就可以知道分界线是<code>01111111 | 10000000 10000000</code>。需要注意的是，MySQL采取 Little Endian 的计数方式，低位在前，高位在后，所以129用两个字节表示就是 <code>10000001 10000000</code>。</li>
<li>变长字段长度列表中每个长度值的排序，和行中varchar列的顺序是相反的，也就是长度值在变长字段长度列表中是倒序存放</li>
</ul>
</li>
</ol>
<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 假如有三个字段 id,name,desc,age。其中name,desc是变长类型（Varchar）</span><br><span class="line">|id|name|desc|age|</span><br><span class="line">|1|wang|shuaige|18|</span><br><span class="line">|2|li|meinv|20|</span><br><span class="line">	</span><br><span class="line">则磁盘里的存储为：</span><br><span class="line">0x07 0x04 null值列表 数据头 1 wang shuaige 18 0x05 0x02 null值列表 数据头 2 li meinv 20</span><br><span class="line"># 其中0x04表示name长度为4 ,0x07表示desc的长度为7，以此类推。</span><br></pre></td></tr></table></figure></code></pre><ol start="2">
<li><p>NULL标志位</p>
<ul>
<li>该部分用来标记该行中哪些列的值是NULL值。</li>
<li>它是一个bitmap，一般占用1个字节（8 bit），它的每一位位指示了该行数据中对应的列是否是NULL值，有则用1表示。</li>
<li>比如NULL标志位如果为0x06，二进制是00000110，很显然第2位和第3位的值是1，那么就表示该行的第二列和第三列当前值为NULL。</li>
<li>NULL标志位一般是占用1个字节，但如果列的数量大于8个，那么会多扩充一个字节，直到能涵盖所有的列。</li>
</ul>
</li>
<li><p>记录头信息（record header）</p>
<ul>
<li>固定占用5字节（40位），每位的含义见下图：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-516d623552830ed65906b93d067e5754855.png" alt=""></li>
<li>值得注意的是RecordHeader的最后两个字节，这16 bit是next_recorder，代表下一个记录的偏移量，假设该值为0x2c，那么它表示当前记录的位置加上偏移量0x2c就是下条记录的起始位置。所以InnoDB存储引擎在页内部是通过一种链表的结构来串连各个行记录的。</li>
</ul>
</li>
<li><p>列数据</p>
<ul>
<li>最后的部分就是实际存储每个列的数据。需要特别注意的是，NULL不占该部分任何空间，即NULL除了占有NULL标志位，实际存储不占有任何空间。</li>
<li>另外有一点需要注意的是，每行数据除了用户定义的列外，还有两个隐藏列，事务ID列和回滚指针列，分别为6字节和7字节的大小，这两个部分与InnoDB实现MVCC有关，版本控制、事务回滚等内容，这里不详述。若InnoDB表没有定义主键，每行还会增加一个6字节的rowid列。</li>
</ul>
</li>
</ol>
<p>我们来用一个实际的例子分析Compact行记录格式吧：</p>
<p>我们先定义一个表mytest，其中t1，t2，t4是变长的varchar类型，t3是固定长度的char类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;mytest&#96; (</span><br><span class="line">&#96;t1&#96; varchar(10) DEFAULT NULL,</span><br><span class="line">&#96;t2&#96; varchar(10) DEFAULT NULL,</span><br><span class="line">&#96;t3&#96; char(10) DEFAULT NULL,</span><br><span class="line">&#96;t4&#96; varchar(10) DEFAULT NULL</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latin1 ROW_FORMAT&#x3D;COMPACT</span><br></pre></td></tr></table></figure>

<p>我们插入如下记录（其中–表示NULL）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from mytest;</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| t1 | t2 | t3 |  t4 |</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| a  | bb | bb | ccc |</span><br><span class="line">| d  | ee | ee | fff |</span><br><span class="line">| d  | -- | -- | fff |</span><br><span class="line">+----+----+----+-----+</span><br></pre></td></tr></table></figure>

<p>然后将打开表空间文件mytest.ibd（这里启用了innodb_file_per_table，若没有启用该选项，打开默认的共享表空间文件 ibdata1）。</p>
<p>在Windows操作系统下，可以选择通过程序UltraEdit打开该二进制文件。在Linux 环境下，使用命令<code>hexdump-C-v mytest.ibd&gt;mytest.txt</code>。这里将结果重定向到了文件mytes.txt，打开 mytest.txt文件，找到如下内容∶</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0000c070 73 75 70 72 65 6d 75 6d 03 02 01 00 00 00 10 00|supremum……</span><br><span class="line">0000c080 2c 00 00 00 2b 68 00 00 00 00 00 06 05 80 00 00|，……+h……</span><br><span class="line">0000c090 00 32 01 10 61 62 62 62 62 20 20 20 20 20 20 20|.2..abbbb</span><br><span class="line">0000c0a0 20 63 63 63 03 02 01 00 00 00 18 00 2b 00 00 00|ccc……+……</span><br><span class="line">0000c0b0 2b 68 01 00 00 00 00 06 06 80 00 00 00 32 01 10|+h……2..</span><br><span class="line">0000c0c0 64 65 65 65 65 20 20 20 20 20 20 20 20 66 66 66|deeeefff</span><br><span class="line">0000c0d0 03 01 06 00 00 20 ff 98 00 00 00 2b 68 02 00 00|……+h……</span><br><span class="line">0000c0e0 00 00 06 07 80 00 00 00 32 01 10 64 66 66 66 00|……2..dfff.</span><br></pre></td></tr></table></figure>

<p>第一行记录（a,bb,bb,ccc）从0000c078开始，我们整理一下，下面都是16进制数，如03就是0x03：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">03 02 01&#x2F;*变长字段长度列表，分别记录t1，t2，t4的长度，逆序*&#x2F;</span><br><span class="line">00&#x2F;*NULL标志位，第一行没有NULL值*&#x2F;</span><br><span class="line">00 00 10 00 2c&#x2F;*记录头信息，固定5字节长度*&#x2F;</span><br><span class="line">00 00 00 2b 68 00&#x2F;*RowID我们建的表没有主键，因此会有RowID*&#x2F;</span><br><span class="line">00 00 00 00 06 05&#x2F;*TransactionID*&#x2F;</span><br><span class="line">80 00 00 00 32 01 10&#x2F;*Roll Pointer*&#x2F;</span><br><span class="line">61&#x2F;*t1数据&#39;a&#39;*&#x2F;</span><br><span class="line">62 62&#x2F;*t2&#39;bb&#39;*&#x2F;</span><br><span class="line">62 62 20 20 20 20 20 20 20 20&#x2F;*t3数据&#39;bb&#39;，因为t3列是固定长度的char类型，所以可以看到，未占用的地方，char用0x20（空格）补全*&#x2F;</span><br><span class="line">63 63 63&#x2F;*t4数据&#39;ccc&#39;*&#x2F;</span><br></pre></td></tr></table></figure>

<p>我们再来看有NULL值的第三行记录（d,NULL,NULL,fff），</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">03 01&#x2F;*变长字段长度列表，逆序*&#x2F;</span><br><span class="line">06&#x2F;*NULL标志位，06的二进制是00000110，很显然第2位和第3位的值是1，所以t2和t3是NULL*&#x2F;</span><br><span class="line">00 00 20 ff 98&#x2F;*记录头信息*&#x2F;</span><br><span class="line">00 00 00 2b 68 02&#x2F;*RowID*&#x2F;</span><br><span class="line">00 00 00 00 06 07&#x2F;*TransactionID*&#x2F;</span><br><span class="line">80 00 00 00 32 01 10&#x2F;*Roll Pointer*&#x2F;</span><br><span class="line">64&#x2F;*t1数据&#39;d&#39;*&#x2F;</span><br><span class="line">66 66 66&#x2F;*t4数据&#39;fff&#39;*&#x2F;</span><br></pre></td></tr></table></figure>

<p>可以发现不管是char还是varchar，NULL都不占用任何空间。</p>
<h4 id="2-2-1-2-Redundant类型格式"><a href="#2-2-1-2-Redundant类型格式" class="headerlink" title="2.2.1.2 Redundant类型格式"></a>2.2.1.2 Redundant类型格式</h4><p>Redundant是MySQL 5.0版本之前InnoDB的行记录存储方式，MySQL 5.0支持Redundant是为了兼容之前版本的页格式。Redundant行记录采用如下所示的方式存储。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8eac0bc22f7a4dbd8dca7ef7491b534d190.png" alt=""></p>
<ol>
<li>字段长度偏移列表<ul>
<li>不同于Compact行记录格式，Redundant行记录格式的首部是一个字段长度<strong>偏移</strong>列表，同样是按照列的顺序<strong>逆序</strong>放置的。</li>
<li>注意该列表记录的是每个列长度的偏移量，而不是长度值本身，比如某个字段长度偏移列表经整理后为<code>23 20 16 14 13 0c 06</code>，因为是逆序排布，所以我们先翻为正序<code>06，0c，13，14，16，20，23</code>，那么这表示：第一列的长度是6，第二列的长度是6（6+6=0x0C），第三列的长度为7（6+6+7=0x13），第四列的长度是1（6+6+7+1=0x14），第五列的长度是2（6+6+7+1+2=0x16），第六列的长度是10（6+6+7+1+2+10=0x20），第七列的长度是3（6+6+7+1+2+10+3=0x23）。</li>
<li>同样的，长度列表中每个列的长度的偏移值一般用一个字节，最多用两个字节来存储。不过不同于compact格式，compact格式允许a列使用1个字节，b列使用两个字节，但是Redundant的话，<strong>要么所有列的偏移值都占用1字节，要么都占用2字节</strong>。</li>
<li>到底每个偏移使用1字节还是2字节，是根据整行记录的长度决定，如果<strong>整行长度</strong>小于 128，则用1字节存储，否则，用2字节。<ul>
<li>如果是1字节存储的情况，那么每个字节最高的那个bit用来标记对应字段值是否为 NULL，如果为NULL，则最高位为1，否则为0。剩下的7位用来存储长度偏移量，所以最多是127。</li>
<li>对于两字节存储，首个字节的最高位还是用来标记对应字段值是否为NULL。最高的第二位则用来标记这条记录是否在同一页，如果在则为0，如果不在则为1，这其实就涉及到了后面要说的溢出页。剩下的连同第二个字节完整8bit在内的14bit表示长度，所以最多是16383</li>
</ul>
</li>
</ul>
</li>
<li>记录头信息（record header）<ul>
<li>不同于Compact行记录格式，Redundant行记录格式的记录头占用6字节（48 位），每位的含义见下表</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-c935a4248a4f545e00e0a7d004ac8d1d5ed.png" alt=""></li>
<li>从中可以发现，n_fields值代表一行中列的数量，占用10位。同时这也很好地解释了为什么MySQL数据库一行支持最多的列为1023。因为2的10次方为1024</li>
<li>另一个需要注意的值为1byte_offs_flag，该值定义了字段长度偏移列表占用的是1字节还是2字节。</li>
</ul>
</li>
<li>列数据<ul>
<li>最后的部分就是实际存储每个列的数据。需要特别注意的是，varchar类型的NULL不占该部分任何空间，char类型的NULL占用固定空间。</li>
<li>另外有一点需要注意的是，每行数据除了用户定义的列外，还有两个隐藏列，事务ID列和回滚指针列，分别为6字节和7字节的大小，这两个部分与InnoDB实现MVCC有关，版本控制、事务回滚等内容，这里不详述。若InnoDB表没有定义主键，每行还会增加一个6字节的rowid列。</li>
</ul>
</li>
</ol>
<p>好，我们也来看下Redundant格式的例子，还是那张表和那些记录：</p>
<p>其中t1，t2，t4是变长的varchar类型，t3是固定长度的char类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from mytest;</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| t1 | t2 | t3 |  t4 |</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| a  | bb | bb | ccc |</span><br><span class="line">| d  | ee | ee | fff |</span><br><span class="line">| d  | -- | -- | fff |</span><br><span class="line">+----+----+----+-----+</span><br></pre></td></tr></table></figure>

<p>我们直接来看有NULL的第三行（下面都是16进制表示）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a1 9e 94 14 13 0c 06&#x2F;*长度偏移列表，逆序*&#x2F;</span><br><span class="line">00 00 20 0f 00 74&#x2F;*记录头信息，固定6个字节*&#x2F;</span><br><span class="line">00 00 00 2b 68 0d&#x2F;*RowID*&#x2F;</span><br><span class="line">00 00 00 00 06 53&#x2F;*TransactionID*&#x2F;</span><br><span class="line">80 00 00 00 32 01 10&#x2F;*Roll Point*&#x2F;</span><br><span class="line">64&#x2F;*t1数据&#39;d&#39;*&#x2F;</span><br><span class="line">00 00 00 00 00 00 00 00 00 00&#x2F;*t3数据NULL*&#x2F;</span><br><span class="line">66 66 66&#x2F;*t4数据&#39;fff&#39;*&#x2F;</span><br></pre></td></tr></table></figure>

<p>可以看到：</p>
<ol>
<li>来看长度偏移列表，<code>21 9e 94 14 13 0c 06</code>翻转为正序是<code>06 0c 13 14 94 9e 21</code>，我们前面说过，每个字节中首位用来表示字段是否为NULL，后面7位才表示偏移值，这里需要将每个字节分成两部分（1bit | 7bit），并转化为十进制是<code>0|6 0|12 0|19 0|20 1|20 1|30 0|33</code></li>
<li>该行中varchar类型的t2列，因为值为NULL，故而在Redundant格式中没有占用任何空间，所以我们看不到t2，t2位NULL的信息其实旨在长度偏移列表中体现了，也就是上文说到的<code>1|20</code>这个字节。但同样为NULL值的t3数据，除了在偏移列表中体现外，却真的占用了10个字节，可见，<strong>在Redundant格式中，varchar类型的NULL不占用空间，char类型的NULL固定占用10字节空间</strong>。</li>
<li>记录头信息中应该注意48位中22～32位（n_fields），为0000000111，表示表共有7个列（包含了隐藏的3列），接下去的33位（1byte_offs_flag）为1，代表偏移列表中每个偏移量占用一个字节。</li>
</ol>
<blockquote>
<p>当前表mytest的字符集为Latin1，每个字符最多只占用1个字节。若这里将表mytest的字符集转换为utf8，则第三列char固定长度类型就不再是只占用10个字节了，而是10×3=30个字节，Redundant行格式下char固定字符类型将会占据可能存放的最大值字节数。</p>
</blockquote>
<h4 id="2-2-1-3-行溢出数据"><a href="#2-2-1-3-行溢出数据" class="headerlink" title="2.2.1.3 行溢出数据"></a>2.2.1.3 行溢出数据</h4><p>InnoDB存储引擎可以将一条记录中的某些数据存储在数据页之外，而不是存放在行记录所在的当前页中，这类数据就叫行溢出数据。什么情况下会出现行溢出数据呢？答案是一个页（16K）放不下的时候，一些数据必然要溢出。</p>
<p>于是我们可以想到BLOB、LOB这类的大对象列类型的存储，InnoDB应该会把数据存放在数据页面之外。但是，这个理解有点偏差，其实BLOB、LOB这类的大对象并不一定非要溢出，而常见的varchar类型也并不一定不会溢出。</p>
<p>那么什么时候会产生行溢出数据呢？这个阈值是多少呢？</p>
<p>前文我们说过，<strong>数据页会被InnoDB以B+树的形式给整理起来</strong>，这就要求了：<strong>一个数据页中应该至少能存两条行记录</strong>（如果一个页只能存一行，那B+树就没有意义了，数据结构就成链表了）</p>
<p>基于这个要求，我们知道一个页为16KB，即16384字节，那么扣除掉页中如header，tail，dictionary等固定字段外，再对半分，则可以得出一行记录不发生行溢出的最大长度上限：<strong>8098字节</strong>。</p>
<p>那么，如果一行记录长度超过了8098字节，InnoDB又会如何存储呢？</p>
<p>在一般情况下，InnoDB存储引擎的数据都是存放在页类型为B-tree node（也就是数据页）的页中。但是当发生行溢出时，数据溢出部分存放在页类型为Uncompress BLOB的页中：</p>
<p>假设我们创建一个列a长度为65532的表t，并插入一条数据</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3164ed940f9d57e06258f6a7c4f77c38145.png" alt=""></p>
<p>通过工具可以观察到表空间中有一个数据页节点B-tree Node，另外有4个未压缩的二进制大对象页Uncompressed BLOB Page，在这些页中才真正存放了65532字节的数据。既然实际存放的数据都在BLOB页中，那数据页中又存放了些什么内容呢?同样通过之前的 hexdump来读取表空间文件，从数据页c000开始查看∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d9bed37dbfbb79292b1af2f46fa441bc2f6.png" alt=""></p>
<p>可以看到，从0x0000c093到0x000c392数据页面其实只保存了VARCHAR（65532）的<strong>前768字节的前缀</strong>（prefix）数据（这里都是a）。然后之后是行溢出页指针（20字节），指向行溢出页，也就是前面用户看到的Uncompressed BLOB Page。因此，对于行溢出数据，其存放采用下图的方式。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-098ad59f67bb0fd52b16d1d84dcfb0809dc.png" alt=""></p>
<h4 id="2-2-1-4-Compressed-Dynamic类型格式"><a href="#2-2-1-4-Compressed-Dynamic类型格式" class="headerlink" title="2.2.1.4 Compressed/Dynamic类型格式"></a>2.2.1.4 Compressed/Dynamic类型格式</h4><p>InnoDB Plugin引入了新的文件格式（file format，可以理解为新的页格式），对于以前支持的Compact和Redundant格式将其称为Antelope文件格式，新的文件格式称为Barracuda。</p>
<p>Barracuda文件格式下拥有两种新的行记录格式Compressed和Dynamic两种。新的两种格式对于存放BLOB的数据采用了完全的行溢出的方式，在数据页中只存放20个字节的指针，实际的数据都存放在BLOB Page中，而之前的Compact和Redundant两种格式会存放768个前缀字节。</p>
<p>下图是Barracuda文件格式的溢出行：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7647fad5539a242a7fdf54a7f1b531af2f2.png" alt=""></p>
<p>Compressed行记录格式的另一个功能就是，存储在其中的行数据会以<strong>zlib的算法</strong>进行压缩，因此对于BLOB、TEXT、VARCHAR这类大长度类型的数据能够进行非常有效的存储。</p>
<h4 id="2-2-1-5-CHAR类型字段的存储"><a href="#2-2-1-5-CHAR类型字段的存储" class="headerlink" title="2.2.1.5 CHAR类型字段的存储"></a>2.2.1.5 CHAR类型字段的存储</h4><p>通常理解 VARCHAR是存储变长长度的字符类型，CHAR是存储固定长度的字符类型。而在前面的小节中，用户已经了解行结构的内部的存储，并可以发现每行的变长字段长度的列表都没有存储CHAR类型的长度。</p>
<p>然而，值得注意的是之前给出的两个例子中的字符集都是单字节的latin1格式。从MySQL4.1版本开始，CHAR（N）中的N指的是字符的个数，而不是之前版本的字节长度。也就说在不同的字符集下，CHAR类型列内部存储的可能不是定长的数据。</p>
<p>例如，对于UTF-8下CHAR（10）类型的列，其最小可以存储10字节的字符（都是拉丁字母），而最大可以存储30字节的字符（10个字符都是汉字）。因此，对于多字节字符编码的CHAR数据类型的存储，<strong>InnoDB存储引擎在内部将其视为VARCHAR变长字符类型</strong>。这也就意味着在变长长度列表中会记录CHAR 数据类型的长度。</p>
<p><strong>因此可以认为在多字节字符集的情况下，CHAR和VARCHAR的实际行存储基本是没有区别的</strong>。</p>
<h3 id="2-2-2-数据页的存储格式"><a href="#2-2-2-数据页的存储格式" class="headerlink" title="2.2.2 数据页的存储格式"></a>2.2.2 数据页的存储格式</h3><p>我们已经知道页是InnoDB存储引擎管理数据库的最小磁盘单位。类型为B-tree Node的页存放的即是表中行的实际数据了。页的结构如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c831f98dd011f807e7100bca08e9c01a305.png" alt=""></p>
<h4 id="2-2-2-1-File-Header"><a href="#2-2-2-1-File-Header" class="headerlink" title="2.2.2.1 File Header"></a>2.2.2.1 File Header</h4><p><strong>File Header</strong> 字段用于记录 Page 的头信息。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b844420e80d52e767ccff0e0a6ef7ebbe0f.png" alt=""></p>
<p>其中比较重要的是 FIL_PAGE_PREV 和 FIL_PAGE_NEXT 字段，它们分别是B+树叶子节点双向链表的前驱和后驱，通过这两个字段，我们可以找到该页的上一页和下一页，实际上所有页通过两个字段可以形成一条双向链表。</p>
<h4 id="2-2-2-2-Page-Header"><a href="#2-2-2-2-Page-Header" class="headerlink" title="2.2.2.2 Page Header"></a>2.2.2.2 Page Header</h4><p><strong>Page Header</strong> 字段用于记录页的状态信息。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-8cfcdf1e3da990c1f0e4164467457bd9da5.png" alt=""></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-e398686bcf847a72564b954a18f4acd5608.png" alt=""></li>
</ul>
<h4 id="2-2-2-3-Infimum-和-Supremum"><a href="#2-2-2-3-Infimum-和-Supremum" class="headerlink" title="2.2.2.3 Infimum 和 Supremum"></a>2.2.2.3 Infimum 和 Supremum</h4><p><strong>Infimum 和 Supremum</strong> 是两个虚拟的行记录，用来确定真实的行记录的边界。</p>
<p>Infimum（下确界）记录比该页中任何主键值都要小的值，Supremum （上确界）记录比该页中任何主键值都要大的值，这个虚拟记录分别构成了页中记录的边界。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f5a741681f7bda057e0743abc1605d5ee30.png" alt=""></p>
<h4 id="2-2-2-4-User-Records"><a href="#2-2-2-4-User-Records" class="headerlink" title="2.2.2.4 User Records"></a>2.2.2.4 User Records</h4><p><strong>User Records</strong> 中存放的是<strong>实际的数据行记录</strong>，行记录的格式，我们在上文中已经介绍过了，有compact/redundant等格式。</p>
<p>我们再来复习一下，不论是什么格式，行记录都有一个记录头信息部分（record header）</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9f530fbc68f17136efaced7cf23194a2e62.png" alt=""></p>
<p>记录头中各个字段如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-516d623552830ed65906b93d067e5754855.png" alt=""></p>
<p>值得注意的是Record Header的最后两个字节，这16 bit是next_recorder，代表下一个记录的偏移量，假设该值为0x2c，那么它表示当前记录的位置加上偏移量0x2c就是下条记录的起始位置。<strong>所以行记录在User Records中是通过一种链表的结构来串连起来的</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-11431516dbe26aa0eb8739349aa5f33dec4.png" alt=""></p>
<p>排序顺序一般是根据primary key升序放置。</p>
<h4 id="2-2-2-5-Free-Space"><a href="#2-2-2-5-Free-Space" class="headerlink" title="2.2.2.5 Free Space"></a>2.2.2.5 Free Space</h4><p><strong>Free Space</strong> 中存放的是空闲空间，当一条行记录被删除后，它的空间会被加入到空闲列表中。</p>
<h4 id="2-2-2-6-Page-Directory"><a href="#2-2-2-6-Page-Directory" class="headerlink" title="2.2.2.6 Page Directory"></a>2.2.2.6 Page Directory</h4><p><strong>Page Directory</strong> 页目录，记录着与二叉查找相关的信息。</p>
<p>前面我们介绍了User Records是有序的，那么维护User Records的记录有序是为了做什么呢？没错，还是为了性能。行记录之间以链表串联，链表的查询性能是O(n)，这显然是不够理想的，为了提升性能，Page Directory应运而生。</p>
<p>我们可以打个比方，我们在看书的时候，如果要找到某一节，而这一节我们并不知道在哪一页，我们是不是就要从前往后，一节一节地去寻找我们需要的内容的页码呢？</p>
<p>答案是否定的，因为在书的前面，存在目录，它会告诉你这一节在哪一页，例如，第一节在第1页、第二节在第13页。在数据库的页中，实际上也使用了这种目录的结构，这就是页目录。</p>
<p>那么引入页目录之后，我们所理解的页结构，就变成了这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fd4a712ed26ec34941484e0d70c742fe25d.png" alt=""></p>
<p>页目录是一个稀疏目录，它有限的目录项会离散的指向整个User Records列表的各个锚点，比如上图的目录项1指向id=1，目录项2指向id=3。</p>
<p>如此一来，假设我们要寻找id=5的数据，就不需要遍历一遍整个User Records列表了，只要通过页目录（假设是<code>[1,3,7,10,...]</code>）定位到id=9是在7-10之间，那么就可以直接跳到id=7，之后再后溯两个行，就能定位到id=9。</p>
<h4 id="2-2-2-7-File-Trailer"><a href="#2-2-2-7-File-Trailer" class="headerlink" title="2.2.2.7 File Trailer"></a>2.2.2.7 File Trailer</h4><p><strong>File Trailer</strong> 存储用于检测数据完整性的校验和等数据。</p>
<p>为了检测页是否已经完整地写人磁盘（如可能发生的写人过程中磁盘损坏、机器关机等），InnoDB存储引擎的页中设置了File Trailer部分。</p>
<p>File Trailer只有一个FIL_PAGE_END_LSN部分，占用8字节。前4字节代表该页的checksum值，最后4字节和File Header中的FIL_PAGELSN相同。将这两个值与File Header中的FIL_PAGE_SPACE_OR_CHKSUM和FIL_PAGELSN值进行比较，看是否一致（checksum的比较需要通过InnoDB的checksum函数来进行比较，不是简单的等值比较），以此来保证页的完整性（not corrupted）。</p>
<h3 id="2-2-3-索引和页的联系"><a href="#2-2-3-索引和页的联系" class="headerlink" title="2.2.3 索引和页的联系"></a>2.2.3 索引和页的联系</h3><p>我们已经知道InnoDB的索引采用B+树来实现，B+树中的叶子节点和非叶子节点，其实它们也都是页，只不过叶子结点的页（我们称为索引页）只存放键值和指向非叶子节点（我们称为数据页）的偏移量：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d56be3c294a4f3897605f7817f60a37d900.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-03e38ce46f0b73c2a688a808d2f8424ea26.png" alt=""></p>
<p>如上图可以看到，page 4/5/6都是叶子节点的数据页，他们存放实际的行记录。除此以外还有存放索引键值和指针的页，比如图中page number=3的页，该页存放键值和指向数据页的指针。这只是一个实例，实际上我们完整的B+树应该长这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3351c306d86845e280dadb774a97ded1de8.png" alt=""></p>
<p>这些页都是被各种指针给<strong>逻辑地</strong>组成了一个B+树，<strong>他们实际上都离散的存放在磁盘上</strong>，也就是我们之前说的独立表空间文件中（tableName.idb文件中）。</p>
<p>当我们需要对某个页做读写的时候，再将某个页从磁盘载入缓冲池，缓冲池大小有限，所以会通过LRU List做淘汰机制，将不常用的页从缓冲池删除。</p>
<p>那么，假设现在要查找一条数据，该怎么查，比如：</p>
<p>select * from t1 where id=6;</p>
<p>在这里我们假设t1表选择自增id来做主键，这时要通过B+树来查找：</p>
<ol>
<li><p>首先查找根页。一般来说，每个表的根页位置在表空间（t1.ibd）中都是不变的，在这里也就是page number=3的页，将page number=3的页载入缓冲池。</p>
<blockquote>
<p>其实一般来说，根页只要进入缓冲池，就基本上都是热点数据，很难被LRU算法淘汰掉，因为基本上所有走t1表索引的查询，都要访问t1表的根页，即便是走非聚簇索引，也会定位到聚簇索引上来。</p>
</blockquote>
</li>
<li><p>找到根页后通过二分查找法，定位到id=6的页应该在指针P5指向的页中。</p>
<blockquote>
<p><strong>需要牢记的是，B+树索引本身并不能找到具体的一条记录，能找到只是该记录所在的页</strong>。</p>
</blockquote>
</li>
<li><p>如果P5指向的页（page number=5）不在缓冲池中，那么把页载入到缓冲池。</p>
</li>
<li><p>发现page number=5的页是非叶子节点了，然后通过Page Directory再进行二叉查找，即可查找到id=6的对应记录了。</p>
<blockquote>
<p>Page Directory二叉查找的时间复杂度很低，同时在缓冲池（也就是内存）中的查找很快，因此通常忽略这部分查找所用的时间。</p>
</blockquote>
</li>
</ol>
<p>再看一张类似的图</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d468bc450e8055f95de04f818faaf23432d.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/31/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%80%E3%80%91%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%92%8C%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/31/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%80%E3%80%91%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%92%8C%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7/" itemprop="url">【InnoDB详解一】体系架构和关键特性</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-31T21:43:59+08:00">
                2020-08-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/31/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%80%E3%80%91%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%92%8C%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/08/31/【InnoDB详解一】体系架构和关键特性/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  14.7k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  53
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>InnoDB存储引擎最早由Innobase Oy公司°开发，被包括在MySQL数据库所有的二进制发行版本中，从MySQL5.5版本开始是默认的表存储引擎（之前的版本IlmoDB 存储引擎仅在Windows下为默认的存储引擎）。该存储引擎是第一个完整支持ACID事务的MySQL存储引擎（BDB是第一个支持事务的MySQL存储引擎，现在已经停止开发），其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读，同时被设计用来最有效地利用以及使用内存和 CPU。</p>
<p>InnoBD通过有如下机制来优化性能：</p>
<ol>
<li><strong>缓冲池</strong>：使用缓冲池来优化读写性能，写的时候，将页从磁盘刷入缓冲池，再做修改，读的时候，读缓冲池的页，脏数据通过异步适时的刷回磁盘。</li>
<li><strong>后台线程</strong>：使用后台线程来减少对用户线程的阻塞。</li>
<li><strong>插入缓冲</strong>：使用插入缓冲（Insert Buffer）机制来优化非唯一性索引的写性能，使其在缓冲池技术的基础上再少一次磁盘IO。</li>
<li><strong>两次写</strong>：使用两次写（doublewrite）机制来确保数据页从内存刷新到硬盘时如果中途宕机，则仍可以通过数据页副本来恢复该数据页，保证数据页向磁盘flush过程的可靠性。</li>
<li><strong>自适应哈希索引</strong>：通过自适应哈希索引（Adaptive Hash Index，AHI）机制来对缓冲中高频热点的B+树索引页自动建立哈希索引，以替代<strong>等值查询</strong>，优化查询性能。</li>
<li><strong>异步IO</strong>：通过异步IO（Asynchronous IO，AIO）机制，将read ahead方式的读取，磁盘的写入，数据的恢复等诸多操作通过异步来处理，提高处理效率。</li>
<li><strong>刷新邻接页</strong>：通过刷新邻接页（Flush Neighbor Page）机制，可以在flush数据页进入缓存的时候，顺序将该页所在区（extent）的所有脏页一起flush，将本该多次IO的操作合并一次完成，该机制在传统机械硬盘场景中性能提升明显。</li>
</ol>
<p>InnoDB存储引擎已经被许多大型网站使用，如用户熟知的Google、Yahoo!、Facebook、YouTube、Flickr，在网络游戏领域有《魔兽世界》、《Second Life》、《神兵玄奇》等。</p>
<h1 id="1-InnoDB的体系架构"><a href="#1-InnoDB的体系架构" class="headerlink" title="1 InnoDB的体系架构"></a>1 InnoDB的体系架构</h1><p>下图2简单显示了InoDB的存储引擎的体系架构，从图可见，InnoDB存储引擎有多个内存块，可以认为这些内存块组成了一个大的内存池，负责如下工作∶</p>
<ul>
<li>维护所有进程/线程需要访问的多个内部数据结构。</li>
<li>缓存磁盘上的数据，方便快速地读取，同时在对磁盘文件的数据修改之前在这里缓存。</li>
<li>重做日志（redo log）缓冲。</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-94e3f8ff530d171d53e872caa4a3c2ca5b4.png" alt=""></p>
<p>后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据。此外将已修改的数据文件刷新到磁盘文件，同时保证在数据库发生异常的情况下 InnoDB 能恢复到正常运行状态。</p>
<h2 id="1-1-InnoDB的后台线程"><a href="#1-1-InnoDB的后台线程" class="headerlink" title="1.1 InnoDB的后台线程"></a>1.1 InnoDB的后台线程</h2><p>InnoDB存储引擎是多线程的模型，因此其后台有多个不同的后台线程，负责处理不同的任务</p>
<h3 id="1-1-1-Master-Thread"><a href="#1-1-1-Master-Thread" class="headerlink" title="1.1.1 Master Thread"></a>1.1.1 Master Thread</h3><p>Master Thread是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲（INSERTBUFER）、UNDO页的回收等。</p>
<p>Master Thread具有最高的线程优先级别。其内部由多个循环（loop）组成∶<strong>主循环（loop）</strong>、<strong>后台循环（backgroup loop）</strong>、<strong>刷新循环（flush loop）</strong>、<strong>暂停循环（suspend loop）</strong>。Master Thread会根据数据库运行的状态在loop、background loop、flush loop和suspend loop之间切换。</p>
<p><strong>主循环（loop）</strong></p>
<p>Loop被称为主循环，因为大多数的操作是在这个循环中，其中有两大部分的操作———每秒钟的操作和每10秒的操作。伪代码如下∶</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">void master thread()&#123;</span><br><span class="line">	loop:</span><br><span class="line">	for(int i&#x3D; 0;i&lt;10;i++)&#123;</span><br><span class="line">		do thing once per second;</span><br><span class="line">		sleep 1 second if necessary;</span><br><span class="line">	&#125;</span><br><span class="line">	do things once per ten seconds</span><br><span class="line">	goto loop;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，loop循环通过 thread sleep来实现，这意味着所谓的每秒一次或每10秒一次的操作是不精确的。在负载很大的情况下可能会有延迟（delay），只能说大概在这个频率下。当然，InnoDB源代码中还通过了其他的方法来尽量保证这个频率。</p>
<p><strong>每秒一次</strong>的操作包括：（有概念尚不清晰的，后文会做详解）</p>
<ol>
<li>日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）;<ul>
<li>即使某个事务还没有提交，InoDB存储引擎仍然每秒会将重做日志缓冲中的内容刷新到重做日志文件。这一点是必须要知道的，因为这可以很好地解释为什么再大的事务提交（commit）的时间也是很短的。</li>
</ul>
</li>
<li>合并插入缓冲（可能）;<ul>
<li>合并插入缓冲（Insert Buffr）并不是每秒都会发生的。InnoDB存储引擎会判断当前一秒内发生的IO次数是否小于5次，如果小于5次，InoDB认为当前的IO压力很小，可以执行合并插人缓冲的操作。</li>
</ul>
</li>
<li>至多刷新100个InnoDB的缓冲池中的脏页到磁盘（可能）;<ul>
<li>同样，刷新100个脏页也不是每秒都会发生的。InoDB存储引擎通过判断当前缓冲池中脏页的比例（buf get_modified_ratio pct）是否超过了配置文件中inodbmax_dirtypages pet这个参数（默认为90，代表90%），如果超过了这个阈值，InoDB存储引擎认为需要做磁盘同步的操作，将100个脏页写人磁盘中。</li>
</ul>
</li>
<li>如果当前没有用户活动，则切换到 background loop（可能）。</li>
</ol>
<p><strong>每10秒一次</strong>的操作包括：（有概念尚不清晰的，后文会做详解）</p>
<ol>
<li>刷新100个脏页到磁盘（可能的情况下）;<ul>
<li>在以上的过程中，InnoDB存储引擎会先判断过去10秒之内磁盘的IO操作是否小于200次，如果是，InnoDB存储引擎认为当前有足够的磁盘IO操作能力，因此将100 个脏页刷新到磁盘。</li>
</ul>
</li>
<li>合并至多5个插人缓冲（总是）;<ul>
<li>接着，InnoDB存储引擎会合并插入缓冲。不同于每秒一次操作时可能发生的合并插入缓冲操作，这次的合并插入缓冲操作总会在这个阶段进行。</li>
</ul>
</li>
<li>将日志缓冲刷新到磁盘（总是）;<ul>
<li>之后，InoDB存储引擎会再进行一次将日志缓冲刷新到磁盘的操作。这和每秒一次时发生的操作是一样的。</li>
</ul>
</li>
<li>删除无用的Undo 页（总是）;<ul>
<li>接着InnoDB存储引擎会进行一步执行full purge操作，即删除无用的Undo 页。对表进行update、delete这类操作时，原先的行被标记为删除，但是因为一致性读（consistent read）的关系，需要保留这些行版本的信息。</li>
<li>但是在full purge过程中，InoDB存储引擎会判断当前事务系统中已被删除的行是否可以删除，比如有时候可能还有查询操作需要读取之前版本的undo信息，如果可以删除，InnoDB会立即将其删除。</li>
</ul>
</li>
<li>刷新100个或者10个脏页到磁盘（总是）。<ul>
<li>然后，InnoDB存储引擎会判断缓冲池中脏页的比例（buf get_modified_ratio pct），如果有超过70%的脏页，则刷新100个脏页到磁盘，如果脏页的比例小于70%，则只需刷新10%的脏页到磁盘。</li>
</ul>
</li>
</ol>
<p><strong>后台循环（backgroup loop）</strong></p>
<p>接着来看background loop，若当前没有用户活动（数据库空闲时）或者数据库关闭（shutdown），就会切换到这个循环。background loop 会执行以下操作∶</p>
<ol>
<li>删除无用的 Undo 页（总是）;</li>
<li>合并20个插人缓冲（总是）;</li>
<li>如果当前数据库还是空闲，则跳回到主循环，否则进入flush loop（总是）;</li>
</ol>
<p><strong>刷新循环（flush loop）</strong><br>刷新循环只做一件事，每次刷新一百个页到磁盘，不断循环直到<code>缓冲池中的脏页比例小于等于innodb_max_dirty_pages_pct的值（默认90）</code></p>
<ol>
<li>不断刷新100个页直到符合条件（可能，跳转到flush loop中完成）。</li>
</ol>
<p><strong>暂停循环（suspend_loop）</strong></p>
<p>若flush loop中也没有什么事情可以做了，InnoDB存储引擎会切换到suspend_loop，将Master Thread挂起，等待事件的发生。若用户启用（enable）了InnoDB存储引擎，却没有使用任何InnoDB存储引擎的表，那么Master Thread总是处于挂起的状态。</p>
<blockquote>
<p>上述核心逻辑是MySQL 1.0.x版本之前的逻辑，在1.0.x版本和1.2.x版本中，Master Thread两次引入了更新</p>
</blockquote>
<p><strong>1.0.x版本的改动：</strong></p>
<ol>
<li>磁盘技术的快速发展中，对于缓冲池向磁盘刷新时都做了一定的hard coding，这些限制很大程度上限制了InnoDB存储引擎对磁盘IO的性能，尤其是写入性能。因此提供参数innodb_io_capacity用来表示IO的吞吐量，默认200，对于刷新到磁盘页的数量，会按照innodb_io_capacity的百分比来控制：<ul>
<li>并插入缓冲时，合并插入缓冲的数量为innodb_io_capacity值的5%;</li>
<li>缓冲池刷新脏页时，刷行脏页的数量为innodb_io_capcity;</li>
</ul>
</li>
<li>脏页比例参数innodb_max_dirty_pages_pct为90太大了。新版本将其改为了75。</li>
<li>innodb_adaptive_flushing参数的引入，该值影响每秒刷新脏页的数量。<ul>
<li>原来的刷新规则是∶脏页在缓冲池所占的比例小于innodb_max_dirty pages pect时，不刷新脏页;大于inodb maxdirtypages_pct时，刷新100个脏页。</li>
<li>随着innodb_adaptive flushing参数的引入，InnoDB存储引擎会通过一个名为buf_flush get_desired_fush_rate的函数来判断需要刷新脏页最合适的数量。</li>
<li>粗略地翻阅源代码后发现 buf flush get desired_fush rate通过判断产生重做日志（redo log）的速度来决定最合适的刷新脏页数量。因此，当脏页的比例小于inodb_max_dirtypages_pct时，也会刷新一定量的脏页。</li>
</ul>
</li>
<li>引入参数innodb_purge_batch_size<ul>
<li>之前每次进行 full purge操作时，最多回收20个Undo页</li>
<li>从InnoDB 1.0.x版本开始引人了参数，该参数可以控制每次 full purge回收的Undo页的数量。该参数的默认值为20，并可以动态地对其进行修改</li>
</ul>
</li>
</ol>
<p><strong>1.2.x版本的改动：</strong></p>
<p>对于刷新脏页的操作，从Master Thread 线程分离到一个单独的<strong>Page Cleaner Thread</strong>，从而减轻了Master Thread的工作，同时进一步提高了系统的并发性。</p>
<p>整体伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">void master_thread()&#123;</span><br><span class="line">    goto loop;</span><br><span class="line">loop:</span><br><span class="line">for (int i&#x3D;0;i&lt;10;i++)&#123;</span><br><span class="line">    thread_sleep(1) &#x2F;&#x2F;sleep 1 second--&gt;每秒执行操作(负载在情况下会延迟)</span><br><span class="line">    do log buffer flush to disk  &#x2F;&#x2F;重做日志缓冲刷新到磁盘，即使这个事务没有提交(总是)</span><br><span class="line">    if ( last_ten_second_ios &lt; 5% innodb_io_capacity) &#x2F;&#x2F;如果当前的10次数小于(5% * 200&#x3D;10)(innodb_io_capacity默认值是200)</span><br><span class="line">        do merger 5% innodb_io_capacity insert buffer &#x2F;&#x2F;执行10个合并插入缓冲的操作(5% * 200&#x3D;10)</span><br><span class="line">    if ( buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct ) &#x2F;&#x2F;如果缓冲池中的脏页比例大于innodb_max_dirty_pages_pct(默认是75时)</span><br><span class="line">        do buffer pool plush 100% innodb_io_capacity dirty page &#x2F;&#x2F;刷新200个脏页到磁盘</span><br><span class="line">    else if enable adaptive flush  &#x2F;&#x2F;如果开户了自适应刷新</span><br><span class="line">        do buffer pool flush desired amount dirty page &#x2F;&#x2F;通过判断产生redo log的速度决定最合适的刷新脏页的数量</span><br><span class="line">    if ( no user activity ) &#x2F;&#x2F;如果当前没有用户活动</span><br><span class="line">        goto backgroud loop  &#x2F;&#x2F;跳到后台循环</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;每10秒执行的操作</span><br><span class="line">if ( last_ten_second_ios &lt; innodb_io_capacity)  &#x2F;&#x2F;如果过去10内磁盘IO次数小于设置的innodb_io_capacity的值（默认是200）</span><br><span class="line">    do buffer pool flush 100% innodb_io_capacity dirty page &#x2F;&#x2F;刷新脏页的数量为innodb_io_capacity的值（默认是200）</span><br><span class="line">do merger 5% innodb_io_capacity insert buffer  &#x2F;&#x2F;合并插入缓冲是innodb_io_capacity的5%（10）（总是）</span><br><span class="line">do log buffer flush to disk                    &#x2F;&#x2F;重做日志缓冲刷新到磁盘，即使这个事务没有提交（总是）</span><br><span class="line">do full purge       &#x2F;&#x2F;删除无用的undo页 （总是）</span><br><span class="line">if (buf_get_modified_ratio_pct &gt; 70%)          &#x2F;&#x2F;如果缓冲池中的胜页比例大于70%</span><br><span class="line">    do buffer pool flush 100% innodb_io_capacity dirty page  &#x2F;&#x2F;刷新200个脏页到磁盘</span><br><span class="line">else</span><br><span class="line">    do buffer pool flush 10% innodb_io_capacity dirty page   &#x2F;&#x2F;否则刷新20个脏页到磁盘</span><br><span class="line">goto loop</span><br><span class="line">backgroud loop:   &#x2F;&#x2F;后台循环</span><br><span class="line">do full purge     &#x2F;&#x2F;删除无用的undo页 （总是）</span><br><span class="line">do merger 5% innodb_io_capacity insert buffer  &#x2F;&#x2F;合并插入缓冲是innodb_io_capacity的5%（10）（总是）</span><br><span class="line">if not idle:      &#x2F;&#x2F;如果不空闲，就跳回主循环，如果空闲就跳入flush loop</span><br><span class="line">goto loop:    &#x2F;&#x2F;跳到主循环</span><br><span class="line">else:</span><br><span class="line">    goto flush loop</span><br><span class="line">flush loop:  &#x2F;&#x2F;刷新循环</span><br><span class="line">do buf_get_modified_ratio_pct pool flush 100% innodb_io_capacity dirty page &#x2F;&#x2F;刷新200个脏页到磁盘</span><br><span class="line">if ( buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct ) &#x2F;&#x2F;如果缓冲池中的脏页比例大于innodb_max_dirty_pages_pct的值（默认75%）</span><br><span class="line">    goto flush loop            &#x2F;&#x2F;跳到刷新循环，不断刷新脏页，直到符合条件</span><br><span class="line">    goto suspend loop          &#x2F;&#x2F;完成刷新脏页的任务后，跳入suspend loop</span><br><span class="line">suspend loop:</span><br><span class="line">suspend_thread()               &#x2F;&#x2F;master线程挂起，等待事件发生</span><br><span class="line">waiting event</span><br><span class="line">goto loop;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="1-1-2-IO-Thread"><a href="#1-1-2-IO-Thread" class="headerlink" title="1.1.2 IO Thread"></a>1.1.2 IO Thread</h3><p>在InnoDB存储引擎中大量使用了AIO（Async IO，异步IO）来处理写IO请求，这样可以极大提高数据库的性能。而IO Thread的工作主要是负责这些IO请求的回调（callback）处理。</p>
<p>InnoDB1.0版本之前共有4个IO Thread，分别是write、read、insert buffer和log IO thread。在Linux平台下，IO Thread的数量不能进行调整，但是在Windows平台下可以通过参数innodb file_io_threads来增大IO Thread。</p>
<p>从InnoDB1.0x版本开始，read thread和 write thread分别增大到了4个，并且不再使用innodb_file io threads参数，而是分别使用innodb_read_io threads和inodb_write io threads参数进行设置，如∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b1937bdac20464ad98c59b01feef5112e89.png" alt=""></p>
<p>可以通过命令<code>SHOW ENGINE INNODB STATUS</code>来观察 InnoDB中的IO Thread∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d5e0d14b4fbf29b6bb3bfdcffb517bc851e.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-aef88c1e57e56d4c88299db8c0ecfc9b6e7.png" alt=""></p>
<p>可以看到IO Thread0为insert buffer thread。IO Thread1为log thread。之后就是根据参数innodb_readio threads及innodb_write_io threads来设置的读写线程，并且读线程的 ID总是小于写线程。</p>
<h3 id="1-1-3-purge-Thread"><a href="#1-1-3-purge-Thread" class="headerlink" title="1.1.3 purge Thread"></a>1.1.3 purge Thread</h3><p>事务被提交后，其所使用的undo log可能不再需要，因此需要PurgeThread来回收已经使用并分配的undo页。</p>
<p>在InnoDB 1.1版本之前，purge操作仅在InnoDB存储引擎的Master Thread中完成。而从InoDB 1.1版本开始，purge操作可以独立到单独的线程中进行，以此来减轻Master Thread的工作，从而提高CPU的使用率以及提升存储引擎的性能。</p>
<p>用户可以在 MySQL数据库的配置文件中添加如下命令来启用独立的Purge Thread:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">innodb_purge_threads&#x3D;1</span><br></pre></td></tr></table></figure>

<p>从InnoDB 1.2版本开始，InnoDB 支持多个Purge Thread，这样做的目的是为了进一步加快undo页的回收。同时由于Purge Thread需要离散地读取undo页，这样也能更进一步利用磁盘的随机读取性能。如用户可以设置4个Purge Thread∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0aa50fbe79b5d8c8da349360afdfadba659.png" alt=""></p>
<h3 id="1-1-4-Page-Cleaner-Thread"><a href="#1-1-4-Page-Cleaner-Thread" class="headerlink" title="1.1.4 Page Cleaner Thread"></a>1.1.4 Page Cleaner Thread</h3><p>Page Cleaner Thread是在InnoDB1.2x版本中引人的。其作用是将之前版本中脏页的刷新操作都放入到单独的线程中来完成。而其目的是为了减轻原Master Thread的工作及对于用户查询线程的阻塞，进一步提高InnoDB存储引擎的性能。</p>
<h2 id="1-2-InnoDB的内存"><a href="#1-2-InnoDB的内存" class="headerlink" title="1.2 InnoDB的内存"></a>1.2 InnoDB的内存</h2><h3 id="1-2-1-缓冲池"><a href="#1-2-1-缓冲池" class="headerlink" title="1.2.1 缓冲池"></a>1.2.1 缓冲池</h3><p>InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可将其视为基于磁盘的数据库系统（Disk-base Database）。在数据库系统中，由于CPU 速度与磁盘速度之间的鸿沟，基于磁盘的数据库系统通常使用缓冲池技术来提高数据库的整体性能。</p>
<p>缓冲池简单来说就是一块内存区域，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。在数据库中进行读取页的操作，首先将从磁盘读到的页存放在缓冲池中，这个过程称为将页”FIX”在缓冲池中。下一次再读相同的页时，首先判断该页是否在缓冲池中。若在缓冲池中，称该页在缓冲池中被命中，直接读取该页。否则，读取磁盘上的页。</p>
<p>对于数据库中页的修改操作，则首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上。这里需要注意的是，页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种称为Checkpoint的机制刷新回磁盘。同样，这也是为了提高数据库的整体性能。</p>
<p>对于InnoDB存储引擎而言，其缓冲池的配置通过参数<code>innodb_buffer poolsize</code>来设置。下面显示一台 MySQL数据库服务器，其将InnoDB存储引擎的缓冲池设置为15GB。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ed636b9b36110b3c4837e6bebd140812c1a.png" alt=""></p>
<p>具体来看，缓冲池中缓存的数据页类型有∶索引页、数据页、undo页、插入缓冲（insert buffer）、自适应哈希索引（adaptive hash index）、InnoDB存储的锁信息（lock info）、数据字典信息（data dictionary）等。不能简单地认为，缓冲池只是缓存索引页和数据页，它们只是占缓冲池很大的一部分而已。下图很好地显示了InnoDB存储引擎中内存的结构情况。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e84b63538abdf9181a48c21e0dadb862049.png" alt=""></p>
<p>从InnoDB1.0.x版本开始，允许有多个缓冲池实例。每个页根据哈希值平均分配到不同缓冲池实例中。这样做的好处是减少数据库内部的资源竞争，增加数据库的并发处理能力。实例数量可以通过参数innodb_buffer_pool_instances来进行配置，该值默认为1：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5b6abb0cac04b945e55fff2553713baee85.png" alt=""></p>
<p>从 MySQL5.6版本开始，还可以通过information_schema架构下的表INNODB_BUFFER_POOL_STATS来观察缓冲的状态，如运行下列命令可以看到各个缓冲池的使用状态∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0e383c72335ac6ec4a71641fba4afa6cbfe.png" alt=""></p>
<h3 id="1-2-2-LRU-Free-Flush-List"><a href="#1-2-2-LRU-Free-Flush-List" class="headerlink" title="1.2.2 LRU/Free/Flush List"></a>1.2.2 LRU/Free/Flush List</h3><p>在前一章节中我们知道了缓冲池是一个很大的内存区域，其中存放各种类型的页，一个页的大小默认为16KB，即缓冲池中会存在大量16KB的数据页结构。那么InnoDB存储引擎是怎么对这么大的内存区域进行管理的呢?</p>
<h4 id="1-2-2-1-LRU-List"><a href="#1-2-2-1-LRU-List" class="headerlink" title="1.2.2.1 LRU List"></a>1.2.2.1 LRU List</h4><p>通常来说，数据库中的缓冲池是通过LRU（Latest Recent Used，最近最少使用）算法来进行管理的。即最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。当缓冲池不能存放从磁盘新读取到的页时，将首先释放LRU列表中尾端的页。</p>
<p>在InnoDB存储引擎中，缓冲池中页的大小默认为16KB，同样使用LRU算法对缓冲池进行管理。稍有不同的是InoDB存储引擎对传统的LRU算法做了一些优化。在InoDB的存储引擎中，<strong>LRU列表中还加入了midpoint位置</strong>。在默认配置下，该位置在LRU列表长度的5/8处。midpoint位置可由参数<code>inodb old blocks pct</code>控制，如∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3574d90f2897e73ca8fb3cf70bfbb0ebce6.png" alt=""></p>
<p>从上面的例子可以看到，参数 innodb oldblocks pect默认值为37。表示新读取的页插入到LRU列表尾端的37%的位置（差不多3/8的位置）。</p>
<p>在InnoDB存储引擎中，把midpoint 之后的列表称为old列表，之前的列表称为new列表。可以简单地理解为new 列表中的页都是最为活跃的热点数据。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b345d48fb199199fff62cb81c183638e6ee.png" alt=""></p>
<p>当用户需要访问数据时，InnoDB首先会在InnoDB缓冲池查找数据，如果缓冲池中没有数据时，InnoDB会查询硬盘上的数据，并将缓冲池中生成新的页；如果InnoDB缓冲池已满，InnoDB通过LRU算法清除InnoDB缓存池中个别数据块。</p>
<p>每当有新数据块需要加载到InnoDB缓冲池中时，该数据块应变为‘‘数据页’’被插到midpoint的位置，并声明为old数据页。这个算法在InnoDB存储引擎下称为<strong>midpoin insertion strategy</strong>。</p>
<p>那么old链表中的数据页什么时候能移动到new链表中呢？参数<code>InnoDB_old_blocks_time</code>可以控制这个时间：</p>
<ol>
<li>当InnoDB_old_blocks_time的参数值设置为0时。当old部分的数据页被访问到时，该数据页会被提升到链表的头部，并被标记为new数据页。</li>
<li>当InnoDB_old_blocks_time的参数值大于0时（以1000毫秒或者1秒为例）。old部分数据页插入缓冲池后，1秒之后再次被访问，则该数据页会被提升到链表的头部，并被标记为new数据页。在刚插入到一秒内，即便old部分的数据页被访问，该数据页也不会移动到new链表的头部。</li>
</ol>
<p><strong>那为什么不采用朴素的LRU算法，直接将最近被sql访问的页放入到LRU列表的首部呢?</strong></p>
<p>这是因为若直接将最近被访问到的页放入到LRU的首部，那么某些SQL操作可能会使热点的页被顶到靠后的位置去，从而LRU List的效率。</p>
<p>常见的这类操作为索引或数据的扫描操作。这类操作需要访问表中的许多页，甚至是全部的页，而这些页通常来说又仅在这次查询操作中需要，并不是活跃的热点数据。如果页被放入LRU列表的首部，那么<strong>非常可能将原本在队首的热点数据页顶到队尾，甚至因为内存空间原因从LRU列表中移除，导致在下一次需要读取该页时，InnoDB存储引擎需要再次访问磁盘</strong>。</p>
<h4 id="1-2-2-2-Free-List"><a href="#1-2-2-2-Free-List" class="headerlink" title="1.2.2.2 Free List"></a>1.2.2.2 Free List</h4><p>LRU列表用来管理已经读取的页，但当数据库刚启动时，LRU列表是空的，即没有任何的页。这时页都存放在Free List中。当需要在缓冲池中划分数据页时，首先从Free列表中查找是否有可用的空闲页。</p>
<ul>
<li><p>若有，则用磁盘中读取的数据填充该页，并将该页从Free列表中移动到LRU列表中。</p>
</li>
<li><p>若没有，则根据LRU算法，淘汰LRU列表末尾的页，将该内存空间分配给新的页。</p>
</li>
</ul>
<h4 id="1-2-2-3-Flush-List"><a href="#1-2-2-3-Flush-List" class="headerlink" title="1.2.2.3 Flush List"></a>1.2.2.3 Flush List</h4><p>在LRU列表中的页被修改后，称该页为脏页（dirty page），即缓冲池中的页和磁盘上的页的数据产生了不一致。这时数据库会通过CHECKPOINT机制将脏页刷新回磁盘，而Flush列表中的页即为脏页列表。</p>
<p>需要注意的是，脏页既存在于LRU列表中，也存在于 Flush列表中。LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘，二者互不影响。</p>
<h4 id="1-2-2-4-List状态查看"><a href="#1-2-2-4-List状态查看" class="headerlink" title="1.2.2.4 List状态查看"></a>1.2.2.4 List状态查看</h4><p>可以通过命令SHOW ENGINE INNODB STATUS来观察LRU列表，Free列表和Flush列表的使用情况和运行状态。</p>
<blockquote>
<p>当页从LRU列表的old部分加入到new部分时，称此时发生的操作为page made young，而因为innodb old_blocks time的设置而导致页没有从old部分移动到new部分的操作称为page not made young。</p>
</blockquote>
<p><img src="https://oscimg.oschina.net/oscnet/up-9eef4f0023da725e57ebf19d77ec6bef001.png" alt=""></p>
<p>通过命令SHOW_ENGINE_INNODB_STATUS可以看到∶当前Buffer_pool_size共有327679个页，即<code>327679*16K</code>，总共5GB的缓冲池。</p>
<p>Free buffers表示当前Free列表中页的数量，Database pages表示LRU列表中页的数量。可能的情况是Free buffers与Database pages的数量之和不等于Buffer pool size。正如之前所说的那样，因为缓冲池中的页还可能会被分配给自适应哈希索引、Lock信息、Insrt Buffer等页，而这部分页不需要LRU算法进行维护，因此不存在于LRU列表中。</p>
<p>pages made young 显示了LRU列表中页从old端移动到new端的次数，因为该服务器在运行阶段没有改变inodb old blocks_time的值，因此not young为0。</p>
<p>youngs/s、non-youngs 表示每秒这两类操作的次数。</p>
<p>Modifed db pages24673就显示了Flush List中脏页的数量。</p>
<p>这里还有一个重要的观察变量——Buffer pool hit rate，表示缓冲池的命中率，这个例子中为100%，说明缓冲池运行状态非常良好。通常该值不应该小于95%。若发生Bufer pool hit rate的值小于95%这种情况，用户需要观察是否是由于全表扫描引起的LRU 列表被污染的问题。</p>
<h3 id="1-2-3-重做日志缓冲"><a href="#1-2-3-重做日志缓冲" class="headerlink" title="1.2.3 重做日志缓冲"></a>1.2.3 重做日志缓冲</h3><p><img src="https://oscimg.oschina.net/oscnet/up-e84b63538abdf9181a48c21e0dadb862049.png" alt=""></p>
<p>在看上图，InnoDB存储引擎的内存区域除了有缓冲池外，还有重做日志缓冲（redo log buffer）。InoDB存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定频率将其刷新到重做日志文件。重做日志缓冲一般不需要设置得很大，因为一般情况下每一秒钟会将重做日志缓冲刷新到日志文件，因此用户只需要保证每秒产生的事务量在这个缓冲大小之内即可。该值可由配置参数 innodb_log buffrsize控制，默认为8MB:</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7b1284e9ce4be6a5be54d776fc9850930b1.png" alt=""></p>
<p>在通常情况下，8MB的重做日志缓冲池足以满足绝大部分的应用，因为重做日志在下列三种情况下会将重做日志缓冲中的内容刷新到外部磁盘的重做日志文件中。</p>
<ul>
<li>Master Thread每一秒将重做日志缓冲刷新到重做日志文件;</li>
<li>每个事务提交时会将重做日志缓冲刷新到重做日志文件;</li>
<li>当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲刷新到重做日志文件。</li>
</ul>
<h3 id="1-2-4-额外的内存池"><a href="#1-2-4-额外的内存池" class="headerlink" title="1.2.4 额外的内存池"></a>1.2.4 额外的内存池</h3><p>额外的内存池通常被DBA忽略，他们认为该值并不十分重要，事实恰恰相反，该值同样十分重要。在InnoDB存储引擎中，对内存的管理是通过一种称为内存堆（heap）的方式进行的。在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。</p>
<p>例如，分配了缓冲池（innodb_buffer_pool），但是每个缓冲池中的帧缓冲（fame buffer）还有对应的缓冲控制对象（buffer control block），这些对象记录了一些诸如LRU、锁、等待等信息，而这个对象的内存需要从额外内存池中申请。因此，在申请了很大的InnoDB缓冲池时，也应考虑相应地增加这个值。</p>
<h1 id="2-InnoDB的关键特性"><a href="#2-InnoDB的关键特性" class="headerlink" title="2 InnoDB的关键特性"></a>2 InnoDB的关键特性</h1><p>InnoDB存储引擎的关键特性包括∶</p>
<ul>
<li>Checkpoint技术</li>
<li>插入缓冲（Insert Buffer）</li>
<li>两次写（Double Write）</li>
<li>自适应哈希索引（Adaptive Hash Index）</li>
<li>异步IO（Async IO）</li>
<li>刷新邻接页（Flush Neighbor Page）</li>
</ul>
<p>上述这些特性为InnoDB存储引擎带来更好的性能以及更高的可靠性。</p>
<h2 id="2-1-Checkpoint技术"><a href="#2-1-Checkpoint技术" class="headerlink" title="2.1 Checkpoint技术"></a>2.1 Checkpoint技术</h2><p>前面已经讲到了，缓冲池的设计目的为了协调 CPU速度与磁盘速度的鸿沟。因此页的操作首先都是在缓冲池中完成的。如果一条 DML语句，如 Update或Delete改变了页中的记录，那么此时页是脏的，即缓冲池中的页的版本要比磁盘的新。数据库需要将新版本的页从缓冲池刷新到磁盘。</p>
<p>刷新到磁盘的操作，就是Checkpoint。</p>
<p>倘若每次一个页发生变化，就将新页的版本刷新到磁盘，那么这个开销是非常大的。若热点数据集中在某几个页中，那么数据库的性能将变得非常差。同时，如果在从缓冲池将页的新版本刷新到磁盘时发生了宕机，那么数据就不能恢复了。为了避免发生数据丢失的问题，当前事务数据库系统普遍都采用了Write Ahead Log策略，即当事务提交时，先写重做日志，再修改页。当由于发生宕机而导致数据丢失时，通过重做日志来完成<strong>对未刷新到硬盘的数据的恢复</strong>。这也是事务 ACID中D（Durability持久性）的要求。</p>
<p>既然不能每次一个页发生变化，就将新页的版本刷新到磁盘，那么，什么时候将脏页数据刷新到硬盘是合适的呢？先不谈我们应该以什么频率进行一次Checkpoint，我们先来谈什么时候必须要Checkpoint（否则会导致 缓冲池+重做日志 机制出问题）</p>
<ol>
<li>当缓冲池不够用时：<ul>
<li>当缓冲池不够用时，根据LRU算法会清除最近最少使用的页，如果此页为脏页，那么需要强制执行Checkpoint，将脏页也就是页的新版本刷回磁盘。</li>
</ul>
</li>
<li>重做日志出现不可用/不够用时：<ul>
<li>因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是让其无限增大的，这从成本及管理上都是比较困难的。<strong>重做日志中记录的已经被flush到磁盘中的部分，我们就认为它是可覆盖重用的</strong>。如果重做日志空间中没有可重用的部分，即目前重用日志记录的都是未flush到磁盘的数据，那么必须强制Checkpoint，使得部分重做日志变为可重用。</li>
</ul>
</li>
</ol>
<h3 id="2-1-1-LSN"><a href="#2-1-1-LSN" class="headerlink" title="2.1.1 LSN"></a>2.1.1 LSN</h3><p>对于InnoDB存储引擎而言，是通过LSN（Log Sequence Number）来标记版本的。LSN是一个一直递增的8字节整型数字，<strong>表示事务写入到redo日志的字节总量（注意LSN的含义是日志的字节总量）</strong>。每个页都有LSN字段，重做日志中也有LSN，Checkpoint也有LSN。</p>
<p>在每个数据页头部的LSN字段，记录当前页最后一次数据修改所对应的重做日志的LSN值，用于在recovery时对比重做日志LSN值，以决定是否对该页进行恢复数据。前面说的checkpoint也是有LSN号记录的，checkpoint的LSN表示已刷新到磁盘的最新的数据所对应的重做日志的LSN，LSN号串联起一个事务开始到恢复的过程。</p>
<blockquote>
<p>比如重做日志的文件是600M，LSN的值已经为1G了，也就是LSN=1000000000。因为重做日志是循环使用的，所以我们可以知道LSN=1G=600M+400M，所以重做日志已经重复使用过一整遍后，目前最新的可写入点，在重做日志偏移量400M的位置。</p>
</blockquote>
<blockquote>
<p>我们执行了一个update语句，产生了一个事务t，这次数据的修改，假设产生了512个字节的日志量，那么LSN就会增加到1000000512，而事务t的修改使得A、B、C三个数据页成为了脏页，那么A、B、C三个数据页的LSN值就会更新为1000000512。如果这时，触发了checkpoint，刚刚好将事务t为止的修改刷新到磁盘，那么此时checkpoint LSN也是1000000512。</p>
</blockquote>
<p>可以通过命令SHOW ENGINE INNODB STATUS来观察∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-179216b430c190ac9ad4b5262885db5ef73.png" alt=""></p>
<h3 id="2-1-2-Checkpoint发生的时机"><a href="#2-1-2-Checkpoint发生的时机" class="headerlink" title="2.1.2 Checkpoint发生的时机"></a>2.1.2 Checkpoint发生的时机</h3><p>在InnoDB存储引擎中，Checkpoint发生的时间、条件及脏页的选择等都非常复杂。而Checkpoint所做的事情无外乎是将缓冲池中的脏页刷回到磁盘。不同之处在于<strong>每次刷新多少页到磁盘，每次从哪里取脏页，以及什么时间触发Checkpoint</strong>。</p>
<p>在InnoDB存储引擎内部，有两种Checkpoint，分别为∶</p>
<ol>
<li>Sharp Checkpoint<ul>
<li>Sharp Checkpoint发生在数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式，即参数 innodb_fast_shutdown=1。</li>
</ul>
</li>
<li>Fuzy Checkpoint<ul>
<li>若数据库在运行时也使用Sharp Checkpoint，那么数据库的可用性就会受到很大的影响。故在InnoDB存储引擎内部使用Fuzzy Checkpoint 进行页的刷新，即只刷新一部分脏页，而不是刷新所有的脏页回磁盘。</li>
</ul>
</li>
</ol>
<p>在InnoDB存储引擎中可能发生如下几种情况的Fuzzy Checkpoint:</p>
<ol>
<li>Master Thread Checkpoint</li>
<li>FLUSH_LRU_LIST Checkpoint</li>
<li>Async/Sync Flush Checkpoint</li>
<li>Dirty Page too much Checkpoint</li>
</ol>
<h4 id="2-1-2-1-Master-Thread-Checkpoint"><a href="#2-1-2-1-Master-Thread-Checkpoint" class="headerlink" title="2.1.2.1  Master Thread Checkpoint"></a>2.1.2.1  Master Thread Checkpoint</h4><p>对于Master Thread中发生的Checkpoint，差不多以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘。这个过程是异步的，即此时InnoDB存储引擎可以进行其他的操作，用户查询线程不会阻塞。</p>
<h4 id="2-1-2-2-FLUSH-LRU-LIST-Checkpoint"><a href="#2-1-2-2-FLUSH-LRU-LIST-Checkpoint" class="headerlink" title="2.1.2.2  FLUSH_LRU_LIST Checkpoint"></a>2.1.2.2  FLUSH_LRU_LIST Checkpoint</h4><p>FLUSH_LRU_LIST Checkpoint是因为InoDB存储引擎需要保证LRU列表中需要有差不多100个空闲页可供使用。在InoDB1.1.x版本之前，需要检查LRU列表中是否有足够可用空间的操作发生在用户查询线程中，显然这会阻塞用户的查询操作。</p>
<p>倘若没有100个可用空闲页，那么InoDB存储引擎会将LRU列表尾端的页移除。如果要移除的这些页中有脏页，那么需要进行Checkpoint，而这些页是来自LRU和FLUSH列表的，因此称为FLUSH_LRU_LIST Checkpoint。</p>
<p>而从MySQL5.6版本，也就是InnoDB1.2.x版本开始，这个检查被放在了一个单独的Page Cleaner线程中进行，并且用户可以通过参数innodb_Iru_scan_depth控制LRU列表中可用页的数量，该值默认为1024。</p>
<h4 id="2-1-2-3-Async-Sync-Flush-Checkpoint"><a href="#2-1-2-3-Async-Sync-Flush-Checkpoint" class="headerlink" title="2.1.2.3  Async/Sync Flush Checkpoint"></a>2.1.2.3  Async/Sync Flush Checkpoint</h4><p>Async/Sync Flush Checkpoint指的是重做日志文件不可用的情况，这时需要强制将一些页刷新回磁盘，而此时脏页是从脏页列表中选取的。</p>
<p>若将已经写入到重做日志的LSN记为redo_lsn，将已经刷新回磁盘最新页的LSN记为checkpoint_lsn，则可定义：</p>
<p><code>checkpoint_age = redo_lsn - checkpoint_lsn</code>，表示重做日志中还有多少个字节量的数据没有刷新到磁盘。</p>
<p>再定义以下的变量：</p>
<ol>
<li><code>async_water_mark = 75% * total_redo_log_file_size</code></li>
<li><code>sync_water_mark = 90% * total_redo_log_file_size</code></li>
</ol>
<p>若每个重做日志文件的大小为1GB，并且定义了两个重做日志文件，则重做日志文件的总大小为2GB。那么async_water_mark=1.5GB，sync_water_mark=1.8GB。则：</p>
<ol>
<li>当checkpoint_age&lt;async_water_mark时，不需要刷新任何脏页到磁盘；</li>
<li>当async_water_mark&lt;checkpoint_age&lt;sync_water_mark时触发Async Flush，从Flush列表中刷新足够的脏页回磁盘，使得刷新后满足checkpoint_age&lt;async_water_mark；</li>
<li>当checkpoint_age&gt;sync_water_mark（这种情况一般很少发生，除非设置的重做日志文件太小，并且在进行类似LOAD DATA的BULK INSERT操作），此时触发Sync Flush操作，从Flush列表中刷新足够的脏页回磁盘，使得刷新后满足checkpoint_age&lt;async_water_mark。</li>
</ol>
<p>可见，Async/Sync Flush Checkpoint是为了保证重做日志的循环使用的可用性。在InnoDB 1.2.x版本之前，Async Flush Checkpoint会阻塞发现问题的用户查询线程，而Sync Flush Checkpoint会阻塞所有的用户查询线程，并且等待脏页刷新完成。从InnoDB 1.2.x版本开始——也就是MySQL 5.6版本，这部分的刷新操作同样放入到了单独的Page Cleaner Thread中，故不会阻塞用户查询线程。</p>
<h4 id="2-1-2-4-Dirty-Page-too-much-Checkpoint"><a href="#2-1-2-4-Dirty-Page-too-much-Checkpoint" class="headerlink" title="2.1.2.4  Dirty Page too much Checkpoint"></a>2.1.2.4  Dirty Page too much Checkpoint</h4><p>即脏页的数量太多，导致InnoDB存储引擎强制进行Checkpoint。其目的总的来说还是为了保证缓冲池中有足够可用的页。其可由参数innodb_max_dirty_pages_pct控制：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4e9f8a50c529eeb28cbe8b5eb5bec171543.png" alt=""></p>
<p>innodb_max_dirtypages_pct值为75表示，当缓冲池中脏页的数量占据75%时，强制进行Checkpoint，刷新一部分的脏页到磁盘。在InnoDB 1.0.x版本之前，该参数默认值为90，之后的版本都为75。</p>
<h2 id="2-2-插入缓冲"><a href="#2-2-插入缓冲" class="headerlink" title="2.2 插入缓冲"></a>2.2 插入缓冲</h2><p>插入缓冲本质上是对于为非唯一索引而言的，即对辅助索引的修改操作并非实时更新磁盘中索引的叶子页（索引存于该表的ibd文件中），而是把若干对同一页面的更新缓存起来做，合并为一次性更新操作，减少IO，转随机IO为顺序IO，这样可以避免随机IO带来性能损耗，提高数据库的写性能</p>
<h3 id="2-2-1-Insert-Buffer"><a href="#2-2-1-Insert-Buffer" class="headerlink" title="2.2.1 Insert Buffer"></a>2.2.1 Insert Buffer</h3><p>Insert Buffer可能是InnoDB存储引擎关键特性中最令人激动与兴奋的一个功能。insert buffer是一种特殊的数据结构（B+ tree）并不是缓存的一部分，而是物理页。</p>
<p>在InoDB存储引擎中，主键是行唯一的标识符。通常应用程序中行记录的插人顺序是按照主键递增的顺序进行插入的。因此，插入聚集索引（Primary Key）一般是顺序的，不需要磁盘的随机读取。</p>
<p>但一个表除了聚集索引外，还可能定义辅助索引，我们知道InnoDB中辅助索引是非聚集的。假设我们有一张表t，其中主键是id字段，除此之外还在name字段上面建了一个辅助索引。那么我们在表t每插入一条数据，<strong>都需要在id聚集索引树和name非聚集索引上新增索引节点</strong>。</p>
<ul>
<li><p>前面说过，因为表t的插入顺序就是按照主键自增的，而id聚集索引又是按照id排序的，所以在id聚集索引上新增节点十分方便，只要在顺序插入即可，性能很高。</p>
</li>
<li><p>而在name非聚集索引上新增索引节点，因为表t记录的插入顺序按照id自增的顺序，不是按照name自增的顺序，但name非聚集索引又是按照name字段顺序排列的，所以表t的每次插入，都需要在name非聚集索引上离散的插入新的索引节点，随机IO的消耗太大，性能十分蛋疼。</p>
</li>
</ul>
<p>为了应对这种情况，InnoDB存储引擎开创性地设计了Insert Buffer，对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入;若不在，则先放入到一个Insert Buffer对象中。</p>
<p>好似欺骗数据库这个非聚集的索引已经插到叶子节点了，而实际并没有，只是存放在另一个位置。然后再以Master Thread的调度规则进行Insert Buffer和辅助索引页子节点的merge（合并）操作，这时通常能将多个插入合并到一个操作中（因为插入的都是在一个索引页中），这就大大提高了对于非聚集索引插人的性能。</p>
<p>然而Insert Buffer的使用需要同时满足以下三个条件∶</p>
<ol>
<li>修改的非聚集索引页不在缓冲池中<ul>
<li>因为如果在缓冲池中，直接改缓冲池就行了，改内存不比改磁盘，没有什么顺序IO/随机IO的性能差异。</li>
</ul>
</li>
<li>索引是辅助索引（secondary index）;<ul>
<li>因为聚集索引的性能很好，不需要用到Insert Buffer。</li>
</ul>
</li>
<li>辅助索引不是唯一（unique）的。<ul>
<li>因为如果辅助索引是唯一的，那么在插入辅助索引树前，要先判断插入的值是否已经在树中重复了，查询操作又是随机IO。</li>
<li>本来Insert Buffer就是为了避免随机IO，既然唯一性辅助索引的插入避免不了随机IO，那Insert Buffer也就没有什么意义了。</li>
</ul>
</li>
</ol>
<h3 id="2-2-2-Change-Buffer"><a href="#2-2-2-Change-Buffer" class="headerlink" title="2.2.2 Change Buffer"></a>2.2.2 Change Buffer</h3><p>InnoDB从1.0.x版本开始引入了Change Buffer，可将其视为Insert Buffer的升级。从这个版本开始，InnoDB存储引擎可以对DML操作——INSERT、DELETE、UPDATE 都进行缓冲，他们分别是∶Insert Buffer、Delete Buffer、Purge buffer。</p>
<p>当然和之前Insert Buffer一样，Change Buffer适用的对象依然是非唯一的辅助索引。</p>
<p>同时，InnoDB存储引擎提供了参数innodb_change_buffering，用来开启各种Buffer的选项。该参数可选的值为∶inserts、deletes、purges、changes、all、none。</p>
<p>inserts、deletes、purges就是前面讨论过的三种情况。changes表示启用inserts和deletes，all表示启用所有，none表示都不启用。该参数默认值为 all。</p>
<p>从InnoDB1.2.x版本开始，可以通过参数innodb_change_buffr_max_size来控制Change Buffer最大使用内存的数量∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-825381052046516637f1d890d48c522270b.png" alt=""></p>
<p>innodb_change_buffer_max_size值默认为25，表示最多使用1/4的缓冲池内存空间。而需要注意的是，该参数的最大有效值为 50。</p>
<h3 id="2-2-3-Insert-Buffer的内部实现"><a href="#2-2-3-Insert-Buffer的内部实现" class="headerlink" title="2.2.3 Insert Buffer的内部实现"></a>2.2.3 Insert Buffer的内部实现</h3><p>Insert Buffer具体是什么呢，内部怎么实现呢？</p>
<p>可能令绝大部分用户感到吃惊的是，Insert Buffer的数据结构是一棵B+树。在MySQL 4.1之前的版本中每张表有一棵Insert Buffer B+树。而在现在的版本中，全局只有一棵Insert Buffer B+树，负责对所有的表的辅助索引进行Insert Buffer。而这棵B+树存放在共享表空间中，默认也就是ibdatal中。</p>
<p>因此，试图通过独立表空间ibd文件恢复表中数据时，往往会导致CHECK TABLE失败。这是因为表的辅助索引中的数据可能还在Insert Buffer中，也就是共享表空间中，所以通过ibd文件进行恢复后，还需要进行REPAIR TABLE 操作来重建表上所有的辅助索引。</p>
<p>Insert Buffer是一棵B+树，因此其也由叶节点和非叶节点组成。非叶节点存放的是查询的search key（键值），其构造如下图所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2bd374d3dcb4e982cd4da066ba7b9114187.png" alt=""></p>
<p>search key一共占用9个字节，其中</p>
<ul>
<li>space表示待插入记录所在表的表空间id，在InnoDB存储引擎中，每个表有一个唯一的 space id，可以通过 space id查询得知是哪张表。space占用4字节。</li>
<li>marker占用1字节，它是用来兼容老版本的Insert Buffer。</li>
<li>offset 表示页所在的偏移量，你可以理解为页的下标，用来定位页的位置，占用4字节。</li>
</ul>
<p>当一个辅助索引要插入到页（由&lt;space，offset&gt;这个二元组可唯一定位一个页）时，如果这个页不在缓冲池中，那么InnoDB存储引擎首先根据上述规则构造一个search key结构，接下来查询Insert Buffer这棵B+树，然后再将这条记录插入到Insert Buffer B+树的合适的叶子节点中。</p>
<p>和非叶子节点一样，Insert Buffer B+树的叶子节点也有一种特殊的结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1ac9a52fd0af013c98409c4c54f0db82ce6.png" alt=""></p>
<ul>
<li>space、marker、offset字段和之前非叶节点中的含义相同，一共占用9字节。</li>
<li>第4个字段metadata 占用4字节，其存储的内容如下表所示。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-8a6dcb73257c42cedfaa860f8cb949d8f3b.png" alt=""></li>
<li>最核心的字段是IBUF_REC_OFFSET_COUNT字段，它保存两个字节的整数，用来排序每个记录进入Insert Buffer的顺序。因为从InnoDB1.0.x开始支持Change Buffer，所以这个值同样记录进入Change Buffer的顺序。merge的时候通过这个顺序回放（replay）才能得到记录的正确值。</li>
</ul>
</li>
<li>从Insert Buffer 叶子节点的第5列开始，就是实际插入记录的各个字段了。因此较之原插入记录，Insert Buffer B+树的叶子节点记录需要额外13字节的开销。</li>
</ul>
<p>因为启用Insert Buffer索引后，辅助索引页（space，offset）中的记录可能被插入到Insert Buffer B+树中，所以为了保证每次Merge Insert Buffer页都能成功，还需要有一个特殊的页用来标记每个辅助索引页（space，offset）的可用空间。这个页的类型为Insert Buffer Bitmap。</p>
<p>每个Insert Buffer Bitmap页用来追踪16384个辅助索引页，也就是256个区（Extent）。<strong>每个辅助索引页</strong>在Insert Buffer Bitmap页中占用4位（bit），这四位的含义见下表</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a9bdfd3ef86c322ef4b88df4ccc1ca4192a.png" alt=""></p>
<h3 id="2-2-4-Merge-Insert-Buffer"><a href="#2-2-4-Merge-Insert-Buffer" class="headerlink" title="2.2.4 Merge Insert Buffer"></a>2.2.4 Merge Insert Buffer</h3><p>我们已经知道了Insert/Change Buffer是一棵B+树。若需要做插入操作的辅助索引页不在缓冲池中，那么需要将辅助索引记录首先插入到这棵B+树中。但是Insert Buffer中的记录何时合并（merge）到真正的辅助索引中呢?这是我们接下来关注的重点。</p>
<p>概括地说，Merge Insert Buffer的操作可能发生在以下几种情况下∶</p>
<ol>
<li>辅助索引页被读取到缓冲池时;<ul>
<li>例如这在执行正常的SELECT查询操作，如果辅助索引页不在缓冲池中，这时我们需要优先将辅助索引读入缓冲池</li>
<li>紧接着检查Insert Buffer Bitmap页，看看该辅助索引页是否有记录存放于Insert Buffer B+树中。若有，则将Insert Buffer B+树中该页的记录插入到缓冲池中的该辅助索引页中。</li>
<li>这样便可以将对该页多次的记录操作通过一次操作合并到了原有的辅助索引页中，因此性能会有大幅提高。</li>
</ul>
</li>
<li>Insert Buffer Bitmap页追踪到该辅助索引页已无可用空间时;<ul>
<li>Insert Buffer Bitmap页用来追踪每个辅助索引页的可用空间，若插入辅助索引记录时检测到插入记录后，辅助索引页的可用空间会小于1/32页，则会强制进行一个合并操作，即强制读取辅助索引页至缓冲池，然后将Insert Buffer B+树中该页的记录及待插入的记录插入到缓冲池的辅助索引页中。</li>
</ul>
</li>
<li>Master Thread。<ul>
<li>在Master Thread线程中每秒或每10秒会进行一次Merge Insert Buffer的操作，不同之处在于每次进行merge操作的页的数量不同。</li>
<li>在Master Thread中，执行merge操作的不止是一个页，而是根据 srv_inodb io capactiy的百分比来决定真正要合并多少个辅助索引页。</li>
</ul>
</li>
</ol>
<p>那么InnoDB存储引擎又是根据怎样的算法来确定Insert Buffer B+树中哪些记录是需要合并的呢?</p>
<p>在Insert Buffer B+树中，辅助索引修改记录会根据（space，offset）排序好，故可以根据（space，offset）的排序顺序进行页的选择。然而，对于Insert Buffer页的选择，InnoDB存储引擎并非采用这个方式，<strong>它随机地选择Insert Buffer B+树的一个页，读取该页中的space及之后所需要数量（不同场景需要的数量不同）的页</strong>。</p>
<p>该算法在复杂情况下应有更好的公平性。</p>
<p>同时，若进行merge时，要进行merge的表已经被删除，此时可以直接丢弃已经被Insert/Change Buffer 的数据记录。</p>
<h3 id="2-2-5-缓冲池和Insert-Buffer的区别"><a href="#2-2-5-缓冲池和Insert-Buffer的区别" class="headerlink" title="2.2.5 缓冲池和Insert Buffer的区别"></a>2.2.5 缓冲池和Insert Buffer的区别</h3><p>我们前面学过缓冲池技术，假如我们要修改页号为40的索引页，而这个页正好不在缓冲池内。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-120ef3437c3b0858f837b70172467832f83.png" alt=""></p>
<p>此时我们依照缓冲池的机制，整个写过程如上图需要3步：</p>
<ol>
<li>先把需要为40的索引页，从磁盘加载到缓冲池，<strong>一次磁盘随机读操作</strong>；</li>
<li>修改缓冲池中的页，一次内存操作；</li>
<li>写入redo log，一次磁盘顺序写操作；</li>
</ol>
<blockquote>
<p>注意：没有命中缓冲池的时候，至少产生一次磁盘IO？</p>
</blockquote>
<p>而InnoDB加入Insert Buffer优化后，则写入流程优化为：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-16b0c1d81b9eda5ab4ee808299dc7421a04.png" alt=""></p>
<ol>
<li>在Insert Buffer B+树中记录这个操作，一次内存操作；</li>
<li>写入redo log，一次磁盘顺序写操作；</li>
</ol>
<p>可以看到，Insert Buffer机制能在缓冲池技术的基础上减少一次磁盘IO，其性能与这个索引页在缓冲池中的情况相近。可以看到，40这一页，并没有加载到缓冲池中。此时数据库异常奔溃，则能够从redo log中恢复数据；</p>
<p>假设稍后的一个时间，有请求查询索引页40的数据。</p>
<p>此时的流程如序号1-3：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b0af759bbe0a2de82eda2ea19bfcadb0fe1.png" alt=""></p>
<ol>
<li>缓冲池未命中，则从磁盘载入索引页，这次磁盘IO不可避免；</li>
<li>从Insert Buffer B+树中读取辅助索引页的修改记录；</li>
<li>根据Insert Buffer修改从缓存载入的索引页，使其达到最终态，并放到缓冲池LRU List里；</li>
</ol>
<p>可以看到，40这一页，在真正被读取时，才会被加载到缓冲池中。</p>
<blockquote>
<p>注意，insert buffer的merge操作是将索引文件从磁盘载入到缓冲池的索引页中，并且将insert buffer里的更改再执行到缓冲池索引页上。</p>
</blockquote>
<blockquote>
<p>系统大部分空闲时或在慢速关闭期间运行的清除（purge）操作会定期将缓冲池中的辅助索引页（此时一般为脏页）写入磁盘。与每个值立即写入磁盘相比，purge操作可以更有效地为一系列索引值写入磁盘块。</p>
</blockquote>
<h3 id="2-2-6-查看insert-change-Buffer"><a href="#2-2-6-查看insert-change-Buffer" class="headerlink" title="2.2.6 查看insert/change Buffer"></a>2.2.6 查看insert/change Buffer</h3><p>用户可以通过命令SHOW ENGINE INNODB STATUS来查看Insert Buffer的信息∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-82548d7a2a410db63648a82d24d08e4ac03.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-bed6c7af819e278cdd9e697ccbf046517d1.png" alt=""></p>
<ul>
<li>seg size显示了当前Insert Buffer的大小为11336×16KB，大约为177MB;</li>
<li>free list len代表了空闲列表的长度;</li>
<li>size代表了已经合并记录页的数量。</li>
</ul>
<p>而黑体部分的第2行可能是用户真正关心的，因为它显示了插入性能的提高。</p>
<ul>
<li>Inserts代表了插入的记录数;</li>
<li>mergedrecs代表了合并的插入记录数量;</li>
<li>merges代表合并的次数，也就是实际读取页的次数。</li>
<li>merges∶merged recs大约为1∶3，代表了插入缓冲将对于非聚集索引页的离散1O 逻辑请求大约降低了23。</li>
</ul>
<p>在MySQL5.5版本中通过命令SHOW ENGINE INNODB STATUS，可以观察到change Buffer的信息∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9c1fb50810e2009f3fb819b428f073d3292.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-ac6e49a8c5cdb7ce94a0622768d87f4d314.png" alt=""></p>
<p>可以看到这里显示了merged operations和discarded operation，并且下面具体显示Change Buffr中每个操作的次数。</p>
<ul>
<li>insert表示Insert Buffer;</li>
<li>delete mark表示 Delete Buffer;</li>
<li>delete表示Purge Buffer;</li>
<li>discarded operations表示当Change Buffer发生merge 时，表已经被删除，此时就无需再将记录合并（merge）到辅助索引中了。</li>
</ul>
<h2 id="2-3-两次写"><a href="#2-3-两次写" class="headerlink" title="2.3 两次写"></a>2.3 两次写</h2><p>如果说Insert Buffer带给InnoDB存储引擎的是性能上的提升，那么doublewrite（两次写）带给InnoDB存储引擎的是数据页的可靠性。</p>
<p><strong>当发生数据库宕机时，可能InnoDB存储引擎正在将某个页写入到表中，而这个页只写了一部分</strong>，比如16KB的页，只写了前4KB，之后就发生了宕机，这种情况被称为部分写失效（partial page write）。在InnoDB存储引擎未使用doublewrite技术前，曾经出现过因为部分写失效而导致数据丢失的情况。</p>
<p>有经验的DBA也许会想，如果发生写失效，可以通过重做日志进行恢复。这是一个办法。<strong>但是必须清楚地认识到，重做日志中记录的是对页的物理操作，如偏移量800，写’aaa’记录。如果这个页本身已经发生了损坏，再对其进行重做是没有意义的</strong>。这就是说，在应用（apply）重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是doublewrite。在InnoDB存储引擎中doublewrite的体系架构如下图所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4f4227efdd3deb6b3833306e6ad4459082b.png" alt=""></p>
<p>doublewrite由两部分组成，一部分是内存中的doublewrite buffer，大小为2MB，另一部分是物理磁盘上共享表空间中连续的128个页，即2个区（extent），大小同样为2MB。</p>
<p>在对缓冲池的脏页进行flush时，并不直接写磁盘，而是会通过memcpy函数将脏页先复制到内存中的doublewrite buffer，之后通过doublewrite buffer再分两次，每次IMB顺序地写入共享表空间的物理磁盘上，然后马上调用fsync函数，同步磁盘，避免缓冲写带来的问题。在这个过程中，因为doublewrite页是连续的，因此这个过程是顺序写的，开销并不是很大。</p>
<p>在完成doublewrite页的写入后，再将doublewrite buffer中的页写入各个表空间文件中，此时的写入则是离散的。可以通过以下命令观察到doublewrite 运行的情况∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-06e023bef3b3f3788a047f8175cd2c0b6f1.png" alt=""></p>
<p>可以看到，doublewrite一共写了6325194个页，但实际的写人次数为100399，基本上符合64∶1。</p>
<p>如果发现系统在高峰时的Innodb_dblwr_pages_written∶Innodb_dblwr_writes远小于64∶1，那么可以说明系统写人压力并不是很高。</p>
<p>如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，InnoDB存储引擎可以从共享表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件，再应用重做日志。</p>
<p><strong>参数skip_innodb_doublewrite可以禁止使用doublewrite功能</strong>，这时可能会发生前面提及的写失效问题。不过如果用户有多个从服务器（slave server），需要提供较快的性能（如在slaves server上做的是RAID0），也许启用这个参数是一个办法。不过对于需要提供数据高可靠性的主服务器（master server），任何时候用户都应确保开启doublewrite 功能。</p>
<h2 id="2-4-自适应哈希索引"><a href="#2-4-自适应哈希索引" class="headerlink" title="2.4 自适应哈希索引"></a>2.4 自适应哈希索引</h2><p>哈希（hash）是一种非常快的查找方法，在一般情况下这种查找的时间复杂度为O（1），即一般仅需要一次查找就能定位数据。而B+树的查找次数，取决于B+树的高度，在生产环境中，B+树的高度一般为3～4层，故需要3～4次的查询。</p>
<p><strong>InnoDB存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引（Adaptive Hash Index，AHI）</strong>。</p>
<p>AHI是通过<strong>缓冲池</strong>中的的B+树页构造而来，因此建立的速度很快，而且不需要对整张表构建哈希索引。InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。</p>
<p>AHI有一个要求，即对这个页的连续访问模式必须是一样的。例如对于（a，b）这样的联合索引页，其访问模式可以是以下情况∶</p>
<ol>
<li>WHERE a=xxx</li>
<li>WHERE a=xxx and b=xxx</li>
</ol>
<p>访问模式一样指的是查询的条件一样，若交替进行上述两种查询，那么InnoDB存储引擎不会对该页构造 AHI。</p>
<p>此外 AHI 还有如下的要求∶</p>
<ol>
<li>以该模式访问了100次</li>
<li>页通过该模式访问了N次，其中<code>N=页中记录/16</code></li>
</ol>
<p>根据InnoDB存储引擎官方的文档显示，启用AHI后，读取和写入速度可以提高2 倍，辅助索引的连接操作性能可以提高5倍。毫无疑问，AHI是非常好的优化模式，其设计思想是数据库自优化的（self-tuning），即无需 DBA对数据库进行人为调整。</p>
<p>通过命令SHOW ENGINE INNODB STATUS可以看到当前AHI的使用状况∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-69ad2998f5404052484ea0489a357b90bb4.png" alt=""></p>
<p>现在可以看到AHI的使用信息了，包括AHI的大小、使用情况、每秒使用AHI搜索的情况。</p>
<p>值得注意的是，哈希索引只能用来搜索等值的查询，如<code>SELECT* FROM table WHERE index_col=&#39;xxx&#39;</code>。而对于其他查找类型，如范围查找，是不能使用哈希索引的，因此这里出现了non-hash searches/s的情况。通过 hash searches∶non-hash searches的比值，可以大概了解使用哈希索引后的效率。</p>
<p>参数 innodb_adaptive_hash_index可以控制是否启动AHI。</p>
<h2 id="2-5-异步IO"><a href="#2-5-异步IO" class="headerlink" title="2.5 异步IO"></a>2.5 异步IO</h2><p>为了提高磁盘操作性能，当前的数据库系统都采用异步IO（Asynchronous IO，AIO）的方式来处理磁盘操作。InnoDB存储引擎亦是如此。</p>
<p>与AIO对应的是Sync IO，即每进行一次IO操作，需要等待此次操作结束才能继续接下来的操作。但是如果用户发出的是一条索引扫描的查询，那么这条SQL查询语句可能需要扫描多个索引页，也就是需要进行多次的IO操作。在每扫描一个页并等待其完成后再进行下一次的扫描，这是没有必要的。用户可以在发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作的完成，这就是AIO。</p>
<p>AIO的另一个优势是可以进行IO Merge操作，也就是将多个IO合并为1个IO，这样可以提高IOPS的性能。例如用户需要访问页的（space，page_no）为∶<code>(8,6)，(8,7)，(8,8)</code></p>
<p>每个页的大小为16KB，那么同步IO需要进行3次IO操作。而AIO会判断到这三个页是连续的（显然可以通过（space，page_no）得知）。因此AIO底层会发送一个IO 请求，从（8，6）开始，读取48KB的页。</p>
<p>在InnoDB1.1.x之前，AIO的实现通过InnoDB存储引擎中的代码来模拟实现。而从InnoDB1.1.x开始（InnoDB Plugin不支持），提供了内核级别AIO的支持，称为Native AIO。因此在编译或者运行该版本MySQL时，需要libaio库的支持。</p>
<p>需要注意的是，Native AIO需要操作系统提供支持。Windows系统和Linux系统都提供Native AIO支持，参数<code>innodb_use_native_aio</code>用来控制是否启用Native AIO，在Linux操作系统下，默认值为 ON。</p>
<p>用户可以通过开启和关闭Native AIO功能来比较InnoDB性能的提升。官方的测试显示，启用Native AIO，恢复速度可以提高 75%。</p>
<p>在InnoDB存储引擎中，read ahead方式的读取都是通过AIO完成，脏页的刷新，即磁盘的写人操作则全部由 AIO完成。</p>
<h2 id="2-6-刷新邻接页"><a href="#2-6-刷新邻接页" class="headerlink" title="2.6 刷新邻接页"></a>2.6 刷新邻接页</h2><p>InnoDB存储引擎还提供了Flush Neighbor Page（刷新邻接页）的特性。其工作原理为∶当flush一个脏页时，InnoDB存储引擎会检测该页所在区（extent）的所有页，如果是脏页，那么一起进行flush。</p>
<p>这样做的好处显而易见，通过AIO可以将多个IO写人操作合并为一个IO操作，故该工作机制在传统机械磁盘下有着显著的优势。但是需要考虑到下面两个问题∶</p>
<ol>
<li>是不是可能将不怎么脏的页进行了写入，而该页之后又会很快变成脏页?</li>
<li>固态硬盘有着较高的IOPS，是否还需要这个特性?</li>
</ol>
<p>为此，InnoDB存储引擎从1.2x版本开始提供了参数 innodb_flush_neighbors，用来控制是否启用该特性。对于传统机械硬盘建议启用该特性，而对于固态硬盘有着超高IOPS性能的磁盘，则建议将该参数设置为0，即关闭此特性。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-hand-o-right" aria-label="accessibility.next_page"></i></a>
  </nav>

          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png"
                alt="cherish-ls" />
            
              <p class="site-author-name" itemprop="name">cherish-ls</p>
              <p class="site-description motion-element" itemprop="description">纸上得来终觉浅</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">53</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">94</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="git@github.com:cherish-ls/cherish-ls.github.io.git" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">cherish-ls</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">369.6k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"cherish"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  
















  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: 'TQhjcmooFXWGQ3qgqUroDKsD-gzGzoHsz',
        appKey: 'zjA9PvG5eljY1JErig8WVQQD',
        placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  

  
  

  

  

  

</body>
</html>
