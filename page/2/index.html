<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="纸上得来终觉浅，绝知此事要躬行" />










<meta name="description" content="纸上得来终觉浅">
<meta property="og:type" content="website">
<meta property="og:title" content="cherish">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="cherish">
<meta property="og:description" content="纸上得来终觉浅">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="cherish-ls">
<meta property="article:tag" content="纸上得来终觉浅，绝知此事要躬行">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title>cherish</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">cherish</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">返朴归真</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/" itemprop="url">【InnoDB详解四】redo log和undo log</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-27T23:36:33+08:00">
                2020-09-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/27/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E5%9B%9B%E3%80%91redo-log%E5%92%8Cundo-log/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/27/【InnoDB详解四】redo-log和undo-log/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  12.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  45
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-redo-log"><a href="#1-redo-log" class="headerlink" title="1 redo log"></a>1 redo log</h1><p>首先我们先明确一下InnoDB的修改数据的基本流程，当我们想要修改DB上某一行数据的时候，InnoDB是把数据从磁盘读取到内存的缓冲池上进行修改。这个时候数据在内存中被修改，与磁盘中相比就存在了差异，我们称这种有差异的数据为脏页。</p>
<p>InnoDB对脏页的处理不是每次生成脏页就将脏页刷新回磁盘，<strong>这样会产生海量的IO操作，严重影响InnoDB的处理性能</strong>。对于此，InnoDB有一套完善的处理策略，与我们这次主题关系不大，表过不提。既然脏页与磁盘中的数据存在差异，那么如果在这期间DB出现故障就会造成数据的丢失（持久性问题产生了）。为了解决这个问题，redo log就应运而生了。</p>
<h2 id="1-1-redo-log的特点"><a href="#1-1-redo-log的特点" class="headerlink" title="1.1 redo log的特点"></a>1.1 redo log的特点</h2><ul>
<li><p>redo log在<strong>数据库重启恢复的时候被使用</strong>。</p>
</li>
<li><p>redo日志占用的空间非常小，存储表空间ID、页号、偏移量以及需要更新的值所需的存储空间是很小的。</p>
</li>
<li><p>redo log属于物理日志，他可以将已提交事务修改的记录记录下来，即某个表空间中某页的某个偏移量的值更新为多少。因为其属于<strong>物理日志</strong>的特性，恢复速度远快于逻辑日志。而我们下文即将介绍的binlog和undo log就属于典型的逻辑日志。</p>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-e43816535e5b18dcd0b5bb54be94f21344a.png" alt=""></p>
<ul>
<li><p>redo日志不止记录索引插入/更新记录等操作，还有执行这个操作影响到的其他动作，如页分裂新增目录项记录，修改页信息等对数据页做的任何修改等等。</p>
</li>
<li><p>redo日志记录的是物理页的情况，它具有幂等性，因此记录日志的方式极其简练。幂等性的意思是多次操作前后状态是一样的，例如新插入一行后又删除该行，前后状态没有变化。</p>
</li>
<li><p>redo日志是顺序写入磁盘的，在执行事务的过程中，每执行一条语句，就可能产生若干条redo日志，这些日志是按照产生的顺序写入磁盘的，也就是使用顺序IO，这比随机IO的性能要高得多。</p>
</li>
</ul>
<h2 id="1-2-redo-log的工作机制简述"><a href="#1-2-redo-log的工作机制简述" class="headerlink" title="1.2 redo log的工作机制简述"></a>1.2 redo log的工作机制简述</h2><p>redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的，并且事务的记录是顺序追加的，性能非常高(磁盘的<strong>顺序写</strong>性能比内存的写性能差不了太多)。</p>
<p>InnoDB使用日志+缓存的策略来减少提交事务时的开销。因为日志中已经记录了事务，所以就无须为了保证持久性而在每个事务提交时都把缓冲池的脏数据刷新(flush)到磁盘中。</p>
<p>事务修改的数据和索引通常会映射到表空间的随机位置，所以刷新这些变更到磁盘需要很多随机IO。InnoDB假设使用常规磁盘，随机IO比顺序IO昂贵得多，因为一个IO请求需要时间把磁头移到正确的位置，然后等待磁盘上读出需要的部分，再转到开始位置。</p>
<p>InnoDB用日志把随机IO变成顺序IO。一旦日志安全写到磁盘，事务就持久化了，即使断电了，InnoDB可以重放日志并且恢复已经提交的事务。</p>
<p>为了确保每次日志数据都能写入到磁盘的事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作(即fsync()系统调用)。</p>
<p>因为MySQL是工作在用户空间的，MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中(也就是redo的ib_logfileN文件，undo的share tablespace或.ibd文件，后面讲undo log时会讲到)，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将OS buffer中的日志刷到磁盘上的log file中。</p>
<p>也就是说，从redo log buffer写日志到磁盘的redo log file中，过程如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c1152ce0028d1f668da73cbc4b28b1794a3.png" alt=""></p>
<h2 id="1-3-redo-log的数据结构（log-block）"><a href="#1-3-redo-log的数据结构（log-block）" class="headerlink" title="1.3 redo log的数据结构（log block）"></a>1.3 redo log的数据结构（log block）</h2><p>InnoDB存储引擎中，redo log以块为单位进行存储的，每个块占512字节（同磁盘扇区大小一致，可以保证块的写入是原子操作。），这称为redo log block。<strong>所以不管是log buffer中还是os buffer中以及redo log file on disk中，都是这样以512字节的块存储的</strong>。</p>
<p>每个redo log block由3部分组成：header、tailer和body。其中日志块头header占用12字节，日志块尾tailer占用8字节，所以每个redo log block的日志主体部分body只有512-12-8=492字节。</p>
<p>因为redo log记录的是数据页的变化，当一个数据页产生的变化需要使用超过492字节的redo log来记录，那么就会使用多个redo log block来记录该数据页的变化。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c6ca3a15d7c42bf5fa449dbe802b692605b.png" alt=""></p>
<p>上面所说的是一个日志块的内容，在redo log buffer或者redo log file on disk中，由很多log block组成。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e7ea51e63422a5719c70835176b989e073e.png" alt=""></p>
<h3 id="1-3-1-block-header"><a href="#1-3-1-block-header" class="headerlink" title="1.3.1 block header"></a>1.3.1 block header</h3><p>header包含4部分：</p>
<ul>
<li>log_block_hdr_no：(4字节)该日志块在redo log buffer/os buffer/log file中的位置ID。log buffer/redo log file on disk是由log block组成，在log buffer内部就好似一个数组，因此LOG_BLOCK HDR_NO用来标记这个数组中的位置。其是递增并且循环使用的。</li>
<li>log_block_hdr_data_len：(2字节)该log block中<strong>已记录</strong>的log大小。写满该log block时为0x200，表示512字节。</li>
<li>log_block_first_rec_group：(2字节)该log block中新的数据页对应的log的开始偏移位置。</li>
<li>lock_block_checkpoint_no：(4字节)写入checkpoint信息的位置。</li>
</ul>
<p>关于log block块头的第三部分<code>log_block_first_rec_group</code>，因为有时候一个数据页产生的日志量<strong>超出了一个日志块</strong>，这时需要用多个日志块来记录该页的相关日志。</p>
<p>例如，某一T1事务产生了792个字节的日志量，那么需要占用两个日志块，第一个日志块占用492字节，第二个日志块需要占用270个字节，那么对于第二个日志块来说，它记录的关于下一个数据页B的第一个log的开始位置就是282字节(270+12)。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fa477acf42ce4e51969e8127c867d22560e.png" alt=""></p>
<p>如果<code>log_block_first_rec_group</code>的值和<code>log_block_hdr_data_len</code>相等，则说明该log block中没有新开始记录下一个数据页的日志，即<strong>表示该日志块用来延续前一个日志块</strong>。</p>
<h3 id="1-3-2-block-tailer"><a href="#1-3-2-block-tailer" class="headerlink" title="1.3.2 block tailer"></a>1.3.2 block tailer</h3><p>tailer只有一个部分：</p>
<ul>
<li><code>log_block_trl_no</code> ，该值和块头的 <code>log_block_hdr_no</code> 相等。</li>
</ul>
<h3 id="1-3-3-block-body"><a href="#1-3-3-block-body" class="headerlink" title="1.3.3 block body"></a>1.3.3 block body</h3><p>因为innodb存储引擎存储数据的单元是页(和SQL Server中一样)，所以redo log也是基于页的格式来存放的。默认情况下，innodb的页大小是16KB(由<code>innodb_page_size</code>变量控制)，一个页内可以存放非常多的log block(每个512字节)，而log block中记录的又是数据页的变化。</p>
<p>其中log block中492字节的部分是block body，<strong>block body存储了很多条的redo日志，每条redo日志的格式分为4部分</strong>：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-952af4bd6ec616062dc8b8ce0a9ec050c1d.png" alt=""></p>
<ul>
<li><p>type：占用1个字节，8bit，其中高位的一个bit另做它用，剩下7个bit表示redo log的日志类型，其值有很多，在MySQL 5.7.21这个版本中，InnoDB一共为redo日志设计了53种不同的类型，下文将详细分析。</p>
</li>
<li><p>space ID：表示表空间的ID，采用压缩的方式后，占用的空间可能小于4字节。</p>
</li>
<li><p>page number：表示页的偏移量，同样是压缩过的。</p>
</li>
<li><p>data：表示每个redo日志的数据部分，恢复时会调用相应的函数进行解析。例如insert语句和delete语句写入redo log的内容是不一样的。</p>
</li>
</ul>
<h3 id="1-3-4-redo-log的类型"><a href="#1-3-4-redo-log的类型" class="headerlink" title="1.3.4 redo log的类型"></a>1.3.4 redo log的类型</h3><p>type字段的低位7个bit用来区分redo log的日志类型，我们来看下简单的场景和复杂的场景下，redo日志的不同类型。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c6af77a689edc02a3cafabd97c02942128c.png" alt=""></p>
<h4 id="1-3-4-1-简单的redo日志类型"><a href="#1-3-4-1-简单的redo日志类型" class="headerlink" title="1.3.4.1 简单的redo日志类型"></a>1.3.4.1 简单的redo日志类型</h4><p>我们前边介绍InnoDB的记录行格式的时候说过，如果我们没有为某个表显式的定义主键，并且表中也没有定义Unique键，那么InnoDB会自动的为表添加一个称之为row_id的隐藏列作为主键。</p>
<p>这时服务器会在内存中维护一个全局变量，每当向某个包含隐藏的row_id列的表中插入一条记录时，就会把该变量的当前值当作新记录的row_id列的值，并且把该变量自增1。</p>
<p>每当这个变量的值为256的倍数时，就会将该变量的值刷新到系统表空间的页号为7的页中一个称之为Max Row ID的属性处。</p>
<p>这是Max Row ID的持久化，即Max Row ID每增加256，就持久化一次，如果期间发生了系统宕机，那么重新启动后，服务器会将持久化的最大的Max Row ID取出，并加上256，当做新的Max Row ID。</p>
<blockquote>
<p>比如Max Row ID自增到800的时候，系统已经持久化了Max Row ID的三个值256，512，768。这时，系统崩溃了，重新启动后，系统取出了最新的768，但不能直接从768开始用，为了防止重复，新的Max Row ID=768+256=1024。</p>
</blockquote>
<p>这个Max Row ID属性占用的存储空间是8个字节，当某个事务向某个包含row_id隐藏列的表插入一条记录，并且为该记录分配的row_id值刚好为256的倍数时，就会向系统表空间页号为7的页面的相应偏移量处写入8个字节的值。</p>
<p>但是我们要知道，这个写入实际上是在Buffer Pool中完成的，我们需要为这个页的修改记录一条redo日志，以便在系统奔溃后能将已经提交的该事务对该页面所做的修改恢复出来。这种情况下对页的修改是极其简单的，<strong>redo日志中只需要记录一下页号为7的页面的某个偏移量处修改了几个字节的值，以及具体被修改的内容是啥就好了</strong>。</p>
<p>这种简单的redo日志，InnoDB定义了如下的type的值，来表示对应字节的redo日志的产生。</p>
<ul>
<li>MLOG_1BYTE(type字段对应的⼗进制数字为1)：表示在⻚⾯的某个偏移量处写⼊1个字节的redo⽇志类型。</li>
<li>MLOG_2BYTE(type字段对应的⼗进制数字为2)：表示在⻚⾯的某个偏移量处写⼊2个字节的redo⽇志类型。</li>
<li>MLOG_4BYTE(type字段对应的⼗进制数字为4)：表示在⻚⾯的某个偏移量处写⼊4个字节的redo⽇志类型。</li>
<li>MLOG_8BYTE(type字段对应的⼗进制数字为8)：表示在⻚⾯的某个偏移量处写⼊8个字节的redo⽇志类型。</li>
<li>MLOG_WRITE_STRING(type字段对应的⼗进制数字为30)：表示在⻚⾯的某个偏移量处写⼊⼀串数据。</li>
</ul>
<p>我们上边提到的Max Row ID属性实际占用8个字节的存储空间，所以在修改页面中的该属性时，会记录一条类型为MLOG_8BYTE的redo日志，MLOG_8BYTE的redo日志结构如下所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c32188a1f15479176b8ec9188c67c622f21.png" alt=""></p>
<p>其余MLOG_1BYTE、MLOG_2BYTE、MLOG_4BYTE类型的redo日志结构和MLOG_8BYTE的类似，只不过具体数据中包含对应个字节的数据罢了。MLOG_WRITE_STRING类型的redo日志表示写入一串数据，但是因为不能确定写入的具体数据占用多少字节，所以需要在日志结构中添加一个len字段：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-554313fb140cc3234089d0f76ff3c927c36.png" alt=""></p>
<blockquote>
<p>其实只要将MLOG_WRITE_STRING类型的redo日志的len字段填充上1、2、4、8这些数字，就可以分别替代MLOG_1BYTE、MLOG_2BYTE、MLOG_4BYTE、MLOG_8BYTE这些类型的redo日志，为啥还要多此一举设计这么多类型呢？还不是因为省空间啊，能不写len字段就不写len字段，省一个字节算一个字节。</p>
</blockquote>
<h4 id="1-3-4-2-复杂的redo日志类型"><a href="#1-3-4-2-复杂的redo日志类型" class="headerlink" title="1.3.4.2 复杂的redo日志类型"></a>1.3.4.2 复杂的redo日志类型</h4><p>有时候执行一条语句会修改非常多的页面，包括系统数据页面（比如上文提到的全局变量Max Row ID的更新）和用户数据页面（用户数据指的就是聚簇索引和二级索引对应的B+树）。</p>
<p>以一条INSERT语句为例，它除了要向B+树的页面中插入数据，也可能更新系统数据Max Row ID的值，不过对于我们用户来说，平时更关心的是语句对B+树所做更新：</p>
<ul>
<li>表中包含多少个索引，一条INSERT语句就可能更新多少棵B+树。</li>
<li>针对某一棵B+树来说，既可能更新叶子节点页面，也可能更新内节点页面，也可能创建新的页面（在该记录插入的叶子节点的剩余空间比较少，不足以存放该记录时，会进行页面的分裂）。</li>
<li>对于B+树上的页来说，新的行被插入，页中的<code>Page Directory</code>的槽信息、<code>Page Header</code>中的各种统计信息，行记录链表的后驱<code>next_record</code>等都要随之更新。</li>
</ul>
<p>画一个简易的示意图就像是这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3371ed59e2f4a43841d84d37c5e6f0d35c5.png" alt=""></p>
<p>说了这么多，就是想表达：把一条记录插入到一个页面时需要更改的地方非常多。这时我们如果使用上边介绍的简单的物理redo日志来记录这些修改时，可以有两种解决方案：</p>
<ul>
<li><p>方案一：在每个修改的地方都记录一条redo日志。</p>
<ul>
<li>也就是如上图所示，有多少个加粗的块，就写多少条物理redo日志。这样子记录redo日志的缺点是显而易见的，因为被修改的地方是在太多了，可能记录的redo日志占用的空间都比整个页面占用的空间都多了。</li>
</ul>
</li>
<li><p>方案二：将整个页面的第一个被修改的字节到最后一个修改的字节之间所有的数据当成是一条物理redo日志中的具体数据。</p>
<ul>
<li>从图中也可以看出来，第一个被修改的字节到最后一个修改的字节之间仍然有许多没有修改过的数据，我们把这些没有修改的数据也加入到redo日志中去岂不是太浪费了。</li>
</ul>
</li>
</ul>
<p>正因为上述两种使用物理redo日志的方式来记录某个页面中做了哪些修改比较浪费，InnoDB的设计者本着勤俭节约的初心，提出了一些新的redo日志类型，比如：</p>
<ul>
<li>MLOG_REC_INSERT(type字段对应的十进制数字为9)：表示插入一条使用非紧凑行格式记录时的redo日志类型（如redundant）</li>
<li>MLOG_COMP_REC_INSERT(type字段对应的十进制数字为38)：表示插入一条使用紧凑行格式记录时的redo日志类型（如compact/dynamic/compressed）</li>
<li>MLOG_COMP_PAGE_CREATE（type字段对应的十进制数字为58）：表示创建一个存储紧凑行格式记录的页面的redo日志类型。</li>
<li>MLOG_COMP_REC_DELET(type字段对应的十进制数字为42)：表示删除一条使用紧凑行格式记录的redo日志类型</li>
<li>MLOG_COMP_LIST_START_DELETE（type字段对应的十进制数字为44）：表示从某条给定记录开始删除页面中的一系列使用紧凑行格式记录的redo日志类型。</li>
<li>MLOG_ZIP_PAGE_COMPRESS（type字段对应的十进制数字为51）：表示压缩一个数据页的redo日志类型。</li>
<li>MLOG_COMP_LIST_END_DELETE（type字段对应的十进制数字为43）：与MLOG_COMP_LIST_START_DELETE类型的redo日志呼应，表示删除一系列记录直到MLOG_COMP_LIST_END_DELETE类型的redo日志对应的记录为止。</li>
</ul>
<p>那这些新类型和旧的类型有什么区别呢？如果还是简单的把所有的物理层面的数据变动都记录下来，那岂不是没什么区别？</p>
<p>区别就是，新的日志类型，除了能体现物理层面的变动，还包含了逻辑层面的变动，它主要是搭配系统恢复的函数的来使用的。</p>
<ol>
<li>物理层面：修改的是哪个表空间，哪个页，以及页的偏移量。</li>
<li>逻辑层面：是插入操作还是删除操作；操作对象是行记录还是其他？如果是行记录，那是什么格式的行记录？紧凑的还是非紧凑的。</li>
</ol>
<p>这样有什么好处呢？？我们以插入一条使用紧凑行格式的记录时的redo日志（MLOG_COMP_REC_INSERT）为例，直接看一下这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志的结构，橙色部分都是block body：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-eda1ea874ed13e2c18c96c51b3c426d2bac.png" alt=""></p>
<p>这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志结构有几个地方需要大家注意：</p>
<ol>
<li>在一个数据页里，行记录都是按照索引列从小到大的顺序排序的。对于二级索引来说，当索引列的值相同时，记录还需要按照主键值进行排序。图中n_uniques的值的含义是在一条记录中，需要几个字段的值才能确保记录的唯一性，这样当插入一条记录时就可以按照记录的前n_uniques个字段进行排序。对于聚簇索引来说，n_uniques的值为主键的列数，对于其他二级索引来说，该值为索引列数+主键列数。这里需要注意的是，唯一二级索引的值可能为NULL，所以该值仍然为索引列数+主键列数。</li>
<li>field1_len ~ fieldn_len代表着该记录若干个字段占用存储空间的大小，需要注意的是，这里不管该字段的类型是固定长度大小的（比如INT），还是可变长度大小（比如VARCHAR(M)）的，该字段占用的大小始终要写入redo日志中。</li>
<li>offset代表的是该记录的前一条记录在页面中的地址。为啥要记录前一条记录的地址呢？这是因为每向数据页插入一条记录，都需要修改该页面中维护的记录链表，每条记录的记录头信息中都包含一个称为next_record的属性，所以在插入新记录时，需要修改前一条记录的next_record属性。</li>
</ol>
<p>很显然这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志并没有记录PAGE_N_DIR_SLOTS的值修改为了啥，PAGE_HEAP_TOP的值修改为了啥，PAGE_N_HEAP的值修改为了啥等等这些信息，<strong>而只是把在本页面中插入一条记录所有必备的要素记了下来</strong>，之后系统奔溃重启时，<strong>服务器会调用相关向某个页面插入一条记录的那个函数，而redo日志中的那些数据就可以被当成是调用这个函数所需的参数</strong>，在调用完该函数后，页面中的PAGE_N_DIR_SLOTS、PAGE_HEAP_TOP、PAGE_N_HEAP等等的值也就都被恢复到系统奔溃前的样子了。这就是所谓的逻辑日志的意思。</p>
<p>如下图，分别是insert和delete大致的记录方式。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1c95c4a1e07f6afdf1f7f9bdb9c5cfa80c2.png" alt=""></p>
<h2 id="1-4-redo日志的原子性（Mini-Transaction）"><a href="#1-4-redo日志的原子性（Mini-Transaction）" class="headerlink" title="1.4  redo日志的原子性（Mini-Transaction）"></a>1.4  redo日志的原子性（Mini-Transaction）</h2><p>前文说到执行一条INSERT的SQL语句，InnoDB在向某个B+树中插入新的记录的过程，会产生许多条的redo日志，因为可能涉及页的分裂，各种段的修改、区的统计信息，各种链表的统计信息等等。</p>
<p>我们知道向某个索引对应的B+树中插入一条记录的这个过程必须是原子的，不能说插了一半之后就停止了。在B+树上插入一个新的行，触发的页的分裂，这时新的页面已经分配好了，数据也复制过去了，新的记录也插入到页面中了，可是没有向数据节点中插入一条目录项记录，那么这个插入过程就是不完整的，这样会形成一棵不正确的B+树。</p>
<p>我们知道redo日志是为了在系统奔溃重启时恢复崩溃前的状态，如果在INSERT的过程中只记录了一部分redo日志，那么在系统奔溃重启时会将索引对应的B+树恢复成一种不正确的状态，这是InnoDB设计者们所不能忍受的。</p>
<p>MySQL把这种<strong>不容许分割的，对底层页面中的一次原子操作的过程</strong>称之为一个<strong>Mini-Transaction</strong>，简称mtr，比如上边所说的修改一次Max Row ID的值算是一个Mini-Transaction，向某个索引对应的B+树中插入一条记录的过程也算是一个Mini-Transaction。</p>
<p>一个mtr可能产生单条或者多条redo日志，就像对redo日志进行编组一样，在进行奔溃恢复时这一组redo日志将作为一个不可分割的整体，要么一起恢复，要么都不恢复。</p>
<blockquote>
<p>一个事务可以包含若干条语句，每一条语句其实是由若干个mtr组成，每一个mtr又可以包含若干条redo日志，画个图表示它们的关系就是这样：</p>
</blockquote>
<p><img src="https://oscimg.oschina.net/oscnet/up-391c80e95bda8d4ae7b97e571b2a5a77e33.png" alt=""></p>
<p>那么如何对一个mtr产生的redo日志进行编组呢？这得分情况讨论：</p>
<ol>
<li>有的操作会生成多条redo日志，比如向某个索引对应的B+树中进行一次插入就需要生成许多条redo日志。</li>
<li>有的需要保证原子性的操作只生成一条redo日志，比如更新全局变量Max Row ID属性的操作就只会生成一条redo日志。</li>
</ol>
<h3 id="1-4-1-原子操作生成多条redo日志"><a href="#1-4-1-原子操作生成多条redo日志" class="headerlink" title="1.4.1 原子操作生成多条redo日志"></a>1.4.1 原子操作生成多条redo日志</h3><p><strong>针对第一种情况</strong>，InnoDB定义了一种新的类型（<code>MLOG_MULTI_REC_END</code>，type字段对应的十进制数字为31）的redo log结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-020bd4a48f5f5c3000bd25452a3b8c4a5cb.png" alt=""></p>
<p>所以某个需要保证原子性的操作产生的一系列redo日志必须要以一个类型为<code>MLOG_MULTI_REC_END</code>结尾，就像这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b10b12fd333ba38b1faf25732f1669596a2.png" alt=""></p>
<p>这样在系统奔溃重启进行恢复时，只有当解析到类型为MLOG_MULTI_REC_END的redo日志，才认为解析到了一组完整的redo日志，才会进行恢复。否则的话直接放弃前边解析到的不完整部分的redo日志。</p>
<h3 id="1-4-2-原子操作生成单条redo日志"><a href="#1-4-2-原子操作生成单条redo日志" class="headerlink" title="1.4.2 原子操作生成单条redo日志"></a>1.4.2 原子操作生成单条redo日志</h3><p><strong>针对第二种情况</strong>，其实在一条日志后边跟一个类型为MLOG_MULTI_REC_END的redo日志也是可以的，但这比较浪费。</p>
<p>别忘了虽然redo日志的类型比较多，但撑死了也就是几十种，是小于127这个数字的，也就是说我们用7个比特位就足以包括所有的redo日志类型，而type字段其实是占用1个字节8比特位的，也就是说我们可以省出来一个比特位用来表示该需要保证原子性的操作只产生单一的一条redo日志，示意图如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c6af77a689edc02a3cafabd97c02942128c.png" alt=""></p>
<p>如果type字段的第一个比特为为1，代表该需要保证原子性的操作只产生了单一的一条redo日志，否则表示该需要保证原子性的操作产生了一系列的redo日志。</p>
<h2 id="1-5-redo日志的写入"><a href="#1-5-redo日志的写入" class="headerlink" title="1.5 redo日志的写入"></a>1.5 redo日志的写入</h2><p>我们前边说过，InnoDB为了解决磁盘速度过慢的问题而引入了Buffer Pool。同理，写入redo日志时也不能直接直接写到磁盘上，实际上在服务器启动时就向操作系统申请了一大片称之为redo log buffer的连续内存空间，翻译成中文就是redo日志缓冲区，我们也可以简称为log buffer。这片内存空间被划分成若干个连续的redo log block，就像这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3166883a72a3121c950bc3e38a1ad5ac71c.png" alt=""></p>
<p>向log buffer中写入redo日志的过程是顺序的，也就是先往前边的block中写，当该block的空闲空间用完之后再往下一个block中写。当我们想往log buffer中写入redo日志时，第一个遇到的问题就是应该写在哪个block的哪个偏移量处，所以InnoDB特意提供了一个称之为<code>buf_free</code>的全局变量，该变量指明后续写入的redo日志应该写入到log buffer中的哪个位置，如图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-34ddf107ece3e7f268d7097b01a4bc312f8.png" alt=""></p>
<p>我们前边说过一个mtr执行过程中可能产生若干条redo日志，这些redo日志是一个不可分割的组，所以其实并不是每生成一条redo日志，就将其插入到log buffer中，<strong>而是每个mtr运行过程中产生的日志先暂时存到一个地方，当该mtr结束的时候，将过程中产生的一组redo日志再全部复制到log buffer中（所以同一mtr的一组log都是一起连续出现）</strong>。</p>
<p>我们现在假设有两个名为T1、T2的事务，每个事务都包含2个mtr，每个mtr都产生若干个redo log：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-19d955d351169129ad49610058aa3f07fcd.png" alt=""></p>
<p>不同的事务可能是并发执行的，所以T1、T2之间的mtr可能是交替执行的。</p>
<p>每当一个mtr执行完成时，伴随该mtr生成的一组redo日志就需要被复制到log buffer中，也就是说不同事务的mtr可能是交替写入log buffer的，我们画个示意图（为了美观，我们把一个mtr中产生的所有的redo日志当作一个整体来画）：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-687b270013902ff1f4d3d65701700de0ef5.png" alt=""></p>
<p>从示意图中我们可以看出来，不同的mtr产生的一组redo日志占用的存储空间可能不一样，有的mtr产生的redo日志量很少，比如mtr_t1_1、mtr_t2_1就被放到同一个block中存储，有的mtr产生的redo日志量非常大，比如mtr_t1_2产生的redo日志甚至占用了3个block来存储。</p>
<h2 id="1-6-redo日志的持久化"><a href="#1-6-redo日志的持久化" class="headerlink" title="1.6 redo日志的持久化"></a>1.6 redo日志的持久化</h2><p>前面我们说过，和InnoDB的数据修改一样，redo log也是借助了日志缓冲区来调节磁盘和CPU的矛盾，提升了性能。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0c9e8dfa4efc1da25a6055de1a9232833db.png" alt=""></p>
<h3 id="1-6-1-redo日志的持久化文件"><a href="#1-6-1-redo日志的持久化文件" class="headerlink" title="1.6.1 redo日志的持久化文件"></a>1.6.1 redo日志的持久化文件</h3><p>我们知道数据页持久化后，是保存在ibdata1（没有开启<code>innodb_file_per_table</code>时的共享表空间文件）或者.ibd（开启 <code>innodb_file_per_table</code>时）文件中的。</p>
<p>InnoDB定义了一个组（log group）的概念，一个组内由多个<strong>大小完全相同</strong>的redo log file组成。组内redo log file的数量由变量<code>innodb_log_files_group</code>决定，默认值为2，即两个redo log file。</p>
<blockquote>
<p>log group为redo日志组，其中有多个redo log file。虽然源码中已支持log group 的镜像功能，但是在ha_innobase.cc 文件中禁止了该功能。因此InnoDB存储引擎实际只有一个log group。</p>
</blockquote>
<p>这个组是一个逻辑的概念，并没有真正的文件来表示这是一个组，但是可以通过变量<code>innodb_log_group_home_dir</code>来定义组的目录，redo log file都放在这个目录下，默认是在datadir下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global variables like &quot;innodb_log%&quot;;</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">| Variable_name               | Value    |</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">| innodb_log_buffer_size      | 8388608  |</span><br><span class="line">| innodb_log_compressed_pages | ON       |</span><br><span class="line">| innodb_log_file_size        | 50331648 |</span><br><span class="line">| innodb_log_files_in_group   | 2        |</span><br><span class="line">| innodb_log_group_home_dir   | .&#x2F;       |</span><br><span class="line">+-----------------------------+----------+</span><br><span class="line">[root@xuexi data]# ll &#x2F;mydata&#x2F;data&#x2F;ib*</span><br><span class="line">-rw-rw---- 1 mysql mysql 79691776 Mar 30 23:12 &#x2F;mydata&#x2F;data&#x2F;ibdata1</span><br><span class="line">-rw-rw---- 1 mysql mysql 50331648 Mar 30 23:12 &#x2F;mydata&#x2F;data&#x2F;ib_logfile0</span><br><span class="line">-rw-rw---- 1 mysql mysql 50331648 Mar 30 23:12 &#x2F;mydata&#x2F;data&#x2F;ib_logfile1</span><br></pre></td></tr></table></figure>
<p>可以看到在默认的数据目录下，有两个ib_logfile开头的文件，它们就是log group中的redo log file，而且它们的大小完全一致且等于变量<code>innodb_log_file_size</code>定义的值。</p>
<p>在innodb将log buffer中的redo log block刷到这些log file中时，会以追加写入的方式循环轮训写入。即先在ib_logfile0的尾部追加写，直到满了之后向ib_logfile1追加写。<strong>当ib_logfile1满了，则又重新向ib_logfile0进行覆盖写</strong>。</p>
<p>由于是将log buffer中的日志刷到log file，所以在log file中记录日志的方式也是log block的方式。在每个组的第一个redo log file中，前2KB负责记录4个特定的部分，从2KB之后才开始记录log block。除了第一个redo log file中会记录这2KB的部分外，<strong>log group中的其他log file不会记录这2KB，但是却会腾出这2KB的空间</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0e974f07531a01ac0003212eab079cea38b.png" alt=""></p>
<blockquote>
<p>redo log file的大小对innodb的性能影响非常大，设置的太大，恢复的时候就会时间较长，设置的太小，就会导致在写redo log的时候循环切换redo log file。</p>
</blockquote>
<h3 id="1-6-1-redo日志的持久化策略"><a href="#1-6-1-redo日志的持久化策略" class="headerlink" title="1.6.1 redo日志的持久化策略"></a>1.6.1 redo日志的持久化策略</h3><p>那么，log buffer里面的日志，什么时候刷到log file中呢？</p>
<ol>
<li>事务提交时</li>
<li>当log buffer中有一半的内存空间已经被使用时</li>
<li>log checkpoint 时</li>
</ol>
<p>其中<code>1. 事务提交时</code>是InnoDB事务的持久性的保证，但就像我们在《【InnoDB详解三】锁和事务》一文中介绍的那样，为了性能，InnoDB允许牺牲一定的持久性，允许执行不同的redo日志持久化策略。</p>
<p>MySQL支持用户自定义在事务提交时是否将log buffer中的日志刷log file中。这种控制通过变量 <code>innodb_flush_log_at_trx_commit</code> 的值来决定。该变量有3种值：0、1、2，默认为1。</p>
<ul>
<li>当设置为0的时候，<strong>事务提交时</strong>不会将log buffer中日志写入到os buffer。那什么时候写入呢？由master thread通过每秒一次的频率来异步写入。该值为0时性能较好，但是会丢失掉master thread还没刷新进磁盘部分的数据。<blockquote>
<p>这里我想简单介绍一下master thread，这是InnoDB一个在后台运行的主线程，从名字就能看出这个线程相当的重要。它做的主要工作包括但不限于：刷新日志缓冲，合并插入缓冲，刷新脏页等。master thread大致分为每秒运行一次的操作和每10秒运行一次的操作。master thread中刷新数据，属于checkpoint的一种。</p>
</blockquote>
</li>
<li>当设置为1的时候，当然是最安全的，即每次commit都会强迫flush到log file，但是数据库性能会受一定影响。</li>
<li>当设置为2的时候，每次提交都仅写入到操作系统的内核空间os buffer，然后由操作系统异步每秒调用一次fsync()将os buffer中的日志写入到log file。</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-29558eb65234c525c09f9651c104f0f9bb1.png" alt=""></p>
<h3 id="1-6-3-redo日志持久化策略的性能"><a href="#1-6-3-redo日志持久化策略的性能" class="headerlink" title="1.6.3 redo日志持久化策略的性能"></a>1.6.3 redo日志持久化策略的性能</h3><p>选择刷日志的策略会严重影响数据修改时的性能，特别是刷到磁盘的过程。下例就测试了<code>innodb_flush_log_at_trx_commit</code>分别为0、1、2时的差距。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#创建测试表</span><br><span class="line">drop table if exists test_flush_log;</span><br><span class="line">create table test_flush_log(id int,name char(50))engine&#x3D;innodb;</span><br><span class="line"></span><br><span class="line">#创建插入指定行数的记录到测试表中的存储过程</span><br><span class="line">drop procedure if exists proc;</span><br><span class="line">delimiter $$</span><br><span class="line">create procedure proc(i int)</span><br><span class="line">begin</span><br><span class="line">    declare s int default 1;</span><br><span class="line">    declare c char(50) default repeat(&#39;a&#39;,50);</span><br><span class="line">    while s&lt;&#x3D;i do</span><br><span class="line">        start transaction;</span><br><span class="line">        insert into test_flush_log values(null,c);</span><br><span class="line">        commit;</span><br><span class="line">        set s&#x3D;s+1;</span><br><span class="line">    end while;</span><br><span class="line">end$$</span><br><span class="line">delimiter ;</span><br></pre></td></tr></table></figure>

<p>当前环境下， <code>innodb_flush_log_at_trx_commit</code> 的值为1，即每次提交都刷日志到磁盘。测试此时插入10W条记录的时间。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; call proc(100000);</span><br><span class="line">Query OK, 0 rows affected (15.48 sec)</span><br></pre></td></tr></table></figure>

<p>结果是15.48秒。</p>
<p>再测试值为2的时候，即每次提交都刷新到os buffer，但每秒才刷入磁盘中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set @@global.innodb_flush_log_at_trx_commit&#x3D;2;</span><br><span class="line">mysql&gt; truncate test_flush_log;</span><br><span class="line"></span><br><span class="line">mysql&gt; call proc(100000);</span><br><span class="line">Query OK, 0 rows affected (3.41 sec)</span><br></pre></td></tr></table></figure>

<p>结果插入时间大减，只需3.41秒。</p>
<p>最后测试值为0的时候，即每秒才刷到os buffer和磁盘。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set @@global.innodb_flush_log_at_trx_commit&#x3D;0;</span><br><span class="line">mysql&gt; truncate test_flush_log;</span><br><span class="line"></span><br><span class="line">mysql&gt; call proc(100000);</span><br><span class="line">Query OK, 0 rows affected (2.10 sec)</span><br></pre></td></tr></table></figure>

<p>结果只有2.10秒。</p>
<p>最后可以发现，其实值为2和0的时候，它们的差距并不太大，但2却比0要安全的多。它们都是每秒从os buffer刷到磁盘，它们之间的时间差体现在log buffer刷到os buffer上。因为将log buffer中的日志刷新到os buffer只是内存数据的转移，并没有太大的开销，所以每次提交和每秒刷入差距并不大。可以测试插入更多的数据来比较，以下是插入100W行数据的情况。从结果可见，值为2和0的时候差距并不大，但值为1的性能却差太多。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5a84cadbc4f69368f44b55bbb5b8c4cb33b.png" alt=""></p>
<p>尽管设置为0和2可以大幅度提升插入性能，但是在故障的时候可能会丢失1秒钟数据，这1秒钟很可能有大量的数据，从上面的测试结果看，100W条记录也只消耗了20多秒，1秒钟大约有4W-5W条数据，尽管上述插入的数据简单，但却说明了数据丢失的大量性。<strong>更好的插入数据的做法是将值设置为1，然后修改存储过程，将每次循环都提交修改为只提交一次，这样既能保证数据的一致性，也能提升性能</strong>，修改如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">drop procedure if exists proc;</span><br><span class="line">delimiter $$</span><br><span class="line">create procedure proc(i int)</span><br><span class="line">begin</span><br><span class="line">    declare s int default 1;</span><br><span class="line">    declare c char(50) default repeat(&#39;a&#39;,50);</span><br><span class="line">    start transaction;</span><br><span class="line">    while s&lt;&#x3D;i DO</span><br><span class="line">        insert into test_flush_log values(null,c);</span><br><span class="line">        set s&#x3D;s+1;</span><br><span class="line">    end while;</span><br><span class="line">    commit;</span><br><span class="line">end$$</span><br><span class="line">delimiter ;</span><br></pre></td></tr></table></figure>

<p>测试值为1时的情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set @@global.innodb_flush_log_at_trx_commit&#x3D;1;</span><br><span class="line">mysql&gt; truncate test_flush_log;</span><br><span class="line"></span><br><span class="line">mysql&gt; call proc(1000000);</span><br><span class="line">Query OK, 0 rows affected (11.26 sec)</span><br></pre></td></tr></table></figure>


<h2 id="1-7-利用redo日志做系统恢复"><a href="#1-7-利用redo日志做系统恢复" class="headerlink" title="1.7 利用redo日志做系统恢复"></a>1.7 利用redo日志做系统恢复</h2><h3 id="1-7-1-LSN和Checkpoint"><a href="#1-7-1-LSN和Checkpoint" class="headerlink" title="1.7.1 LSN和Checkpoint"></a>1.7.1 LSN和Checkpoint</h3><p>说到恢复，就不得不提LSN，我们在《【InnoDB详解一】体系架构和关键特性》一文中已经有过介绍，为方便计，我们粘贴过来。</p>
<p>对于InnoDB存储引擎而言，是通过LSN（Log Sequence Number）来标记版本的。LSN是一个一直递增的8字节整型数字，<strong>表示事务写入到redo日志的字节总量（注意LSN的含义是日志的字节总量）</strong>。每个页都有LSN字段，重做日志中也有LSN，Checkpoint也有LSN。</p>
<p>在每个数据页头部的LSN字段，记录当前页最后一次数据修改所对应的重做日志的LSN值，用于在recovery时对比重做日志LSN值，以决定是否对该页进行恢复数据。前面说的checkpoint也是有LSN号记录的，checkpoint的LSN表示已刷新到磁盘的最新的数据所对应的重做日志的LSN，LSN号串联起一个事务开始到恢复的过程。</p>
<blockquote>
<p>比如redo日志的文件是600M，LSN的值已经为1G了，也就是LSN=1000000000。因为redo日志是循环使用的，所以我们可以知道LSN=1G=600M+400M，所以redo日志已经重复使用过一整遍后，目前最新的可写入点，在redo日志偏移量400M的位置。</p>
</blockquote>
<blockquote>
<p>我们执行了一个update语句，产生了一个事务t，这次数据的修改，假设产生了512个字节的日志量，那么LSN就会增加到1000000512，而事务t的修改使得A、B、C三个数据页成为了脏页，那么A、B、C三个数据页的LSN值就会更新为1000000512。如果这时，触发了checkpoint，刚刚好将事务t为止的修改刷新到磁盘，那么此时checkpoint LSN也是1000000512。</p>
</blockquote>
<p>除了LSN之外，我们还要知道Checkpoint，同样在《【InnoDB详解一】体系架构和关键特性》一文中已经有过介绍。简单来说就是Checkpoint会定时将buffer里面的redo日志持久化到磁盘。</p>
<h3 id="1-7-2-恢复过程"><a href="#1-7-2-恢复过程" class="headerlink" title="1.7.2 恢复过程"></a>1.7.2 恢复过程</h3><p>InnoDB存储引擎在启动时<strong>不管上次数据库运行时是否正常关闭，都会尝试进行恢复</strong>。因为重做日志记录的是物理日志，因此恢复的速度比逻辑日志，如二进制日毒要快很多。与此同时，InnoDB存储引擎自身也对恢复进行了一定程度的优化，如顺序读取及并行应用重做日志，这样可以进一步地提高数据库恢复的速度。</p>
<p>由于checkpoint会记录已经刷新到磁盘页上的LSN，因此在恢复过程中仅需恢复checkpoint开始的日志部分。假设当数据库在checkpoint的LSN为10000时发生宕机，恢复操作仅恢复LSN10000～13000范围内的日志。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f46c3e46759e30a6596ccab8491f2c7c8af.png" alt=""></p>
<p>恢复的过程中，系统会根据redo日志的类型，调用相关的恢复函数进行恢复，而redo日志中的那些数据就可以被当成是调用这个函数所需的参数。从而使数据库恢复原样。</p>
<p>注意，调用相关的恢复函数的结果是幂等的，即便是insert一条行记录的redo日志，即便多次被恢复函数调用，其结果也是幂等的。</p>
<h1 id="2-undo-log"><a href="#2-undo-log" class="headerlink" title="2 undo log"></a>2 undo log</h1><p>undo log有两个作用：</p>
<ol>
<li>提供回滚<ul>
<li>InnoDB在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。</li>
</ul>
</li>
<li>多个行版本控制(MVCC)<ul>
<li>有时候应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而根据事务的版本和行记录的版本匹配，让用户实现非锁定一致性读取。</li>
</ul>
</li>
</ol>
<p>undo log和redo log记录物理日志不一样，<strong>它是逻辑日志</strong>。因此只是将数据库<strong>逻辑地</strong>恢复到原来的样子。所有修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能大不相同。</p>
<p>这是因为在多用户并发系统中，可能会有数十、数百甚至数千个并发事务。数据库的主要任务就是协调对数据记录的并发访问。比如，一个事务在修改当前一个页中某几条记录，同时还有别的事务在对同一个页中另几条记录进行修改。因此，不能将一个页回滚到事务开始的样子，<strong>因为这样会影响其他事务正在进行的工作</strong>。</p>
<p>例如，用户执行了一个INSERT 10W条记录的事务，这个事务会导致分配一个新的段，即表空间会增大。在用户执行ROLLBACK时，会将插入的事务进行回滚，但是表空间的大小<strong>并不会因此而收缩</strong>。因此，当InnoDB存储引擎回滚时，它实际上做的是与先前相反的工作。</p>
<p><strong>可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录</strong>。</p>
<p><strong>undo log是采用段(segment)的方式来记录的</strong>，每个undo操作在记录的时候占用一个undo log segment。</p>
<p><strong>另外，undo log也会产生redo log，因为undo log也要实现持久性保护</strong>。</p>
<h2 id="2-1-purge线程"><a href="#2-1-purge线程" class="headerlink" title="2.1 purge线程"></a>2.1 purge线程</h2><p>在详述undo log之前，我们需要了解一个前置知识点：purge线程</p>
<p>delete和update操作可能并不直接删除原有的数据。例如表t（a,b）如下的SQL语句∶</p>
<p><code>DELETE FROM t WHERE a=1;</code></p>
<p>表t上列a有聚集索引，列b上有辅助索引。</p>
<p>对于上述的delete操作，在MVCC的章节介绍已经知道仅是将主键列等于1的记录delete flag设置为1，记录并没有被删除，即记录还是存在于B+树中。其次，对辅助索引上a等于1，b等于1的记录同样没有做任何处理，甚至没有产生undo log。而真正删除这行记录的操作其实被”延时”了，最终在 purge操作中完成。</p>
<p>purge用于最终完成delete和 update操作。这样设计是因为InnoDB存储引擎支持MVCC，所以记录不能在事务提交时立即进行处理。这时其他事物可能正在引用这行，故InnoDB存储引擎需要保存记录之前的版本。而是否可以删除该条记录通过purge来进行判断。若该行记录已不被任何其他事务引用，那么就可以进行真正的delete操作。</p>
<p>可见，purge操作是清理之前的delete和update操作，将上述操作”最终”完成。而实际执行的操作为delete操作，清理之前行记录的版本。</p>
<p>为了节省存储空间，InnoDB存储引擎的undo log设计是这样的：</p>
<ol>
<li>一个页上允许多个事务的undo log存在。虽然这不代表事务在全局过程中提交的顺序，但是后面的事务产生的undo log总在最后。</li>
<li>此外，ImnoDB存储引擎还有一个history列表，它根据事务提交的顺序，将undo log进行链接。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-88c56db52cf6ad7facfd77561eae1e1e56b.png" alt=""></p>
<p>在图7-17的例子中，history list表示<strong>按照事务提交的顺序</strong>将undo log进行组织。在InnoDB存储引擎的设计中，先提交的事务总在尾端。</p>
<p>undo page存放了undo log，由于可以重用，因此一个undo page中可能存放了<strong>多个不同事务</strong>的undo log。tx5的灰色阴影表示该 undo log还被其他事务引用。</p>
<p>执行 purge的过程中，InnoDB存储引擎首先从history list中找到第一个需要被清理的记录，这里为trx1，清理之后InnoDB存储引擎会在trx1的undo log所在的页中继续寻找是否存在可以被清理的记录，这里会找到事务trx3，接着找到trx5，但是发现trx5被其他事务所引用而不能清理，故去再次去history list中查找，发现这时最尾端的记录为trx2，接着找到trx2所在的页，然后依次再把事务trx6、trx4的记录进行清理。</p>
<p>InnoDB存储引擎这种先从history list中找undo log，然后再从undo page中找undo log的设计模式是<strong>为了避免大量的随机读取操作，从而提高 purge的效率</strong>。</p>
<h2 id="2-2-undo-log的存储方式"><a href="#2-2-undo-log的存储方式" class="headerlink" title="2.2 undo log的存储方式"></a>2.2 undo log的存储方式</h2><p>Innodb存储引擎对undo的管理采用段（segment）的方式。rollback segment称为回滚段，每个回滚段中有1024个undo log segment。</p>
<p>在以前老版本，只支持1个rollback segment，这样就只能记录1024个undo log segment。后来MySQL5.5可以支持128个rollback segment，即支持<code>128*1024</code>个undo操作，还可以通过变量 <code>innodb_undo_logs</code> (5.6版本以前该变量是 innodb_rollback_segments )自定义多少个rollback segment，默认值为128。</p>
<p>undo log默认存放在共享表空间中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@xuexi data]# ll &#x2F;mydata&#x2F;data&#x2F;ibda*</span><br><span class="line">-rw-rw---- 1 mysql mysql 79691776 Mar 31 01:42 &#x2F;mydata&#x2F;data&#x2F;ibdata1</span><br></pre></td></tr></table></figure>

<p>同样的，如果开启了 innodb_file_per_table ，将放在每个表的.ibd文件中。</p>
<p>在MySQL5.6中，undo的存放位置还可以通过变量 <code>innodb_undo_directory</code> 来自定义存放目录，默认值为”.”表示datadir。</p>
<p>默认rollback segment全部写在一个文件中，但可以通过设置变量 <code>innodb_undo_tablespaces</code> 平均分配到多少个文件中。该变量默认值为0，即全部写入一个表空间文件。该变量为静态变量，只能在数据库示例停止状态下修改，如写入配置文件或启动时带上对应参数。但是innodb存储引擎在启动过程中提示，不建议修改为非0的值，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: Expected to open 3 undo tablespaces but was able</span><br><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: to find only 0 undo tablespaces.</span><br><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: Set the innodb_undo_tablespaces parameter to the</span><br><span class="line">2017-03-31 13:16:00 7f665bfab720 InnoDB: correct value and retry. Suggested value is 0</span><br></pre></td></tr></table></figure>
<h2 id="2-3-undo-log的数据结构"><a href="#2-3-undo-log的数据结构" class="headerlink" title="2.3 undo log的数据结构"></a>2.3 undo log的数据结构</h2><p>InnoDB采用回滚段的方式来维护undo log是为了保证事务并发操作时，在写各自的undo log时不产生冲突。回滚段实际上是一种 Undo 文件组织方式，每个回滚段又有多个undo log slot。具体的文件组织方式如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a25c818ad84c7493b4eb9f92c1c8ea108b8.png" alt=""></p>
<p>当事务开启时，会给它指定使用哪个rollback segment，然后在真正执行操作时，分配具体的slot，通常会有两种slot：</p>
<ul>
<li>insert_undo：只用于事务内的insert语句<ul>
<li>insert undo log是指在insert操作中产生的undo log。因为insert操作的记录，只对事务本身可见，对其他事务不可见（这是事务隔离性的要求），故该undo log不会被其他事务引用，不用进行purge操作，可以在事务提交后直接删除（事务提交后就没有回滚需求了）。</li>
</ul>
</li>
<li>update_undo: 只用于事务内的update语句<ul>
<li>update undo log记录的是对delete和 update操作产生的undo log。该undo log可能需要提供MVCC机制，因此不能在事务提交时就进行删除。提交时放入undo log链表，等待 purge线程进行最后的删除。</li>
</ul>
</li>
</ul>
<p>通常如果事务内只包含一种操作类型，则只使用一个slot。但也有例外，例如insert操作，如果insert的记录在page上已经存在了，但是是无效的，那么就可以直接通过更新这条无效记录的方式来实现插入，这时候使用的是update_undo。</p>
<h3 id="2-3-1-insert-undo的数据结构"><a href="#2-3-1-insert-undo的数据结构" class="headerlink" title="2.3.1 insert_undo的数据结构"></a>2.3.1 insert_undo的数据结构</h3><p>insert undo log的数据结构如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1886e6ec7203188f0fa788d3d6d5c1b6c40.png" alt=""></p>
<p>其中<code>*</code>表示对存储的字段进行了压缩。</p>
<ol>
<li>insete undo log开始的前两个字节next 记录的是下一个undo log的位置，通过该next的字节可以知道一个undo log所占的空间字节数。</li>
<li>类似地，尾部的两个字节记录的是undo log的开始位置。</li>
<li>type_cmpl占用一个字节，记录的是undo的类型，对于insert undo log，该值总是为11。</li>
<li>undo_no记录事务的ID，table_id记录undo log所对应的表对象。这两个值都是在压缩后保存的。</li>
<li>接着的部分记录了所有主键的列和值。在进行 rollback操作时，根据这些值可以定位到具体的记录，然后进行删除即可。</li>
</ol>
<h3 id="2-3-2-update-undo的数据结构"><a href="#2-3-2-update-undo的数据结构" class="headerlink" title="2.3.2 update_undo的数据结构"></a>2.3.2 update_undo的数据结构</h3><p>update undo log的结构如图所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1add9223f47f7e189d289b96332cf7f655e.png" alt=""></p>
<p>update undo log相对于之前介绍的insert undo log，记录的内容更多，所需点用的空间也更大。</p>
<ol>
<li>next、start、undo_no、table_id与之前介绍的insert undo log部分相同。</li>
<li>这里的 type_cmpl，由于update undo log本身还有分类，故其可能的值如下∶<ul>
<li>12 TRXUNDO_UPD_EXIST_REC更新 non-delete-mark的记录</li>
<li>13 TRX_UNDO_UPD_DEL_REC将delete的记录标记为not delete </li>
<li>14 TRX_UNDO_DEL_MARK_REC将记录标记为delete</li>
</ul>
</li>
<li>接着的部分记录 update_vector信息，update_vector表示update操作导致发生改变的列。每个修改的列信息都要记录的undo log中。</li>
</ol>
<p>对于不同的undo log类型，可能还需要记录对索引列所做的修改。</p>
<h2 id="2-4-相关参数"><a href="#2-4-相关参数" class="headerlink" title="2.4 相关参数"></a>2.4 相关参数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show global variables like &#39;%undo%&#39;;</span><br><span class="line">+--------------------------+------------+</span><br><span class="line">| Variable_name            | Value      |</span><br><span class="line">+--------------------------+------------+</span><br><span class="line">| innodb_max_undo_log_size | 1073741824 |</span><br><span class="line">| innodb_undo_directory    | .&#x2F;         |</span><br><span class="line">| innodb_undo_log_truncate | OFF        |</span><br><span class="line">| innodb_undo_logs         | 128        |</span><br><span class="line">| innodb_undo_tablespaces  | 3          |</span><br><span class="line">+--------------------------+------------+</span><br><span class="line"> </span><br><span class="line">mysql&gt; show global variables like &#39;%truncate%&#39;;</span><br><span class="line">+--------------------------------------+-------+</span><br><span class="line">| Variable_name                        | Value |</span><br><span class="line">+--------------------------------------+-------+</span><br><span class="line">| innodb_purge_rseg_truncate_frequency | 128   |</span><br><span class="line">| innodb_undo_log_truncate             | OFF   |</span><br><span class="line">+--------------------------------------+-------+</span><br></pre></td></tr></table></figure>
<ul>
<li>innodb_undo_directory<ul>
<li>变量 <code>innodb_undo_directory</code> 来自定义存放目录，默认值为”.”表示datadir。</li>
</ul>
</li>
<li>innodb_max_undo_log_size<ul>
<li>控制最大undo tablespace文件的大小，当启动了innodb_undo_log_truncate 时，undo tablespace 超过innodb_max_undo_log_size 阀值时才会去尝试truncate。该值默认大小为1G，truncate后的大小默认为10M。</li>
</ul>
</li>
<li>innodb_undo_tablespaces<ul>
<li>设置undo独立表空间个数，范围为0-128， 默认为0，0表示表示不开启独立undo表空间，且 undo日志存储在ibdata文件中。该参数只能在最开始初始化MySQL实例的时候指定，如果实例已创建，这个参数是不能变动的，如果在数据库配置文件 .cnf 中指定innodb_undo_tablespaces 的个数大于实例创建时的指定个数，则会启动失败，提示该参数设置有误。</li>
<li>设置该参数后，会在路径inodb_undo_directory看到undo为前缀的文件，该文件就代表rollback segment文件。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-dfb2af1207e6212f287c7518853aae22234.png" alt=""></li>
</ul>
</li>
<li><strong>innodb_undo_log_truncate</strong><ul>
<li>InnoDB的purge线程，根据innodb_undo_log_truncate设置开启或关闭、innodb_max_undo_log_size的参数值，以及truncate的频率来进行空间回收和undo file的重新初始化。</li>
<li>该参数生效的前提是，已设置独立表空间且独立表空间个数大于等于2个。</li>
<li>purge线程在truncate undo log file的过程中，需要检查该文件上是否还有活动事务，如果没有，需要把该undo log file标记为不可分配，这个时候，undo log 都会记录到其他文件上，所以至少需要2个独立表空间文件，才能进行truncate 操作。</li>
<li>标注不可分配后，会创建一个独立的文件undo__trunc.log，记录现在正在truncate 某个undo log文件，然后开始初始化undo log file到10M，操作结束后，删除表示truncate动作的 undo__trunc.log 文件，这个文件保证了即使在truncate过程中发生了故障重启数据库服务，重启后，服务发现这个文件，也会继续完成truncate操作，删除文件结束后，标识该undo log file可分配。</li>
</ul>
</li>
<li>innodb_purge_rseg_truncate_frequency<ul>
<li>用于控制purge回滚段的频度，默认为128。假设设置为n，则说明，当Innodb Purge操作的协调线程 purge事务128次时，就会触发一次History purge，检查当前的undo log 表空间状态是否会触发truncate。</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/" itemprop="url">【InnoDB详解三】锁和事务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-21T21:26:54+08:00">
                2020-09-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/21/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%89%E3%80%91%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/21/【InnoDB详解三】锁和事务/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  9.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  34
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-InnoDB锁机制"><a href="#1-InnoDB锁机制" class="headerlink" title="1. InnoDB锁机制"></a>1. InnoDB锁机制</h1><p>锁是数据库系统区别于文件系统的一个关键特性。锁机制用于管理对共享资源的并发访问。InnoDB存储引擎会在行级别上对表数据上锁，这固然不错。不过InnoDB存储引擎也会在数据库内部其他多个地方使用锁，从而允许对多种不同资源提供并发访问。例如，操作缓冲池中的LRU列表，删除、添加、移动LRU列表中的元素，为了保证一致性，必须有锁的介入。数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。</p>
<p>InnoDB存储引擎锁的实现和Oracle数据库非常类似，提供一致性的非锁定读、行级锁支持。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。</p>
<h2 id="1-1-InnoDB中锁的类型"><a href="#1-1-InnoDB中锁的类型" class="headerlink" title="1.1 InnoDB中锁的类型"></a>1.1 InnoDB中锁的类型</h2><h3 id="1-1-1-共享锁和排他锁"><a href="#1-1-1-共享锁和排他锁" class="headerlink" title="1.1.1 共享锁和排他锁"></a>1.1.1 共享锁和排他锁</h3><p>InoDB存储引擎实现了如下两种标准的锁∶</p>
<ol>
<li>共享锁（S Lock），S是Share的缩写，也叫作<strong>读锁</strong>，允许事务读取共享资源的数据。</li>
<li>排他锁（X Lock），X是Exclusive的缩写，也叫作<strong>写锁</strong>，允许事务删除或更新资源的数据。</li>
</ol>
<p>InnoDB存储引擎支持多粒度（granular）锁定，S Lock和X Lock锁定的对象可以是行，也可以是页，也可以是表。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a9dd75ae92e3c9b415c077c8106a7bc91be.png" alt=""></p>
<p>如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r 的共享锁，因为读取并没有改变行r的数据，我们称这种情况为锁兼容（Lock Compatible）。</p>
<p>但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁才行——这种情况称为锁不兼容。</p>
<p>下图显示了共享锁和排他锁的兼容性：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-98ab6eecdfd147396fad62b458bc3021d40.png" alt=""></p>
<blockquote>
<p>总结为一句话，只有二者都是共享锁的时候才会兼容。</p>
</blockquote>
<h3 id="1-1-2-意向锁"><a href="#1-1-2-意向锁" class="headerlink" title="1.1.2 意向锁"></a>1.1.2 意向锁</h3><p>我们之前说过，S/X锁针对的对象可以是行，也可以是表。这种多粒度（granular）锁定是InnoDB锁机制的特点，但多粒度锁定会不可避免的带来一种问题：</p>
<ul>
<li>假设事务A锁住了表中的一行，让这一行只能读，不能写。</li>
<li>之后，事务B申请整个表的写锁。</li>
<li>如果事务B申请成功，那么理论上它就能修改表中的任意一行，这与A持有的行锁是冲突的。</li>
</ul>
<p>数据库需要避免这种冲突，就是说要让B的申请被阻塞，直到A释放了行锁。那么数据库要怎么判断这个冲突呢？</p>
<ol>
<li>step1：判断表是否已被其他事务用表锁锁表</li>
<li>step2：判断表中的每一行是否已被行锁锁住。</li>
</ol>
<p>注意step2，这样的判断方法需要遍历整个表，效率实在不高，于是就有了意向锁。</p>
<p>在意向锁存在的情况下，<strong>事务A必须先申请表的意向共享锁，成功后才能申请表中行的行锁</strong>。于是上面的判断可以改成：</p>
<ol>
<li>step1：判断表是否已被其他事务用表锁锁表</li>
<li>step2：发现表上有意向锁：<ol>
<li>如果是意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。</li>
<li>如果是意向排他锁，说明表中有些行被排他行锁锁住了，因此，事务B申请表的写锁会被阻塞。</li>
</ol>
</li>
</ol>
<p>是的没错，InnoDB的意向锁也支持如下两种，不过意向锁不是多粒度的，<strong>它只支持表级锁定</strong>：</p>
<ol>
<li>意向共享锁（IS Lock），表示事务已经获得一张表中某几行的共享锁。</li>
<li>意向排他锁（IX Lock），表示事务已经获得一张表中某几行的排他锁。</li>
</ol>
<blockquote>
<p>IS和IX的I是intention的缩写，意向的意思可以理解为：一个事务在申请行级锁前，先宣称对行所在表的读/写的意向，宣称之后，在不兼容的情况，其他锁就会冲突了。</p>
</blockquote>
<p>因为意向锁是表级锁，所以也不存在和行级锁/页级锁的兼容性问题，但意向锁之间，以及意向锁和表级共享/排他锁之间是存在不兼容的情况的，具体兼容性如下表（注意下标的S和X是表级锁）：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7b141535385456447ca04fd14e64f38744b.png" alt=""></p>
<blockquote>
<p>一句话：意向锁内部都兼容，除此之外，意向共享锁只和表级共享锁兼容。</p>
</blockquote>
<h3 id="1-1-3-自增锁"><a href="#1-1-3-自增锁" class="headerlink" title="1.1.3 自增锁"></a>1.1.3 自增锁</h3><p>自增长在数据库中是非常常见的一种属性，也是很多DBA或开发人员首选的主键方式。在InnoDB存储引擎的内存结构中，对每个含有自增长值的表都有一个自增长计数器（auto-increment counter）。当对含有自增长的计数器的表进行插入操作时，这个计数器会被初始化，执行如下的语句来得到计数器的值∶</p>
<p><code>SELECT MAX(auto_inc_col) FROM t FOR UPDATE;</code></p>
<p>插入操作会依据这个自增长的计数器值加1赋予自增长列。这个实现方式称做AUTO-INC Locking。<strong>这种锁其实是采用一种特殊的表锁机制，为了提高插人的性能，锁不是在一个事务完成后才释放，而是在完成对自增长值插人的SQL语句后立即释放</strong>。</p>
<h2 id="1-2-行锁的加锁方式"><a href="#1-2-行锁的加锁方式" class="headerlink" title="1.2 行锁的加锁方式"></a>1.2 行锁的加锁方式</h2><p>前面我们说过，InnoDB存储引擎支持多粒度（granular）锁定，S Lock和X Lock锁定的对象可以是行，也可以是页，也可以是表。</p>
<p>不过当锁定的对象是<strong>行记录</strong>的时候，InnoDB有三种加锁方式，或者说，有三种锁的算法：</p>
<ol>
<li>Record Lock：锁单条行记录；</li>
<li>Gap Lock：间隙锁，锁定一个范围，但不包含记录本身</li>
<li>Next-Key Lock：Gap Lock+RecordLock，记录锁和间隙锁的组合，锁定一个范围，并且锁定记录本身</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-a52d4cd7eca7873d81b9ba93bd670e0ba7d.png" alt=""></p>
<p><strong>这里需要重点注意间隙锁，它可以解决幻读</strong>，因为MySQL默认的事务隔离级别是<code>可重复读</code>，其底层就是使用Next-Key Lock，也就是说Next-Key Lock是目前InnoDB对行锁默认的加锁方式。下文我们再对各个事务隔离级别的底层实现做描述。</p>
<blockquote>
<p>InnoDB的行锁是通过给索引项加锁实现的（这个我们后面会说到），这就意味着只有通过索引条件检索数据时，InnoDB才使用行锁，否则使用表锁。也就是说，<strong>如果批量update，如果条件的字段没有索引，将会锁表，如果有索引，则只会出现行锁</strong>。</p>
</blockquote>
<h2 id="1-3-并发控制协议"><a href="#1-3-并发控制协议" class="headerlink" title="1.3 并发控制协议"></a>1.3 并发控制协议</h2><h3 id="1-3-1-MVCC和一致性非锁定读"><a href="#1-3-1-MVCC和一致性非锁定读" class="headerlink" title="1.3.1 MVCC和一致性非锁定读"></a>1.3.1 MVCC和一致性非锁定读</h3><p>MVCC全称Multi-Version Concurrent Control，即多版本并发控制，是一种乐观锁的实现。它最大的特点是：读可不加锁，读写不冲突。并发性能很高。</p>
<p>MVCC中默认的读是<strong>非锁定的一致性读</strong>，也称快照读。读取的是记录的可见版本，当读取的的记录正在被别的事务并发修改时，会读取记录的历史版本。读取过程中不对记录加锁。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-03b0ae53e0ab9979a20a7de00545fa3a388.png" alt=""></p>
<p>如上图，如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB存储引擎会去读取行的一个快照数据。之所以称其为非锁定读，因为不需要等待访问的行上X锁的释放。</p>
<p>那么快照数据如何产生呢？</p>
<p>在InnoDB的行记录的列数据中有两个隐藏的列：当前行<strong>创建时的版本号</strong>和<strong>删除时的版本号</strong>（可能为空，其实还有一列称为回滚指针，用于事务回滚，这里暂不讨论）。这里的版本号并不是实际的时间值，而是系统版本号。每开始新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询每行记录的版本号进行比较。</p>
<p>每个事务又有自己的版本号，这样事务内执行CRUD操作时，就通过版本号的比较来达到数据版本控制的目的。</p>
<p>MVCC的实现依赖于undo日志（undo日志具体可见本站博客《【InnoDB详解四】redo log和undo log》），该日志通过回滚指针把一个数据行（Record）的所有快照数据（也都是数据行）连接起来：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cd6044f25be571296c160c23277dc144dc8.png" alt=""></p>
<blockquote>
<p>后文会讲到，MVCC主要用于<strong>可重复读</strong>和<strong>读已提交</strong>这两种事务隔离级别的实现中。</p>
</blockquote>
<p>那么MVCC下InnoDB的增删查改是怎么运作的呢？</p>
<h4 id="1-3-1-1-MVCC下的insert"><a href="#1-3-1-1-MVCC下的insert" class="headerlink" title="1.3.1.1 MVCC下的insert"></a>1.3.1.1 MVCC下的insert</h4><p>插入时，记录的版本号即当前事务的版本号。我们执行一条数据语句：</p>
<p><code>insert into testmvcc values(1,&quot;test&quot;);</code></p>
<p>假设事务id为1，那么插入后的数据行如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-893019c4b35d3863e2820831cd3236e0d37.png" alt=""></p>
<h4 id="1-3-1-2-MVCC下的update"><a href="#1-3-1-2-MVCC下的update" class="headerlink" title="1.3.1.2 MVCC下的update"></a>1.3.1.2 MVCC下的update</h4><p>在更新操作的时候，采用的是先标记旧的那行记录为已删除，并且删除版本号是事务版本号，然后插入一行新的记录的方式。</p>
<p>比如，针对上面那行记录，把name字段更新：</p>
<p><code>update table set name= &#39;new_value&#39; where id=1;</code></p>
<p>假设事务id为2，那么更新后的结果如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-18f88aa062b8044a6961d63c28231563dc3.png" alt=""></p>
<h4 id="1-3-1-3-MVCC下的delete"><a href="#1-3-1-3-MVCC下的delete" class="headerlink" title="1.3.1.3 MVCC下的delete"></a>1.3.1.3 MVCC下的delete</h4><p>在删除操作的时候，就把事务版本号作为删除版本号。比如</p>
<p><code>delete from table where id=1;</code></p>
<p>假设事务id为3，那么删除后的结果如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-37153c8fa1ea12e85f2cfd6f4d1b46c6bec.png" alt=""></p>
<h4 id="1-3-1-4-MVCC下的select"><a href="#1-3-1-4-MVCC下的select" class="headerlink" title="1.3.1.4 MVCC下的select"></a>1.3.1.4 MVCC下的select</h4><p>综合上文，我们可以知道，在查询时要<strong>符合以下两个条件的记录</strong>才能被事务查询出来：</p>
<ol>
<li><p>删除版本号<strong>未指定</strong>或者<strong>大于当前事务版本号</strong>，即要确保查询事务开启时，要读取的行未被删除。(比如上述事务id为2的事务查询时，依然能读取到被id=3的事务所删除的数据行)</p>
</li>
<li><p>创建版本号<strong>小于</strong>或者<strong>等于</strong>当前事务版本号 ，即要确保查询事务开启时，要读取的行记录<strong>正在</strong>（等于的情况）或者<strong>已经</strong>（小于的情况）被创建。(比如上述事务id为2的事务查询时，只能读取到被id=1或者id=2的事务所创建的行)</p>
</li>
</ol>
<h3 id="1-3-2-LBCC和一致性锁定读"><a href="#1-3-2-LBCC和一致性锁定读" class="headerlink" title="1.3.2 LBCC和一致性锁定读"></a>1.3.2 LBCC和一致性锁定读</h3><p>在前文中我们说到，默认配置下，即事务的隔离级别为<code>可重复读</code>模式下，InnoDB存储引擎的SELECT操作使用一致性非锁定读。但是在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。而这要求数据库支持加锁语句，即使是对于SELECT的只读操作。</p>
<p>LBCC全称Lock-Based Concurrent Control，即基于锁的并发控制，是一种悲观锁的实现。LBCC中的读是<strong>一致性锁定读</strong>，也称当前读：读取的是记录的最新版本，并且会对记录加锁。</p>
<p>InnoDB存储引擎对于SELECT语句支持两种一致性的锁定读（locking read）操作∶</p>
<ol>
<li>SELECT…FOR UPDATE<ul>
<li>SELECT…FOR UPDATE 对读取的行记录加一个X锁，其他事务不能对已锁定的行加上任何锁。</li>
</ul>
</li>
<li>SELECT…LOCK IN SHARE MODE<ul>
<li>SELECT.·…LOCKIN SHARE MODE对读取的行记录加一个S锁，其他事务可以向被锁定的行加S锁，但是如果加X锁，则会被阻塞。</li>
</ul>
</li>
</ol>
<blockquote>
<p>对于一致性非锁定读，即使读取的行已被执行了SELECT…FOR UPDATE，也是可以进行读取的，这和之前讨论的情况一样。</p>
</blockquote>
<blockquote>
<p>此外，SELECT.…FOR UPDATE，SELECT.…·LOCK IN SHARE MODE必须在一个事务中，当事务提交了，锁也就释放了。因此在使用上述两句SELECT锁定语句时，务必加上BEGIN，STARTTRANSACTION或者SET AUTOCOMMIT=0。</p>
</blockquote>
<blockquote>
<p>LBCC被用在seraliable隔离级别中，seraliable级别会对每个select语句后面自动加上lock in share mode。</p>
</blockquote>
<h2 id="1-4-锁的数据结构"><a href="#1-4-锁的数据结构" class="headerlink" title="1.4 锁的数据结构"></a>1.4 锁的数据结构</h2><p>锁升级（Lock Escalation）是指将当前锁的粒度降低。举例来说，如果一个页中，有大量的行都被加了锁，那么维护这么多的锁对象，需要占用大量内存，那为了节约内存提高效率，数据库会将锁升级，从行锁升级为页锁。这样只需要维护一个页锁对象就可以替代可能是几千个行锁对象了。同理，页锁升级为表锁也是同样的道理。</p>
<p>如果在数据库的设计中认为锁是一种稀有资源，而且想避免锁的开销，那数据库中会频繁出现锁升级现象，虽然这种做法会降低并发性能。</p>
<p>这种升级保护了系统资源，防止系统使用太多的内存来维护锁，在一定程度上提高了效率。</p>
<p><strong>然而，InnoDB不需要锁升级机制，因为InnoDB对锁对象的维护十分特殊</strong>，InnoDB并非将行锁维护在每一个行记录中，而是使用了位图+哈希表，前者保证了占用少量内存，后者保证了查询效率极高。</p>
<h3 id="1-4-1-锁对象和位图"><a href="#1-4-1-锁对象和位图" class="headerlink" title="1.4.1 锁对象和位图"></a>1.4.1 锁对象和位图</h3><p>InnoDB定义了<strong>页锁结构</strong>和<strong>表锁结构</strong>两种数据结构，来分别描述<strong>行级锁和表级锁</strong></p>
<h4 id="1-4-1-1-页锁结构"><a href="#1-4-1-1-页锁结构" class="headerlink" title="1.4.1.1 页锁结构"></a>1.4.1.1 页锁结构</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;页锁结构</span><br><span class="line">typedef struct lock_rec_struct        lock_rec_t</span><br><span class="line">struct lock_rec_struct&#123;</span><br><span class="line">    ulint space;    &#x2F;*space id*&#x2F;</span><br><span class="line">    ulint page_no;  &#x2F;*page number*&#x2F;</span><br><span class="line">    unint n_bits;   &#x2F;*number of bits in the lock bitmap*&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>space+page_no可以唯一定位一个页，所以InnoDB中有多少个数据页，就最多有多少个页锁对象。</li>
<li>n_bits是一个位图。如果要查看锁对象某行记录是否上锁，只需要根据space／page_no找到对应的页，然后根据位图中对应位置是否是1来决定此行记录是否上锁。</li>
</ul>
<p>假设页中有250条行记录，那么位图n_bit的占用空间为=250bit+64bit(额外预留的)=314bit，那么实际位图需要40个字节（320bit）用于位图的管理，若页中heap_no为2，3，4的记录都已经上锁，则对应的数据结构lock_rec_t 在内存中的关系如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a64fdbec884bcbc7141720cf86b5edf2092.png" alt=""></p>
<p>我们可以看到，行级锁并非维护在数据页的行记录里面，而是另外寻了一处空间来存放，这种锁的实现机制可以最大程度地重用锁对象，节省系统资源，不存在锁升级的问题。</p>
<p>可想而知，如果每个行锁都生成一个锁对象，将会导致严重的性能损耗，比如接近于全表扫描的查询就会生成大量的锁对象，内存开销将会很大。位图的方式很好地避免了这个问题。</p>
<h4 id="1-4-1-2-表锁结构"><a href="#1-4-1-2-表锁结构" class="headerlink" title="1.4.1.2 表锁结构"></a>1.4.1.2 表锁结构</h4><p>表级锁的数据结构（用于表的意向锁和自增锁）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">typedef struct lock_table_struct lock_table_t;</span><br><span class="line">struct lock_table_struct &#123;</span><br><span class="line">    dict_table_t*          table;   &#x2F;*database table in dictionary cache*&#x2F;</span><br><span class="line">    UT_LIST_NODE_T(lock_t) locks;   &#x2F;*list of locks on the same table*&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#define UT_LIST_NODE_T(TYPE)</span><br><span class="line">struct &#123;</span><br><span class="line">       TYPE *   prev;       &#x2F;* pointer to the previous node,NULL if start of list *&#x2F;</span><br><span class="line">       TYPE *   next;       &#x2F;* pointer to next node, NULL if end of list *&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一目了然，结构内的table变量是一个表结构（dict_table_t）的指针，它表示被锁住的是哪个表，一个表锁结构对应一张表。</p>
<p>然后locks变量是lock_struct结构（<code>typedef struct lock_struct  lock_t;</code>）组成的链表节点，UT_LIST_NODE_T是一个典型的链表节点结构，有前驱和后驱。</p>
<p>lock_struct是锁信息的整合结构，下面我们会介绍，locks所在的这个链表，连接了所有加在当前table上的锁对象，<strong>这样就能通过locks变量，遍历到当前表级锁对象所锁定的表上一共有哪些类型的锁</strong>。</p>
<h4 id="1-4-1-3-整合的锁结构"><a href="#1-4-1-3-整合的锁结构" class="headerlink" title="1.4.1.3 整合的锁结构"></a>1.4.1.3 整合的锁结构</h4><p>上面我们知道InnoDB定义了页锁结构和表锁结构，但通过这二者，我们只能知道哪些行记录或者表被加了锁，<strong>却不知道这锁是由哪个事务加的，加的是什么类型的锁</strong>，于是，InnoDB定义了一个新的锁结构，它就是我们前面看到的struct lock_struct  lock_t：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">typedef struct lock_struct  lock_t;</span><br><span class="line">struct lock_struct&#123;</span><br><span class="line">    trx_t*                  trx;       &#x2F;*这个锁属于哪个事务*&#x2F;</span><br><span class="line">    UT_LIST_NODE_T(lock_t)  trx_locks;  &#x2F;*该事务拥有的锁通过一个链表连接起来*&#x2F;</span><br><span class="line">    ulint                   type_mode;  &#x2F;* lock type, mode, gap flag, and wait flag, ORed *&#x2F;</span><br><span class="line">    hash_node_t             hash;       &#x2F;* hash chain node for a record lock *&#x2F;</span><br><span class="line">    dict_index_t*           index;      &#x2F;* 在该锁类型是行锁是有效，指向一个索引，因为行锁本质是索引记录锁。 *&#x2F;</span><br><span class="line">    union &#123;</span><br><span class="line">        lock_table_t    tab_lock; &#x2F;* table lock *&#x2F;</span><br><span class="line">        lock_rec_t      rec_lock; &#x2F;* record lock *&#x2F;</span><br><span class="line">    &#125; un_member;  &#x2F;*如果是表锁则un_member为lock_table_t，如果是记录锁则un_member为lock_rec_t，通过type_mode来判断类型*&#x2F;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>lock_struct是<code>&lt;事务，页/表&gt;</code>维度的结构，不同事务的每个页（或每个表）都要定义一个lock_struct结构。但一个事务可能在不同页/表上有锁，trx_locks变量将一个事务所有的锁信息进行链接，这样就可以快速查询一个事务所有锁信息。</p>
<p>un_member变量是一个结构共同体，它可以是表锁对象lock_table_t，也可以是页锁对象lock_rec_t，这根据type_mode来区分，type_mode控制了该锁结构（lock_struct）是属于什么类型的锁，已经目前处于的状态。</p>
<p>type_mode变量是一个无符号的4字节32位整型，从低位排列，</p>
<ol>
<li>第1个字节为lock_mode，定义如下； <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* Basic lock modes *&#x2F;</span><br><span class="line">enum lock_mode &#123;</span><br><span class="line">	LOCK_IS &#x3D; 0,    &#x2F;* intention shared *&#x2F;</span><br><span class="line">	LOCK_IX,    &#x2F;* intention exclusive *&#x2F;</span><br><span class="line">	LOCK_S,     &#x2F;* shared *&#x2F;</span><br><span class="line">	LOCK_X,     &#x2F;* exclusive *&#x2F;</span><br><span class="line">	LOCK_AUTO_INC,  &#x2F;* locks the auto-inc counter of a table</span><br><span class="line">			in an exclusive mode *&#x2F;</span><br><span class="line">	LOCK_NONE,  &#x2F;* this is used elsewhere to note consistent read *&#x2F;</span><br><span class="line">	LOCK_NUM &#x3D; LOCK_NONE, &#x2F;* number of lock modes *&#x2F;</span><br><span class="line">	LOCK_NONE_UNSET &#x3D; 255</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
<li>第2个字节为lock_type，目前只用前两位，大小为16和32，分别表示LOCK_TABLE 和LOCK_REC，这一个字节控制了lock_struct是表级锁还是行级锁。 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define LOCK_TABLE      16</span><br><span class="line">#define LOCK_REC        32</span><br></pre></td></tr></table></figure></li>
<li>剩下的高位bit表示行锁的类型record_lock_type <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#define LOCK_WAIT   256        &#x2F;* 表示正在等待锁 *&#x2F;</span><br><span class="line">#define LOCK_ORDINARY 0     &#x2F;* 表示 Next-Key Lock ，锁住记录本身和记录之前的 Gap*&#x2F;</span><br><span class="line">#define LOCK_GAP    512        &#x2F;* 表示锁住记录之前 Gap（不锁记录本身） *&#x2F;</span><br><span class="line">#define LOCK_REC_NOT_GAP 1024    &#x2F;* 表示锁住记录本身，不锁记录前面的 gap *&#x2F;</span><br><span class="line">#define LOCK_INSERT_INTENTION 2048    &#x2F;* 插入意向锁 *&#x2F;</span><br><span class="line">#define LOCK_CONV_BY_OTHER 4096        &#x2F;* 表示锁是由其它事务创建的(比如隐式锁转换) *&#x2F;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="1-4-2-行级锁的查询"><a href="#1-4-2-行级锁的查询" class="headerlink" title="1.4.2 行级锁的查询"></a>1.4.2 行级锁的查询</h3><p>有些时候，我们需要查询某个具体行记录的锁信息。<strong>比如行记录id=3是否有锁</strong>？</p>
<p>InnoDB使用一个哈希表映射行数据和锁信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">struct lock_sys_struct&#123;</span><br><span class="line">    hash_table_t* rec_hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>每次新建一个锁对象，都要插入到lock_sys_struct-&gt;rec_hash中。lock_sys_struct中的key通过页的space和page_no计算得到，而value则是页锁结构lock_rec_struct。</p>
<p>因此若需查询某一行记录是否有锁，首先则先要根据索引，定位到该行记录具体在哪一页。然后根据页的space和page_no进行哈希查询，得到lock_rec_struct，再根据lock_rec_struct里面的位图n_bits，最终得到该行记录是否有锁。</p>
<blockquote>
<p>正是因为行锁的查询需要根据页的space和page_no，而页的定位又基于索引，所以才说InnoDB的行锁是通过给索引项加锁实现的，这就意味着只有通过索引条件检索数据时，InnoDB才使用行锁，否则使用表锁。也就是说，<strong>如果批量update，如果条件的字段没有索引，将会锁表，如果有索引，则只会出现行锁</strong>。</p>
</blockquote>
<p>可以看出，根据页来查找行锁的查询并不是高效设计，但这种方式的资源开销非常小。某一事务对一个页任意行加锁开销都是一样的（不管锁住多少行）。因此也不需要支持锁升级的功能。</p>
<h2 id="1-5-死锁"><a href="#1-5-死锁" class="headerlink" title="1.5 死锁"></a>1.5 死锁</h2><p>死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种相互等待的现象。若无外力作用，他们都将无法推进下去。</p>
<p>解决死锁常用的两个方案：</p>
<ol>
<li><p>超时机制</p>
<ul>
<li>即两个事务互相等待时，当一个等待时间超过设置的某一阀值时，其中一个事务回滚，另一个事务继续执行。MySQL4.0版本开始，提供innodb_lock_wait_time用于设置等待超时时间。</li>
</ul>
</li>
<li><p>等待图（wait-for graph）</p>
<ul>
<li>较之超时的解决方案，这是一种更为主动的死锁检测方式。InnoDB通过锁的信息链表和事务等待链表，判断是否存在等待回路。如有，则存在死锁。每次加锁操作需要等待时都判断是否产生死锁，若有则回滚事务。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-279d2538466f15ae9ef9796f6a07cdb3e81.png" alt=""></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-eff83ca3d0abfed2f6c40dd447116b8ed61.png" alt=""></li>
</ul>
</li>
</ol>
<h2 id="1-6-锁的监控方式"><a href="#1-6-锁的监控方式" class="headerlink" title="1.6 锁的监控方式"></a>1.6 锁的监控方式</h2><p><code>show engine innodb status</code>命令可以获取最近一次的死锁日志。<br>MySQL8之前，可以通过<code>INFORMATION_SCHEMA</code>下<code>INNODB_TRX</code>,<code>INNODB_LOCKS</code>,<code>INNODB_LOCK_WAITS</code>查看事务和锁信息。<br>INNODB_TRX在MySQL8依然保留。</p>
<h1 id="2-InnoDB事务机制"><a href="#2-InnoDB事务机制" class="headerlink" title="2. InnoDB事务机制"></a>2. InnoDB事务机制</h1><p>在关系型数据库中，事务的重要性不言而喻，只要对数据库稍有了解的人都知道事务具有ACID四个基本特性。回顾一下事务的ACID特性，分别是原子性、一致性、隔离性、持久性， 一致性是事务的最终追求的目标，隔离性、原子性、持久性是达成一致性目标的手段。</p>
<ul>
<li><p>A : atomicity 原子性。原子性是我们对事务最直观的理解：事务就是一系列的操作，要么全部都执行，要么全部都不执行。</p>
</li>
<li><p>C : consistency 一致性。数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。它分为数据库外部的一致性和内部的一致性：</p>
<ul>
<li>数据库外部的一致性，例如对银行转帐事务，不管事务成功还是失败，应该保证事务结束后ACCOUNTS表中Tom和Jack的存款总和不变。这个由外部应用的编码来保证，即某个应用在执行转帐的数据库操作时，必须在同一个事务内部调用对帐户A和帐户B的操作。</li>
<li>数据库内部的一致性，这是数据库层面去保证的，体现在我们利用事务将账户A和账户B的操作绑定时，要么一起成功，要么一起失败（原子性）。同时，如果在并发场景下，还要保证其他事务的操作不会影响当前事务（隔离性）。</li>
</ul>
</li>
<li><p>I : isolation 隔离性。在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。</p>
</li>
<li><p>D : durability 持久性。只要事务成功结束，它对数据库所做的更新就必须永久保存下来。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态。</p>
</li>
</ul>
<p>事务的 ACID 特性概念简单，但需要注意的是这几个特性不是一种平级关系：</p>
<ol>
<li>只有满足一致性，事务的执行结果才是正确的。</li>
<li>在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。</li>
<li>事务满足持久化是为了能应对数据库崩溃的情况。</li>
</ol>
<p>所以他们的关系如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f5ac61c75c660df67f8e210a7db7fc834b2.png" alt=""></p>
<p><strong>接下来就让我们来探究一下InnoDB是如何实现事务的——如何保证事务的ACID特性</strong>。</p>
<h2 id="2-1-InnoDB事务原子性的保证"><a href="#2-1-InnoDB事务原子性的保证" class="headerlink" title="2.1 InnoDB事务原子性的保证"></a>2.1 InnoDB事务原子性的保证</h2><p>原子性，核心要点是，<strong>要么全部都执行成功，要么全部都不执行</strong>：</p>
<ol>
<li>要么全部都执行成功：修改后的数据的新状态也是原子的，如果执行成功，那新状态（可能涉及到多个行的变更）应该就像一个操作那样同时全部生效。而不是这一秒3个行被更新完成，下一秒剩下2个行才被更新完成。</li>
<li>要么全部都不执行：也就是如果失败了，要可回滚，将一切都恢复原样。</li>
</ol>
<p><strong>前者通过MVCC来实现</strong>，前文我们已经介绍过MVCC了，同一个事务而产生的新的数据行都带有相同的版本号，配合上一致性非锁定读，可以实现统一事务的变更同时在一个瞬间（也就是同一个系统版本）生效。</p>
<p><strong>而后者，则通过undo日志来实现</strong>，undo日志的详细介绍可见本站博客《【InnoDB详解四】redo log和undo log》，这里简单介绍一下：</p>
<p>在对数据库进行修改时，InnoDB存储引擎会产生一定量的undo log，它记录了事务中每一步操作的<strong>反向逻辑操作</strong>：</p>
<ol>
<li>如果是一个INSERT操作，那么undo log会对应产生一条DELETE操作。</li>
<li>如果是一个DELETE操作，那么undo log会对应产生一条INSERT操作。</li>
<li>如果是一个UPDATE操作，假设是将行A的值从a变更为b，那么undo log会对应产生一条UPDATE操作，将行A的值从b变更为a。</li>
</ol>
<p>这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。</p>
<blockquote>
<p>前者我们说过，MVCC也是通过undo日志实现的，所以本质上，InnoDB事务原子性的保证（undo log + MVCC），其实全都是依赖于undo日志。</p>
</blockquote>
<h2 id="2-3-InnoDB事务持久性的保证"><a href="#2-3-InnoDB事务持久性的保证" class="headerlink" title="2.3 InnoDB事务持久性的保证"></a>2.3 InnoDB事务持久性的保证</h2><p>持久性的核心在于已经提交的修改必须永久的保存下来，对于数据库而言，也就是要写入磁盘中，这才能做到真正的数据持久化。</p>
<p>InnoDB事务持久性的保证依赖于redo日志，redo日志由两部分组成：</p>
<ol>
<li>内存中的重做日志缓冲（redo log buffr），其是易失的;</li>
<li>重做日志文件（redo log file），其是持久的。</li>
</ol>
<blockquote>
<p>redo日志的详细介绍可见本站博客《【InnoDB详解四】redo log和undo log》</p>
</blockquote>
<p>redo日志是物理日志，它的内容和undo日志那样的逻辑日志不一样，它记录的是数据页的物理变更信息，对于事务中的任何操作，都会产生redo日志，用来记录其对数据页的物理变动信息。</p>
<p>InnoDB通过<strong>Force Log at Commit</strong>机制实现事务的持久性，即当事务提交（COMMIT）时，<strong>必须先将该事务产生的所有redo日志写入到重做日志文件（redo log file）进行持久化</strong>，这样就能保证<strong>就算数据的变更还在缓冲池中（在脏页里面），如果系统崩溃了，也可以通过已经持久化的redo日志进行数据恢复</strong>。</p>
<p>将redo日志写入重做日志文件（redo log file）的操作叫做fsync操作，理论上为了保证持久性，每一次事务提交前，InnoDB应该都要执行一次fsync操作，不过很显然，频繁的fsync操作会影响并发性能。</p>
<p>InnoDB存储引擎允许用户手工设置fsync操作的频率，以此提高数据库的性能。参数<code>innodb_flush_log_at_trx_commit</code>用来控制重做日志刷新到磁盘的策略：</p>
<ol>
<li>该参数的默认值为1，表示事务提交时必须调用一次 fsync操作。<ul>
<li>这是最安全的持久化策略，不会发生更新丢失的情况。</li>
</ul>
</li>
<li>还可以设置该参数的值为0，表示事务提交时不进行写人重做日志操作，这个操作仅在master thread中完成，而在master thread中每1秒会进行一次重做日志文件的fsync操作。<ul>
<li>此时如果发生宕机，<strong>最多会丢失1秒的那部分更新</strong>。</li>
</ul>
</li>
<li>还可以设置该参数的值为2，表示事务提交时将重做日志写入重做日志文件，但仅写入文件系统的缓存中，不进行fsync操作。<ul>
<li>在这个设置下，当MySQL数据库发生宕机而操作系统不发生宕机时，并不会导致事务的丢失。而当操作系统宕机时，重启数据库后会丢失<strong>未从文件系统缓存刷新到重做日志文件那部分更新</strong>。</li>
</ul>
</li>
</ol>
<h2 id="2-3-InnoDB事务隔离性的保证"><a href="#2-3-InnoDB事务隔离性的保证" class="headerlink" title="2.3 InnoDB事务隔离性的保证"></a>2.3 InnoDB事务隔离性的保证</h2><p>在本站博客《MySQL核心要点汇总》一文中，我们简单了解过MySQL中事务的隔离级别：</p>
<p>SQL 标准定义了四个隔离级别：</p>
<ul>
<li><strong>READ-UNCOMMITTED(读未提交)</strong>： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。</li>
<li><strong>READ-COMMITTED(读已提交)</strong>： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。</li>
<li><strong>REPEATABLE-READ(可重复读)</strong>： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生（这是针对Oracle，SQL server等数据库而言，InnoDB采用Next-Key Lock，在可重复读级别下就可以避免幻读）。</li>
<li><strong>SERIALIZABLE(串行化)</strong>： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。</li>
</ul>
<p>同样的，我们回顾一下 脏读/不可重复读/幻读 这三类并发的问题。</p>
<ul>
<li><strong>脏读</strong>：指的是在不同的事务下，当前事务可以读到另外事务<strong>未提交的数据</strong>，简单来说就是可以读到脏数据。</li>
<li><strong>不可重复读</strong>：是指在事务A中多次读取同一批数据。在这个多次访问之间，事务B也访问该批数据，并做了一些DML操作，并且提交（如果没提交就是脏读了）。因此，在事务A中的两次读数据之间，由于事务B的修改，导致事务A两次读到的数据可能是不一样的。不可重复读和脏读的区别是脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据。</li>
<li><strong>幻读</strong>：是指在同一事务（事务A）下，连续执行两次同样的SQL语句可能搜出不同的结果，<strong>第二次的SQL语句可能会返回之前不存在的行，就像产生了幻觉一样</strong>。也就是说，在两次查询之间，其他事务insert并且提交的行，如果满足事务A查询的where条件，那么也会被查出来。幻读和不可重复读的区别在于幻读是查询的行数量变多（因为其他事务insert），不可重复读是行数据不一致（因为其他事务update）。</li>
</ul>
<p><strong>那么，各个隔离级别是如何实现的呢？他们分别是如何解决脏读/不可重复读/幻读问题的呢</strong>？</p>
<p>我们可以先来个开门见山的总结：</p>
<ul>
<li><strong>READ-UNCOMMITTED(读未提交)</strong><ul>
<li>无锁</li>
<li>无并发控制协议</li>
</ul>
</li>
<li><strong>READ-COMMITTED(读已提交)</strong><ul>
<li>使用乐观锁MVCC，其<code>非一致性读取</code>，可以避免事务读取被上锁的行记录（防止脏读），只能读取快照数据。</li>
<li>但在该级别下，所有事务的<code>非一致性读</code>都会<strong>读取最新版本的快照</strong>，即便这个最新版本是在事务开启之后才提交的，这就可能产生<code>不可重复读</code>问题。</li>
</ul>
</li>
<li><strong>REPEATABLE-READ(可重复读)</strong><ul>
<li>使用乐观锁MVCC，并且所有事务的<code>非一致性读</code>都会<strong>读取当前事务开启时最新版本的快照</strong>，这样就能避免<code>不可重复读</code>的发送。</li>
<li>使用Next-Key Lock，给事务查询的where条件涵盖的行记录加上范围锁，防止其他事务在这些行数据间隙插入新的记录，从而避免幻读问题。</li>
</ul>
</li>
<li><strong>SERIALIZABLE(串行化)</strong><ul>
<li>使用悲观锁LBCC。<code>一致性读取</code>会在操作的每一行数据上都加上锁，读取加S锁，其余加X锁。</li>
</ul>
</li>
</ul>
<p>其中MVCC和LBCC我们在前文已经介绍过了，这里不再赘述。</p>
<p>不过需要注意的是，各个隔离级别的加锁，其实是加在索引上的，而且在不同的情况下，加锁逻辑也不太相同，比如我们执行一条delete语句：<code>delete from t1 where id=10;</code>，那么在执行这条语句前，我们需要确定：</p>
<ol>
<li>id列是不是主键？</li>
<li>事务的隔离级别是什么？</li>
<li>id非主键的话，其上有建立索引吗？</li>
<li>建立的索引是唯一索引吗？</li>
<li>该SQL的执行计划是什么？索引扫描？全表扫描？</li>
</ol>
<p>不同场景的不同实现，我们逐一来看下：</p>
<h3 id="2-3-1-READ-UNCOMMITTED的加锁方式"><a href="#2-3-1-READ-UNCOMMITTED的加锁方式" class="headerlink" title="2.3.1 READ-UNCOMMITTED的加锁方式"></a>2.3.1 READ-UNCOMMITTED的加锁方式</h3><p>无锁，没有什么实现，忽略。</p>
<h3 id="2-3-2-READ-COMMITTED的加锁方式"><a href="#2-3-2-READ-COMMITTED的加锁方式" class="headerlink" title="2.3.2 READ-COMMITTED的加锁方式"></a>2.3.2 READ-COMMITTED的加锁方式</h3><h4 id="2-3-2-1-id列是主键"><a href="#2-3-2-1-id列是主键" class="headerlink" title="2.3.2.1 id列是主键"></a>2.3.2.1 id列是主键</h4><p>当id是主键的时候，我们只需要在该id=10的记录上加上x锁即可。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ca2458bf61c1ae996c19d02fdde2db595a0.png" alt=""></p>
<h4 id="2-3-2-2-id列是辅助唯一索引"><a href="#2-3-2-2-id列是辅助唯一索引" class="headerlink" title="2.3.2.2 id列是辅助唯一索引"></a>2.3.2.2 id列是辅助唯一索引</h4><p>当id列不是主键，但是为辅助唯一索引时，辅助索引和聚集索引都会加X锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cb574ee9a9fdd4fcdfefb3a51340e84f729.png" alt=""></p>
<h4 id="2-3-2-3-id列是辅助非唯一索引"><a href="#2-3-2-3-id列是辅助非唯一索引" class="headerlink" title="2.3.2.3 id列是辅助非唯一索引"></a>2.3.2.3 id列是辅助非唯一索引</h4><p>当id列不是主键，如果id是非唯一索引，那么所对应的<strong>所有的辅佐索引和聚集索引记录</strong>上都会上x锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a65e9c01d5eec8ee913abdebd626bc2315b.png" alt=""></p>
<h4 id="2-3-2-4-id列上没有索引"><a href="#2-3-2-4-id列上没有索引" class="headerlink" title="2.3.2.4 id列上没有索引"></a>2.3.2.4 id列上没有索引</h4><p>由于id列上没有索引，因此只能走聚簇索引，进行全表扫描。因此聚集索引上的每条记录，无论是否满足条件，都会被加上X锁。</p>
<p>但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，<strong>会在判断后放锁</strong>，最终持有的，是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不会省略。同时，优化也违背了2PL约束（同时加锁同时放锁）。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0af0e86bcea7ffd644e3639c095cea54f0c.png" alt=""></p>
<p>最后只有id=10的锁留下了。</p>
<h3 id="2-3-3-REPEATABLE-READ的加锁方式"><a href="#2-3-3-REPEATABLE-READ的加锁方式" class="headerlink" title="2.3.3 REPEATABLE-READ的加锁方式"></a>2.3.3 REPEATABLE-READ的加锁方式</h3><h4 id="2-3-3-1-id列是主键"><a href="#2-3-3-1-id列是主键" class="headerlink" title="2.3.3.1 id列是主键"></a>2.3.3.1 id列是主键</h4><p>与id列是主键，RC隔离级别的情况，完全相同。因为只有一条结果记录，只能在上面加锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ca2458bf61c1ae996c19d02fdde2db595a0.png" alt=""></p>
<blockquote>
<p>RR级别是需要同时加间隙锁的，但因为id列是唯一主键，且delete的where条件是id=10，这种情况不会发生幻读，所以此例没加。但如果delete语句不是id=10，而是id&gt;10 and id &lt; 15，那么就要加间隙锁了。</p>
</blockquote>
<h4 id="2-3-3-2-id列是辅助唯一索引"><a href="#2-3-3-2-id列是辅助唯一索引" class="headerlink" title="2.3.3.2 id列是辅助唯一索引"></a>2.3.3.2 id列是辅助唯一索引</h4><p>与id列是辅助唯一索引，RC隔离级别的情况，完全相同。因为只有一条结果记录，只能在上面加锁。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cb574ee9a9fdd4fcdfefb3a51340e84f729.png" alt=""></p>
<blockquote>
<p>RR级别是需要同时加间隙锁的，但因为id列是唯一索引，且delete的where条件是id=10，这种情况不会发生幻读，所以此例没加。但如果delete语句不是id=10，而是id&gt;10 and id &lt; 15，那么就要加间隙锁了。</p>
</blockquote>
<h4 id="2-3-3-3-id列是辅助非唯一索引"><a href="#2-3-3-3-id列是辅助非唯一索引" class="headerlink" title="2.3.3.3 id列是辅助非唯一索引"></a>2.3.3.3 id列是辅助非唯一索引</h4><p>在RR隔离级别下，为了防止幻读的发生，会使用间隙锁（GAP锁）。</p>
<p>首先，通过辅助索引定位到第一条满足查询条件的记录，加记录上的X锁，加GAP上的GAP锁，然后加聚簇索引上的记录X锁，然后返回；</p>
<p>然后读取下一条，重复进行。直至进行到第一条不满足条件的记录<code>[11,f]</code>，此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-12f73d7997a01391c31de0c36df7bcb90dd.png" alt=""></p>
<h4 id="2-3-3-4-id列上没有索引"><a href="#2-3-3-4-id列上没有索引" class="headerlink" title="2.3.3.4 id列上没有索引"></a>2.3.3.4 id列上没有索引</h4><p>在这种情况下，聚集索引上的所有记录，都被加上了X锁。其次，聚集索引每条记录间的间隙(GAP)，也同时被加上了GAP锁。</p>
<p>但是，InnoDB也做了相关的优化，就是所谓的semi-consistent read。semi-consistent read开启的情况下，<strong>对于不满足查询条件的记录，MySQL会提前放锁，同时也不会添加Gap锁</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0805e613bf1d63f1919bf5224e5ffb01cb8.png" alt=""></p>
<h3 id="2-3-4-SERIALIZABLE的加锁方式"><a href="#2-3-4-SERIALIZABLE的加锁方式" class="headerlink" title="2.3.4 SERIALIZABLE的加锁方式"></a>2.3.4 SERIALIZABLE的加锁方式</h3><p>因为这是DML（delete）操作，<strong>所以与REPEATABLE-READ级别的各种情况下表现完全相同</strong>。但如果是select操作，会有所不同：</p>
<ul>
<li><p>REPEATABLE-READ级别默认是一致性非锁定读，在行记录有锁的情况下可以不用阻塞，而是去读取快照，除非SQL中主动加锁进行一致性锁定读（lock in share mode 或 for update）；</p>
</li>
<li><p>而Serializable级别下，会对每条select语句，自动加上lock in share mode，进行一致性锁定读，即如果行上有锁，只能阻塞。</p>
</li>
</ul>
<h2 id="2-4-InnoDB事务一致性的保证"><a href="#2-4-InnoDB事务一致性的保证" class="headerlink" title="2.4 InnoDB事务一致性的保证"></a>2.4 InnoDB事务一致性的保证</h2><p>前文我们已经阐述过了，数据库外的数据一致性，需要通过外部编码来实现，而数据库内的数据一致性，则依赖于原子性和隔离性。在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f5ac61c75c660df67f8e210a7db7fc834b2.png" alt=""></p>
<p>所以InnoDB实现了原子性和隔离性，也就自然而然实现了一致性。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/" itemprop="url">【图论】拓扑排序详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-15T21:36:36+08:00">
                2020-09-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%9B%BE/" itemprop="url" rel="index">
                    <span itemprop="name">图</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E8%AF%A6%E8%A7%A3/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/15/【图论】拓扑排序详解/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在正文开始前，我们先来了解一下<strong>有向无环图(Directed Acyclic Graph简称DAG)</strong></p>
<p>如下图就是一个DAG图，DAG图是我们讨论拓扑排序的基础。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8f6717028963b3bea2b37a3ce72eae8f784.png" alt=""></p>
<blockquote>
<p>AOV网：数据在顶点 可以理解为面向对象<br>AOE网：数据在边上，可以理解为面向过程！</p>
</blockquote>
<h1 id="1-什么是拓扑排序"><a href="#1-什么是拓扑排序" class="headerlink" title="1. 什么是拓扑排序"></a>1. 什么是拓扑排序</h1><p><strong>拓扑排序（Topological Order）</strong>，很多人听说过，但是不了解的一种算法。或许很多人只知道它是图论的一种排序，至于干什么的不清楚。又或许很多人可能还会认为它是一种啥排序。</p>
<p>而实质上<strong>它只是将DAG图的顶点排成一个线性序列，得到一个顶点的全序集合</strong>。其排序的顺序依据就是节点的指向关系。比如前言的DAG图：</p>
<ul>
<li>…</li>
<li>节点5在节点4和节点3的后面</li>
<li>节点9在节点6和节点7的后面</li>
<li>…</li>
</ul>
<p>那么最后得到的节点的线性序列结果,也一定要满足上面的指向顺序。</p>
<p>每一个节点都拥有<strong>入度</strong>（有多少点导向它，也就是开始它有多少前提）和<strong>出度</strong>（它导向多少点，也就是它是多少其他节点开始的前提）。例如节点5的入度为3和4，出度为7。</p>
<p><strong>拓扑排序的结果不是唯一的</strong>，只要符合上面的条件，那么它就是拓扑序列，比如<code>1 2 4 3 6 5 7 9</code>和<code>2 1 3 4 5 6 7 9</code>，这两个结果都是可行的。</p>
<blockquote>
<p>官方一点的定义：将有向图中的节点以线性方式进行排序。即对于任何连接自节点u到节点v的有向边uv，在最后的排序结果中，节点u总是在节点v的前面。</p>
</blockquote>
<h1 id="2-现实案例"><a href="#2-现实案例" class="headerlink" title="2. 现实案例"></a>2. 现实案例</h1><p>看了上面关于拓扑排序的概念如果还觉得十分抽象的话，那么不妨考虑一个非常非常经典的例子——选课。</p>
<p>假设我非常想学习一门《jsp入门》的课程，但是在修这么课程之前，我们必须要学习一些基础课程，比如《JAVA语言程序设计》，《HTML指南》等等。那么这个制定选修课程顺序的过程，实际上就是一个拓扑排序的过程，每门课程相当于有向图中的一个顶点，而连接顶点之间的有向边就是课程学习的先后关系。</p>
<p>只不过这个过程不是那么复杂，从而很自然的在我们的大脑中完成了。将这个过程以算法的形式描述出来的结果，就是拓扑排序。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ed6f21ce9608d461a3bccfea80f57b48fa6.png" alt=""></p>
<p>可以看到，上图中的学习顺序，就是拓扑序列，其不止一个结果。</p>
<p>拓扑排序算法在工程学中十分重要。</p>
<blockquote>
<p>节点成环的图，无法被拓扑排序，因为这在工程上本身没有意义，比如A——&gt;B——&gt;C——&gt;A，那么这个工程永远无法被开始。</p>
</blockquote>
<h1 id="3-算法实现"><a href="#3-算法实现" class="headerlink" title="3. 算法实现"></a>3. 算法实现</h1><p>拓扑排序的<strong>最优时间复杂度是O(m+n)</strong>,其中m和n是DAG图中节点数和边数。因为拓扑排序<strong>至少</strong>要对DAG图的节点和边进行一次完整的遍历。</p>
<p>拓扑排序的<strong>最优空间复杂度是O(m+n)</strong>,其中m和n是DAG图中节点数和边数。我们一般使用邻接表来存储DAG图，因此空间复杂度是O(m+n)。</p>
<h2 id="3-1-广度优先搜索法（BFS）"><a href="#3-1-广度优先搜索法（BFS）" class="headerlink" title="3.1 广度优先搜索法（BFS）"></a>3.1 广度优先搜索法（BFS）</h2><h3 id="3-1-1-BFS实现拓扑排序"><a href="#3-1-1-BFS实现拓扑排序" class="headerlink" title="3.1.1 BFS实现拓扑排序"></a>3.1.1 BFS实现拓扑排序</h3><p>广度优先搜索法的思路很简单：</p>
<ol>
<li>从DAG图中找到<strong>入度为0</strong>的节点A（也就是没有箭头指向它的节点），将其放入拓扑序列的结果集。</li>
<li>同时删除由节点A出发的所有边。</li>
<li>在剩下的DAG图中重复1-2两步。</li>
<li>如果最后可以把全部的节点都删除并加入到结果集，那表示DAG图可以被拓扑排序；否则，如果最后有节点被剩下，那说明该图是有环图，无法被拓扑排序。</li>
</ol>
<p>如下图</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3391dd5692b37d49a3f885971f434cf5a02.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-60263c4c74b83269df50907f42790bb5234.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-77d989dca380e2eba9c57d1e815326edc56.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fe6e6c396e5c66160ca7a86e6bde5c3c5b3.png" alt=""></p>
<h3 id="3-1-2-BFS实现拓扑排序的优化"><a href="#3-1-2-BFS实现拓扑排序的优化" class="headerlink" title="3.1.2 BFS实现拓扑排序的优化"></a>3.1.2 BFS实现拓扑排序的优化</h3><p>如果有时候，我们只需要知道某个DAG图是否可以拓扑排序，而不需要真正得到拓扑排序后的结果，那么可以不需要结果集列表，<strong>只需要统计被删除的节点的数量即可，如果该数量等于DAG图的节点数，那么DAG图可以被拓扑排序</strong>。</p>
<h2 id="3-2-深度优先搜索法（DFS）"><a href="#3-2-深度优先搜索法（DFS）" class="headerlink" title="3.2 深度优先搜索法（DFS）"></a>3.2 深度优先搜索法（DFS）</h2><h3 id="3-2-1-DFS实现拓扑排序"><a href="#3-2-1-DFS实现拓扑排序" class="headerlink" title="3.2.1 DFS实现拓扑排序"></a>3.2.1 DFS实现拓扑排序</h3><p>深度优先搜索法是广度优先搜索法的逆向思路，它的步骤如下：</p>
<ol>
<li>选取图中任意一个节点A，将其状态标记为“搜索中”</li>
<li>寻找节点A的邻接点（沿着箭头指向寻找相邻的节点）<ol>
<li>如果A存在邻接点<ol>
<li>如果A的邻接点中存在状态为“搜索中”的邻接点，那么表示DAG图有环路，不可拓扑排序。</li>
<li>否则，那么任意选择一个状态为“未搜索”的邻接点B，使用递归对B重复做1和2操作，注意此时B的邻接点判断不包含来路（也就是A节点）。等到A的所有邻接点都被搜索到，递归回溯回A节点的时候，那么A节点也会被标记为“已搜索”，并压入结果栈。</li>
</ol>
</li>
<li>如果A不存在邻接点，那么将节点A的状态改为“已完成”，并且将其压入一个结果集的栈中。</li>
</ol>
</li>
<li>A节点及其相邻节点都搜索完毕后，如果还有未搜索的节点，那么任意选取一个节点当做出发点，继续重复1,2,3步骤。</li>
<li>直到所有的节点都被搜索并压入栈，那么此时结果栈中，从栈顶到栈底的顺序，就是拓扑排序的顺序。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-4c28b181876a97519a71c906921c05e9a8a.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8527f61ef65f2e3bde9e47f8b7a22481fae.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f6b9acea12ae9b5876b792b3394a4b0b480.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a70c8606a0f12ed549991a6a6fd584d5030.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-788b9456add4b59dc890a12950e0efdd024.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2cbe7ded9481877300dbf1a2e519a85f8fc.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8be9445aae16147097ac42f8bc08002a114.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4386e32bbe6db3348a0b5051aac0114cacb.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-102c038f31cec5cbdea7102f2e612f06b67.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c091a2e5694ff8708a1884c9492c8cdf551.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-50cc6d8c4050ac9c0b8114c2bb3a49e809d.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-59af3a05a56757f166044305474cf42922f.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-700d02c9347cef22f44ce631a6b088a2011.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8445591c7013e1633e194c4f4f71a31eb71.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ee05cf7512bfb71807f9b3ad8d91b026685.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5a462ba6ac4e920c4cc444eef497fd02d62.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6d626a51209e2c008ff9a1f7008f196a4a4.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-46b3b2f1532c08a3c29aa71b97b049ef3b9.png" alt=""></p>
<h3 id="3-2-2-DFS实现拓扑排序的优化"><a href="#3-2-2-DFS实现拓扑排序的优化" class="headerlink" title="3.2.2 DFS实现拓扑排序的优化"></a>3.2.2 DFS实现拓扑排序的优化</h3><p>如果有时候，我们只需要知道某个DAG图是否可以拓扑排序，而不需要真正得到拓扑排序后的结果，那么可以不需要结果栈，只需要判断整个深度优先搜索过程，没有发生“搜索中”节点的相邻节点（不包含来路的节点）也是“搜索中”就行。</p>
<h1 id="4-算法题解"><a href="#4-算法题解" class="headerlink" title="4 算法题解"></a>4 算法题解</h1><h2 id="4-1-课程表I"><a href="#4-1-课程表I" class="headerlink" title="4.1 课程表I"></a>4.1 课程表I</h2><p><a href="https://leetcode-cn.com/problems/course-schedule/" target="_blank" rel="noopener" title="leetcode-207. 课程表">leetcode-207. 课程表I</a></p>
<h2 id="4-2-课程表II"><a href="#4-2-课程表II" class="headerlink" title="4.2 课程表II"></a>4.2 课程表II</h2><p><a href="https://leetcode-cn.com/problems/course-schedule-ii/" target="_blank" rel="noopener" title="leetcode-210.课程表II">leetcode-210.课程表II</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/" itemprop="url">【图论】广度/深度优先搜索算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-15T21:29:34+08:00">
                2020-09-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%9B%BE/" itemprop="url" rel="index">
                    <span itemprop="name">图</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/15/%E3%80%90%E5%9B%BE%E8%AE%BA%E3%80%91%E5%B9%BF%E5%BA%A6-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/15/【图论】广度-深度优先搜索算法/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我们首次接触<strong>广度优先搜索</strong>和<strong>深度优先搜索</strong>时，应该是在数据结构课上讲的 “图的遍历”。还有就是刷题的时候，遍历二叉树/拓扑排序我们会经常用到这两种遍历方法。</p>
<p><strong>广度优先搜索算法（Breadth-First-Search，缩写为 BFS）</strong>，是一种利用<strong>队列</strong>实现的搜索算法。简单来说，其搜索过程和 “湖面丢进一块石头激起层层涟漪” 类似。</p>
<p><strong>深度优先搜索算法（Depth-First-Search，缩写为 DFS）</strong>，是一种利用<strong>递归</strong>实现的搜索算法。简单来说，其搜索过程和 “不撞南墙不回头” 类似。</p>
<p><strong>BFS 的重点在于队列，而 DFS 的重点在于递归。这是它们的本质区别。</strong></p>
<h1 id="1-广度优先搜索法"><a href="#1-广度优先搜索法" class="headerlink" title="1. 广度优先搜索法"></a>1. 广度优先搜索法</h1><p>广度优先搜索，也叫做广度优先遍历，其主要思想类似于树的层序遍历。</p>
<ol>
<li>从任意一个节点A开始，遍历它的全部的邻接点B,C</li>
<li>然后再以它其中一个邻接点B为起点，遍历B的所有的邻接点D，F。</li>
<li>然后再以它另外一个邻接点C为起点，遍历C的所有的邻接点G，H。</li>
<li>然后再以它其中一个邻接点D为起点，遍历D的所有的邻接点…。</li>
<li>以此类推….</li>
</ol>
<p>伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;queue：结果集，queue队列</span><br><span class="line">&#x2F;&#x2F;nodeA：开始节点</span><br><span class="line">public void bfsSearch(List&lt;Node&gt; queue ,Node StrartNode)&#123;</span><br><span class="line">    &#x2F;&#x2F;先选择一个出发点，加入队列。</span><br><span class="line">    queue.add(StrartNode);</span><br><span class="line">    int size &#x3D; queue.getSize();</span><br><span class="line">    for(int index&#x3D;0;index&lt;size;index++)&#123;</span><br><span class="line">        &#x2F;&#x2F;BFS的重点在于队列，它的思路就是沿着queue的添加顺序，依次遍历他们的邻接点。</span><br><span class="line">        for(Node node : queue.get(index).getNeighbor())&#123;</span><br><span class="line">            &#x2F;&#x2F;没被搜索过，那么加入结果集</span><br><span class="line">            if(!queue.contain(node))&#123;</span><br><span class="line">                queue.add(node);</span><br><span class="line">                size &#x3D; queue.getSize();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void main()&#123;</span><br><span class="line">    &#x2F;&#x2F;定义一个结果集，queue队列</span><br><span class="line">    List&lt;Node&gt; queue &#x3D; new LinkedList&lt;Node&gt;();</span><br><span class="line">    &#x2F;&#x2F;先选择一个节点作为开始节点。</span><br><span class="line">    Node startNode&#x3D;nodeA;</span><br><span class="line">    bfsSearch(queue,startNode);</span><br><span class="line">    while(queue.size()不等于节点总数)&#123;</span><br><span class="line">        &#x2F;&#x2F;说明可能因为边有向的问题，有些节点没有被遍历到</span><br><span class="line">        &#x2F;&#x2F;此时需要在剩下的节点中另找一个出发点（假设为B）</span><br><span class="line">        startNode &#x3D; nodeB;&#x2F;&#x2F;省略找出B的过程</span><br><span class="line">        bfsSearch(queue,startNode);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>BFS比较适合判断二分图，以及用于实现寻找最小生成树（MST），如在BFS基础上的Kruskal算法。还有寻找最短路径问题（如Dijkstra算法）。</p>
<p><img src="https://cuijiahua.com/wp-content/uploads/2018/01/alogrithm_10_2.gif" alt="image"></p>
<h2 id="1-1-无向图的广度优先遍历"><a href="#1-1-无向图的广度优先遍历" class="headerlink" title="1.1 无向图的广度优先遍历"></a>1.1 无向图的广度优先遍历</h2><p>我们先给出一个图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-251c89eb3165548739c5acd6ea271c41554.png" alt=""></p>
<ol>
<li>先找到A，这是第一层。</li>
<li>再找到A的邻接点，遍历到B，C，D，F。</li>
<li>再找到B，C，D，F的邻接点，遍历到G，E，H</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-3b6c768580717218780d806bc60e913008b.png" alt=""></p>
<h2 id="1-2-有向图的广度优先遍历"><a href="#1-2-有向图的广度优先遍历" class="headerlink" title="1.2 有向图的广度优先遍历"></a>1.2 有向图的广度优先遍历</h2><p><img src="https://oscimg.oschina.net/oscnet/up-aa815c87267ef276969876712cfccf33128.png" alt=""></p>
<p>思路和与无向图类似，只不过需要考虑边的走向问题。</p>
<ol>
<li>先找到A，这是第一层。</li>
<li>再找到A的邻接点，遍历到B，C，F。</li>
<li>再找到B，C，F的邻接点，遍历到D，H</li>
<li>再找到D，H的邻接点，遍历到E，G</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-684db1b8e0400316ab9d8a86a457489f9fa.png" alt=""></p>
<h1 id="2-深度优先搜索法"><a href="#2-深度优先搜索法" class="headerlink" title="2. 深度优先搜索法"></a>2. 深度优先搜索法</h1><p>深度优先搜索，也叫做深度优先遍历，其主要思想是回溯法，它的核心是使用递归。</p>
<p>例如这张图，从1开始到2，之后到5，5不能再走了，退回2，到6，退回2退回1，到3，以此类推；</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-45757424adba38157c8d3c14ffb0dd6f61a.png" alt=""></p>
<p>伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;stack：定义的结果集stack栈</span><br><span class="line">&#x2F;&#x2F;currentNode：本次递归搜索的当前node</span><br><span class="line">public void dfsSearch(Stack&lt;Node&gt; stack,Node currentNode)&#123;</span><br><span class="line">    if(currentNode没有邻接点 &amp;&amp; !stack.contain(currentNode))&#123;</span><br><span class="line">        &#x2F;&#x2F;压入结果栈</span><br><span class="line">        stack.push(currentNode);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;node有邻接点，那么遍历邻接点，依次深搜</span><br><span class="line">    for(Node node : currentNode.getNeighbor())&#123;</span><br><span class="line">        if(node.isVisited() || stack.contain(currentNode))&#123;</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line">        node.setVisited(true);</span><br><span class="line">        dfsSearch(stack,node);</span><br><span class="line">        node.setVisited(false);</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;currentNode的邻接点都已经遍历过了，现在逻辑回溯回currentNode</span><br><span class="line">    &#x2F;&#x2F;那么需要将currentNode压入结果栈</span><br><span class="line">    stack.push(currentNode);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void main()&#123;</span><br><span class="line">    &#x2F;&#x2F;定义一个结果集</span><br><span class="line">    Stack&lt;Node&gt; stack &#x3D; new Stack&lt;Node&gt;();</span><br><span class="line">    &#x2F;&#x2F;先选择一个节点作为开始节点。</span><br><span class="line">    Node startNode&#x3D;nodeA;</span><br><span class="line">    dfsSearch(stack,startNode);</span><br><span class="line">    while(queue.size()不等于节点总数)&#123;</span><br><span class="line">        &#x2F;&#x2F;说明可能因为边有向的问题，有些节点没有被遍历到</span><br><span class="line">        &#x2F;&#x2F;此时需要在剩下的节点中另找一个出发点（假设为B）</span><br><span class="line">        startNode &#x3D; nodeB;&#x2F;&#x2F;省略找出B的过程</span><br><span class="line">        dfsSearch(stack,startNode);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><img src="https://cuijiahua.com/wp-content/uploads/2018/01/alogrithm_10_3.gif" alt="image"></p>
<h2 id="2-1-无向图的深度优先遍历"><a href="#2-1-无向图的深度优先遍历" class="headerlink" title="2.1 无向图的深度优先遍历"></a>2.1 无向图的深度优先遍历</h2><p>我们先给出一个图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-74f1f6bfb457012ec8d3b5e0dd1cd05fcc1.png" alt=""></p>
<p>对上无向图进行深度优先遍历，从A开始：</p>
<p><strong>第1步</strong>：访问A。</p>
<p><strong>第2步</strong>：访问B(A的邻接点)。 在第1步访问A之后，接下来应该访问的是A的邻接点，即”B,D,F”中的一个。但在本文的实现中，顶点ABCDEFGH是按照顺序存储，B在”D和F”的前面，因此，先访问B。</p>
<p><strong>第3步</strong>：访问G(B的邻接点)。 和B相连只有”G”(A已经访问过了)  </p>
<p><strong>第4步</strong>：访问E(G的邻接点)。 在第3步访问了B的邻接点G之后，接下来应该访问G的邻接点，即”E和H”中一个(B已经被访问过，就不算在内)。而由于E在H之前，先访问E。</p>
<p><strong>第5步</strong>：访问C(E的邻接点)。 和E相连只有”C”(G已经访问过了)。</p>
<p><strong>第6步</strong>：访问D(C的邻接点)。 </p>
<p><strong>第7步</strong>：访问H。因为D没有未被访问的邻接点；因此，一直回溯到访问G的另一个邻接点H。</p>
<p><strong>第8步</strong>：访问(H的邻接点)F。</p>
<p>因此访问顺序是：<strong>A -&gt; B -&gt; G -&gt; E -&gt; C -&gt; D -&gt; H</strong> <strong>-&gt;</strong> <strong>F</strong></p>
<h2 id="2-2-有向图的深度优先遍历"><a href="#2-2-有向图的深度优先遍历" class="headerlink" title="2.2 有向图的深度优先遍历"></a>2.2 有向图的深度优先遍历</h2><p><img src="https://oscimg.oschina.net/oscnet/up-c270810594e5678e4b97eedac94bd900bbf.png" alt=""></p>
<p>对上有向图进行深度优先遍历，从A开始：</p>
<p><strong>第1步</strong>：访问A。</p>
<p><strong>第2步</strong>：访问(A的出度对应的字母)B。 在第1步访问A之后，接下来应该访问的是A的出度对应字母，即”B,C,F”中的一个。但在本文的实现中，顶点ABCDEFGH是按照顺序存储，B在”C和F”的前面，因此，先访问B。</p>
<p><strong>第3步</strong>：访问(B的出度对应的字母)F。 B的出度对应字母只有F。 </p>
<p><strong>第4步</strong>：访问H(F的出度对应的字母)。 F的出度对应字母只有H。 </p>
<p><strong>第5步</strong>：访问(H的出度对应的字母)G。</p>
<p><strong>第6步</strong>：访问(G的出度对应字母)E。 在第5步访问G之后，接下来应该访问的是G的出度对应字母，即”B,C,E”中的一个。但在本文的实现中，顶点B已经访问了，由于C在E前面，所以先访问C。</p>
<p><strong>第7步</strong>：访问(C的出度对应的字母)D。</p>
<p><strong>第8步</strong>：访问(C的出度对应字母)D。 在第7步访问C之后，接下来应该访问的是C的出度对应字母，即”B,D”中的一个。但在本文的实现中，顶点B已经访问了，所以访问D。</p>
<p><strong>第9步</strong>：访问E。D无出度，所以一直回溯到G对应的另一个出度E。</p>
<p>因此访问顺序是：<strong>A -&gt; B -&gt; F -&gt; H -&gt; G -&gt; C -&gt; D</strong> <strong>-&gt; E</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/" itemprop="url">【InnoDB详解二】MySQL文件系统和InnoDB存储结构</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-08T21:47:43+08:00">
                2020-09-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/08/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%BA%8C%E3%80%91MySQL%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8CInnoDB%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/09/08/【InnoDB详解二】MySQL文件系统和InnoDB存储结构/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  10.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  38
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-MySQL文件系统"><a href="#1-MySQL文件系统" class="headerlink" title="1 MySQL文件系统"></a>1 MySQL文件系统</h1><p>本章节将分析构成MySQL数据库和InnoDB存储引擎表的各种类型文件。这些文件有以下这些。</p>
<ol>
<li>参数文件∶告诉MySQL实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数，这些参数定义了某种内存结构的大小等设置，还会介绍各种参数的类型。</li>
<li>日志文件∶用来记录MySQL实例对某种条件做出响应时写人的文件，如错误日志文件、二进制日志文件、慢查询日志文件、查询日志文件等。</li>
<li>socket文件∶当用UNIX域套接字方式进行连接时需要的文件。</li>
<li>pid文件∶MySQL实例的进程 ID文件。</li>
<li>MySQL表结构文件∶用来存放 MySQL表结构定义文件。</li>
<li>存储引擎文件∶因为MySQL表存储引擎的关系，每个存储引擎都会有自己的文件来保存各种数据。这些存储引擎真正存储了记录和索引等数据。本章主要介绍与 InnoDB有关的存储引擎文件。</li>
</ol>
<h2 id="1-1-参数文件"><a href="#1-1-参数文件" class="headerlink" title="1.1 参数文件"></a>1.1 参数文件</h2><p>当 MySQL实例启动时，数据库会先去读取一个配置参数文件，用来寻找数据库的各种文件所在位置以及指定某些初始化参数，这些参数通常定义了某种内存结构有多大等。</p>
<p>在默认情况下，MySQL实例会按照一定的顺序在指定的位置进行读取，用户只需通过命令<code>mysql--help | grep my.cnf</code>来寻找即可。</p>
<p>MySQL数据库参数文件的作用和Oracle数据库的参数文件极其类似，不同的是，Oracle实例在启动时若找不到参数文件，是不能进行装载（mount）操作的。MySQL稍微有所不同，MySQL实例可以不需要参数文件，这时所有的参数值取决于编译MySQL时指定的默认值和源代码中指定参数的默认值。</p>
<p>MySQL数据库的参数文件是以文本方式进行存储的。用户可以直接通过一些常用的文本编辑软件（如vi和emacs）进行参数的修改。</p>
<p>MySQL数据库参数是一个键/值（key/value）对。如innodb_buffer_pool_size=1G。</p>
<p>可以通过命令 SHOW VARIABLES查看数据库中的所有参数，也可以通过LIKE来过滤参数名。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-829069acf66ead1907d807695b02b7bc6cd.png" alt=""></p>
<h2 id="1-1-参数的类型"><a href="#1-1-参数的类型" class="headerlink" title="1.1 参数的类型"></a>1.1 参数的类型</h2><p>MySQL数据库中的参数可以分为两类∶</p>
<ol>
<li>动态（dynamic）参数</li>
<li>静态（static）参数</li>
</ol>
<p>动态参数意味着可以在MySQL实例运行中进行更改，静态参数说明在整个实例生命周期内都不得进行更改，就好像是只读（read only）的。可以通过SET命令对动态的参数值进行修改，SET 的语法如下∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b80574245a07a91e0ffdcac095ec1c0f029.png" alt=""></p>
<p>这里可以看到global和session关键字，它们表明该参数的修改是基于当前会话还是整个实例的生命周期。</p>
<p>有些动态参数只能在会话中进行修改，如autocommit;</p>
<p>而有些参数修改完后，在整个实例生命周期中都会生效，如binlog_cache_size;</p>
<p>而有些参数既可以在会话中又可以在整个实例的生命周期内生效，如 read_buffer_size。</p>
<p>举例如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4dae9240c84d8f5ccdb2a89b83c8d3c2c35.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-be3d687886cb98ef05ae7ba432b35e1ae1e.png" alt=""></p>
<p>上述示例中将当前会话的参数read_buffer_size从2MB调整为了512KB，而用户可以看到全局的read_buffer_size的值仍然是2MB，也就是说如果有另一个会话登录到MySQL实例，它的read_buffer_size的值是2MB，而不是512KB。这里使用了set global | session来改变动态变量的值。用户同样可以直接使用SET@@global | @@session来更改，如下所示∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9eb8d6ca15b99a9b523638d9573f069bdbe.png" alt=""></p>
<p>这次把read_buffer_size全局值更改为IMB，而当前会话的read bufer_size的值还是512KB。</p>
<p><strong>这里需要注意的是，对变量的全局值进行了修改，仅在这次的实例生命周期内都有效，但MySQL实例本身并不会对参数文件中的该值进行修改</strong>。也就是说，在下次启动时MySQL实例还是会读取参数文件。若想在数据库实例下一次启动时该参数还是保留为当前修改的值，那么用户必须去修改参数文件。</p>
<h2 id="1-2-日志文件"><a href="#1-2-日志文件" class="headerlink" title="1.2 日志文件"></a>1.2 日志文件</h2><p>日志文件相关介绍详见本站文章《MySQL日志体系详解》</p>
<h2 id="1-3-socket文件"><a href="#1-3-socket文件" class="headerlink" title="1.3 socket文件"></a>1.3 socket文件</h2><p>之前的文章中我们提到过，在UNIX系统下本地连接MySQL可以采用UNIX域套接字方式，这种方式需要一个套接字（socket）文件。套接字文件可由参数socket控制。一般在/tmp 目录下，名为mysql.sock∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-27971b64ed5d9b0d3d21735b54082076be9.png" alt=""></p>
<h2 id="1-4-pid文件"><a href="#1-4-pid文件" class="headerlink" title="1.4 pid文件"></a>1.4 pid文件</h2><p>当MySQL实例启动时，会将自己的进程ID写入一个文件中——该文件即为pid文件。该文件可由参数pid_file控制，默认位于数据库目录下，文件名为主机名.pid∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5d5410fd7723a267507026c3c8aea14ad95.png" alt=""></p>
<h2 id="1-5-表结构定义文件"><a href="#1-5-表结构定义文件" class="headerlink" title="1.5 表结构定义文件"></a>1.5 表结构定义文件</h2><p>MySQL数据的存储是根据表进行的，但因为MySQL插件式存储引擎的体系结构的关系，所以MySQL要在存储引擎之上将表信息记录下来，于是，MySQL为每个表都定义与之对应的文件。不论表采用何种存储引擎，MySQL都有一个以frm为后缀名的文件，这个文件记录了该表的表结构定义。</p>
<p>frm还用来存放视图的定义，如用户创建了一个va视图，那么对应地会产生一个v_a.frm文件，用来记录视图的定义，该文件是文本文件，可以直接使用cat命令进行查看∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-da9b95f3bb49699a68f530e23797414618a.png" alt=""></p>
<h2 id="1-6-InnoDB存储引擎文件"><a href="#1-6-InnoDB存储引擎文件" class="headerlink" title="1.6 InnoDB存储引擎文件"></a>1.6 InnoDB存储引擎文件</h2><p>之前介绍的文件都是MySQL数据库本身的文件，和存储引擎无关。除了这些文件外，每个表存储引擎还有其自己独有的文件。本节将具体介绍与InnoDB存储引擎密切相关的文件，这些文件包括重做日志文件、表空间文件。</p>
<h3 id="1-6-1-表空间文件"><a href="#1-6-1-表空间文件" class="headerlink" title="1.6.1 表空间文件"></a>1.6.1 表空间文件</h3><p>InnoDB采用将存储的数据按表空间（tablespace）进行存放的设计。在默认配置下会有一个初始大小为10MB，名为ibdata1的文件。该文件就是默认的表空间文件（tablespace file），又称作<strong>共享表空间</strong>，用户可以通过参数innodb_data_file_path对其进行设置，格式如下∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7a23c3bfaca6805e33740c49fa5ab0eb7dc.png" alt=""></p>
<p>用户可以通过多个文件组成一个表空间，同时制定文件的属性，如∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e51162c902e23c04cbcf254b852dda4502f.png" alt=""></p>
<p>这里将/db/ibdata1和/dr2/db/ibdata2两个文件用来组成表空间。若这两个文件位于不同的磁盘上，磁盘的负载可能被平均，因此可以提高数据库的整体性能。同时，两个文件的文件名后都跟了属性，表示文件idbdata1的大小为2000MB，文件ibdata2的大小为2000MB，如果用完了这2000MB，该文件可以自动增长（autoextend）。</p>
<p>设置<code>innodb_data_file_path</code>参数后，所有基于InnoDB存储引擎的表的数据都会记录到该<strong>共享表空间</strong>中。若设置了参数<code>innodb_file_per_table</code>，则用户可以将每个基于InnoDB存储引擎的表产生一个独立表空间。独立表空间的命名规则为∶表名.ibd。通过这样的方式，用户不用将所有数据都存放于共享表空间中。</p>
<p>下面这台MySQL数据库服务器设置了<code>innodb_file_per_table</code>，故可以观察到∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a9dd36b64935cb056ec5b1b365e10efb40d.png" alt=""></p>
<p>表Profile、t1和t2都是基于InnoDB存储的表，由于设置参数<code>innodb_file_per_table=ON</code>，因此产生了单独的.ibd独立表空间文件。</p>
<p>直到这里，我们知道了表空间有两种：</p>
<ol>
<li>共享表文件：<code>innodb_data_file_path</code>参数指向的ibdata1这种文件。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-7c5ac8a6a59f66a5069f82358a7d6cc7a8d.png" alt=""></li>
</ul>
</li>
<li>单独表文件：由于设置参数<code>innodb_file_per_table=ON</code>，因此产生了单独的.ibd独立表空间文件。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-f47d86f905134c1cff8100e6e9ff99140e9.png" alt=""></li>
</ul>
</li>
</ol>
<blockquote>
<p>需要注意的是，这些单独的表空间文件（tableName.ibd）仅存储该表的数据、索引和插入缓冲Bitmap等信息，其余信息，如回滚（undo）信息，插入缓冲索引页、系统事务信息，二次写缓冲（Double write buffer）等信息，还是存放在共享表空间（ibdata1文件）中。</p>
</blockquote>
<p>下图显示了InnoDB存储引擎对于文件的存储方式</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f63c067633b130643ee0baf138d33fc5376.png" alt=""></p>
<h3 id="1-6-2-redo-log文件"><a href="#1-6-2-redo-log文件" class="headerlink" title="1.6.2 redo log文件"></a>1.6.2 redo log文件</h3><p>在默认情况下，在InnoDB存储引擎的数据目录下会有两个名为ib_logfile0和ib_logfile1的文件。在MySQL官方手册中将其称为InnoDB存储引擎的日志文件，不过更准确的定义应该是重做日志文件（redo log file）。为什么强调是重做日志文件呢?因为重做日志文件对于InnoDB存储引擎至关重要，它们记录了对于InnoDB存储引擎的事务日志。</p>
<p>当实例或介质失败（media failure）时，重做日志文件就能派上用场。例如，数据库由于所在主机掉电导致实例失败，InnoDB存储引擎会使用重做日志恢复到掉电前的时刻，以此来保证数据的完整性。</p>
<p>每个InoDB存储引擎至少有1个重做日志文件组（group），每个文件组下至少有2个重做日志文件，如默认的ib_logfile0和ib_logfile1。为了得到更高的可靠性，用户可以设置多个的镜像日志组（mirored log groups），将不同的文件组放在不同的磁盘上，以此提高重做日志的高可用性。在日志组中每个重做日志文件的大小一致，并以循环写入的方式运行。</p>
<p>InnoDB存储引擎先写重做日志文件1，当达到文件的最后时会切换至重做日志文件2，再当重做日志文件2也被写满时，会再切换到重做日志文件1中。</p>
<p>redo log文件详情，可见本站文章《【InnoDB详解四】redo log和undo log》</p>
<h1 id="2-InnoDB存储结构"><a href="#2-InnoDB存储结构" class="headerlink" title="2 InnoDB存储结构"></a>2 InnoDB存储结构</h1><p>我们接下来将从InnoDB存储引擎表的逻辑存储及实现开始进行介绍，然后将重点分析表的物理存储特征，即数据在表中是如何组织和存放的。简单来说，表就是关于特定实体的数据集合，这也是关系型数据库模型的核心。</p>
<p>在InnoDB存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表（index organized table）。在InnoDB存储引擎表中，每张表都有个主键（Primary Key），如果在创建表时没有显式地定义主键，则InnoDB存储引擎会按如下方式选择或创建主键∶</p>
<ol>
<li>首先判断表中是否有非空的唯一索引（Unique NOTNULL），如果有，则该列即为主键。</li>
<li>如果不符合上述条件，InnoDB存储引擎自动创建一个6字节大小的指针。当表中有多个非空唯一索引时，InnoDB存储引擎将选择建表时第一个定义的非空唯一索引为主键。这里需要非常注意的是，<strong>主键的选择根据的是定义索引的顺序，而不是建表时列的顺序</strong>。</li>
</ol>
<h2 id="2-1-InnoDB逻辑存储结构"><a href="#2-1-InnoDB逻辑存储结构" class="headerlink" title="2.1 InnoDB逻辑存储结构"></a>2.1 InnoDB逻辑存储结构</h2><p>从 InnoDB存储引擎的<strong>逻辑</strong>存储结构看，所有数据都被<strong>逻辑地</strong>存放在一个空间中，称之为表空间（tablespace）。表空间又由段（segment）、区（extent）、页（page）组成。页在一些文档中有时也称为块（block），InnoDB存储引擎的逻辑存储结构大致如图4-1所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-dde687244bd19181c20420210e6075394e6.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-57ddcbdf067648c3485d71a95bb15e4974a.png" alt=""></p>
<p>表空间可以看做是InnoDB存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。前文我们已经介绍了表空间，并且知道了表空间分为共享表空间和独立表空间（若有），这里就不再赘述了。</p>
<h3 id="2-1-1-段"><a href="#2-1-1-段" class="headerlink" title="2.1.1 段"></a>2.1.1 段</h3><p>图4-1中显示了表空间是由各个段组成的，常见的段有<strong>数据段、索引段、回滚段</strong>等。</p>
<p>因为前面已经介绍过了InnoDB存储引擎表是索引组织的（index organized），因此数据即索引，索引即数据。那么数据段即为B+树的叶子节点（图4-1的Leafnode segment），索引段即为B+树的非索引节点（图4-1的Non-leaf node segment）。</p>
<p>回滚段较为特殊，将会在后面的章节进行单独的介绍。</p>
<p>在InnoDB存储引擎中，对段的管理都是由引擎自身所完成，DBA不能也没有必要对其进行控制。这和Oracle数据库中的自动段空间管理（ASSM）类似，从一定程度上简化了DBA 对于段的管理。</p>
<h3 id="2-1-2-区"><a href="#2-1-2-区" class="headerlink" title="2.1.2 区"></a>2.1.2 区</h3><p>区是由连续页组成的空间，在任何情况下每个区的大小都为1MB。为了保证区中页的连续性，InnoDB存储引擎一次从磁盘申请4～5个区。在默认情况下，InnoDB存储引擎页的大小为16KB，即一个区中一共有64个连续的页。</p>
<p>InnoDB1.0.x版本开始引入压缩页，即每个页的大小可以通过参数KEY_BLOCK_SIZE设置为2K、4K、8K，因此每个区对应页的数量就应该为512、256、128。</p>
<p>InnoDB 1.2.x版本新增了参数 innodb_page_size，通过该参数可以将默认页的大小设置为4K、8K，但是页中的数据库不是压缩。这时区中页的数量同样也为256、128。总之，不论页的大小怎么变化，区的大小总是为1M。</p>
<p>但是，这里还有这样一个问题∶在用户启用了参数innodb_file_per_talbe后，创建的表默认大小是96KB。区中是64个连续的页，创建的表的大小至少是1MB才对啊，这是什么原因呢?</p>
<p>其实这是因为在每个段开始时，<strong>先用32个页大小的碎片页（fragment page）来存放数据，在使用完这些页之后才是64个连续页的申请</strong>。这样做的目的是，对于一些小表，或者是undo这类的段，可以在开始时申请较少的空间，节省磁盘容量的开销。</p>
<h3 id="2-1-3-页"><a href="#2-1-3-页" class="headerlink" title="2.1.3 页"></a>2.1.3 页</h3><p>同大多数数据库一样，InnoDB有页（Page）的概念（也可以称为块），页是InnoDB磁盘管理的最小单位。在InnoDB存储引擎中，默认每个页的大小为16KB。而从InnoDB 1.2.x版本开始，可以通过参数innodb_page_size将页的大小设置为4K、8K、16K。</p>
<p>若设置完成，则所有表中页的大小都为innodb_page_size，不可以对其再次进行修改。除非通过mysqldump导入和导出操作来产生新的库。</p>
<p>页是InnoDB磁盘管理的最小单位：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4b9e083e4419ed6d4a329215524a2d2a4b7.png" alt=""></p>
<blockquote>
<p>在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，InnoDB存储引擎一个页的大小是16K。</p>
</blockquote>
<h4 id="2-1-3-1-页的类型"><a href="#2-1-3-1-页的类型" class="headerlink" title="2.1.3.1 页的类型"></a>2.1.3.1 页的类型</h4><p>在InnoDB存储引擎中，常见的页类型有∶</p>
<ol>
<li>数据页（B-tree Node）</li>
<li>undo页（undo Log Page）</li>
<li>系统页（System Page）</li>
<li>事务数据页（Transaction system Page）</li>
<li>插入缓冲bitmap页（Insert Buffer Bitmap）</li>
<li>插入缓冲空闲列表页（Insert Buffer Free List）</li>
<li>未压缩的二进制大对象页（Uncompressed BLOB Page）</li>
<li>压缩的二进制大对象页（compressed BLOB Page）</li>
</ol>
<p>在页的File Header结构中，FIL_PAGE_TYPE字段被用来区分数据页的类型（后文会介绍），他们的值如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-96b64aa4d0334ea009a815bc45dd48924ab.png" alt=""></p>
<h3 id="2-1-4-行"><a href="#2-1-4-行" class="headerlink" title="2.1.4 行"></a>2.1.4 行</h3><p>InnoDB存储引擎是面向列的（row-oriented），也就说数据是按行进行存放的。每个页存放的行记录也是有硬性定义的，最多允许存放16KB/2-200行的记录，即7992行记录。</p>
<blockquote>
<p>这里提到了row-oriented的数据库，也就是说，存在有colum-riented的数据库。MySQL infobright存储引擎就是按列来存放数据的，这对于数据仓库下的分析类 SQL语句的执行及数据压缩非常有帮助。类似的数据库还有Sybase IQ、Google Big Table。面向列的数据库是当前数据库发展的一个方向，但这超出了本书涵盖的内容，有兴趣的读者可以在网上寻找相关资料。</p>
</blockquote>
<h2 id="2-2-InnoDB存储格式"><a href="#2-2-InnoDB存储格式" class="headerlink" title="2.2 InnoDB存储格式"></a>2.2 InnoDB存储格式</h2><h3 id="2-2-1-InnoDB行记录格式"><a href="#2-2-1-InnoDB行记录格式" class="headerlink" title="2.2.1 InnoDB行记录格式"></a>2.2.1 InnoDB行记录格式</h3><p>InnoDB存储引擎和大多数数据库一样（如 Oracle和Microsof SQL Server数据库），记录是以行的形式存储的。这意味着页中保存着表中一行行的数据。在InmoDB1.0x版本之前，InnoDB存储引擎提供了Compact和Redundant两种格式来存放行记录数据，这也是目前使用最多的一种格式。</p>
<p>Redundant格式是为兼容之前版本而保留的，如果阅读过InnoDB的源代码，用户会发现源代码中是用PHYSICALRECORD（NEW STYLE）和PHYSICALRECORD（OLD STYLE）来区分两种格式的。</p>
<p>在MySQL5.1版本中，默认设置为Compact行格式。用户可以通过命令SHOW TABLE STATUS LIKE’table_name’来查看当前表使用的行格式，其中row_format 属性表示当前所使用的行记录结构类型。如∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-52ac4e4b7bd5e8d753a861b5a795d430c68.png" alt=""></p>
<p>可以看到，这里的mytest表是Compact的行格式，mytest2表是Redundant的行格式。</p>
<h4 id="2-2-1-1-Compact类型格式"><a href="#2-2-1-1-Compact类型格式" class="headerlink" title="2.2.1.1 Compact类型格式"></a>2.2.1.1 Compact类型格式</h4><p>Compact行记录是在MySQL5.0中引入的，其设计目标是高效地存储数据。简单来说，一个页中存放的行数据越多，其性能就越高。下图显示了Compact行记录的存储方式∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9f530fbc68f17136efaced7cf23194a2e62.png" alt=""></p>
<ol>
<li>变长字段长度列表<ul>
<li>这部分用来记录该行中每个varchar字段的长度（注意，只记录varchar字段的长度，单位是字节），假设数据行中会有n个varchar列，所以该部分也会对应存储n个长度值。</li>
<li><strong>每个varchar列的长度一般用一个字节（对应字段真正长度 &lt; 128字节），最多只能用两个字节（16 bit）（对应字段真正长度 &gt;= 128字节）表示</strong>，所以在MySQL数据库中varchar类型的最大长度限制为65535字节（2的16次方）。</li>
<li>不过这里就有问题了，如果a列的长度占用1个字节，b列的长度占用两个字节，那解析的时候如何知道这三个字节的分界线呢？InnoDB规定如果某个字节最高位为0，那么这个字节就是独立的字节；如果某个字节最高位为1，那么就和它后面的字节共同表示一个长度（第二个字节可以用所有位表示长度）。<strong>也正是因为字节首位另有用处，所以一个字节最多表示长度为小于128</strong>。</li>
<li>所以如果a，b两列长度紧密排列，如<code>01111111 10000000 10000000</code>，那就可以知道分界线是<code>01111111 | 10000000 10000000</code>。需要注意的是，MySQL采取 Little Endian 的计数方式，低位在前，高位在后，所以129用两个字节表示就是 <code>10000001 10000000</code>。</li>
<li>变长字段长度列表中每个长度值的排序，和行中varchar列的顺序是相反的，也就是长度值在变长字段长度列表中是倒序存放</li>
</ul>
</li>
</ol>
<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 假如有三个字段 id,name,desc,age。其中name,desc是变长类型（Varchar）</span><br><span class="line">|id|name|desc|age|</span><br><span class="line">|1|wang|shuaige|18|</span><br><span class="line">|2|li|meinv|20|</span><br><span class="line">	</span><br><span class="line">则磁盘里的存储为：</span><br><span class="line">0x07 0x04 null值列表 数据头 1 wang shuaige 18 0x05 0x02 null值列表 数据头 2 li meinv 20</span><br><span class="line"># 其中0x04表示name长度为4 ,0x07表示desc的长度为7，以此类推。</span><br></pre></td></tr></table></figure></code></pre><ol start="2">
<li><p>NULL标志位</p>
<ul>
<li>该部分用来标记该行中哪些列的值是NULL值。</li>
<li>它是一个bitmap，一般占用1个字节（8 bit），它的每一位位指示了该行数据中对应的列是否是NULL值，有则用1表示。</li>
<li>比如NULL标志位如果为0x06，二进制是00000110，很显然第2位和第3位的值是1，那么就表示该行的第二列和第三列当前值为NULL。</li>
<li>NULL标志位一般是占用1个字节，但如果列的数量大于8个，那么会多扩充一个字节，直到能涵盖所有的列。</li>
</ul>
</li>
<li><p>记录头信息（record header）</p>
<ul>
<li>固定占用5字节（40位），每位的含义见下图：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-516d623552830ed65906b93d067e5754855.png" alt=""></li>
<li>值得注意的是RecordHeader的最后两个字节，这16 bit是next_recorder，代表下一个记录的偏移量，假设该值为0x2c，那么它表示当前记录的位置加上偏移量0x2c就是下条记录的起始位置。所以InnoDB存储引擎在页内部是通过一种链表的结构来串连各个行记录的。</li>
</ul>
</li>
<li><p>列数据</p>
<ul>
<li>最后的部分就是实际存储每个列的数据。需要特别注意的是，NULL不占该部分任何空间，即NULL除了占有NULL标志位，实际存储不占有任何空间。</li>
<li>另外有一点需要注意的是，每行数据除了用户定义的列外，还有两个隐藏列，事务ID列和回滚指针列，分别为6字节和7字节的大小，这两个部分与InnoDB实现MVCC有关，版本控制、事务回滚等内容，这里不详述。若InnoDB表没有定义主键，每行还会增加一个6字节的rowid列。</li>
</ul>
</li>
</ol>
<p>我们来用一个实际的例子分析Compact行记录格式吧：</p>
<p>我们先定义一个表mytest，其中t1，t2，t4是变长的varchar类型，t3是固定长度的char类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;mytest&#96; (</span><br><span class="line">&#96;t1&#96; varchar(10) DEFAULT NULL,</span><br><span class="line">&#96;t2&#96; varchar(10) DEFAULT NULL,</span><br><span class="line">&#96;t3&#96; char(10) DEFAULT NULL,</span><br><span class="line">&#96;t4&#96; varchar(10) DEFAULT NULL</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latin1 ROW_FORMAT&#x3D;COMPACT</span><br></pre></td></tr></table></figure>

<p>我们插入如下记录（其中–表示NULL）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from mytest;</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| t1 | t2 | t3 |  t4 |</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| a  | bb | bb | ccc |</span><br><span class="line">| d  | ee | ee | fff |</span><br><span class="line">| d  | -- | -- | fff |</span><br><span class="line">+----+----+----+-----+</span><br></pre></td></tr></table></figure>

<p>然后将打开表空间文件mytest.ibd（这里启用了innodb_file_per_table，若没有启用该选项，打开默认的共享表空间文件 ibdata1）。</p>
<p>在Windows操作系统下，可以选择通过程序UltraEdit打开该二进制文件。在Linux 环境下，使用命令<code>hexdump-C-v mytest.ibd&gt;mytest.txt</code>。这里将结果重定向到了文件mytes.txt，打开 mytest.txt文件，找到如下内容∶</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0000c070 73 75 70 72 65 6d 75 6d 03 02 01 00 00 00 10 00|supremum……</span><br><span class="line">0000c080 2c 00 00 00 2b 68 00 00 00 00 00 06 05 80 00 00|，……+h……</span><br><span class="line">0000c090 00 32 01 10 61 62 62 62 62 20 20 20 20 20 20 20|.2..abbbb</span><br><span class="line">0000c0a0 20 63 63 63 03 02 01 00 00 00 18 00 2b 00 00 00|ccc……+……</span><br><span class="line">0000c0b0 2b 68 01 00 00 00 00 06 06 80 00 00 00 32 01 10|+h……2..</span><br><span class="line">0000c0c0 64 65 65 65 65 20 20 20 20 20 20 20 20 66 66 66|deeeefff</span><br><span class="line">0000c0d0 03 01 06 00 00 20 ff 98 00 00 00 2b 68 02 00 00|……+h……</span><br><span class="line">0000c0e0 00 00 06 07 80 00 00 00 32 01 10 64 66 66 66 00|……2..dfff.</span><br></pre></td></tr></table></figure>

<p>第一行记录（a,bb,bb,ccc）从0000c078开始，我们整理一下，下面都是16进制数，如03就是0x03：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">03 02 01&#x2F;*变长字段长度列表，分别记录t1，t2，t4的长度，逆序*&#x2F;</span><br><span class="line">00&#x2F;*NULL标志位，第一行没有NULL值*&#x2F;</span><br><span class="line">00 00 10 00 2c&#x2F;*记录头信息，固定5字节长度*&#x2F;</span><br><span class="line">00 00 00 2b 68 00&#x2F;*RowID我们建的表没有主键，因此会有RowID*&#x2F;</span><br><span class="line">00 00 00 00 06 05&#x2F;*TransactionID*&#x2F;</span><br><span class="line">80 00 00 00 32 01 10&#x2F;*Roll Pointer*&#x2F;</span><br><span class="line">61&#x2F;*t1数据&#39;a&#39;*&#x2F;</span><br><span class="line">62 62&#x2F;*t2&#39;bb&#39;*&#x2F;</span><br><span class="line">62 62 20 20 20 20 20 20 20 20&#x2F;*t3数据&#39;bb&#39;，因为t3列是固定长度的char类型，所以可以看到，未占用的地方，char用0x20（空格）补全*&#x2F;</span><br><span class="line">63 63 63&#x2F;*t4数据&#39;ccc&#39;*&#x2F;</span><br></pre></td></tr></table></figure>

<p>我们再来看有NULL值的第三行记录（d,NULL,NULL,fff），</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">03 01&#x2F;*变长字段长度列表，逆序*&#x2F;</span><br><span class="line">06&#x2F;*NULL标志位，06的二进制是00000110，很显然第2位和第3位的值是1，所以t2和t3是NULL*&#x2F;</span><br><span class="line">00 00 20 ff 98&#x2F;*记录头信息*&#x2F;</span><br><span class="line">00 00 00 2b 68 02&#x2F;*RowID*&#x2F;</span><br><span class="line">00 00 00 00 06 07&#x2F;*TransactionID*&#x2F;</span><br><span class="line">80 00 00 00 32 01 10&#x2F;*Roll Pointer*&#x2F;</span><br><span class="line">64&#x2F;*t1数据&#39;d&#39;*&#x2F;</span><br><span class="line">66 66 66&#x2F;*t4数据&#39;fff&#39;*&#x2F;</span><br></pre></td></tr></table></figure>

<p>可以发现不管是char还是varchar，NULL都不占用任何空间。</p>
<h4 id="2-2-1-2-Redundant类型格式"><a href="#2-2-1-2-Redundant类型格式" class="headerlink" title="2.2.1.2 Redundant类型格式"></a>2.2.1.2 Redundant类型格式</h4><p>Redundant是MySQL 5.0版本之前InnoDB的行记录存储方式，MySQL 5.0支持Redundant是为了兼容之前版本的页格式。Redundant行记录采用如下所示的方式存储。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-8eac0bc22f7a4dbd8dca7ef7491b534d190.png" alt=""></p>
<ol>
<li>字段长度偏移列表<ul>
<li>不同于Compact行记录格式，Redundant行记录格式的首部是一个字段长度<strong>偏移</strong>列表，同样是按照列的顺序<strong>逆序</strong>放置的。</li>
<li>注意该列表记录的是每个列长度的偏移量，而不是长度值本身，比如某个字段长度偏移列表经整理后为<code>23 20 16 14 13 0c 06</code>，因为是逆序排布，所以我们先翻为正序<code>06，0c，13，14，16，20，23</code>，那么这表示：第一列的长度是6，第二列的长度是6（6+6=0x0C），第三列的长度为7（6+6+7=0x13），第四列的长度是1（6+6+7+1=0x14），第五列的长度是2（6+6+7+1+2=0x16），第六列的长度是10（6+6+7+1+2+10=0x20），第七列的长度是3（6+6+7+1+2+10+3=0x23）。</li>
<li>同样的，长度列表中每个列的长度的偏移值一般用一个字节，最多用两个字节来存储。不过不同于compact格式，compact格式允许a列使用1个字节，b列使用两个字节，但是Redundant的话，<strong>要么所有列的偏移值都占用1字节，要么都占用2字节</strong>。</li>
<li>到底每个偏移使用1字节还是2字节，是根据整行记录的长度决定，如果<strong>整行长度</strong>小于 128，则用1字节存储，否则，用2字节。<ul>
<li>如果是1字节存储的情况，那么每个字节最高的那个bit用来标记对应字段值是否为 NULL，如果为NULL，则最高位为1，否则为0。剩下的7位用来存储长度偏移量，所以最多是127。</li>
<li>对于两字节存储，首个字节的最高位还是用来标记对应字段值是否为NULL。最高的第二位则用来标记这条记录是否在同一页，如果在则为0，如果不在则为1，这其实就涉及到了后面要说的溢出页。剩下的连同第二个字节完整8bit在内的14bit表示长度，所以最多是16383</li>
</ul>
</li>
</ul>
</li>
<li>记录头信息（record header）<ul>
<li>不同于Compact行记录格式，Redundant行记录格式的记录头占用6字节（48 位），每位的含义见下表</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-c935a4248a4f545e00e0a7d004ac8d1d5ed.png" alt=""></li>
<li>从中可以发现，n_fields值代表一行中列的数量，占用10位。同时这也很好地解释了为什么MySQL数据库一行支持最多的列为1023。因为2的10次方为1024</li>
<li>另一个需要注意的值为1byte_offs_flag，该值定义了字段长度偏移列表占用的是1字节还是2字节。</li>
</ul>
</li>
<li>列数据<ul>
<li>最后的部分就是实际存储每个列的数据。需要特别注意的是，varchar类型的NULL不占该部分任何空间，char类型的NULL占用固定空间。</li>
<li>另外有一点需要注意的是，每行数据除了用户定义的列外，还有两个隐藏列，事务ID列和回滚指针列，分别为6字节和7字节的大小，这两个部分与InnoDB实现MVCC有关，版本控制、事务回滚等内容，这里不详述。若InnoDB表没有定义主键，每行还会增加一个6字节的rowid列。</li>
</ul>
</li>
</ol>
<p>好，我们也来看下Redundant格式的例子，还是那张表和那些记录：</p>
<p>其中t1，t2，t4是变长的varchar类型，t3是固定长度的char类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from mytest;</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| t1 | t2 | t3 |  t4 |</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">| a  | bb | bb | ccc |</span><br><span class="line">| d  | ee | ee | fff |</span><br><span class="line">| d  | -- | -- | fff |</span><br><span class="line">+----+----+----+-----+</span><br></pre></td></tr></table></figure>

<p>我们直接来看有NULL的第三行（下面都是16进制表示）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a1 9e 94 14 13 0c 06&#x2F;*长度偏移列表，逆序*&#x2F;</span><br><span class="line">00 00 20 0f 00 74&#x2F;*记录头信息，固定6个字节*&#x2F;</span><br><span class="line">00 00 00 2b 68 0d&#x2F;*RowID*&#x2F;</span><br><span class="line">00 00 00 00 06 53&#x2F;*TransactionID*&#x2F;</span><br><span class="line">80 00 00 00 32 01 10&#x2F;*Roll Point*&#x2F;</span><br><span class="line">64&#x2F;*t1数据&#39;d&#39;*&#x2F;</span><br><span class="line">00 00 00 00 00 00 00 00 00 00&#x2F;*t3数据NULL*&#x2F;</span><br><span class="line">66 66 66&#x2F;*t4数据&#39;fff&#39;*&#x2F;</span><br></pre></td></tr></table></figure>

<p>可以看到：</p>
<ol>
<li>来看长度偏移列表，<code>21 9e 94 14 13 0c 06</code>翻转为正序是<code>06 0c 13 14 94 9e 21</code>，我们前面说过，每个字节中首位用来表示字段是否为NULL，后面7位才表示偏移值，这里需要将每个字节分成两部分（1bit | 7bit），并转化为十进制是<code>0|6 0|12 0|19 0|20 1|20 1|30 0|33</code></li>
<li>该行中varchar类型的t2列，因为值为NULL，故而在Redundant格式中没有占用任何空间，所以我们看不到t2，t2位NULL的信息其实旨在长度偏移列表中体现了，也就是上文说到的<code>1|20</code>这个字节。但同样为NULL值的t3数据，除了在偏移列表中体现外，却真的占用了10个字节，可见，<strong>在Redundant格式中，varchar类型的NULL不占用空间，char类型的NULL固定占用10字节空间</strong>。</li>
<li>记录头信息中应该注意48位中22～32位（n_fields），为0000000111，表示表共有7个列（包含了隐藏的3列），接下去的33位（1byte_offs_flag）为1，代表偏移列表中每个偏移量占用一个字节。</li>
</ol>
<blockquote>
<p>当前表mytest的字符集为Latin1，每个字符最多只占用1个字节。若这里将表mytest的字符集转换为utf8，则第三列char固定长度类型就不再是只占用10个字节了，而是10×3=30个字节，Redundant行格式下char固定字符类型将会占据可能存放的最大值字节数。</p>
</blockquote>
<h4 id="2-2-1-3-行溢出数据"><a href="#2-2-1-3-行溢出数据" class="headerlink" title="2.2.1.3 行溢出数据"></a>2.2.1.3 行溢出数据</h4><p>InnoDB存储引擎可以将一条记录中的某些数据存储在数据页之外，而不是存放在行记录所在的当前页中，这类数据就叫行溢出数据。什么情况下会出现行溢出数据呢？答案是一个页（16K）放不下的时候，一些数据必然要溢出。</p>
<p>于是我们可以想到BLOB、LOB这类的大对象列类型的存储，InnoDB应该会把数据存放在数据页面之外。但是，这个理解有点偏差，其实BLOB、LOB这类的大对象并不一定非要溢出，而常见的varchar类型也并不一定不会溢出。</p>
<p>那么什么时候会产生行溢出数据呢？这个阈值是多少呢？</p>
<p>前文我们说过，<strong>数据页会被InnoDB以B+树的形式给整理起来</strong>，这就要求了：<strong>一个数据页中应该至少能存两条行记录</strong>（如果一个页只能存一行，那B+树就没有意义了，数据结构就成链表了）</p>
<p>基于这个要求，我们知道一个页为16KB，即16384字节，那么扣除掉页中如header，tail，dictionary等固定字段外，再对半分，则可以得出一行记录不发生行溢出的最大长度上限：<strong>8098字节</strong>。</p>
<p>那么，如果一行记录长度超过了8098字节，InnoDB又会如何存储呢？</p>
<p>在一般情况下，InnoDB存储引擎的数据都是存放在页类型为B-tree node（也就是数据页）的页中。但是当发生行溢出时，数据溢出部分存放在页类型为Uncompress BLOB的页中：</p>
<p>假设我们创建一个列a长度为65532的表t，并插入一条数据</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3164ed940f9d57e06258f6a7c4f77c38145.png" alt=""></p>
<p>通过工具可以观察到表空间中有一个数据页节点B-tree Node，另外有4个未压缩的二进制大对象页Uncompressed BLOB Page，在这些页中才真正存放了65532字节的数据。既然实际存放的数据都在BLOB页中，那数据页中又存放了些什么内容呢?同样通过之前的 hexdump来读取表空间文件，从数据页c000开始查看∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d9bed37dbfbb79292b1af2f46fa441bc2f6.png" alt=""></p>
<p>可以看到，从0x0000c093到0x000c392数据页面其实只保存了VARCHAR（65532）的<strong>前768字节的前缀</strong>（prefix）数据（这里都是a）。然后之后是行溢出页指针（20字节），指向行溢出页，也就是前面用户看到的Uncompressed BLOB Page。因此，对于行溢出数据，其存放采用下图的方式。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-098ad59f67bb0fd52b16d1d84dcfb0809dc.png" alt=""></p>
<h4 id="2-2-1-4-Compressed-Dynamic类型格式"><a href="#2-2-1-4-Compressed-Dynamic类型格式" class="headerlink" title="2.2.1.4 Compressed/Dynamic类型格式"></a>2.2.1.4 Compressed/Dynamic类型格式</h4><p>InnoDB Plugin引入了新的文件格式（file format，可以理解为新的页格式），对于以前支持的Compact和Redundant格式将其称为Antelope文件格式，新的文件格式称为Barracuda。</p>
<p>Barracuda文件格式下拥有两种新的行记录格式Compressed和Dynamic两种。新的两种格式对于存放BLOB的数据采用了完全的行溢出的方式，在数据页中只存放20个字节的指针，实际的数据都存放在BLOB Page中，而之前的Compact和Redundant两种格式会存放768个前缀字节。</p>
<p>下图是Barracuda文件格式的溢出行：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7647fad5539a242a7fdf54a7f1b531af2f2.png" alt=""></p>
<p>Compressed行记录格式的另一个功能就是，存储在其中的行数据会以<strong>zlib的算法</strong>进行压缩，因此对于BLOB、TEXT、VARCHAR这类大长度类型的数据能够进行非常有效的存储。</p>
<h4 id="2-2-1-5-CHAR类型字段的存储"><a href="#2-2-1-5-CHAR类型字段的存储" class="headerlink" title="2.2.1.5 CHAR类型字段的存储"></a>2.2.1.5 CHAR类型字段的存储</h4><p>通常理解 VARCHAR是存储变长长度的字符类型，CHAR是存储固定长度的字符类型。而在前面的小节中，用户已经了解行结构的内部的存储，并可以发现每行的变长字段长度的列表都没有存储CHAR类型的长度。</p>
<p>然而，值得注意的是之前给出的两个例子中的字符集都是单字节的latin1格式。从MySQL4.1版本开始，CHAR（N）中的N指的是字符的个数，而不是之前版本的字节长度。也就说在不同的字符集下，CHAR类型列内部存储的可能不是定长的数据。</p>
<p>例如，对于UTF-8下CHAR（10）类型的列，其最小可以存储10字节的字符（都是拉丁字母），而最大可以存储30字节的字符（10个字符都是汉字）。因此，对于多字节字符编码的CHAR数据类型的存储，<strong>InnoDB存储引擎在内部将其视为VARCHAR变长字符类型</strong>。这也就意味着在变长长度列表中会记录CHAR 数据类型的长度。</p>
<p><strong>因此可以认为在多字节字符集的情况下，CHAR和VARCHAR的实际行存储基本是没有区别的</strong>。</p>
<h3 id="2-2-2-数据页的存储格式"><a href="#2-2-2-数据页的存储格式" class="headerlink" title="2.2.2 数据页的存储格式"></a>2.2.2 数据页的存储格式</h3><p>我们已经知道页是InnoDB存储引擎管理数据库的最小磁盘单位。类型为B-tree Node的页存放的即是表中行的实际数据了。页的结构如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c831f98dd011f807e7100bca08e9c01a305.png" alt=""></p>
<h4 id="2-2-2-1-File-Header"><a href="#2-2-2-1-File-Header" class="headerlink" title="2.2.2.1 File Header"></a>2.2.2.1 File Header</h4><p><strong>File Header</strong> 字段用于记录 Page 的头信息。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b844420e80d52e767ccff0e0a6ef7ebbe0f.png" alt=""></p>
<p>其中比较重要的是 FIL_PAGE_PREV 和 FIL_PAGE_NEXT 字段，它们分别是B+树叶子节点双向链表的前驱和后驱，通过这两个字段，我们可以找到该页的上一页和下一页，实际上所有页通过两个字段可以形成一条双向链表。</p>
<h4 id="2-2-2-2-Page-Header"><a href="#2-2-2-2-Page-Header" class="headerlink" title="2.2.2.2 Page Header"></a>2.2.2.2 Page Header</h4><p><strong>Page Header</strong> 字段用于记录页的状态信息。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-8cfcdf1e3da990c1f0e4164467457bd9da5.png" alt=""></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-e398686bcf847a72564b954a18f4acd5608.png" alt=""></li>
</ul>
<h4 id="2-2-2-3-Infimum-和-Supremum"><a href="#2-2-2-3-Infimum-和-Supremum" class="headerlink" title="2.2.2.3 Infimum 和 Supremum"></a>2.2.2.3 Infimum 和 Supremum</h4><p><strong>Infimum 和 Supremum</strong> 是两个虚拟的行记录，用来确定真实的行记录的边界。</p>
<p>Infimum（下确界）记录比该页中任何主键值都要小的值，Supremum （上确界）记录比该页中任何主键值都要大的值，这个虚拟记录分别构成了页中记录的边界。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f5a741681f7bda057e0743abc1605d5ee30.png" alt=""></p>
<h4 id="2-2-2-4-User-Records"><a href="#2-2-2-4-User-Records" class="headerlink" title="2.2.2.4 User Records"></a>2.2.2.4 User Records</h4><p><strong>User Records</strong> 中存放的是<strong>实际的数据行记录</strong>，行记录的格式，我们在上文中已经介绍过了，有compact/redundant等格式。</p>
<p>我们再来复习一下，不论是什么格式，行记录都有一个记录头信息部分（record header）</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9f530fbc68f17136efaced7cf23194a2e62.png" alt=""></p>
<p>记录头中各个字段如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-516d623552830ed65906b93d067e5754855.png" alt=""></p>
<p>值得注意的是Record Header的最后两个字节，这16 bit是next_recorder，代表下一个记录的偏移量，假设该值为0x2c，那么它表示当前记录的位置加上偏移量0x2c就是下条记录的起始位置。<strong>所以行记录在User Records中是通过一种链表的结构来串连起来的</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-11431516dbe26aa0eb8739349aa5f33dec4.png" alt=""></p>
<p>排序顺序一般是根据primary key升序放置。</p>
<h4 id="2-2-2-5-Free-Space"><a href="#2-2-2-5-Free-Space" class="headerlink" title="2.2.2.5 Free Space"></a>2.2.2.5 Free Space</h4><p><strong>Free Space</strong> 中存放的是空闲空间，当一条行记录被删除后，它的空间会被加入到空闲列表中。</p>
<h4 id="2-2-2-6-Page-Directory"><a href="#2-2-2-6-Page-Directory" class="headerlink" title="2.2.2.6 Page Directory"></a>2.2.2.6 Page Directory</h4><p><strong>Page Directory</strong> 页目录，记录着与二叉查找相关的信息。</p>
<p>前面我们介绍了User Records是有序的，那么维护User Records的记录有序是为了做什么呢？没错，还是为了性能。行记录之间以链表串联，链表的查询性能是O(n)，这显然是不够理想的，为了提升性能，Page Directory应运而生。</p>
<p>我们可以打个比方，我们在看书的时候，如果要找到某一节，而这一节我们并不知道在哪一页，我们是不是就要从前往后，一节一节地去寻找我们需要的内容的页码呢？</p>
<p>答案是否定的，因为在书的前面，存在目录，它会告诉你这一节在哪一页，例如，第一节在第1页、第二节在第13页。在数据库的页中，实际上也使用了这种目录的结构，这就是页目录。</p>
<p>那么引入页目录之后，我们所理解的页结构，就变成了这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fd4a712ed26ec34941484e0d70c742fe25d.png" alt=""></p>
<p>页目录是一个稀疏目录，它有限的目录项会离散的指向整个User Records列表的各个锚点，比如上图的目录项1指向id=1，目录项2指向id=3。</p>
<p>如此一来，假设我们要寻找id=5的数据，就不需要遍历一遍整个User Records列表了，只要通过页目录（假设是<code>[1,3,7,10,...]</code>）定位到id=9是在7-10之间，那么就可以直接跳到id=7，之后再后溯两个行，就能定位到id=9。</p>
<h4 id="2-2-2-7-File-Trailer"><a href="#2-2-2-7-File-Trailer" class="headerlink" title="2.2.2.7 File Trailer"></a>2.2.2.7 File Trailer</h4><p><strong>File Trailer</strong> 存储用于检测数据完整性的校验和等数据。</p>
<p>为了检测页是否已经完整地写人磁盘（如可能发生的写人过程中磁盘损坏、机器关机等），InnoDB存储引擎的页中设置了File Trailer部分。</p>
<p>File Trailer只有一个FIL_PAGE_END_LSN部分，占用8字节。前4字节代表该页的checksum值，最后4字节和File Header中的FIL_PAGELSN相同。将这两个值与File Header中的FIL_PAGE_SPACE_OR_CHKSUM和FIL_PAGELSN值进行比较，看是否一致（checksum的比较需要通过InnoDB的checksum函数来进行比较，不是简单的等值比较），以此来保证页的完整性（not corrupted）。</p>
<h3 id="2-2-3-索引和页的联系"><a href="#2-2-3-索引和页的联系" class="headerlink" title="2.2.3 索引和页的联系"></a>2.2.3 索引和页的联系</h3><p>我们已经知道InnoDB的索引采用B+树来实现，B+树中的叶子节点和非叶子节点，其实它们也都是页，只不过叶子结点的页（我们称为索引页）只存放键值和指向非叶子节点（我们称为数据页）的偏移量：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d56be3c294a4f3897605f7817f60a37d900.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-03e38ce46f0b73c2a688a808d2f8424ea26.png" alt=""></p>
<p>如上图可以看到，page 4/5/6都是叶子节点的数据页，他们存放实际的行记录。除此以外还有存放索引键值和指针的页，比如图中page number=3的页，该页存放键值和指向数据页的指针。这只是一个实例，实际上我们完整的B+树应该长这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3351c306d86845e280dadb774a97ded1de8.png" alt=""></p>
<p>这些页都是被各种指针给<strong>逻辑地</strong>组成了一个B+树，<strong>他们实际上都离散的存放在磁盘上</strong>，也就是我们之前说的独立表空间文件中（tableName.idb文件中）。</p>
<p>当我们需要对某个页做读写的时候，再将某个页从磁盘载入缓冲池，缓冲池大小有限，所以会通过LRU List做淘汰机制，将不常用的页从缓冲池删除。</p>
<p>那么，假设现在要查找一条数据，该怎么查，比如：</p>
<p>select * from t1 where id=6;</p>
<p>在这里我们假设t1表选择自增id来做主键，这时要通过B+树来查找：</p>
<ol>
<li><p>首先查找根页。一般来说，每个表的根页位置在表空间（t1.ibd）中都是不变的，在这里也就是page number=3的页，将page number=3的页载入缓冲池。</p>
<blockquote>
<p>其实一般来说，根页只要进入缓冲池，就基本上都是热点数据，很难被LRU算法淘汰掉，因为基本上所有走t1表索引的查询，都要访问t1表的根页，即便是走非聚簇索引，也会定位到聚簇索引上来。</p>
</blockquote>
</li>
<li><p>找到根页后通过二分查找法，定位到id=6的页应该在指针P5指向的页中。</p>
<blockquote>
<p><strong>需要牢记的是，B+树索引本身并不能找到具体的一条记录，能找到只是该记录所在的页</strong>。</p>
</blockquote>
</li>
<li><p>如果P5指向的页（page number=5）不在缓冲池中，那么把页载入到缓冲池。</p>
</li>
<li><p>发现page number=5的页是非叶子节点了，然后通过Page Directory再进行二叉查找，即可查找到id=6的对应记录了。</p>
<blockquote>
<p>Page Directory二叉查找的时间复杂度很低，同时在缓冲池（也就是内存）中的查找很快，因此通常忽略这部分查找所用的时间。</p>
</blockquote>
</li>
</ol>
<p>再看一张类似的图</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d468bc450e8055f95de04f818faaf23432d.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/31/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%80%E3%80%91%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%92%8C%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/31/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%80%E3%80%91%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%92%8C%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7/" itemprop="url">【InnoDB详解一】体系架构和关键特性</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-31T21:43:59+08:00">
                2020-08-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/31/%E3%80%90InnoDB%E8%AF%A6%E8%A7%A3%E4%B8%80%E3%80%91%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%92%8C%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/08/31/【InnoDB详解一】体系架构和关键特性/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  14.7k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  53
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>InnoDB存储引擎最早由Innobase Oy公司°开发，被包括在MySQL数据库所有的二进制发行版本中，从MySQL5.5版本开始是默认的表存储引擎（之前的版本IlmoDB 存储引擎仅在Windows下为默认的存储引擎）。该存储引擎是第一个完整支持ACID事务的MySQL存储引擎（BDB是第一个支持事务的MySQL存储引擎，现在已经停止开发），其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读，同时被设计用来最有效地利用以及使用内存和 CPU。</p>
<p>InnoBD通过有如下机制来优化性能：</p>
<ol>
<li><strong>缓冲池</strong>：使用缓冲池来优化读写性能，写的时候，将页从磁盘刷入缓冲池，再做修改，读的时候，读缓冲池的页，脏数据通过异步适时的刷回磁盘。</li>
<li><strong>后台线程</strong>：使用后台线程来减少对用户线程的阻塞。</li>
<li><strong>插入缓冲</strong>：使用插入缓冲（Insert Buffer）机制来优化非唯一性索引的写性能，使其在缓冲池技术的基础上再少一次磁盘IO。</li>
<li><strong>两次写</strong>：使用两次写（doublewrite）机制来确保数据页从内存刷新到硬盘时如果中途宕机，则仍可以通过数据页副本来恢复该数据页，保证数据页向磁盘flush过程的可靠性。</li>
<li><strong>自适应哈希索引</strong>：通过自适应哈希索引（Adaptive Hash Index，AHI）机制来对缓冲中高频热点的B+树索引页自动建立哈希索引，以替代<strong>等值查询</strong>，优化查询性能。</li>
<li><strong>异步IO</strong>：通过异步IO（Asynchronous IO，AIO）机制，将read ahead方式的读取，磁盘的写入，数据的恢复等诸多操作通过异步来处理，提高处理效率。</li>
<li><strong>刷新邻接页</strong>：通过刷新邻接页（Flush Neighbor Page）机制，可以在flush数据页进入缓存的时候，顺序将该页所在区（extent）的所有脏页一起flush，将本该多次IO的操作合并一次完成，该机制在传统机械硬盘场景中性能提升明显。</li>
</ol>
<p>InnoDB存储引擎已经被许多大型网站使用，如用户熟知的Google、Yahoo!、Facebook、YouTube、Flickr，在网络游戏领域有《魔兽世界》、《Second Life》、《神兵玄奇》等。</p>
<h1 id="1-InnoDB的体系架构"><a href="#1-InnoDB的体系架构" class="headerlink" title="1 InnoDB的体系架构"></a>1 InnoDB的体系架构</h1><p>下图2简单显示了InoDB的存储引擎的体系架构，从图可见，InnoDB存储引擎有多个内存块，可以认为这些内存块组成了一个大的内存池，负责如下工作∶</p>
<ul>
<li>维护所有进程/线程需要访问的多个内部数据结构。</li>
<li>缓存磁盘上的数据，方便快速地读取，同时在对磁盘文件的数据修改之前在这里缓存。</li>
<li>重做日志（redo log）缓冲。</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-94e3f8ff530d171d53e872caa4a3c2ca5b4.png" alt=""></p>
<p>后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据。此外将已修改的数据文件刷新到磁盘文件，同时保证在数据库发生异常的情况下 InnoDB 能恢复到正常运行状态。</p>
<h2 id="1-1-InnoDB的后台线程"><a href="#1-1-InnoDB的后台线程" class="headerlink" title="1.1 InnoDB的后台线程"></a>1.1 InnoDB的后台线程</h2><p>InnoDB存储引擎是多线程的模型，因此其后台有多个不同的后台线程，负责处理不同的任务</p>
<h3 id="1-1-1-Master-Thread"><a href="#1-1-1-Master-Thread" class="headerlink" title="1.1.1 Master Thread"></a>1.1.1 Master Thread</h3><p>Master Thread是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲（INSERTBUFER）、UNDO页的回收等。</p>
<p>Master Thread具有最高的线程优先级别。其内部由多个循环（loop）组成∶<strong>主循环（loop）</strong>、<strong>后台循环（backgroup loop）</strong>、<strong>刷新循环（flush loop）</strong>、<strong>暂停循环（suspend loop）</strong>。Master Thread会根据数据库运行的状态在loop、background loop、flush loop和suspend loop之间切换。</p>
<p><strong>主循环（loop）</strong></p>
<p>Loop被称为主循环，因为大多数的操作是在这个循环中，其中有两大部分的操作———每秒钟的操作和每10秒的操作。伪代码如下∶</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">void master thread()&#123;</span><br><span class="line">	loop:</span><br><span class="line">	for(int i&#x3D; 0;i&lt;10;i++)&#123;</span><br><span class="line">		do thing once per second;</span><br><span class="line">		sleep 1 second if necessary;</span><br><span class="line">	&#125;</span><br><span class="line">	do things once per ten seconds</span><br><span class="line">	goto loop;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，loop循环通过 thread sleep来实现，这意味着所谓的每秒一次或每10秒一次的操作是不精确的。在负载很大的情况下可能会有延迟（delay），只能说大概在这个频率下。当然，InnoDB源代码中还通过了其他的方法来尽量保证这个频率。</p>
<p><strong>每秒一次</strong>的操作包括：（有概念尚不清晰的，后文会做详解）</p>
<ol>
<li>日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）;<ul>
<li>即使某个事务还没有提交，InoDB存储引擎仍然每秒会将重做日志缓冲中的内容刷新到重做日志文件。这一点是必须要知道的，因为这可以很好地解释为什么再大的事务提交（commit）的时间也是很短的。</li>
</ul>
</li>
<li>合并插入缓冲（可能）;<ul>
<li>合并插入缓冲（Insert Buffr）并不是每秒都会发生的。InnoDB存储引擎会判断当前一秒内发生的IO次数是否小于5次，如果小于5次，InoDB认为当前的IO压力很小，可以执行合并插人缓冲的操作。</li>
</ul>
</li>
<li>至多刷新100个InnoDB的缓冲池中的脏页到磁盘（可能）;<ul>
<li>同样，刷新100个脏页也不是每秒都会发生的。InoDB存储引擎通过判断当前缓冲池中脏页的比例（buf get_modified_ratio pct）是否超过了配置文件中inodbmax_dirtypages pet这个参数（默认为90，代表90%），如果超过了这个阈值，InoDB存储引擎认为需要做磁盘同步的操作，将100个脏页写人磁盘中。</li>
</ul>
</li>
<li>如果当前没有用户活动，则切换到 background loop（可能）。</li>
</ol>
<p><strong>每10秒一次</strong>的操作包括：（有概念尚不清晰的，后文会做详解）</p>
<ol>
<li>刷新100个脏页到磁盘（可能的情况下）;<ul>
<li>在以上的过程中，InnoDB存储引擎会先判断过去10秒之内磁盘的IO操作是否小于200次，如果是，InnoDB存储引擎认为当前有足够的磁盘IO操作能力，因此将100 个脏页刷新到磁盘。</li>
</ul>
</li>
<li>合并至多5个插人缓冲（总是）;<ul>
<li>接着，InnoDB存储引擎会合并插入缓冲。不同于每秒一次操作时可能发生的合并插入缓冲操作，这次的合并插入缓冲操作总会在这个阶段进行。</li>
</ul>
</li>
<li>将日志缓冲刷新到磁盘（总是）;<ul>
<li>之后，InoDB存储引擎会再进行一次将日志缓冲刷新到磁盘的操作。这和每秒一次时发生的操作是一样的。</li>
</ul>
</li>
<li>删除无用的Undo 页（总是）;<ul>
<li>接着InnoDB存储引擎会进行一步执行full purge操作，即删除无用的Undo 页。对表进行update、delete这类操作时，原先的行被标记为删除，但是因为一致性读（consistent read）的关系，需要保留这些行版本的信息。</li>
<li>但是在full purge过程中，InoDB存储引擎会判断当前事务系统中已被删除的行是否可以删除，比如有时候可能还有查询操作需要读取之前版本的undo信息，如果可以删除，InnoDB会立即将其删除。</li>
</ul>
</li>
<li>刷新100个或者10个脏页到磁盘（总是）。<ul>
<li>然后，InnoDB存储引擎会判断缓冲池中脏页的比例（buf get_modified_ratio pct），如果有超过70%的脏页，则刷新100个脏页到磁盘，如果脏页的比例小于70%，则只需刷新10%的脏页到磁盘。</li>
</ul>
</li>
</ol>
<p><strong>后台循环（backgroup loop）</strong></p>
<p>接着来看background loop，若当前没有用户活动（数据库空闲时）或者数据库关闭（shutdown），就会切换到这个循环。background loop 会执行以下操作∶</p>
<ol>
<li>删除无用的 Undo 页（总是）;</li>
<li>合并20个插人缓冲（总是）;</li>
<li>如果当前数据库还是空闲，则跳回到主循环，否则进入flush loop（总是）;</li>
</ol>
<p><strong>刷新循环（flush loop）</strong><br>刷新循环只做一件事，每次刷新一百个页到磁盘，不断循环直到<code>缓冲池中的脏页比例小于等于innodb_max_dirty_pages_pct的值（默认90）</code></p>
<ol>
<li>不断刷新100个页直到符合条件（可能，跳转到flush loop中完成）。</li>
</ol>
<p><strong>暂停循环（suspend_loop）</strong></p>
<p>若flush loop中也没有什么事情可以做了，InnoDB存储引擎会切换到suspend_loop，将Master Thread挂起，等待事件的发生。若用户启用（enable）了InnoDB存储引擎，却没有使用任何InnoDB存储引擎的表，那么Master Thread总是处于挂起的状态。</p>
<blockquote>
<p>上述核心逻辑是MySQL 1.0.x版本之前的逻辑，在1.0.x版本和1.2.x版本中，Master Thread两次引入了更新</p>
</blockquote>
<p><strong>1.0.x版本的改动：</strong></p>
<ol>
<li>磁盘技术的快速发展中，对于缓冲池向磁盘刷新时都做了一定的hard coding，这些限制很大程度上限制了InnoDB存储引擎对磁盘IO的性能，尤其是写入性能。因此提供参数innodb_io_capacity用来表示IO的吞吐量，默认200，对于刷新到磁盘页的数量，会按照innodb_io_capacity的百分比来控制：<ul>
<li>并插入缓冲时，合并插入缓冲的数量为innodb_io_capacity值的5%;</li>
<li>缓冲池刷新脏页时，刷行脏页的数量为innodb_io_capcity;</li>
</ul>
</li>
<li>脏页比例参数innodb_max_dirty_pages_pct为90太大了。新版本将其改为了75。</li>
<li>innodb_adaptive_flushing参数的引入，该值影响每秒刷新脏页的数量。<ul>
<li>原来的刷新规则是∶脏页在缓冲池所占的比例小于innodb_max_dirty pages pect时，不刷新脏页;大于inodb maxdirtypages_pct时，刷新100个脏页。</li>
<li>随着innodb_adaptive flushing参数的引入，InnoDB存储引擎会通过一个名为buf_flush get_desired_fush_rate的函数来判断需要刷新脏页最合适的数量。</li>
<li>粗略地翻阅源代码后发现 buf flush get desired_fush rate通过判断产生重做日志（redo log）的速度来决定最合适的刷新脏页数量。因此，当脏页的比例小于inodb_max_dirtypages_pct时，也会刷新一定量的脏页。</li>
</ul>
</li>
<li>引入参数innodb_purge_batch_size<ul>
<li>之前每次进行 full purge操作时，最多回收20个Undo页</li>
<li>从InnoDB 1.0.x版本开始引人了参数，该参数可以控制每次 full purge回收的Undo页的数量。该参数的默认值为20，并可以动态地对其进行修改</li>
</ul>
</li>
</ol>
<p><strong>1.2.x版本的改动：</strong></p>
<p>对于刷新脏页的操作，从Master Thread 线程分离到一个单独的<strong>Page Cleaner Thread</strong>，从而减轻了Master Thread的工作，同时进一步提高了系统的并发性。</p>
<p>整体伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">void master_thread()&#123;</span><br><span class="line">    goto loop;</span><br><span class="line">loop:</span><br><span class="line">for (int i&#x3D;0;i&lt;10;i++)&#123;</span><br><span class="line">    thread_sleep(1) &#x2F;&#x2F;sleep 1 second--&gt;每秒执行操作(负载在情况下会延迟)</span><br><span class="line">    do log buffer flush to disk  &#x2F;&#x2F;重做日志缓冲刷新到磁盘，即使这个事务没有提交(总是)</span><br><span class="line">    if ( last_ten_second_ios &lt; 5% innodb_io_capacity) &#x2F;&#x2F;如果当前的10次数小于(5% * 200&#x3D;10)(innodb_io_capacity默认值是200)</span><br><span class="line">        do merger 5% innodb_io_capacity insert buffer &#x2F;&#x2F;执行10个合并插入缓冲的操作(5% * 200&#x3D;10)</span><br><span class="line">    if ( buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct ) &#x2F;&#x2F;如果缓冲池中的脏页比例大于innodb_max_dirty_pages_pct(默认是75时)</span><br><span class="line">        do buffer pool plush 100% innodb_io_capacity dirty page &#x2F;&#x2F;刷新200个脏页到磁盘</span><br><span class="line">    else if enable adaptive flush  &#x2F;&#x2F;如果开户了自适应刷新</span><br><span class="line">        do buffer pool flush desired amount dirty page &#x2F;&#x2F;通过判断产生redo log的速度决定最合适的刷新脏页的数量</span><br><span class="line">    if ( no user activity ) &#x2F;&#x2F;如果当前没有用户活动</span><br><span class="line">        goto backgroud loop  &#x2F;&#x2F;跳到后台循环</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;每10秒执行的操作</span><br><span class="line">if ( last_ten_second_ios &lt; innodb_io_capacity)  &#x2F;&#x2F;如果过去10内磁盘IO次数小于设置的innodb_io_capacity的值（默认是200）</span><br><span class="line">    do buffer pool flush 100% innodb_io_capacity dirty page &#x2F;&#x2F;刷新脏页的数量为innodb_io_capacity的值（默认是200）</span><br><span class="line">do merger 5% innodb_io_capacity insert buffer  &#x2F;&#x2F;合并插入缓冲是innodb_io_capacity的5%（10）（总是）</span><br><span class="line">do log buffer flush to disk                    &#x2F;&#x2F;重做日志缓冲刷新到磁盘，即使这个事务没有提交（总是）</span><br><span class="line">do full purge       &#x2F;&#x2F;删除无用的undo页 （总是）</span><br><span class="line">if (buf_get_modified_ratio_pct &gt; 70%)          &#x2F;&#x2F;如果缓冲池中的胜页比例大于70%</span><br><span class="line">    do buffer pool flush 100% innodb_io_capacity dirty page  &#x2F;&#x2F;刷新200个脏页到磁盘</span><br><span class="line">else</span><br><span class="line">    do buffer pool flush 10% innodb_io_capacity dirty page   &#x2F;&#x2F;否则刷新20个脏页到磁盘</span><br><span class="line">goto loop</span><br><span class="line">backgroud loop:   &#x2F;&#x2F;后台循环</span><br><span class="line">do full purge     &#x2F;&#x2F;删除无用的undo页 （总是）</span><br><span class="line">do merger 5% innodb_io_capacity insert buffer  &#x2F;&#x2F;合并插入缓冲是innodb_io_capacity的5%（10）（总是）</span><br><span class="line">if not idle:      &#x2F;&#x2F;如果不空闲，就跳回主循环，如果空闲就跳入flush loop</span><br><span class="line">goto loop:    &#x2F;&#x2F;跳到主循环</span><br><span class="line">else:</span><br><span class="line">    goto flush loop</span><br><span class="line">flush loop:  &#x2F;&#x2F;刷新循环</span><br><span class="line">do buf_get_modified_ratio_pct pool flush 100% innodb_io_capacity dirty page &#x2F;&#x2F;刷新200个脏页到磁盘</span><br><span class="line">if ( buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct ) &#x2F;&#x2F;如果缓冲池中的脏页比例大于innodb_max_dirty_pages_pct的值（默认75%）</span><br><span class="line">    goto flush loop            &#x2F;&#x2F;跳到刷新循环，不断刷新脏页，直到符合条件</span><br><span class="line">    goto suspend loop          &#x2F;&#x2F;完成刷新脏页的任务后，跳入suspend loop</span><br><span class="line">suspend loop:</span><br><span class="line">suspend_thread()               &#x2F;&#x2F;master线程挂起，等待事件发生</span><br><span class="line">waiting event</span><br><span class="line">goto loop;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="1-1-2-IO-Thread"><a href="#1-1-2-IO-Thread" class="headerlink" title="1.1.2 IO Thread"></a>1.1.2 IO Thread</h3><p>在InnoDB存储引擎中大量使用了AIO（Async IO，异步IO）来处理写IO请求，这样可以极大提高数据库的性能。而IO Thread的工作主要是负责这些IO请求的回调（callback）处理。</p>
<p>InnoDB1.0版本之前共有4个IO Thread，分别是write、read、insert buffer和log IO thread。在Linux平台下，IO Thread的数量不能进行调整，但是在Windows平台下可以通过参数innodb file_io_threads来增大IO Thread。</p>
<p>从InnoDB1.0x版本开始，read thread和 write thread分别增大到了4个，并且不再使用innodb_file io threads参数，而是分别使用innodb_read_io threads和inodb_write io threads参数进行设置，如∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b1937bdac20464ad98c59b01feef5112e89.png" alt=""></p>
<p>可以通过命令<code>SHOW ENGINE INNODB STATUS</code>来观察 InnoDB中的IO Thread∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d5e0d14b4fbf29b6bb3bfdcffb517bc851e.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-aef88c1e57e56d4c88299db8c0ecfc9b6e7.png" alt=""></p>
<p>可以看到IO Thread0为insert buffer thread。IO Thread1为log thread。之后就是根据参数innodb_readio threads及innodb_write_io threads来设置的读写线程，并且读线程的 ID总是小于写线程。</p>
<h3 id="1-1-3-purge-Thread"><a href="#1-1-3-purge-Thread" class="headerlink" title="1.1.3 purge Thread"></a>1.1.3 purge Thread</h3><p>事务被提交后，其所使用的undo log可能不再需要，因此需要PurgeThread来回收已经使用并分配的undo页。</p>
<p>在InnoDB 1.1版本之前，purge操作仅在InnoDB存储引擎的Master Thread中完成。而从InoDB 1.1版本开始，purge操作可以独立到单独的线程中进行，以此来减轻Master Thread的工作，从而提高CPU的使用率以及提升存储引擎的性能。</p>
<p>用户可以在 MySQL数据库的配置文件中添加如下命令来启用独立的Purge Thread:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">innodb_purge_threads&#x3D;1</span><br></pre></td></tr></table></figure>

<p>从InnoDB 1.2版本开始，InnoDB 支持多个Purge Thread，这样做的目的是为了进一步加快undo页的回收。同时由于Purge Thread需要离散地读取undo页，这样也能更进一步利用磁盘的随机读取性能。如用户可以设置4个Purge Thread∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0aa50fbe79b5d8c8da349360afdfadba659.png" alt=""></p>
<h3 id="1-1-4-Page-Cleaner-Thread"><a href="#1-1-4-Page-Cleaner-Thread" class="headerlink" title="1.1.4 Page Cleaner Thread"></a>1.1.4 Page Cleaner Thread</h3><p>Page Cleaner Thread是在InnoDB1.2x版本中引人的。其作用是将之前版本中脏页的刷新操作都放入到单独的线程中来完成。而其目的是为了减轻原Master Thread的工作及对于用户查询线程的阻塞，进一步提高InnoDB存储引擎的性能。</p>
<h2 id="1-2-InnoDB的内存"><a href="#1-2-InnoDB的内存" class="headerlink" title="1.2 InnoDB的内存"></a>1.2 InnoDB的内存</h2><h3 id="1-2-1-缓冲池"><a href="#1-2-1-缓冲池" class="headerlink" title="1.2.1 缓冲池"></a>1.2.1 缓冲池</h3><p>InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可将其视为基于磁盘的数据库系统（Disk-base Database）。在数据库系统中，由于CPU 速度与磁盘速度之间的鸿沟，基于磁盘的数据库系统通常使用缓冲池技术来提高数据库的整体性能。</p>
<p>缓冲池简单来说就是一块内存区域，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。在数据库中进行读取页的操作，首先将从磁盘读到的页存放在缓冲池中，这个过程称为将页”FIX”在缓冲池中。下一次再读相同的页时，首先判断该页是否在缓冲池中。若在缓冲池中，称该页在缓冲池中被命中，直接读取该页。否则，读取磁盘上的页。</p>
<p>对于数据库中页的修改操作，则首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上。这里需要注意的是，页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种称为Checkpoint的机制刷新回磁盘。同样，这也是为了提高数据库的整体性能。</p>
<p>对于InnoDB存储引擎而言，其缓冲池的配置通过参数<code>innodb_buffer poolsize</code>来设置。下面显示一台 MySQL数据库服务器，其将InnoDB存储引擎的缓冲池设置为15GB。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ed636b9b36110b3c4837e6bebd140812c1a.png" alt=""></p>
<p>具体来看，缓冲池中缓存的数据页类型有∶索引页、数据页、undo页、插入缓冲（insert buffer）、自适应哈希索引（adaptive hash index）、InnoDB存储的锁信息（lock info）、数据字典信息（data dictionary）等。不能简单地认为，缓冲池只是缓存索引页和数据页，它们只是占缓冲池很大的一部分而已。下图很好地显示了InnoDB存储引擎中内存的结构情况。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e84b63538abdf9181a48c21e0dadb862049.png" alt=""></p>
<p>从InnoDB1.0.x版本开始，允许有多个缓冲池实例。每个页根据哈希值平均分配到不同缓冲池实例中。这样做的好处是减少数据库内部的资源竞争，增加数据库的并发处理能力。实例数量可以通过参数innodb_buffer_pool_instances来进行配置，该值默认为1：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5b6abb0cac04b945e55fff2553713baee85.png" alt=""></p>
<p>从 MySQL5.6版本开始，还可以通过information_schema架构下的表INNODB_BUFFER_POOL_STATS来观察缓冲的状态，如运行下列命令可以看到各个缓冲池的使用状态∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0e383c72335ac6ec4a71641fba4afa6cbfe.png" alt=""></p>
<h3 id="1-2-2-LRU-Free-Flush-List"><a href="#1-2-2-LRU-Free-Flush-List" class="headerlink" title="1.2.2 LRU/Free/Flush List"></a>1.2.2 LRU/Free/Flush List</h3><p>在前一章节中我们知道了缓冲池是一个很大的内存区域，其中存放各种类型的页，一个页的大小默认为16KB，即缓冲池中会存在大量16KB的数据页结构。那么InnoDB存储引擎是怎么对这么大的内存区域进行管理的呢?</p>
<h4 id="1-2-2-1-LRU-List"><a href="#1-2-2-1-LRU-List" class="headerlink" title="1.2.2.1 LRU List"></a>1.2.2.1 LRU List</h4><p>通常来说，数据库中的缓冲池是通过LRU（Latest Recent Used，最近最少使用）算法来进行管理的。即最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。当缓冲池不能存放从磁盘新读取到的页时，将首先释放LRU列表中尾端的页。</p>
<p>在InnoDB存储引擎中，缓冲池中页的大小默认为16KB，同样使用LRU算法对缓冲池进行管理。稍有不同的是InoDB存储引擎对传统的LRU算法做了一些优化。在InoDB的存储引擎中，<strong>LRU列表中还加入了midpoint位置</strong>。在默认配置下，该位置在LRU列表长度的5/8处。midpoint位置可由参数<code>inodb old blocks pct</code>控制，如∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3574d90f2897e73ca8fb3cf70bfbb0ebce6.png" alt=""></p>
<p>从上面的例子可以看到，参数 innodb oldblocks pect默认值为37。表示新读取的页插入到LRU列表尾端的37%的位置（差不多3/8的位置）。</p>
<p>在InnoDB存储引擎中，把midpoint 之后的列表称为old列表，之前的列表称为new列表。可以简单地理解为new 列表中的页都是最为活跃的热点数据。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b345d48fb199199fff62cb81c183638e6ee.png" alt=""></p>
<p>当用户需要访问数据时，InnoDB首先会在InnoDB缓冲池查找数据，如果缓冲池中没有数据时，InnoDB会查询硬盘上的数据，并将缓冲池中生成新的页；如果InnoDB缓冲池已满，InnoDB通过LRU算法清除InnoDB缓存池中个别数据块。</p>
<p>每当有新数据块需要加载到InnoDB缓冲池中时，该数据块应变为‘‘数据页’’被插到midpoint的位置，并声明为old数据页。这个算法在InnoDB存储引擎下称为<strong>midpoin insertion strategy</strong>。</p>
<p>那么old链表中的数据页什么时候能移动到new链表中呢？参数<code>InnoDB_old_blocks_time</code>可以控制这个时间：</p>
<ol>
<li>当InnoDB_old_blocks_time的参数值设置为0时。当old部分的数据页被访问到时，该数据页会被提升到链表的头部，并被标记为new数据页。</li>
<li>当InnoDB_old_blocks_time的参数值大于0时（以1000毫秒或者1秒为例）。old部分数据页插入缓冲池后，1秒之后再次被访问，则该数据页会被提升到链表的头部，并被标记为new数据页。在刚插入到一秒内，即便old部分的数据页被访问，该数据页也不会移动到new链表的头部。</li>
</ol>
<p><strong>那为什么不采用朴素的LRU算法，直接将最近被sql访问的页放入到LRU列表的首部呢?</strong></p>
<p>这是因为若直接将最近被访问到的页放入到LRU的首部，那么某些SQL操作可能会使热点的页被顶到靠后的位置去，从而LRU List的效率。</p>
<p>常见的这类操作为索引或数据的扫描操作。这类操作需要访问表中的许多页，甚至是全部的页，而这些页通常来说又仅在这次查询操作中需要，并不是活跃的热点数据。如果页被放入LRU列表的首部，那么<strong>非常可能将原本在队首的热点数据页顶到队尾，甚至因为内存空间原因从LRU列表中移除，导致在下一次需要读取该页时，InnoDB存储引擎需要再次访问磁盘</strong>。</p>
<h4 id="1-2-2-2-Free-List"><a href="#1-2-2-2-Free-List" class="headerlink" title="1.2.2.2 Free List"></a>1.2.2.2 Free List</h4><p>LRU列表用来管理已经读取的页，但当数据库刚启动时，LRU列表是空的，即没有任何的页。这时页都存放在Free List中。当需要在缓冲池中划分数据页时，首先从Free列表中查找是否有可用的空闲页。</p>
<ul>
<li><p>若有，则用磁盘中读取的数据填充该页，并将该页从Free列表中移动到LRU列表中。</p>
</li>
<li><p>若没有，则根据LRU算法，淘汰LRU列表末尾的页，将该内存空间分配给新的页。</p>
</li>
</ul>
<h4 id="1-2-2-3-Flush-List"><a href="#1-2-2-3-Flush-List" class="headerlink" title="1.2.2.3 Flush List"></a>1.2.2.3 Flush List</h4><p>在LRU列表中的页被修改后，称该页为脏页（dirty page），即缓冲池中的页和磁盘上的页的数据产生了不一致。这时数据库会通过CHECKPOINT机制将脏页刷新回磁盘，而Flush列表中的页即为脏页列表。</p>
<p>需要注意的是，脏页既存在于LRU列表中，也存在于 Flush列表中。LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘，二者互不影响。</p>
<h4 id="1-2-2-4-List状态查看"><a href="#1-2-2-4-List状态查看" class="headerlink" title="1.2.2.4 List状态查看"></a>1.2.2.4 List状态查看</h4><p>可以通过命令SHOW ENGINE INNODB STATUS来观察LRU列表，Free列表和Flush列表的使用情况和运行状态。</p>
<blockquote>
<p>当页从LRU列表的old部分加入到new部分时，称此时发生的操作为page made young，而因为innodb old_blocks time的设置而导致页没有从old部分移动到new部分的操作称为page not made young。</p>
</blockquote>
<p><img src="https://oscimg.oschina.net/oscnet/up-9eef4f0023da725e57ebf19d77ec6bef001.png" alt=""></p>
<p>通过命令SHOW_ENGINE_INNODB_STATUS可以看到∶当前Buffer_pool_size共有327679个页，即<code>327679*16K</code>，总共5GB的缓冲池。</p>
<p>Free buffers表示当前Free列表中页的数量，Database pages表示LRU列表中页的数量。可能的情况是Free buffers与Database pages的数量之和不等于Buffer pool size。正如之前所说的那样，因为缓冲池中的页还可能会被分配给自适应哈希索引、Lock信息、Insrt Buffer等页，而这部分页不需要LRU算法进行维护，因此不存在于LRU列表中。</p>
<p>pages made young 显示了LRU列表中页从old端移动到new端的次数，因为该服务器在运行阶段没有改变inodb old blocks_time的值，因此not young为0。</p>
<p>youngs/s、non-youngs 表示每秒这两类操作的次数。</p>
<p>Modifed db pages24673就显示了Flush List中脏页的数量。</p>
<p>这里还有一个重要的观察变量——Buffer pool hit rate，表示缓冲池的命中率，这个例子中为100%，说明缓冲池运行状态非常良好。通常该值不应该小于95%。若发生Bufer pool hit rate的值小于95%这种情况，用户需要观察是否是由于全表扫描引起的LRU 列表被污染的问题。</p>
<h3 id="1-2-3-重做日志缓冲"><a href="#1-2-3-重做日志缓冲" class="headerlink" title="1.2.3 重做日志缓冲"></a>1.2.3 重做日志缓冲</h3><p><img src="https://oscimg.oschina.net/oscnet/up-e84b63538abdf9181a48c21e0dadb862049.png" alt=""></p>
<p>在看上图，InnoDB存储引擎的内存区域除了有缓冲池外，还有重做日志缓冲（redo log buffer）。InoDB存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定频率将其刷新到重做日志文件。重做日志缓冲一般不需要设置得很大，因为一般情况下每一秒钟会将重做日志缓冲刷新到日志文件，因此用户只需要保证每秒产生的事务量在这个缓冲大小之内即可。该值可由配置参数 innodb_log buffrsize控制，默认为8MB:</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7b1284e9ce4be6a5be54d776fc9850930b1.png" alt=""></p>
<p>在通常情况下，8MB的重做日志缓冲池足以满足绝大部分的应用，因为重做日志在下列三种情况下会将重做日志缓冲中的内容刷新到外部磁盘的重做日志文件中。</p>
<ul>
<li>Master Thread每一秒将重做日志缓冲刷新到重做日志文件;</li>
<li>每个事务提交时会将重做日志缓冲刷新到重做日志文件;</li>
<li>当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲刷新到重做日志文件。</li>
</ul>
<h3 id="1-2-4-额外的内存池"><a href="#1-2-4-额外的内存池" class="headerlink" title="1.2.4 额外的内存池"></a>1.2.4 额外的内存池</h3><p>额外的内存池通常被DBA忽略，他们认为该值并不十分重要，事实恰恰相反，该值同样十分重要。在InnoDB存储引擎中，对内存的管理是通过一种称为内存堆（heap）的方式进行的。在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。</p>
<p>例如，分配了缓冲池（innodb_buffer_pool），但是每个缓冲池中的帧缓冲（fame buffer）还有对应的缓冲控制对象（buffer control block），这些对象记录了一些诸如LRU、锁、等待等信息，而这个对象的内存需要从额外内存池中申请。因此，在申请了很大的InnoDB缓冲池时，也应考虑相应地增加这个值。</p>
<h1 id="2-InnoDB的关键特性"><a href="#2-InnoDB的关键特性" class="headerlink" title="2 InnoDB的关键特性"></a>2 InnoDB的关键特性</h1><p>InnoDB存储引擎的关键特性包括∶</p>
<ul>
<li>Checkpoint技术</li>
<li>插入缓冲（Insert Buffer）</li>
<li>两次写（Double Write）</li>
<li>自适应哈希索引（Adaptive Hash Index）</li>
<li>异步IO（Async IO）</li>
<li>刷新邻接页（Flush Neighbor Page）</li>
</ul>
<p>上述这些特性为InnoDB存储引擎带来更好的性能以及更高的可靠性。</p>
<h2 id="2-1-Checkpoint技术"><a href="#2-1-Checkpoint技术" class="headerlink" title="2.1 Checkpoint技术"></a>2.1 Checkpoint技术</h2><p>前面已经讲到了，缓冲池的设计目的为了协调 CPU速度与磁盘速度的鸿沟。因此页的操作首先都是在缓冲池中完成的。如果一条 DML语句，如 Update或Delete改变了页中的记录，那么此时页是脏的，即缓冲池中的页的版本要比磁盘的新。数据库需要将新版本的页从缓冲池刷新到磁盘。</p>
<p>刷新到磁盘的操作，就是Checkpoint。</p>
<p>倘若每次一个页发生变化，就将新页的版本刷新到磁盘，那么这个开销是非常大的。若热点数据集中在某几个页中，那么数据库的性能将变得非常差。同时，如果在从缓冲池将页的新版本刷新到磁盘时发生了宕机，那么数据就不能恢复了。为了避免发生数据丢失的问题，当前事务数据库系统普遍都采用了Write Ahead Log策略，即当事务提交时，先写重做日志，再修改页。当由于发生宕机而导致数据丢失时，通过重做日志来完成<strong>对未刷新到硬盘的数据的恢复</strong>。这也是事务 ACID中D（Durability持久性）的要求。</p>
<p>既然不能每次一个页发生变化，就将新页的版本刷新到磁盘，那么，什么时候将脏页数据刷新到硬盘是合适的呢？先不谈我们应该以什么频率进行一次Checkpoint，我们先来谈什么时候必须要Checkpoint（否则会导致 缓冲池+重做日志 机制出问题）</p>
<ol>
<li>当缓冲池不够用时：<ul>
<li>当缓冲池不够用时，根据LRU算法会清除最近最少使用的页，如果此页为脏页，那么需要强制执行Checkpoint，将脏页也就是页的新版本刷回磁盘。</li>
</ul>
</li>
<li>重做日志出现不可用/不够用时：<ul>
<li>因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是让其无限增大的，这从成本及管理上都是比较困难的。<strong>重做日志中记录的已经被flush到磁盘中的部分，我们就认为它是可覆盖重用的</strong>。如果重做日志空间中没有可重用的部分，即目前重用日志记录的都是未flush到磁盘的数据，那么必须强制Checkpoint，使得部分重做日志变为可重用。</li>
</ul>
</li>
</ol>
<h3 id="2-1-1-LSN"><a href="#2-1-1-LSN" class="headerlink" title="2.1.1 LSN"></a>2.1.1 LSN</h3><p>对于InnoDB存储引擎而言，是通过LSN（Log Sequence Number）来标记版本的。LSN是一个一直递增的8字节整型数字，<strong>表示事务写入到redo日志的字节总量（注意LSN的含义是日志的字节总量）</strong>。每个页都有LSN字段，重做日志中也有LSN，Checkpoint也有LSN。</p>
<p>在每个数据页头部的LSN字段，记录当前页最后一次数据修改所对应的重做日志的LSN值，用于在recovery时对比重做日志LSN值，以决定是否对该页进行恢复数据。前面说的checkpoint也是有LSN号记录的，checkpoint的LSN表示已刷新到磁盘的最新的数据所对应的重做日志的LSN，LSN号串联起一个事务开始到恢复的过程。</p>
<blockquote>
<p>比如重做日志的文件是600M，LSN的值已经为1G了，也就是LSN=1000000000。因为重做日志是循环使用的，所以我们可以知道LSN=1G=600M+400M，所以重做日志已经重复使用过一整遍后，目前最新的可写入点，在重做日志偏移量400M的位置。</p>
</blockquote>
<blockquote>
<p>我们执行了一个update语句，产生了一个事务t，这次数据的修改，假设产生了512个字节的日志量，那么LSN就会增加到1000000512，而事务t的修改使得A、B、C三个数据页成为了脏页，那么A、B、C三个数据页的LSN值就会更新为1000000512。如果这时，触发了checkpoint，刚刚好将事务t为止的修改刷新到磁盘，那么此时checkpoint LSN也是1000000512。</p>
</blockquote>
<p>可以通过命令SHOW ENGINE INNODB STATUS来观察∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-179216b430c190ac9ad4b5262885db5ef73.png" alt=""></p>
<h3 id="2-1-2-Checkpoint发生的时机"><a href="#2-1-2-Checkpoint发生的时机" class="headerlink" title="2.1.2 Checkpoint发生的时机"></a>2.1.2 Checkpoint发生的时机</h3><p>在InnoDB存储引擎中，Checkpoint发生的时间、条件及脏页的选择等都非常复杂。而Checkpoint所做的事情无外乎是将缓冲池中的脏页刷回到磁盘。不同之处在于<strong>每次刷新多少页到磁盘，每次从哪里取脏页，以及什么时间触发Checkpoint</strong>。</p>
<p>在InnoDB存储引擎内部，有两种Checkpoint，分别为∶</p>
<ol>
<li>Sharp Checkpoint<ul>
<li>Sharp Checkpoint发生在数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式，即参数 innodb_fast_shutdown=1。</li>
</ul>
</li>
<li>Fuzy Checkpoint<ul>
<li>若数据库在运行时也使用Sharp Checkpoint，那么数据库的可用性就会受到很大的影响。故在InnoDB存储引擎内部使用Fuzzy Checkpoint 进行页的刷新，即只刷新一部分脏页，而不是刷新所有的脏页回磁盘。</li>
</ul>
</li>
</ol>
<p>在InnoDB存储引擎中可能发生如下几种情况的Fuzzy Checkpoint:</p>
<ol>
<li>Master Thread Checkpoint</li>
<li>FLUSH_LRU_LIST Checkpoint</li>
<li>Async/Sync Flush Checkpoint</li>
<li>Dirty Page too much Checkpoint</li>
</ol>
<h4 id="2-1-2-1-Master-Thread-Checkpoint"><a href="#2-1-2-1-Master-Thread-Checkpoint" class="headerlink" title="2.1.2.1  Master Thread Checkpoint"></a>2.1.2.1  Master Thread Checkpoint</h4><p>对于Master Thread中发生的Checkpoint，差不多以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘。这个过程是异步的，即此时InnoDB存储引擎可以进行其他的操作，用户查询线程不会阻塞。</p>
<h4 id="2-1-2-2-FLUSH-LRU-LIST-Checkpoint"><a href="#2-1-2-2-FLUSH-LRU-LIST-Checkpoint" class="headerlink" title="2.1.2.2  FLUSH_LRU_LIST Checkpoint"></a>2.1.2.2  FLUSH_LRU_LIST Checkpoint</h4><p>FLUSH_LRU_LIST Checkpoint是因为InoDB存储引擎需要保证LRU列表中需要有差不多100个空闲页可供使用。在InoDB1.1.x版本之前，需要检查LRU列表中是否有足够可用空间的操作发生在用户查询线程中，显然这会阻塞用户的查询操作。</p>
<p>倘若没有100个可用空闲页，那么InoDB存储引擎会将LRU列表尾端的页移除。如果要移除的这些页中有脏页，那么需要进行Checkpoint，而这些页是来自LRU和FLUSH列表的，因此称为FLUSH_LRU_LIST Checkpoint。</p>
<p>而从MySQL5.6版本，也就是InnoDB1.2.x版本开始，这个检查被放在了一个单独的Page Cleaner线程中进行，并且用户可以通过参数innodb_Iru_scan_depth控制LRU列表中可用页的数量，该值默认为1024。</p>
<h4 id="2-1-2-3-Async-Sync-Flush-Checkpoint"><a href="#2-1-2-3-Async-Sync-Flush-Checkpoint" class="headerlink" title="2.1.2.3  Async/Sync Flush Checkpoint"></a>2.1.2.3  Async/Sync Flush Checkpoint</h4><p>Async/Sync Flush Checkpoint指的是重做日志文件不可用的情况，这时需要强制将一些页刷新回磁盘，而此时脏页是从脏页列表中选取的。</p>
<p>若将已经写入到重做日志的LSN记为redo_lsn，将已经刷新回磁盘最新页的LSN记为checkpoint_lsn，则可定义：</p>
<p><code>checkpoint_age = redo_lsn - checkpoint_lsn</code>，表示重做日志中还有多少个字节量的数据没有刷新到磁盘。</p>
<p>再定义以下的变量：</p>
<ol>
<li><code>async_water_mark = 75% * total_redo_log_file_size</code></li>
<li><code>sync_water_mark = 90% * total_redo_log_file_size</code></li>
</ol>
<p>若每个重做日志文件的大小为1GB，并且定义了两个重做日志文件，则重做日志文件的总大小为2GB。那么async_water_mark=1.5GB，sync_water_mark=1.8GB。则：</p>
<ol>
<li>当checkpoint_age&lt;async_water_mark时，不需要刷新任何脏页到磁盘；</li>
<li>当async_water_mark&lt;checkpoint_age&lt;sync_water_mark时触发Async Flush，从Flush列表中刷新足够的脏页回磁盘，使得刷新后满足checkpoint_age&lt;async_water_mark；</li>
<li>当checkpoint_age&gt;sync_water_mark（这种情况一般很少发生，除非设置的重做日志文件太小，并且在进行类似LOAD DATA的BULK INSERT操作），此时触发Sync Flush操作，从Flush列表中刷新足够的脏页回磁盘，使得刷新后满足checkpoint_age&lt;async_water_mark。</li>
</ol>
<p>可见，Async/Sync Flush Checkpoint是为了保证重做日志的循环使用的可用性。在InnoDB 1.2.x版本之前，Async Flush Checkpoint会阻塞发现问题的用户查询线程，而Sync Flush Checkpoint会阻塞所有的用户查询线程，并且等待脏页刷新完成。从InnoDB 1.2.x版本开始——也就是MySQL 5.6版本，这部分的刷新操作同样放入到了单独的Page Cleaner Thread中，故不会阻塞用户查询线程。</p>
<h4 id="2-1-2-4-Dirty-Page-too-much-Checkpoint"><a href="#2-1-2-4-Dirty-Page-too-much-Checkpoint" class="headerlink" title="2.1.2.4  Dirty Page too much Checkpoint"></a>2.1.2.4  Dirty Page too much Checkpoint</h4><p>即脏页的数量太多，导致InnoDB存储引擎强制进行Checkpoint。其目的总的来说还是为了保证缓冲池中有足够可用的页。其可由参数innodb_max_dirty_pages_pct控制：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4e9f8a50c529eeb28cbe8b5eb5bec171543.png" alt=""></p>
<p>innodb_max_dirtypages_pct值为75表示，当缓冲池中脏页的数量占据75%时，强制进行Checkpoint，刷新一部分的脏页到磁盘。在InnoDB 1.0.x版本之前，该参数默认值为90，之后的版本都为75。</p>
<h2 id="2-2-插入缓冲"><a href="#2-2-插入缓冲" class="headerlink" title="2.2 插入缓冲"></a>2.2 插入缓冲</h2><p>插入缓冲本质上是对于为非唯一索引而言的，即对辅助索引的修改操作并非实时更新磁盘中索引的叶子页（索引存于该表的ibd文件中），而是把若干对同一页面的更新缓存起来做，合并为一次性更新操作，减少IO，转随机IO为顺序IO，这样可以避免随机IO带来性能损耗，提高数据库的写性能</p>
<h3 id="2-2-1-Insert-Buffer"><a href="#2-2-1-Insert-Buffer" class="headerlink" title="2.2.1 Insert Buffer"></a>2.2.1 Insert Buffer</h3><p>Insert Buffer可能是InnoDB存储引擎关键特性中最令人激动与兴奋的一个功能。insert buffer是一种特殊的数据结构（B+ tree）并不是缓存的一部分，而是物理页。</p>
<p>在InoDB存储引擎中，主键是行唯一的标识符。通常应用程序中行记录的插人顺序是按照主键递增的顺序进行插入的。因此，插入聚集索引（Primary Key）一般是顺序的，不需要磁盘的随机读取。</p>
<p>但一个表除了聚集索引外，还可能定义辅助索引，我们知道InnoDB中辅助索引是非聚集的。假设我们有一张表t，其中主键是id字段，除此之外还在name字段上面建了一个辅助索引。那么我们在表t每插入一条数据，<strong>都需要在id聚集索引树和name非聚集索引上新增索引节点</strong>。</p>
<ul>
<li><p>前面说过，因为表t的插入顺序就是按照主键自增的，而id聚集索引又是按照id排序的，所以在id聚集索引上新增节点十分方便，只要在顺序插入即可，性能很高。</p>
</li>
<li><p>而在name非聚集索引上新增索引节点，因为表t记录的插入顺序按照id自增的顺序，不是按照name自增的顺序，但name非聚集索引又是按照name字段顺序排列的，所以表t的每次插入，都需要在name非聚集索引上离散的插入新的索引节点，随机IO的消耗太大，性能十分蛋疼。</p>
</li>
</ul>
<p>为了应对这种情况，InnoDB存储引擎开创性地设计了Insert Buffer，对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入;若不在，则先放入到一个Insert Buffer对象中。</p>
<p>好似欺骗数据库这个非聚集的索引已经插到叶子节点了，而实际并没有，只是存放在另一个位置。然后再以Master Thread的调度规则进行Insert Buffer和辅助索引页子节点的merge（合并）操作，这时通常能将多个插入合并到一个操作中（因为插入的都是在一个索引页中），这就大大提高了对于非聚集索引插人的性能。</p>
<p>然而Insert Buffer的使用需要同时满足以下三个条件∶</p>
<ol>
<li>修改的非聚集索引页不在缓冲池中<ul>
<li>因为如果在缓冲池中，直接改缓冲池就行了，改内存不比改磁盘，没有什么顺序IO/随机IO的性能差异。</li>
</ul>
</li>
<li>索引是辅助索引（secondary index）;<ul>
<li>因为聚集索引的性能很好，不需要用到Insert Buffer。</li>
</ul>
</li>
<li>辅助索引不是唯一（unique）的。<ul>
<li>因为如果辅助索引是唯一的，那么在插入辅助索引树前，要先判断插入的值是否已经在树中重复了，查询操作又是随机IO。</li>
<li>本来Insert Buffer就是为了避免随机IO，既然唯一性辅助索引的插入避免不了随机IO，那Insert Buffer也就没有什么意义了。</li>
</ul>
</li>
</ol>
<h3 id="2-2-2-Change-Buffer"><a href="#2-2-2-Change-Buffer" class="headerlink" title="2.2.2 Change Buffer"></a>2.2.2 Change Buffer</h3><p>InnoDB从1.0.x版本开始引入了Change Buffer，可将其视为Insert Buffer的升级。从这个版本开始，InnoDB存储引擎可以对DML操作——INSERT、DELETE、UPDATE 都进行缓冲，他们分别是∶Insert Buffer、Delete Buffer、Purge buffer。</p>
<p>当然和之前Insert Buffer一样，Change Buffer适用的对象依然是非唯一的辅助索引。</p>
<p>同时，InnoDB存储引擎提供了参数innodb_change_buffering，用来开启各种Buffer的选项。该参数可选的值为∶inserts、deletes、purges、changes、all、none。</p>
<p>inserts、deletes、purges就是前面讨论过的三种情况。changes表示启用inserts和deletes，all表示启用所有，none表示都不启用。该参数默认值为 all。</p>
<p>从InnoDB1.2.x版本开始，可以通过参数innodb_change_buffr_max_size来控制Change Buffer最大使用内存的数量∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-825381052046516637f1d890d48c522270b.png" alt=""></p>
<p>innodb_change_buffer_max_size值默认为25，表示最多使用1/4的缓冲池内存空间。而需要注意的是，该参数的最大有效值为 50。</p>
<h3 id="2-2-3-Insert-Buffer的内部实现"><a href="#2-2-3-Insert-Buffer的内部实现" class="headerlink" title="2.2.3 Insert Buffer的内部实现"></a>2.2.3 Insert Buffer的内部实现</h3><p>Insert Buffer具体是什么呢，内部怎么实现呢？</p>
<p>可能令绝大部分用户感到吃惊的是，Insert Buffer的数据结构是一棵B+树。在MySQL 4.1之前的版本中每张表有一棵Insert Buffer B+树。而在现在的版本中，全局只有一棵Insert Buffer B+树，负责对所有的表的辅助索引进行Insert Buffer。而这棵B+树存放在共享表空间中，默认也就是ibdatal中。</p>
<p>因此，试图通过独立表空间ibd文件恢复表中数据时，往往会导致CHECK TABLE失败。这是因为表的辅助索引中的数据可能还在Insert Buffer中，也就是共享表空间中，所以通过ibd文件进行恢复后，还需要进行REPAIR TABLE 操作来重建表上所有的辅助索引。</p>
<p>Insert Buffer是一棵B+树，因此其也由叶节点和非叶节点组成。非叶节点存放的是查询的search key（键值），其构造如下图所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2bd374d3dcb4e982cd4da066ba7b9114187.png" alt=""></p>
<p>search key一共占用9个字节，其中</p>
<ul>
<li>space表示待插入记录所在表的表空间id，在InnoDB存储引擎中，每个表有一个唯一的 space id，可以通过 space id查询得知是哪张表。space占用4字节。</li>
<li>marker占用1字节，它是用来兼容老版本的Insert Buffer。</li>
<li>offset 表示页所在的偏移量，你可以理解为页的下标，用来定位页的位置，占用4字节。</li>
</ul>
<p>当一个辅助索引要插入到页（由&lt;space，offset&gt;这个二元组可唯一定位一个页）时，如果这个页不在缓冲池中，那么InnoDB存储引擎首先根据上述规则构造一个search key结构，接下来查询Insert Buffer这棵B+树，然后再将这条记录插入到Insert Buffer B+树的合适的叶子节点中。</p>
<p>和非叶子节点一样，Insert Buffer B+树的叶子节点也有一种特殊的结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1ac9a52fd0af013c98409c4c54f0db82ce6.png" alt=""></p>
<ul>
<li>space、marker、offset字段和之前非叶节点中的含义相同，一共占用9字节。</li>
<li>第4个字段metadata 占用4字节，其存储的内容如下表所示。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-8a6dcb73257c42cedfaa860f8cb949d8f3b.png" alt=""></li>
<li>最核心的字段是IBUF_REC_OFFSET_COUNT字段，它保存两个字节的整数，用来排序每个记录进入Insert Buffer的顺序。因为从InnoDB1.0.x开始支持Change Buffer，所以这个值同样记录进入Change Buffer的顺序。merge的时候通过这个顺序回放（replay）才能得到记录的正确值。</li>
</ul>
</li>
<li>从Insert Buffer 叶子节点的第5列开始，就是实际插入记录的各个字段了。因此较之原插入记录，Insert Buffer B+树的叶子节点记录需要额外13字节的开销。</li>
</ul>
<p>因为启用Insert Buffer索引后，辅助索引页（space，offset）中的记录可能被插入到Insert Buffer B+树中，所以为了保证每次Merge Insert Buffer页都能成功，还需要有一个特殊的页用来标记每个辅助索引页（space，offset）的可用空间。这个页的类型为Insert Buffer Bitmap。</p>
<p>每个Insert Buffer Bitmap页用来追踪16384个辅助索引页，也就是256个区（Extent）。<strong>每个辅助索引页</strong>在Insert Buffer Bitmap页中占用4位（bit），这四位的含义见下表</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a9bdfd3ef86c322ef4b88df4ccc1ca4192a.png" alt=""></p>
<h3 id="2-2-4-Merge-Insert-Buffer"><a href="#2-2-4-Merge-Insert-Buffer" class="headerlink" title="2.2.4 Merge Insert Buffer"></a>2.2.4 Merge Insert Buffer</h3><p>我们已经知道了Insert/Change Buffer是一棵B+树。若需要做插入操作的辅助索引页不在缓冲池中，那么需要将辅助索引记录首先插入到这棵B+树中。但是Insert Buffer中的记录何时合并（merge）到真正的辅助索引中呢?这是我们接下来关注的重点。</p>
<p>概括地说，Merge Insert Buffer的操作可能发生在以下几种情况下∶</p>
<ol>
<li>辅助索引页被读取到缓冲池时;<ul>
<li>例如这在执行正常的SELECT查询操作，如果辅助索引页不在缓冲池中，这时我们需要优先将辅助索引读入缓冲池</li>
<li>紧接着检查Insert Buffer Bitmap页，看看该辅助索引页是否有记录存放于Insert Buffer B+树中。若有，则将Insert Buffer B+树中该页的记录插入到缓冲池中的该辅助索引页中。</li>
<li>这样便可以将对该页多次的记录操作通过一次操作合并到了原有的辅助索引页中，因此性能会有大幅提高。</li>
</ul>
</li>
<li>Insert Buffer Bitmap页追踪到该辅助索引页已无可用空间时;<ul>
<li>Insert Buffer Bitmap页用来追踪每个辅助索引页的可用空间，若插入辅助索引记录时检测到插入记录后，辅助索引页的可用空间会小于1/32页，则会强制进行一个合并操作，即强制读取辅助索引页至缓冲池，然后将Insert Buffer B+树中该页的记录及待插入的记录插入到缓冲池的辅助索引页中。</li>
</ul>
</li>
<li>Master Thread。<ul>
<li>在Master Thread线程中每秒或每10秒会进行一次Merge Insert Buffer的操作，不同之处在于每次进行merge操作的页的数量不同。</li>
<li>在Master Thread中，执行merge操作的不止是一个页，而是根据 srv_inodb io capactiy的百分比来决定真正要合并多少个辅助索引页。</li>
</ul>
</li>
</ol>
<p>那么InnoDB存储引擎又是根据怎样的算法来确定Insert Buffer B+树中哪些记录是需要合并的呢?</p>
<p>在Insert Buffer B+树中，辅助索引修改记录会根据（space，offset）排序好，故可以根据（space，offset）的排序顺序进行页的选择。然而，对于Insert Buffer页的选择，InnoDB存储引擎并非采用这个方式，<strong>它随机地选择Insert Buffer B+树的一个页，读取该页中的space及之后所需要数量（不同场景需要的数量不同）的页</strong>。</p>
<p>该算法在复杂情况下应有更好的公平性。</p>
<p>同时，若进行merge时，要进行merge的表已经被删除，此时可以直接丢弃已经被Insert/Change Buffer 的数据记录。</p>
<h3 id="2-2-5-缓冲池和Insert-Buffer的区别"><a href="#2-2-5-缓冲池和Insert-Buffer的区别" class="headerlink" title="2.2.5 缓冲池和Insert Buffer的区别"></a>2.2.5 缓冲池和Insert Buffer的区别</h3><p>我们前面学过缓冲池技术，假如我们要修改页号为40的索引页，而这个页正好不在缓冲池内。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-120ef3437c3b0858f837b70172467832f83.png" alt=""></p>
<p>此时我们依照缓冲池的机制，整个写过程如上图需要3步：</p>
<ol>
<li>先把需要为40的索引页，从磁盘加载到缓冲池，<strong>一次磁盘随机读操作</strong>；</li>
<li>修改缓冲池中的页，一次内存操作；</li>
<li>写入redo log，一次磁盘顺序写操作；</li>
</ol>
<blockquote>
<p>注意：没有命中缓冲池的时候，至少产生一次磁盘IO？</p>
</blockquote>
<p>而InnoDB加入Insert Buffer优化后，则写入流程优化为：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-16b0c1d81b9eda5ab4ee808299dc7421a04.png" alt=""></p>
<ol>
<li>在Insert Buffer B+树中记录这个操作，一次内存操作；</li>
<li>写入redo log，一次磁盘顺序写操作；</li>
</ol>
<p>可以看到，Insert Buffer机制能在缓冲池技术的基础上减少一次磁盘IO，其性能与这个索引页在缓冲池中的情况相近。可以看到，40这一页，并没有加载到缓冲池中。此时数据库异常奔溃，则能够从redo log中恢复数据；</p>
<p>假设稍后的一个时间，有请求查询索引页40的数据。</p>
<p>此时的流程如序号1-3：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b0af759bbe0a2de82eda2ea19bfcadb0fe1.png" alt=""></p>
<ol>
<li>缓冲池未命中，则从磁盘载入索引页，这次磁盘IO不可避免；</li>
<li>从Insert Buffer B+树中读取辅助索引页的修改记录；</li>
<li>根据Insert Buffer修改从缓存载入的索引页，使其达到最终态，并放到缓冲池LRU List里；</li>
</ol>
<p>可以看到，40这一页，在真正被读取时，才会被加载到缓冲池中。</p>
<blockquote>
<p>注意，insert buffer的merge操作是将索引文件从磁盘载入到缓冲池的索引页中，并且将insert buffer里的更改再执行到缓冲池索引页上。</p>
</blockquote>
<blockquote>
<p>系统大部分空闲时或在慢速关闭期间运行的清除（purge）操作会定期将缓冲池中的辅助索引页（此时一般为脏页）写入磁盘。与每个值立即写入磁盘相比，purge操作可以更有效地为一系列索引值写入磁盘块。</p>
</blockquote>
<h3 id="2-2-6-查看insert-change-Buffer"><a href="#2-2-6-查看insert-change-Buffer" class="headerlink" title="2.2.6 查看insert/change Buffer"></a>2.2.6 查看insert/change Buffer</h3><p>用户可以通过命令SHOW ENGINE INNODB STATUS来查看Insert Buffer的信息∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-82548d7a2a410db63648a82d24d08e4ac03.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-bed6c7af819e278cdd9e697ccbf046517d1.png" alt=""></p>
<ul>
<li>seg size显示了当前Insert Buffer的大小为11336×16KB，大约为177MB;</li>
<li>free list len代表了空闲列表的长度;</li>
<li>size代表了已经合并记录页的数量。</li>
</ul>
<p>而黑体部分的第2行可能是用户真正关心的，因为它显示了插入性能的提高。</p>
<ul>
<li>Inserts代表了插入的记录数;</li>
<li>mergedrecs代表了合并的插入记录数量;</li>
<li>merges代表合并的次数，也就是实际读取页的次数。</li>
<li>merges∶merged recs大约为1∶3，代表了插入缓冲将对于非聚集索引页的离散1O 逻辑请求大约降低了23。</li>
</ul>
<p>在MySQL5.5版本中通过命令SHOW ENGINE INNODB STATUS，可以观察到change Buffer的信息∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9c1fb50810e2009f3fb819b428f073d3292.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-ac6e49a8c5cdb7ce94a0622768d87f4d314.png" alt=""></p>
<p>可以看到这里显示了merged operations和discarded operation，并且下面具体显示Change Buffr中每个操作的次数。</p>
<ul>
<li>insert表示Insert Buffer;</li>
<li>delete mark表示 Delete Buffer;</li>
<li>delete表示Purge Buffer;</li>
<li>discarded operations表示当Change Buffer发生merge 时，表已经被删除，此时就无需再将记录合并（merge）到辅助索引中了。</li>
</ul>
<h2 id="2-3-两次写"><a href="#2-3-两次写" class="headerlink" title="2.3 两次写"></a>2.3 两次写</h2><p>如果说Insert Buffer带给InnoDB存储引擎的是性能上的提升，那么doublewrite（两次写）带给InnoDB存储引擎的是数据页的可靠性。</p>
<p><strong>当发生数据库宕机时，可能InnoDB存储引擎正在将某个页写入到表中，而这个页只写了一部分</strong>，比如16KB的页，只写了前4KB，之后就发生了宕机，这种情况被称为部分写失效（partial page write）。在InnoDB存储引擎未使用doublewrite技术前，曾经出现过因为部分写失效而导致数据丢失的情况。</p>
<p>有经验的DBA也许会想，如果发生写失效，可以通过重做日志进行恢复。这是一个办法。<strong>但是必须清楚地认识到，重做日志中记录的是对页的物理操作，如偏移量800，写’aaa’记录。如果这个页本身已经发生了损坏，再对其进行重做是没有意义的</strong>。这就是说，在应用（apply）重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是doublewrite。在InnoDB存储引擎中doublewrite的体系架构如下图所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4f4227efdd3deb6b3833306e6ad4459082b.png" alt=""></p>
<p>doublewrite由两部分组成，一部分是内存中的doublewrite buffer，大小为2MB，另一部分是物理磁盘上共享表空间中连续的128个页，即2个区（extent），大小同样为2MB。</p>
<p>在对缓冲池的脏页进行flush时，并不直接写磁盘，而是会通过memcpy函数将脏页先复制到内存中的doublewrite buffer，之后通过doublewrite buffer再分两次，每次IMB顺序地写入共享表空间的物理磁盘上，然后马上调用fsync函数，同步磁盘，避免缓冲写带来的问题。在这个过程中，因为doublewrite页是连续的，因此这个过程是顺序写的，开销并不是很大。</p>
<p>在完成doublewrite页的写入后，再将doublewrite buffer中的页写入各个表空间文件中，此时的写入则是离散的。可以通过以下命令观察到doublewrite 运行的情况∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-06e023bef3b3f3788a047f8175cd2c0b6f1.png" alt=""></p>
<p>可以看到，doublewrite一共写了6325194个页，但实际的写人次数为100399，基本上符合64∶1。</p>
<p>如果发现系统在高峰时的Innodb_dblwr_pages_written∶Innodb_dblwr_writes远小于64∶1，那么可以说明系统写人压力并不是很高。</p>
<p>如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，InnoDB存储引擎可以从共享表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件，再应用重做日志。</p>
<p><strong>参数skip_innodb_doublewrite可以禁止使用doublewrite功能</strong>，这时可能会发生前面提及的写失效问题。不过如果用户有多个从服务器（slave server），需要提供较快的性能（如在slaves server上做的是RAID0），也许启用这个参数是一个办法。不过对于需要提供数据高可靠性的主服务器（master server），任何时候用户都应确保开启doublewrite 功能。</p>
<h2 id="2-4-自适应哈希索引"><a href="#2-4-自适应哈希索引" class="headerlink" title="2.4 自适应哈希索引"></a>2.4 自适应哈希索引</h2><p>哈希（hash）是一种非常快的查找方法，在一般情况下这种查找的时间复杂度为O（1），即一般仅需要一次查找就能定位数据。而B+树的查找次数，取决于B+树的高度，在生产环境中，B+树的高度一般为3～4层，故需要3～4次的查询。</p>
<p><strong>InnoDB存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引（Adaptive Hash Index，AHI）</strong>。</p>
<p>AHI是通过<strong>缓冲池</strong>中的的B+树页构造而来，因此建立的速度很快，而且不需要对整张表构建哈希索引。InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。</p>
<p>AHI有一个要求，即对这个页的连续访问模式必须是一样的。例如对于（a，b）这样的联合索引页，其访问模式可以是以下情况∶</p>
<ol>
<li>WHERE a=xxx</li>
<li>WHERE a=xxx and b=xxx</li>
</ol>
<p>访问模式一样指的是查询的条件一样，若交替进行上述两种查询，那么InnoDB存储引擎不会对该页构造 AHI。</p>
<p>此外 AHI 还有如下的要求∶</p>
<ol>
<li>以该模式访问了100次</li>
<li>页通过该模式访问了N次，其中<code>N=页中记录/16</code></li>
</ol>
<p>根据InnoDB存储引擎官方的文档显示，启用AHI后，读取和写入速度可以提高2 倍，辅助索引的连接操作性能可以提高5倍。毫无疑问，AHI是非常好的优化模式，其设计思想是数据库自优化的（self-tuning），即无需 DBA对数据库进行人为调整。</p>
<p>通过命令SHOW ENGINE INNODB STATUS可以看到当前AHI的使用状况∶</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-69ad2998f5404052484ea0489a357b90bb4.png" alt=""></p>
<p>现在可以看到AHI的使用信息了，包括AHI的大小、使用情况、每秒使用AHI搜索的情况。</p>
<p>值得注意的是，哈希索引只能用来搜索等值的查询，如<code>SELECT* FROM table WHERE index_col=&#39;xxx&#39;</code>。而对于其他查找类型，如范围查找，是不能使用哈希索引的，因此这里出现了non-hash searches/s的情况。通过 hash searches∶non-hash searches的比值，可以大概了解使用哈希索引后的效率。</p>
<p>参数 innodb_adaptive_hash_index可以控制是否启动AHI。</p>
<h2 id="2-5-异步IO"><a href="#2-5-异步IO" class="headerlink" title="2.5 异步IO"></a>2.5 异步IO</h2><p>为了提高磁盘操作性能，当前的数据库系统都采用异步IO（Asynchronous IO，AIO）的方式来处理磁盘操作。InnoDB存储引擎亦是如此。</p>
<p>与AIO对应的是Sync IO，即每进行一次IO操作，需要等待此次操作结束才能继续接下来的操作。但是如果用户发出的是一条索引扫描的查询，那么这条SQL查询语句可能需要扫描多个索引页，也就是需要进行多次的IO操作。在每扫描一个页并等待其完成后再进行下一次的扫描，这是没有必要的。用户可以在发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作的完成，这就是AIO。</p>
<p>AIO的另一个优势是可以进行IO Merge操作，也就是将多个IO合并为1个IO，这样可以提高IOPS的性能。例如用户需要访问页的（space，page_no）为∶<code>(8,6)，(8,7)，(8,8)</code></p>
<p>每个页的大小为16KB，那么同步IO需要进行3次IO操作。而AIO会判断到这三个页是连续的（显然可以通过（space，page_no）得知）。因此AIO底层会发送一个IO 请求，从（8，6）开始，读取48KB的页。</p>
<p>在InnoDB1.1.x之前，AIO的实现通过InnoDB存储引擎中的代码来模拟实现。而从InnoDB1.1.x开始（InnoDB Plugin不支持），提供了内核级别AIO的支持，称为Native AIO。因此在编译或者运行该版本MySQL时，需要libaio库的支持。</p>
<p>需要注意的是，Native AIO需要操作系统提供支持。Windows系统和Linux系统都提供Native AIO支持，参数<code>innodb_use_native_aio</code>用来控制是否启用Native AIO，在Linux操作系统下，默认值为 ON。</p>
<p>用户可以通过开启和关闭Native AIO功能来比较InnoDB性能的提升。官方的测试显示，启用Native AIO，恢复速度可以提高 75%。</p>
<p>在InnoDB存储引擎中，read ahead方式的读取都是通过AIO完成，脏页的刷新，即磁盘的写人操作则全部由 AIO完成。</p>
<h2 id="2-6-刷新邻接页"><a href="#2-6-刷新邻接页" class="headerlink" title="2.6 刷新邻接页"></a>2.6 刷新邻接页</h2><p>InnoDB存储引擎还提供了Flush Neighbor Page（刷新邻接页）的特性。其工作原理为∶当flush一个脏页时，InnoDB存储引擎会检测该页所在区（extent）的所有页，如果是脏页，那么一起进行flush。</p>
<p>这样做的好处显而易见，通过AIO可以将多个IO写人操作合并为一个IO操作，故该工作机制在传统机械磁盘下有着显著的优势。但是需要考虑到下面两个问题∶</p>
<ol>
<li>是不是可能将不怎么脏的页进行了写入，而该页之后又会很快变成脏页?</li>
<li>固态硬盘有着较高的IOPS，是否还需要这个特性?</li>
</ol>
<p>为此，InnoDB存储引擎从1.2x版本开始提供了参数 innodb_flush_neighbors，用来控制是否启用该特性。对于传统机械硬盘建议启用该特性，而对于固态硬盘有着超高IOPS性能的磁盘，则建议将该参数设置为0，即关闭此特性。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/13/%E8%AF%A6%E8%A7%A3IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%92%8C%E5%85%B6%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94select-poll-epoll/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/13/%E8%AF%A6%E8%A7%A3IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%92%8C%E5%85%B6%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94select-poll-epoll/" itemprop="url">详解IO多路复用和其三种模式——select/poll/epoll</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-13T22:52:48+08:00">
                2020-08-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机协议和技术</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%8A%80%E6%9C%AF/Linux%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index">
                    <span itemprop="name">Linux相关</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/13/%E8%AF%A6%E8%A7%A3IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%92%8C%E5%85%B6%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94select-poll-epoll/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/08/13/详解IO多路复用和其三种模式——select-poll-epoll/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  7k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  25
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我们平常采用的多进程方式实现的服务器端，即一次创建多个工作子进程来给客户端提供服务。其实这种方式是存在问题的。</p>
<p>可以打个比方：如果我们先前创建的几个进程承载不了目前快速发展的业务的话，是不是还得增加进程数？我们都知道系统创建进程是需要消耗大量资源的，多进程方式实现的服务器端会导致系统出现资源不足的情况。</p>
<p>那么有没有一种方式可以让一个进程同时为多个客户端端提供服务？</p>
<p>接下来要讲的<strong>IO多路复用技术</strong>就是对于上述问题的最好解答。即一个进程同时为多个客户端端提供服务。</p>
<p>对于IO复用，我们可以通过一个例子来很好的理解它。（例子来自于《TCP/IP网络编程》）</p>
<p>某教室有10名学生和1名老师，这些学生上课会不停的提问，所以一个老师处理不了这么多的问题。那么学校为每个学生都配一名老师，</p>
<p>也就是这个教室目前有10名老师。此后，只要有新的转校生，那么就会为这个学生专门分配一个老师，因为转校生也喜欢提问题。如果把以上例子中的学生比作客户端，那么老师就是负责进行数据交换的服务端。则该例子可以比作是多进程的方式。</p>
<p>后来有一天，来了一位具有超能力的老师，这位老师回答问题非常迅速，并且可以应对所有的问题。而这位老师采用的方式是学生提问前必须先举手，老师确认举手学生后再回答问题，这就是IO复用。</p>
<p>目前的常用的IO复用模型有三种：select，poll，epoll。</p>
<p>在了解IO复用模型前，我们需要连接一些<strong>Linux操作系统</strong>中的前置知识。</p>
<h1 id="1-前置知识"><a href="#1-前置知识" class="headerlink" title="1 前置知识"></a>1 前置知识</h1><h2 id="1-1-socket编程"><a href="#1-1-socket编程" class="headerlink" title="1.1 socket编程"></a>1.1 socket编程</h2><p>socket编程内容繁多，具体详见该文章</p>
<p><a href="https://blog.csdn.net/hguisu/article/details/7445768" target="_blank" rel="noopener" title="Linux的SOCKET编程详解">Linux的SOCKET编程详解</a></p>
<h2 id="1-2-用户空间-内核空间"><a href="#1-2-用户空间-内核空间" class="headerlink" title="1.2 用户空间 / 内核空间"></a>1.2 用户空间 / 内核空间</h2><p>现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。</p>
<p>操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操作系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。</p>
<h2 id="1-3-文件描述符"><a href="#1-3-文件描述符" class="headerlink" title="1.3 文件描述符"></a>1.3 文件描述符</h2><p>文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述<strong>指向文件的引用</strong>的抽象化概念。</p>
<p>文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。</p>
<p>我们都知道在Linux下一切皆文件。当然设备也不例外，如果要对某个设备进行操作，就不得不打开此设备文件，打开文件就会获得该文件的文件描述符fd( file discriptor)，它就是一个很小的整数。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-27980055d2ce450a71129b9f92c697d9df0.png" alt=""></p>
<p>每个进程在PCB（Process Control Block，进程控制块）中保存着一份文件描述符表，文件描述符就是这个表的索引，文件描述符表中每个表项都有一个指向已打开文件的指针。<strong>现在我们明确一下：已打开的文件在内核中用file结构体表示，文件描述符表中的指针指向file结构体</strong>。file结构体才是内核中用来描述文件属性的结构体。</p>
<p>file结构体如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">struct FILE</span><br><span class="line">&#123;</span><br><span class="line">    char *_ptr;&#x2F;&#x2F;文件输入的下一个位置</span><br><span class="line">    int _cnt;&#x2F;&#x2F;当前缓冲区的相对位置</span><br><span class="line">    char *_base;&#x2F;&#x2F;指基础位置（文件的起始位置）</span><br><span class="line">    int _flag;&#x2F;&#x2F;文件标志</span><br><span class="line">    int _file;&#x2F;&#x2F;文件的有效性验证</span><br><span class="line">    int _charbuf;&#x2F;&#x2F;检查缓冲区状况，如果缓冲区则不读取</span><br><span class="line">    int _bufsiz;&#x2F;&#x2F;文件的大小</span><br><span class="line">    char *_tmpfname;&#x2F;&#x2F;临时文件名</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>具体详见文章<a href="https://blog.csdn.net/mm_hh/article/details/71374474" target="_blank" rel="noopener" title="Linux下 文件描述符（fd）与 文件指针（FILE*）">Linux下 文件描述符（fd）与 文件指针（FILE*）</a></p>
<h1 id="2-select模式"><a href="#2-select模式" class="headerlink" title="2 select模式"></a>2 select模式</h1><p>select模型的原理，套用前言中的老师回答学生问题的例子，则是：<strong>老师仅仅知道有学生举手了，但是到底是哪些学生举手了，他需要用眼睛扫描一遍全班同学，找出举手的同学，然后倾听他的问题，并回答他的问题</strong>。</p>
<p>所以select具有O(n)的无差别轮询时间复杂度，同时处理的流越多，无差别轮询时间就越长。</p>
<h2 id="2-1-select函数"><a href="#2-1-select函数" class="headerlink" title="2.1 select函数"></a>2.1 select函数</h2><p>Linux系统提供了一个函数来供开发者使用select多路复用机制：</p>
<p><code>int select(int maxfdp,fd_set *readfds,fd_set *writefds,fd_set *errorfds,struct timeval *timeout);</code></p>
<p>该函数的作用是：<strong>通过轮询，可以同时监视多个文件描述符是否发生了读/写/异常这三类IO变化，最后返回发生变化的文件描述符数量，以及读/写/异常这三种变化分别发生在哪些文件描述符中</strong>。</p>
<p>我们来看看它的参数的含义：</p>
<blockquote>
<p>在看参数前，我们要了解：struct fd_set可以理解为一个集合，这个集合中存放的是文件描述符(file descriptor)，即文件句柄。fd_set集合可以通过下列宏由人为来操作。<br>FD_ZERO(fd_set *fdset)：清空fdset与所有文件句柄的联系。<br>FD_SET(int fd, fd_set *fdset)：建立文件句柄fd与fdset的联系。<br>FD_CLR(int fd, fd_set *fdset)：清除文件句柄fd与fdset的联系。<br>FD_ISSET(int fd, fdset *fdset)：检查fdset联系的文件句柄fd是否可读写，&gt;0表示可读写。</p>
</blockquote>
<ol>
<li><p>int maxfdp：是一个整数值，是指集合中所有文件描述符的范围，即所有文件描述符的最大值加1，不能错！在Windows中这个参数的值无所谓，可以设置不正确。</p>
</li>
<li><p>readfds：传入select函数的需要被监控读IO的fd_set文件描述符集合，select函数会负责监视readfds的读变化，如果readfds中的某个文件描述符指向的文件能读出数据，那么在返回的时候，select不仅会统计它的数量，而且还会改写readfds，以标出是它的位置。</p>
</li>
<li><p>writefds：传入select函数的需要被监控写IO的fd_set文件描述符集合，select函数会负责监视writefds的写变化，如果writefds中的某个文件描述符指向的文件能写入数据，那么在返回的时候，select不仅会统计它的数量，而且还会改写writefds，以标出是它的位置。</p>
</li>
<li><p>errorfds：传入select函数的需要被监控异常IO的fd_set文件描述符集合，select函数会负责监视errorfds的异常变化，如果readfds中的某个文件描述符指向的文件能读出异常数据，那么在返回的时候，select不仅会统计它的数量，而且还会改写errorfds，以标出是它的位置。</p>
</li>
<li><p>struct timeval：用来代表时间值，有两个成员，一个是秒数，另一个是毫秒数。 </p>
<ol>
<li>若将NULL以形参传入，即不传入时间结构，就是将select置于阻塞状态，一定等到监视文件描述符集合中某个文件描述符发生变化为止；</li>
<li>若将时间值设为0秒0毫秒，就变成一个纯粹的非阻塞函数，不管文件描述符是否有变化，都立刻返回继续执行，文件无变化返回0，有变化返回一个正值；</li>
<li>timeout的值如果大于0，这就是等待的超时时间，即select在timeout时间内阻塞，超时时间之内有事件到来就返回了，否则在超时后不管怎样一定返回。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">struct timeval&#123;</span><br><span class="line"></span><br><span class="line">	long tv_sec;   &#x2F;*秒 *&#x2F;</span><br><span class="line"></span><br><span class="line">	long tv_usec;  &#x2F;*微秒 *&#x2F;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
</li>
</ol>
<h2 id="2-2-select函数的使用"><a href="#2-2-select函数的使用" class="headerlink" title="2.2 select函数的使用"></a>2.2 select函数的使用</h2><p>select函数用来验证3种读、写、异常三种监视项的变化情况。使用前，我们先声明3个fd_set变量，然后分别向其注册文件描述符信息，并把变量的地址传入到函数的readfds/writefds/errorfds参数上。</p>
<p>同时我们要明确要监控的文件描述符数量，原本这个数量不好计算，但好在每次新建文件描述符时，其值（文件描述符是非负整数）都会增1，故只需将最大的文件描述符值加1（因为文件描述符从0开始，所以要+1）再传递到select函数的maxfdp参数即可。</p>
<p>最后再设置一下超时时间（如果需要的话）到timeval参数即可。</p>
<h2 id="2-3-select函数的返回"><a href="#2-3-select函数的返回" class="headerlink" title="2.3 select函数的返回"></a>2.3 select函数的返回</h2><p>在超时时间之内，如果三个fd_set对应的文件描述符有变化，那么select会返回一个大于0的值，表示<strong>发生变化的文件描述符数量</strong>。如果没有变化，则在timeout的时间后select返回0，若发生错误返回负值。</p>
<p>那么问题来了，select函数只返回了变化的文件描述符数量，那么怎样获知哪些文件描述符发生了变化呢？</p>
<p>原来select函数还会改写传进去的readfds/writefds/errorfds集合，即将他们都用<code>FD_ZERO(fd_set *fdset)</code>清空，即fd_set中的所有位数都置为0，然后如果某个文件描述符有读IO，那么在其对应项上用<code>FD_SET(int fd, fd_set *fdset)</code>来设置1；</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1f994da65488ceafb471a4eb3d2edc6c75f.png" alt=""></p>
<p>select函数调用完成后，向其传递的fd_set变量中将发生变化。发生变化的文件描述符对应位除外，其他原来为1的所有位均变为0。因此，可以认为readfds中值为1的位置上的文件描述符发生了读变化，writefds中值为1的位置上的文件描述符发生了写变化，errorfds中值为1的位置上的文件描述符发生了异常变化。</p>
<blockquote>
<p>因为传入的三个fd_set会被改写，所以使用前记得备份原set。</p>
</blockquote>
<h2 id="2-4-select的实现机制"><a href="#2-4-select的实现机制" class="headerlink" title="2.4 select的实现机制"></a>2.4 select的实现机制</h2><p>我们来简单了解一下select机制的源码：</p>
<ol>
<li>使用copy_from_user从用户空间拷贝fd_set到内核空间</li>
<li>注册回调函数__pollwait，__pollwait的主要工作就是把current进程（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk-&gt;sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。驱动程序在得知设备有IO事件时（通常是该设备上IO事件中断），会调用wakeup，wakeup –&gt; _wake_up_common -&gt; curr-&gt;func(即pollwake)，pollwake函数里面调用_pollwake函数, 通过pwq-&gt;triggered = 1将进程标志为唤醒。再调用default_wake_function(&amp;dummy_wait, mode, sync, key)这个默认的通用唤醒函数唤醒调用select的进程，这时current进程便被唤醒了。</li>
<li>遍历所有fd，依次调用其fd的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll），poll函数调用poll_wait函数，poll_wait函数调用__pollwait()。</li>
<li>以tcp_poll为例，tcp_poll的核心实现就是<strong>pollwait，也就是上面注册的回调函数。它调用</strong>pollwait检查是否有读写操作，并返回一个描述读写操作是否就绪的mask掩码（可以理解为我们上面说的fd_set对应项置为1的那个1），根据这个mask掩码给fd_set中当前fd的对应项赋值。</li>
<li>如果遍历完所有的fd，fd_set中还没有一个表示可读/写/异常的mask掩码（也就是三个fd_set还没有位置置1），则会调用schedule_timeout使调用select的进程（也就是current进程）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。</li>
<li>重复直到要么超时，要么有就绪的fd，然后返回，并把fd_set从内核空间拷贝回用户空间。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-9d4e33a737df6b520954a3db71599b59979.png" alt=""></p>
<h2 id="2-5-select机制的缺点"><a href="#2-5-select机制的缺点" class="headerlink" title="2.5 select机制的缺点"></a>2.5 select机制的缺点</h2><ol>
<li>每次调用select，都需要把fd_set集合从用户态拷贝到内核态，如果fd_set集合很大时，那这个开销也很大</li>
<li>同时每次调用select都需要在内核遍历传递进来的所有fd_set，如果fd_set集合很大时，那这个开销也很大</li>
<li>为了减少数据拷贝带来的性能损坏，内核对被监控的fd_set集合大小做了限制，并且这个是通过宏控制的，一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048。</li>
</ol>
<h1 id="3-poll模式"><a href="#3-poll模式" class="headerlink" title="3 poll模式"></a>3 poll模式</h1><p>poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，pollfd结构使用链表而非数组，<strong>这导致pollfd的长度没有限制</strong>。除此之外，二者的原理基本一致，即对多个描述符也是进行轮询，根据描述符的状态进行处理。</p>
<h2 id="3-1-poll函数"><a href="#3-1-poll函数" class="headerlink" title="3.1 poll函数"></a>3.1 poll函数</h2><p><code>int poll (struct pollfd *fds, unsigned int nfds, int timeout);</code></p>
<p>不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。</p>
<p>同时也不需要三个fd_set来表示分别要监控哪些事件，poll定义的pollfd结构，就封装了该fd需要监控的事件:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct pollfd &#123;</span><br><span class="line">    int fd; &#x2F;* file descriptor *&#x2F;</span><br><span class="line">    short events; &#x2F;* requested events to watch *&#x2F;</span><br><span class="line">    short revents; &#x2F;* returned events witnessed *&#x2F;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>和select函数一样，poll会改写pollfd，返回后，<strong>需要轮询pollfd来获取就绪的描述符</strong>。</p>
<h2 id="3-2-poll函数的实现"><a href="#3-2-poll函数的实现" class="headerlink" title="3.2 poll函数的实现"></a>3.2 poll函数的实现</h2><p>poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。</p>
<p>因为poll和select的区别不大，所以除了fd集合没有限制外(但是数量过大后性能也是会下降)，select其他的缺点poll都有。</p>
<h1 id="4-epoll模式"><a href="#4-epoll模式" class="headerlink" title="4 epoll模式"></a>4 epoll模式</h1><p>由于epoll的实现机制与select/poll机制完全不同，上面所说的 select的缺点在epoll上不复存在。</p>
<p>设想一下如下场景：有100万个客户端同时与一个服务器进程保持着TCP连接。而每一时刻，通常只有几百上千个TCP连接是活跃的(事实上大部分场景都是这种情况)。如何实现这样的高并发？</p>
<p>在select/poll时代，服务器进程每次都把这100万个连接告诉操作系统(从用户态复制句柄数据结构到内核态)，让操作系统内核去查询这些套接字上是否有事件发生，轮询完后，再将句柄数据复制到用户态，让服务器应用程序轮询处理已发生的网络事件，这一过程资源消耗较大，因此，select/poll一般只能处理几千的并发连接。</p>
<h2 id="4-1-epoll的设计"><a href="#4-1-epoll的设计" class="headerlink" title="4.1 epoll的设计"></a>4.1 epoll的设计</h2><p>epoll的设计和实现与select完全不同。epoll通过在Linux内核中申请一个简易的文件系统，这个文件系统早期使用哈希表实现，后来改用红黑树来实现。</p>
<p>epoll把原先的select/poll调用分成了3个部分：</p>
<ol>
<li><p>调用epoll_create()建立一个epoll句柄对象(在epoll文件系统中为这个句柄对象分配资源)</p>
</li>
<li><p>调用epoll_ctl向epoll对象中添加这100万个连接的套接字</p>
</li>
<li><p>调用epoll_wait收集发生的事件的连接</p>
</li>
</ol>
<p>如此一来，要实现上面说是的场景，只需要在进程启动时建立一个epoll对象，然后在需要的时候向这个epoll对象中添加或者删除连接。同时，epoll_wait的效率也非常高，因为调用epoll_wait时，并没有一股脑的向操作系统复制这100万个连接的句柄数据，内核也不需要去遍历全部的连接（epoll通过内核和用户空间共享一块内存来实现共享句柄数据）。</p>
<h2 id="4-2-epoll函数"><a href="#4-2-epoll函数" class="headerlink" title="4.2 epoll函数"></a>4.2 epoll函数</h2><p>epoll操作过程需要三个函数，分别如下：</p>
<ol>
<li><p><code>int epoll_create(int size)；</code></p>
<ul>
<li>创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。</li>
<li>当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。</li>
</ul>
</li>
<li><p><code>int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；</code></p>
<ul>
<li>该函数是对指定描述符fd执行op操作，你可以理解为将套接字以及它要监控的事件，注册到epoll句柄中。通过此调用向epoll对象中添加、删除、修改感兴趣的事件，返回0标识成功，返回-1表示失败。其各参数含义如下</li>
<li>epfd：是epoll_create()的返回值，可以理解为指向epoll句柄的指针。</li>
<li>op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。</li>
<li>fd：是需要监听的fd（文件描述符）</li>
<li>epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">struct epoll_event &#123;</span><br><span class="line">  __uint32_t events;  &#x2F;* Epoll events *&#x2F;</span><br><span class="line">  epoll_data_t data;  &#x2F;* User data variable *&#x2F;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;events可以是以下几个宏的集合：</span><br><span class="line">EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；</span><br><span class="line">EPOLLOUT：表示对应的文件描述符可以写；</span><br><span class="line">EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；</span><br><span class="line">EPOLLERR：表示对应的文件描述符发生错误；</span><br><span class="line">EPOLLHUP：表示对应的文件描述符被挂断；</span><br><span class="line">EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。</span><br><span class="line">EPOLLONESHOT：只监听一次，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里</span><br></pre></td></tr></table></figure>
<blockquote>
<p>epoll的全程是eventpoll，顾名思义，它的实现机制是基于event事件的，所以不同于select使用三个fd_set来对应读/写/异常的IO变化，也不同于poll只是在pollfd的结构体中使用short events来对应事件，epoll专门定义了一个epoll_event结构体，将其作为读/写/异常的IO变化的逻辑封装，称为事件（event）。</p>
</blockquote>
</li>
</ul>
</li>
<li><p><code>int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);</code></p>
<ul>
<li>等待epfd上的io事件，最多返回maxevents个事件。</li>
<li>epfd参数是epoll_create()的返回值，可以理解为指向epoll句柄的指针。</li>
<li>events参数用来从内核得到事件的集合</li>
<li>maxevents参数告知内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size。</li>
<li>timeout参数是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。</li>
</ul>
</li>
</ol>
<h2 id="4-3-epoll的两种工作模式"><a href="#4-3-epoll的两种工作模式" class="headerlink" title="4.3 epoll的两种工作模式"></a>4.3 epoll的两种工作模式</h2><p>epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：</p>
<ul>
<li><strong>LT模式</strong>：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。<ul>
<li>LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。</li>
</ul>
</li>
<li><strong>ET模式</strong>：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。<ul>
<li>ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核也不会发送更多的通知(only once)</li>
<li>ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作，把处理多个文件描述符的任务饿死。</li>
</ul>
</li>
</ul>
<p>二者的区别举个一个例子：</p>
<ol>
<li>我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符</li>
<li>这个时候从管道的另一端被写入了2KB的数据</li>
<li>调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作</li>
<li>然后我们读取了1KB的数据</li>
<li>调用epoll_wait(2)……</li>
</ol>
<p>如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能收到通知RFD有事件。因为第四步我们没有把RFD的数据读完，只读了1KB。</p>
<p>如果是ET模式，那么在第5步调用epoll_wait(2)之后，不会收到通知RFD有事件了，ET模式只会在第三步提醒一次。</p>
<h2 id="4-4-epoll的实现机制"><a href="#4-4-epoll的实现机制" class="headerlink" title="4.4 epoll的实现机制"></a>4.4 epoll的实现机制</h2><p>当某一进程调用epoll_create方法时，Linux内核会创建一个eventpoll结构体，这个结构体中有两个成员与epoll的使用方式密切相关。eventpoll结构体如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">struct eventpoll&#123;</span><br><span class="line">    ....</span><br><span class="line">    &#x2F;*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*&#x2F;</span><br><span class="line">    struct rb_root  rbr;</span><br><span class="line">    &#x2F;*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*&#x2F;</span><br><span class="line">    struct list_head rdlist;</span><br><span class="line">    ....</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p><strong>每一个epoll对象都有一个独立的eventpoll结构体</strong>，用于存放通过epoll_ctl方法向epoll对象中添加进来的事件。<strong>这些事件都会挂载在红黑树中</strong>，如此，重复添加的事件就可以通过红黑树而高效的识别出来(红黑树的插入时间效率是lgn，其中n为树的高度)。</p>
<p>而所有添加到epoll中的事件都会与设备(网卡)驱动程序建立回调关系，也就是说，<strong>当相应的事件发生时会调用这个回调方法</strong>。这个回调方法在内核中叫ep_poll_callback,它会将发生的event事件添加到rdlist双链表中。</p>
<p>在epoll中，对于每一个事件，都会建立一个epitem结构体，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">struct epitem&#123;</span><br><span class="line">    struct rb_node  rbn;&#x2F;&#x2F;红黑树节点</span><br><span class="line">    struct list_head    rdllink;&#x2F;&#x2F;双向链表节点</span><br><span class="line">    struct epoll_filefd  ffd;  &#x2F;&#x2F;事件句柄信息</span><br><span class="line">    struct eventpoll *ep;    &#x2F;&#x2F;指向其所属的eventpoll对象</span><br><span class="line">    struct epoll_event event; &#x2F;&#x2F;期待发生的事件类型</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>epitem可以理解为：事件逻辑结构体epoll_event与双向链表/红黑树之间的映射关系，其关系如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ed4db33152307f23c38cd588d76916d6f16.png" alt=""></p>
<p>当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-82bebc2938db6e54af7df375b24c9ddfa52.png" alt=""></p>
<h1 id="5-三种模型的区别和取舍"><a href="#5-三种模型的区别和取舍" class="headerlink" title="5 三种模型的区别和取舍"></a>5 三种模型的区别和取舍</h1><ol>
<li><p>支持一个进程所能打开的最大连接数</p>
<ul>
<li>select：单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小，当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。</li>
<li>poll：poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的。</li>
<li>epoll：虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接。</li>
</ul>
</li>
<li><p>FD剧增后带来的IO效率问题</p>
<ul>
<li>select：因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。</li>
<li>poll：同上</li>
<li>epoll：因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。</li>
</ul>
</li>
<li><p>消息传递方式</p>
<ul>
<li>select：内核需要将消息传递到用户空间，都需要内核拷贝动作</li>
<li>poll：同上</li>
<li>epoll：epoll通过内核和用户空间共享一块内存来实现的。</li>
</ul>
</li>
</ol>
<p>综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点。</p>
<p>表面上看epoll的性能最好，但是<strong>在连接数少并且连接都十分活跃</strong>的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。</p>
<p>select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。</p>
<p>select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善 </p>
<p>select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/07/volatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/07/volatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/" itemprop="url">volatile关键字详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-07T22:38:04+08:00">
                2020-08-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/JAVA%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA线程与并发控制</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/07/volatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/08/07/volatile关键字详解/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  3.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  11
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>提到JAVA的并发编程，就不得不提volatile关键字，不管是在面试还是实际开发中，volatile关键字的使用都是一个应该掌握的技能。它之所以重要，是因为它和JAVA并发编程中会遇到三种重要问题中的两种密切相关。</p>
<p>在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。而volatile关键字之所以神奇，在于它可以解决<strong>可见性问题</strong>和<strong>有序性问题</strong>。</p>
<h1 id="1-可见性"><a href="#1-可见性" class="headerlink" title="1 可见性"></a>1 可见性</h1><h2 id="1-1-可见性问题"><a href="#1-1-可见性问题" class="headerlink" title="1.1 可见性问题"></a>1.1 可见性问题</h2><p>如果我们学过java内存模型的话，对下面这张图想必不陌生：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-abfdf25cd3ba1dc266bdfed64c2e8d577b5.png" alt=""></p>
<p>每一个线程都有一份自己的本地内存，所有线程共用一份主内存。如果一个线程A对主内存中的某个数据V进行了修改，而此时另外一个线程B不知道该数据V已经发生了修改，它会从本地内存中去读取这个数据V，显然数据V已经过时了。<strong>这就是说，本次线程A修改后的数据V，对线程B来说，此时是不可见的</strong>。</p>
<h2 id="1-2-volatile保证内存可见性"><a href="#1-2-volatile保证内存可见性" class="headerlink" title="1.2 volatile保证内存可见性"></a>1.2 volatile保证内存可见性</h2><p>可见性问题在并发场景中是十分常见，那么volatile关键字如何保证内存可见性呢？</p>
<p>volatile关键字的作用很简单，就是一个线程在对主内存的某一份数据进行更改时，改完之后会立刻刷新到主内存。并且会强制让缓存了该变量的线程中的数据清空，必须从主内存重新读取最新数据。这样一来就保证了可见性。</p>
<p>其底层原理如下：</p>
<p>JMM把主内存和线程的本地内存之间的交互分为8个原子操作，他们分别是：</p>
<ul>
<li>lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。</li>
<li>unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。</li>
<li>read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。</li>
<li>load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。</li>
<li>use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。</li>
<li>assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。</li>
<li>store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。</li>
<li>write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。</li>
</ul>
<p>JMM要求，如果要把一个变量从主内存复制到工作内存，那么应该顺序的执行read和load操作。反之，应该顺序的执行store和write操作。JMM只要求上述两个指令是顺序执行，不要求必须要连续执行，也就说是，可以在read和load操作之间插入其他指令。这基本构成了JMM的主内存和工作内存之间的交互逻辑。</p>
<p>而volatile如何实现内存可见性呢？其实很简单，下面我截取一段被volatile关键字修饰的变量的赋值逻辑的汇编指令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">···</span><br><span class="line">0x0000000002931351: lock add dword ptr [rsp],0h  ;*putstatic instance</span><br><span class="line">                                                ; - org.xrq.test.design.singleton.LazySingleton::getInstance@13 (line 14)</span><br><span class="line">···</span><br></pre></td></tr></table></figure>

<p>你不用去关心这段字节码什么意思，你知道知道它的语意是对一个volatile修饰的变量进行赋值操作。<strong>和没有volatile修饰的变量的赋值操作字节码相比，volatile修饰的变量的赋值操作仅仅是多了一个lock指令前缀</strong>。</p>
<p>lock指令前缀有什么作用呢？<strong>lock后的写操作会强制回写已修改的数据到主内存，相当于连续执行了store和write操作</strong>。</p>
<p>看到这里有同学不禁要问了，lock操作只是强制回写数据到主内存，但没有强制其他线程去刷新他们工作内存中的值啊。</p>
<p>这要结合JMM的缓存一致性协议——MESI协议来看了，不懂的同学可回顾本博客另外一篇文章《JAVA内存模型》的MESI协议一章。</p>
<p>假如线程A操作赋值逻辑，使用lock操作强制回写数据V到主内存，根据MESI协议，线程A会将主内存中该数据V的状态改为M，其他线程一直在监听主内存，发现该数据V的状态为M后，会将他们的工作内存中的数据V的状态改为I——即失效状态，最终迫使其他线程在使用V之前，必须去主内存读取新值。</p>
<p>这就是volatile保证内存可见性的原理，其实只是一个lock指令前缀而已。</p>
<h1 id="2-有序性"><a href="#2-有序性" class="headerlink" title="2 有序性"></a>2 有序性</h1><h2 id="2-1-有序性问题"><a href="#2-1-有序性问题" class="headerlink" title="2.1 有序性问题"></a>2.1 有序性问题</h2><p>并发场景中，有序性问题，许多是由JVM的指令重排优化引起的。</p>
<p>指令重排序是JVM为了优化指令、提高程序运行效率，在不影响单线程程序执行结果的前提下，尽可能地提高并行度。指令重排序包括编译器重排序和运行时重排序。</p>
<blockquote>
<p>实质上指令重排序是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理</p>
</blockquote>
<p>我们来看一个因为指令重排而引起的并发问题，懒加载的双重检查模型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Singleton &#123;</span><br><span class="line">	private static Singleton instance;</span><br><span class="line">	private Singleton()&#123;&#125;</span><br><span class="line">	public static Singleton getInstance() &#123;</span><br><span class="line">		if ( instance &#x3D;&#x3D; null ) &#123; &#x2F;&#x2F;当instance不为null时，仍可能指向一个“被部分初始化的对象”</span><br><span class="line">			synchronized (Singleton.class) &#123;</span><br><span class="line">				if ( instance &#x3D;&#x3D; null ) &#123;</span><br><span class="line">					instance &#x3D; new Singleton();</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return instance;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个模型我们并不陌生，在 《Effecitve Java》一书中作者层提到了双重检查模式，并指出这种模式在Java中通常并不适用。并不适用的原因，就是因为指令重排。</p>
<p>上面这段代码，初看没问题，但是在并发模型下，可能会出错。那是因为<code>instance = new Singleton();</code>并非一个原子操作，编译器会将其编译为三行字节码，也就是三个步骤：</p>
<ol>
<li><p>memory=allocate();// 分配内存</p>
</li>
<li><p>ctorInstanc(memory) //初始化对象</p>
</li>
<li><p>instance=memory //设置instance指向刚分配的地址</p>
</li>
</ol>
<p>在编译器运行时，因为步骤三和步骤二无依赖关系，故而JVM会对其进行指令重排优化，从1-2-3顺序优化为1-3-2顺序。</p>
<p>可以看到指令重排之后，操作3排在了操作2之前，即引用instance指向内存memory时，这段崭新的内存还没有初始化——也就是说引用instance指向了一个”被部分初始化的对象”。</p>
<p>此时，如果另一个线程调用getInstance方法，由于instance已经指向了一块内存空间，从而if (instance == null) 条件判为false，方法返回instance引用，那么用户则得到了没有完成初始化的“半个”单例。从而发生问题。</p>
<h2 id="2-2-volatile防止指令重排"><a href="#2-2-volatile防止指令重排" class="headerlink" title="2.2 volatile防止指令重排"></a>2.2 volatile防止指令重排</h2><p>解决这个该问题，只需要将instance声明为volatile变量：<code>private static volatile Singleton instance;</code></p>
<p>volatile关键字能够禁止JVM对修饰的变量的读写做指令重排，从而保证了<code>instance = new Singleton();</code>在底层能够按照顺序执行。</p>
<p><strong>其底层原理其实和volatile保证可见性的原理是一样的，也就是在汇编指令层面加入一个lock前缀</strong>：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-97a29eb4b5f1305232f4981ff4d69b16a3f.png" alt=""></p>
<p>这里的lock前缀指令相当于一个内存屏障（但实际上不是内存屏障），它保证了：<strong>当程序执行到volatile变量的读或写时，在lock指令前面的操作必须全部执行完毕，且结果必须已经对后面的操作可见（也就是上面说的lock会强制刷新新值到主存）；</strong></p>
<p>指令重排的原则是无依赖关系间的优化排序，而volatile字段带来的lock前缀，则会使<code>instance = new Singleton();</code>的三个字节码<strong>相当于</strong>变成这样（lock是汇编指令，所以说只是相当于）：</p>
<ol>
<li><p>memory=allocate();// 分配内存</p>
</li>
<li><p>ctorInstanc(memory) //初始化对象</p>
</li>
<li><p><strong>lock</strong> instance=memory //设置instance指向刚分配的地址</p>
</li>
</ol>
<p>这使得原本没有依赖关系的2和3操作，<strong>因为lock前缀的语意强制，被强加上了一个2必须在3之前完成的“依赖”</strong>，形成了虽然不是内存屏障，但却达到了内存屏障功能的效果，给人一种指令重排无法越过volatile读写操作两边的观感。</p>
<h1 id="3-lock指令前缀作用总结"><a href="#3-lock指令前缀作用总结" class="headerlink" title="3 lock指令前缀作用总结"></a>3 lock指令前缀作用总结</h1><p>Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。它后面可以跟ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG等指令。</p>
<ul>
<li><p>确保指令重排序时不会把lock指令后面的指令排到lock之前的位置，也不会把前面的指令排到lock的后面；即在执行到lock这句指令时，在它前面的操作已经全部完成；</p>
</li>
<li><p>强制将对缓存的修改操作立即写入主存，同时利用缓存一致性机制，让其他工作线程从主存重新读值；</p>
</li>
</ul>
<h1 id="4-volatile不能保证原子性"><a href="#4-volatile不能保证原子性" class="headerlink" title="4 volatile不能保证原子性"></a>4 volatile不能保证原子性</h1><p>从上文我们知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？</p>
<p>下面看一个例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public class Test &#123;</span><br><span class="line">    public volatile int inc &#x3D; 0;</span><br><span class="line">    public void increase() &#123;</span><br><span class="line">        inc++;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;有10个线程分别进行了1000次操作inc的自增操作</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        final Test test &#x3D; new Test();</span><br><span class="line">        for(int i&#x3D;0;i&lt;10;i++)&#123;</span><br><span class="line">            new Thread()&#123;</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    for(int j&#x3D;0;j&lt;1000;j++)</span><br><span class="line">                        test.increase();</span><br><span class="line">                &#125;;</span><br><span class="line">            &#125;.start();</span><br><span class="line">        &#125;</span><br><span class="line">        while(Thread.activeCount()&gt;1)  &#x2F;&#x2F;保证前面的线程都执行完</span><br><span class="line">            Thread.yield();</span><br><span class="line">        System.out.println(test.inc);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。</p>
<p>可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。</p>
<p>这里面就有一个误区了，volatile关键字能保证可见性没有错，但可见性只能保证每次读取的是最新的值，volatile没办法保证对变量的操作的原子性。</p>
<p>自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：</p>
<ol>
<li>假如某个时刻变量inc的值为10，</li>
<li>线程1对变量进行自增操作，线程1先读取了变量inc的原始值10。</li>
<li>线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，还没有没有对变量进行修改操作，线程2读到的10也是10；</li>
<li>这时候线程1对inc进行自增，并且通过可见性，将结果11写回主存，并将线程2的工作内存中inc的状态改为无效。</li>
<li>但是此时线程2对inc的读操作已经结束了，已经在进行+1操作了，inc就算在线程2中被置为无效，线程2也过了能感知到的时间点了，导致线程2也是对10+1，得到11再写回主存。</li>
</ol>
<p>以此类推，导致最后的结果必定小于10000；这说明了volatile无法保证原子性，它本身也不适用类似场景。</p>
<p><strong>volatile比较适合用来修饰一个会被单线程更改，但又需要立刻让其他线程感知到值变化的值，比如代码逻辑里面的业务开关等</strong>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/05/JAVA%E7%9A%84CAS%E5%8F%8A%E5%85%B6ABA%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/05/JAVA%E7%9A%84CAS%E5%8F%8A%E5%85%B6ABA%E9%97%AE%E9%A2%98/" itemprop="url">JAVA的CAS及其ABA问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-05T23:35:26+08:00">
                2020-08-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/JAVA%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA线程与并发控制</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/05/JAVA%E7%9A%84CAS%E5%8F%8A%E5%85%B6ABA%E9%97%AE%E9%A2%98/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/08/05/JAVA的CAS及其ABA问题/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-CAS是什么"><a href="#1-CAS是什么" class="headerlink" title="1 CAS是什么"></a>1 CAS是什么</h1><p>CAS是Compare-And-Swap的缩写，即<strong>对比和替换</strong>，它在保证数据原子性的前提下尽可能的减少了锁的使用，很多编程语言或者系统实现上都大量的使用了CAS。</p>
<p>因为没有没有线程阻塞唤醒带来的性能消耗问题。这也是为什么CAS比synchronized性能高的原因！</p>
<h2 id="1-1-JAVA中CAS的实现"><a href="#1-1-JAVA中CAS的实现" class="headerlink" title="1.1 JAVA中CAS的实现"></a>1.1 JAVA中CAS的实现</h2><p>JAVA中的CAS主要使用的是Unsafe类。Unsafe的CAS操作主要是基于硬件平台的汇编指令，目前的处理器基本都支持CAS，只不过不同的厂家的实现不一样罢了。</p>
<p>sun.misc.Unsafe虽然类提供了一系列直接操作内存对象的方法，但只是在 jdk 内部使用，JAVA官方不建议开发者直接调用Unsafe类；所以我们一般直接使用到的，都是java.util.concurrent.atomic 包下的Atomic*类，比如 AtomicBoolean、AtomicInteger 等，其compareAndSet方法，也都是调用的Unsafe的CAS方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public final class Unsafe &#123;</span><br><span class="line">	...</span><br><span class="line">	public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);</span><br><span class="line">	public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);</span><br><span class="line">	public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>value 表示 需要操作的对象</li>
<li>valueOffset 表示 对象(value)的地址的偏移量（通过Unsafe.objectFieldOffset(Field valueField)获取）</li>
<li>expect 表示更新时value的期待值</li>
<li>update 表示将要更新的值</li>
</ul>
<p>具体过程为每次在执行CAS操作时，线程会根据valueOffset去内存中获取当前值去跟expect的值做对比如果一致则修改并返回true，如果不一致说明有别的线程也在修改此对象的值，则返回false。</p>
<p>Unsafe类中compareAndSwapInt的具体实现所对应的cpp代码为：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x))</span><br><span class="line">  UnsafeWrapper(<span class="string">"Unsafe_CompareAndSwapInt"</span>);</span><br><span class="line">  oop p = JNIHandles::resolve(obj);</span><br><span class="line">  jint* addr = (jint *) index_oop_from_field_offset_long(p, offset);</span><br><span class="line">  <span class="keyword">return</span> (jint)(Atomic::cmpxchg(x, addr, e)) == e;</span><br><span class="line">UNSAFE_END</span><br></pre></td></tr></table></figure>

<h2 id="1-2-CAS和自旋的配合"><a href="#1-2-CAS和自旋的配合" class="headerlink" title="1.2 CAS和自旋的配合"></a>1.2 CAS和自旋的配合</h2><blockquote>
<p>很多文章都信誓旦旦的说CAS底层使用自旋，从而达到高效的无锁并发。这时将Atomic的CAS实现和Unsafe的CAS实现混淆的结果，JAVA的CAS追本溯源都在Unsafe的CAS方法中，它顾名思义，只有比较和替换，没有自旋。</p>
</blockquote>
<p>但不可否认，当CAS和自旋搭配使用的时候，确实效果更佳，尤其是在并发做加减的时候，所以Unsafe类提供了一个将CAS和自旋搭配使用的自增方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public final int getAndSetInt(Object var1, long var2, int var4) &#123;</span><br><span class="line">    int var5;</span><br><span class="line">    do &#123;</span><br><span class="line">        &#x2F;&#x2F;getIntVolatile方法获取对象var1中offset&#x3D;var2偏移地址对应的整型field的值,支持volatile load语义。</span><br><span class="line">        &#x2F;&#x2F;说人话就是取出var1内存中偏移量为var2位置对应的整型field的值</span><br><span class="line">        var5 &#x3D; this.getIntVolatile(var1, var2);</span><br><span class="line">        &#x2F;&#x2F;自旋操作，不停比较该值，如果CAS成功，则退出，否则一直循环。</span><br><span class="line">    &#125; while(!this.compareAndSwapInt(var1, var2, var5, var4));</span><br><span class="line"></span><br><span class="line">    return var5;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>相同原理的还有getAndSetLong/getAndSetObject/getAndAddLong/getAndAddInt等方法。</p>
<h2 id="1-3-Java-8对CAS机制的优化——LongAdder"><a href="#1-3-Java-8对CAS机制的优化——LongAdder" class="headerlink" title="1.3 Java 8对CAS机制的优化——LongAdder"></a>1.3 Java 8对CAS机制的优化——LongAdder</h2><p>当并发操作一个AtomicInteger而不是使用synchronize时，我们确实可以享受到CAS无锁并发带来的高性能，但CAS就完美无缺么？肯定不是的，比如说大量的线程同时并发修改一个AtomicInteger，可能有很多线程会不停的自旋，进入一个无限重复的循环中。</p>
<p>这些线程不停地获取值，然后发起CAS操作，但是发现这个值被别人改过了，于是再次进入下一个循环，获取值，发起CAS操作又失败了，再次进入下一个循环。</p>
<p>在大量线程高并发更新AtomicInteger的时候，这种问题可能会比较明显，导致大量线程空循环，自旋转，性能和效率都不是特别好。</p>
<p>于是，Java 8推出了一个新的类，LongAdder，他尝试使用分段CAS以及自动分段迁移的方式来大幅度提升多线程高并发执行CAS操作的性能！</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-610bcb236b50f94729fea4711c012e101fa.png" alt=""></p>
<p>在LongAdder的底层实现中，首先有一个base值，刚开始多线程来不停的累加数值，都是对base进行累加的，比如刚开始累加成了base = 5。</p>
<p>接着如果发现并发更新的线程数量过多，就会开始施行分段CAS的机制，也就是内部会搞一个Cell数组，每个数组是一个数值分段。这时，<strong>让大量的线程分别去对不同Cell内部的value值进行CAS累加操作</strong>，这样就把CAS计算压力分散到了不同的Cell分段数值中。</p>
<p>如此操作可以大幅度的降低多线程并发更新同一个数值时出现的无限循环的问题，大幅度提升了多线程并发更新数值的性能和效率！</p>
<p>更重要的是他内部实现了<strong>自动分段迁移的机制</strong>，也就是如果某个Cell的value执行CAS失败了，那么就会自动去找另外一个Cell分段内的value值进行CAS操作。这样也解决了线程空旋转、自旋不停等待执行CAS操作的问题，让一个线程过来执行CAS时可以尽快的完成这个操作。</p>
<p>最后，如果你要从LongAdder中获取当前累加的总值，<strong>就会把base值和所有Cell分段数值加起来返回给你</strong>。</p>
<h1 id="2-CAS的ABA问题"><a href="#2-CAS的ABA问题" class="headerlink" title="2 CAS的ABA问题"></a>2 CAS的ABA问题</h1><p>CAS还存在一个更加严重的问题——ABA问题：</p>
<p>线程1准备用CAS修改变量值A，在此之前，其它线程将变量的值由A替换为B，又由B替换为A，然后线程1执行CAS时发现变量的值仍然为A，所以CAS成功。但实际上这时的现场已经和最初不同了。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-36b9583db6094422fbc837b64cceb1cf483.png" alt=""></p>
<p>有没有解决方案呢？有的，JAVA中ABA中解决方案有两种，我们依次介绍</p>
<h2 id="2-1-AtomicStampedReference类"><a href="#2-1-AtomicStampedReference类" class="headerlink" title="2.1 AtomicStampedReference类"></a>2.1 AtomicStampedReference类</h2><p>解决ABA最简单的方案就是给值加一个修改版本号，每次值变化，都会修改它版本号，CAS操作时都对比此版本号。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2594f459d269ecbecaca0fbea9d4b37d1ce.png" alt=""></p>
<p>AtomicStampedReference就是这种思路在JAVA中的产物，它主要维护包含一个对象引用以及一个可以自动更新的整数”stamp”的pair对象来解决ABA问题。</p>
<p>其关键代码如下（省略无用代码）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;关键代码</span><br><span class="line">public class AtomicStampedReference&lt;V&gt; &#123;</span><br><span class="line">    private static class Pair&lt;T&gt; &#123;</span><br><span class="line">        final T reference;  &#x2F;&#x2F;维护对象引用</span><br><span class="line">        final int stamp;  &#x2F;&#x2F;用于标志版本</span><br><span class="line">        private Pair(T reference, int stamp) &#123;</span><br><span class="line">            this.reference &#x3D; reference;</span><br><span class="line">            this.stamp &#x3D; stamp;</span><br><span class="line">        &#125;</span><br><span class="line">        static &lt;T&gt; Pair&lt;T&gt; of(T reference, int stamp) &#123;</span><br><span class="line">            return new Pair&lt;T&gt;(reference, stamp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    private volatile Pair&lt;V&gt; pair;</span><br><span class="line">    ....</span><br><span class="line">    &#x2F;**</span><br><span class="line">      * expectedReference ：更新之前的原始值</span><br><span class="line">      * newReference : 将要更新的新值</span><br><span class="line">      * expectedStamp : 期待更新的标志版本</span><br><span class="line">      * newStamp : 将要更新的标志版本</span><br><span class="line">      *&#x2F;</span><br><span class="line">    public boolean compareAndSet(V   expectedReference,</span><br><span class="line">                                 V   newReference,</span><br><span class="line">                                 int expectedStamp,</span><br><span class="line">                                 int newStamp) &#123;</span><br><span class="line">        Pair&lt;V&gt; current &#x3D; pair; &#x2F;&#x2F;获取当前pair</span><br><span class="line">        return</span><br><span class="line">            expectedReference &#x3D;&#x3D; current.reference &amp;&amp; &#x2F;&#x2F;原始值等于当前pair的值引用，说明值未变化</span><br><span class="line">            expectedStamp &#x3D;&#x3D; current.stamp &amp;&amp; &#x2F;&#x2F; 原始标记版本等于当前pair的标记版本，说明标记未变化</span><br><span class="line">            ((newReference &#x3D;&#x3D; current.reference &amp;&amp;</span><br><span class="line">              newStamp &#x3D;&#x3D; current.stamp) || &#x2F;&#x2F; 将要更新的值和标记都没有变化</span><br><span class="line">             casPair(current, Pair.of(newReference, newStamp))); &#x2F;&#x2F; cas 更新pair</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>不需要过分在意源码，我们只要知道怎么用就好，demo如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">        AtomicStampedReference&lt;String&gt; reference &#x3D; new AtomicStampedReference&lt;String&gt;(&quot;aaa&quot;,1);</span><br><span class="line">        reference.compareAndSet(&quot;aaa&quot;,&quot;bbb&quot;,reference.getStamp(),reference.getStamp()+1);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-2-AtomicMarkableReference类"><a href="#2-2-AtomicMarkableReference类" class="headerlink" title="2.2 AtomicMarkableReference类"></a>2.2 AtomicMarkableReference类</h2><p>AtomicMarkableReference可以理解为AtomicStampedReference的简化版，就是不关心修改过几次，仅仅关心是否修改过。因此变量mark是boolean类型，仅记录值是否有过修改。</p>
<p>关键代码如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Pair对象维护对象的引用和对象标记</span><br><span class="line">private static class Pair&lt;T&gt; &#123;</span><br><span class="line">    final T reference;</span><br><span class="line">    final boolean mark;&#x2F;&#x2F; 通过标记的状态区分对象是否有更改</span><br><span class="line"></span><br><span class="line">    private Pair(T reference, boolean mark) &#123;</span><br><span class="line">        this.reference &#x3D; reference;</span><br><span class="line">        this.mark &#x3D; mark;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    static &lt;T&gt; Pair&lt;T&gt; of(T reference, boolean mark) &#123;</span><br><span class="line">        return new Pair&lt;T&gt;(reference, mark);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;**</span><br><span class="line"> * @param expectedReference 期待的原始对象</span><br><span class="line"> * @param newReference      将要更新的对象</span><br><span class="line"> * @param expectedMark      期待原始对象的标记</span><br><span class="line"> * @param newMark           将要更新对象的标记</span><br><span class="line"> *&#x2F;</span><br><span class="line">public boolean compareAndSet(V expectedReference,</span><br><span class="line">                             V newReference,</span><br><span class="line">                             boolean expectedMark,</span><br><span class="line">                             boolean newMark) &#123;</span><br><span class="line">    Pair&lt;V&gt; current &#x3D; pair;</span><br><span class="line">    return</span><br><span class="line">            expectedReference &#x3D;&#x3D; current.reference &amp;&amp; &#x2F;&#x2F; 如果期待的原始对象与Pair的reference一样则返回true</span><br><span class="line">                    expectedMark &#x3D;&#x3D; current.mark &amp;&amp; &#x2F;&#x2F; 如果期待的原始对象的标记与Pair的mark一样则返回true</span><br><span class="line">                    ((newReference &#x3D;&#x3D; current.reference &amp;&amp;</span><br><span class="line">                            newMark &#x3D;&#x3D; current.mark) || &#x2F;&#x2F; 如果要更新的对象和对象标记与Pair的refernce和mark一样的话直接返回true，否则执行CAS操作</span><br><span class="line">                            casPair(current, Pair.of(newReference, newMark)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>不需要过分在意源码，我们只要知道怎么用就好，demo如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">public class AtomicMarkableReferenceDemo &#123;</span><br><span class="line"></span><br><span class="line">    private static final Integer INIT_NUM &#x3D; 10;</span><br><span class="line"></span><br><span class="line">    private static final Integer TEM_NUM &#x3D; 20;</span><br><span class="line"></span><br><span class="line">    private static final Integer UPDATE_NUM &#x3D; 100;</span><br><span class="line"></span><br><span class="line">    private static final Boolean INITIAL_MARK &#x3D; Boolean.FALSE;</span><br><span class="line"></span><br><span class="line">    private static AtomicMarkableReference atomicMarkableReference &#x3D; new AtomicMarkableReference(INIT_NUM, INITIAL_MARK);</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        new Thread(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread().getName() + &quot; ： 初始值为：&quot; + INIT_NUM + &quot; , 标记为： &quot; + INITIAL_MARK);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(1000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            if (atomicMarkableReference.compareAndSet(INIT_NUM, UPDATE_NUM, atomicMarkableReference.isMarked(), Boolean.TRUE)) &#123;</span><br><span class="line">                System.out.println(Thread.currentThread().getName() + &quot; ： 修改后的值为：&quot; + atomicMarkableReference.getReference() + &quot; , 标记为： &quot; + atomicMarkableReference.isMarked());</span><br><span class="line">            &#125;else&#123;</span><br><span class="line">                System.out.println(Thread.currentThread().getName() +  &quot; CAS返回false&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, &quot;线程A&quot;).start();</span><br><span class="line"></span><br><span class="line">        new Thread(() -&gt; &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">            System.out.println(Thread.currentThread().getName() + &quot; ： 初始值为：&quot; + atomicMarkableReference.getReference() + &quot; , 标记为： &quot; + INITIAL_MARK);</span><br><span class="line">            atomicMarkableReference.compareAndSet(atomicMarkableReference.getReference(), TEM_NUM, atomicMarkableReference.isMarked(), Boolean.TRUE);</span><br><span class="line">            System.out.println(Thread.currentThread().getName() + &quot; ： 修改后的值为：&quot; + atomicMarkableReference.getReference() + &quot; , 标记为： &quot; + atomicMarkableReference.isMarked());</span><br><span class="line">        &#125;, &quot;线程B&quot;).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>输出结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">线程A ： 初始值为：10 , 标记为： false</span><br><span class="line">线程B ： 初始值为：10 , 标记为： false</span><br><span class="line">线程B ： 修改后的值为：20 , 标记为： true</span><br><span class="line">线程A CAS返回false</span><br></pre></td></tr></table></figure>

<p>由于线程B修改了对象，标记由false改为true，所以当上下文切换为线程A的时候，如果标记不一致，线程A执行CAS方法就会返回false。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/04/LRU%E5%92%8CLFU%E7%AE%97%E6%B3%95%E4%BB%A5%E5%8F%8A%E5%85%B6%E5%9C%A8Redis%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/04/LRU%E5%92%8CLFU%E7%AE%97%E6%B3%95%E4%BB%A5%E5%8F%8A%E5%85%B6%E5%9C%A8Redis%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/" itemprop="url">LRU和LFU算法以及其在Redis中的实现</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-04T23:34:29+08:00">
                2020-08-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index">
                    <span itemprop="name">中间件</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/04/LRU%E5%92%8CLFU%E7%AE%97%E6%B3%95%E4%BB%A5%E5%8F%8A%E5%85%B6%E5%9C%A8Redis%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/08/04/LRU和LFU算法以及其在Redis中的实现/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  6.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  25
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文讲述的两个缓存淘汰算法，LRU算法（Least recently used）和LFU算法（Least Frequently used），两者看起来很相似，但我们要明确其区别在于：</p>
<ul>
<li><p>LRU是按访问时间排序，发生淘汰的时候，把访问时间最旧的淘汰掉。</p>
</li>
<li><p>LFU是按频次排序，一个数据被访问过，把它的频次+1，发生淘汰的时候，把频次低的淘汰掉。</p>
</li>
</ul>
<p>本文旨在描述LRU/LFU算法定义，并给出性能最佳的实现方式，最后再延伸至当前最热门的缓存中间件Redis中二者的实现。</p>
<p>其中，LRU/LFU算法性能最优的实现，也是各大厂技术面的常问题。leetcode上有两个这样的题目，要求是缓存的加入put()，缓存读取get()，都要在O(1)内实现：</p>
<ul>
<li>LRU：<a href="https://leetcode.com/problems/lru-cache/description/" target="_blank" rel="noopener">https://leetcode.com/problems/lru-cache/description/</a> 或者 <a href="https://leetcode-cn.com/problems/lru-cache/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/lru-cache/</a></li>
<li>LFU：<a href="https://leetcode.com/problems/lfu-cache/description/" target="_blank" rel="noopener">https://leetcode.com/problems/lfu-cache/description/</a> 或者 <a href="https://leetcode-cn.com/problems/lfu-cache/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/lfu-cache/</a></li>
</ul>
<h1 id="1-LRU算法"><a href="#1-LRU算法" class="headerlink" title="1 LRU算法"></a>1 LRU算法</h1><p>LRU（Least recently used）算法，也叫作<strong>最近最久未使用算法</strong>，顾名思义，就是哪个是最近不用的，就把他淘汰掉。它根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。它经常使用在内存/缓存空间不足的场景，以便在受限时舍弃掉不常用的数据。</p>
<h2 id="1-1-链表实现简单LRU"><a href="#1-1-链表实现简单LRU" class="headerlink" title="1.1 链表实现简单LRU"></a>1.1 链表实现简单LRU</h2><p>使用链表，可以实现最简单的LRU算法：</p>
<ol>
<li>维护一个定长的链表</li>
<li>当一个新的key被访问时<ul>
<li>如果这个key不存在链表中，那么新key插入到链表头部；</li>
<li>如果这个key存在链表中，那么将这个key移到链表头部；</li>
</ul>
</li>
<li>当链表满的时候，如果还有新的key要插入，则将链表尾部的key丢弃。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-c609868da6b2cfefb197343aeee43d3d711.png" alt=""></p>
<p>这种简单的实现固然能达到我们的目的，但也有致命的要求：这种实现的性能不是很好，查询一个key是否存在链表中，以及在链表中的具体位置的时间复杂度是O(n)，这在数据数量巨大的场景下是灾难的。</p>
<h2 id="1-2-HashMap和双向链表实现高性能LRU"><a href="#1-2-HashMap和双向链表实现高性能LRU" class="headerlink" title="1.2 HashMap和双向链表实现高性能LRU"></a>1.2 HashMap和双向链表实现高性能LRU</h2><p>链表实现的LRU算法瓶颈主要在<strong>定位一个key在链表中位置的消耗</strong>。</p>
<p>为了规避这个代价，我们可以引入在查询和定位方面具有极高优势的HashMap来作为互补，整体的设计思路是，可以使用 HashMap 存储 key，而HashMap的Value指向双向链表实现的LRU的 Node 节点。这样可以做到save和get的时间都是 O(1)。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-04a2a22decea9ebd74bd5aab3ad4de3fbb6.png" alt=""></p>
<p>假如我们预设链表的大小是3，下图展示了LRU链表在存储和访问过程中的变化。为了简化图复杂度，图中没有展示HashMap部分的变化，仅仅演示了上图LRU双向链表的变化。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9bbae79816c5ac35c34cd21e3bb7f20a342.png" alt=""></p>
<h2 id="1-3-继承LinkedHashMap实现LRU"><a href="#1-3-继承LinkedHashMap实现LRU" class="headerlink" title="1.3 继承LinkedHashMap实现LRU"></a>1.3 继承LinkedHashMap实现LRU</h2><p>LinkedHashMap底层就是用的HashMap加双链表实现的，而且本身已经实现了按照访问顺序的存储（也就是其put方法会将最近访问的数据放到表头）。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e15263be2c99e9a89332fc6c464029aa4df.png" alt=""></p>
<p>此外，LinkedHashMap中本身就实现了一个方法removeEldestEntry，用于在每次数据发生变更时（put和get）判断是否需要移除最不常读取的数，方法默认是直接返回false，不会移除元素（也正因此，LinkedHashMap是无限长的）。所以为了将其改造为一个定长且会自动移除队尾数据的链表，需要重写removeEldestEntry方法，即当缓存满后就移除最不常用的数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private final int CACHE_SIZE;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 这里就是传递进来最多能缓存多少数据</span><br><span class="line">    public LRUCache(int cacheSize) &#123;</span><br><span class="line">        &#x2F;&#x2F; 设置一个hashmap的初始大小，最后一个true指的是让linkedhashmap按照访问顺序来进行排序，最近访问的放在头，最老访问的就在尾</span><br><span class="line">        super((int) Math.ceil(cacheSize &#x2F; 0.75) + 1, 0.75f, true);</span><br><span class="line">        CACHE_SIZE &#x3D; cacheSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected boolean removeEldestEntry(Map.Entry eldest) &#123;</span><br><span class="line">        &#x2F;&#x2F; 当map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据</span><br><span class="line">        return size() &gt; CACHE_SIZE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="2-Redis中的LRU"><a href="#2-Redis中的LRU" class="headerlink" title="2 Redis中的LRU"></a>2 Redis中的LRU</h1><blockquote>
<p>在讨论Redis的LRU之前，需要明确，Redis的缓存淘汰策略（LRU）与Redis键的过期删除策略不是一回事，LRU是在Redis内存使用超过一定值的时候（一般这个值可以配置）使用的淘汰降级策略；而后者是通过定期删除+惰性删除两者结合的方式进行过期删除的。</p>
</blockquote>
<h2 id="2-1-Redis缓存淘汰策略"><a href="#2-1-Redis缓存淘汰策略" class="headerlink" title="2.1 Redis缓存淘汰策略"></a>2.1 Redis缓存淘汰策略</h2><p>当内存达到极限时，Redis就要开始利用回收策略对内存进行回收释放。回收的配置在 redis.conf 中填写，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">maxmemory 1073741824</span><br><span class="line">maxmemory-policy noeviction</span><br><span class="line">maxmemory-samples 5</span><br></pre></td></tr></table></figure>

<ul>
<li>maxmemory： 指定了内存使用的极限，以字节为单位。当内存达到极限时，他会尝试去删除一些键值。</li>
<li>maxmemory-policy：指定删除的策略。Redis提供了如下几种缓存淘汰策略的取值<ul>
<li>noeviction：当内存使用超过配置的时候（如SET、LPUSH 等等命令）会返回错误，不会驱逐任何键。</li>
<li>allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键</li>
<li>volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键</li>
<li>allkeys-random：加入键的时候如果过限，从所有key随机删除</li>
<li>volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐</li>
<li>volatile-ttl：从配置了过期时间的键中驱逐过期时间最近 (TTL 最小)的键</li>
<li>volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键</li>
<li>allkeys-lfu：从所有键中驱逐使用频率最少的键</li>
</ul>
</li>
<li>maxmemory-samples ：指定了在进行删除时的键的采样数量。LRU 和 TTL 都是近似算法，所以可以根据参数来进行取舍，到底是要速度还是精确度。默认值一般填 5。10 的话已经非常近似正式的 LRU 算法了，但是会多一些 CPU 消耗；3 的话执行更快，然而不够精确。</li>
</ul>
<p>上述说到的缓存淘汰策略中，带lru后缀的，就是采用Redis LRU算法的策略，带有lfu后缀的策略，就是采用Redis LFU算法的策略（后文详述）。</p>
<h2 id="2-2-Redis中的LRU时钟"><a href="#2-2-Redis中的LRU时钟" class="headerlink" title="2.2 Redis中的LRU时钟"></a>2.2 Redis中的LRU时钟</h2><p>在LRU实现中，最核心的要点就是标记哪些数据是“最久”的，前文提到的LRU实现，我们利用链表的顺序来确定哪个数据“最久”，但如果按照性能较好的HashMap和双向链表来实现，在Redis key数量巨大的情况下，HashMap和双向链表的长度也会非常巨大，会牺牲比较大的存储空间，显然是不划算的。</p>
<p> 我们知道Redis中的所有对象都被定义为redisObject结构体。Redis LRU算法回收的数据，也正是这些对象。</p>
<p>Redis不采用链表来确定哪些redisObject是最久的，而是在redisObject结构体中定义了一个lru成员来用来记录该对象的最近一次被访问的时间。由于时钟的最大值只需要 24 个比特位就能表示，所以结构体定义时采用了位域。定义如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef struct redisObject &#123;</span><br><span class="line">    unsigned type:4;</span><br><span class="line">    unsigned encoding:4;</span><br><span class="line">    unsigned lru:LRU_BITS;</span><br><span class="line">    int refcount;</span><br><span class="line">    void *ptr;</span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure>


<p>而在Redis在全局中也维护了一个24位全局时钟，可以简单理解为当前系统的时间戳。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">struct redisServer &#123;</span><br><span class="line">       pid_t pid;</span><br><span class="line">       char *configfile;</span><br><span class="line">       &#x2F;&#x2F;全局时钟</span><br><span class="line">       unsigned lruclock:LRU_BITS;</span><br><span class="line">       ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>Redis每隔一定时间会通过全局的定时器函数serverCron来更新这个时钟。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int serverCron(...) &#123;</span><br><span class="line">    ...</span><br><span class="line">    server.lruclock &#x3D; getLRUClock();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这个时钟的刷新频率由 server.hz 决定，即每秒钟会调用 server.hz （默认值为 10）次 serverCron 函数。那么，服务器每 1 / server.hz 秒就会调用一次定时器函数 serverCron。</p>
</blockquote>
<p>当一个对象redisObject新建或者被访问时，redis使用全局lru时钟来赋值对象内的lru时钟。</p>
<p>基于上面的基础，redis就可以很轻易的得到一个对象的空闲时间了：<strong>用全局的lru时钟减去对象本身的lru时钟，得到的就是这个对象没有被访问的时间间隔（也称空闲时间，idle time），空闲时间最大的就是需要淘汰的对象</strong>。</p>
<h2 id="2-3-Redis-LRU回收流程"><a href="#2-3-Redis-LRU回收流程" class="headerlink" title="2.3 Redis LRU回收流程"></a>2.3 Redis LRU回收流程</h2><p>Redis并不需要一个完全准确的LRU算法，就算移除了一个最近访问过的Key，影响也不大。为了性能计，Redis采用了一个近似LRU的实现：</p>
<p>Redis的数据库是一个巨大的字典，redisDb结构体中，维护着一个全局的，保存了数据库中的所有键值对的字典——dict字典，我们也称它做键空间。还维护着一个保存了所有带过期配置的键值对的字典——expire字典。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d6e14f11d52889dd33329a8330c815e5b10.png" alt=""></p>
<p>当内存使用超过最大使用数（即超过maxmemory的上限）时，就需要采用回收策略进行内存回收。如果回收策略采用带有LRU算法的策略，那么就会使用到Redis的近似LRU算法实现，流程如下</p>
<ol>
<li><p><strong>触发淘汰</strong>：在每一次处理客户端命令时。当 server.maxmemory的值非 0，则检测是否有需要回收淘汰的内存，如果有则触发redis.c/freeMemoryIfNeeded(void)函数以清理超出的内存，即步骤2的逻辑</p>
</li>
<li><p><strong>更新回收池</strong>：随机按策略从dict或者expire中取出maxmemory_samples个键（实际取到的数量取决于大字典原本的大小）</p>
<ul>
<li>然后用一个长度为16（由宏 MAXMEMORY_EVICTION_POOL_SIZE 指定）的evictionPool（回收池）对这几个键进行筛选</li>
<li>依次将取出的键的idle time和evictionPool中最小的idle time比较。将随机取出的键中，idle time比当前evictionPool中最小的idle time还要大的键，按idle time从小到大的顺序插入到evictionPool内的相应位置中（因为evictionPool是定长，所以如果在evictionPool已满的情况下插入新key，则要释放idle time较小的key）。</li>
</ul>
</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-fe014848ed18d0f5f5cc817267d06dc2268.png" alt=""></p>
<ol start="3">
<li><strong>删除淘汰的键</strong>：最后再从evictionPool池中取出idle time最大且在字典中存在的键作为bestkey执行删除，并且将该key从evictionPool池中移除；</li>
</ol>
<blockquote>
<p>注意这个清理过程是阻塞的，直到清理出足够的内存空间。所以如果在达到maxmemory并且调用方还在不断写入的情况下，可能会反复触发主动清理策略，导致请求会有一定的延迟。</p>
</blockquote>
<p>Redis采用回收池，把一个<strong>全局排序问题</strong>转化成为了<strong>局部的比较问题</strong>。要想知道idle time最大的key，精确的LRU需要对全局的key的idle time排序，这样的成本对于Redis来说太高了。Redis的LRU算法采用一种近似的思想，即随机采样(samping)若干个key，这若干个key就代表着全局的key，把samping得到的key放到pool里面，每次采样之后更新pool，使得pool里面总是保存着随机选择过的key的idle time最大的那些key。</p>
<p>需要evict key时，直接从pool里面取出idle time最大的key，将之evict掉。这种思想是很值得借鉴的。</p>
<p>而且，Redis团队经过试验，发现当samples=10时，Redis随机的LRU算法，已经能够很准确的淘汰掉最久没有使用的键，其效果和精确的LRU基本持平。如下图（浅灰色表示已经删除的键，深灰色表示没有被删除的键，绿色表示新加入的键，越往上表示键加入的时间越久）：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-da6975d89b1e5c0929529b709d71d0d0840.png" alt=""></p>
<h1 id="3-LFU算法"><a href="#3-LFU算法" class="headerlink" title="3 LFU算法"></a>3 LFU算法</h1><p>LFU（Least Frequently used）算法，也叫作<strong>最近最少使用算法</strong>，顾名思义，就是淘汰缓存里面用的最少的数据。它根据数据的访问频次来进行淘汰数据，一个数据被访问过，把它的频次+1，发生淘汰的时候，把频次低的淘汰掉。</p>
<h2 id="3-1-使用双哈希表实现高性能LFU"><a href="#3-1-使用双哈希表实现高性能LFU" class="headerlink" title="3.1 使用双哈希表实现高性能LFU"></a>3.1 使用双哈希表实现高性能LFU</h2><p>有了LRU的打底，我们知道，在排序问题中（LFU和LRU本质都是排序问题）要想实现O(1)时间复杂度的get性能，必须要借助哈希表来实现。但LFU相比LRU有个难点：<strong>频次相比于访问时间，更容易重复，即容易同时出现多于一个的key，他们的频次是一样的，且都是最低的。这时候出现平局，则需要在频次最低的基础上，再在重复的key中间，找到最久未使用的key，并淘汰</strong>。</p>
<p>也就是说，LFU的实现，除了要按照访问频率来排序，还要按照访问时间来排序。排序顺序是：访问频率降序&gt;访问时间降序。</p>
<p>为了达到上述目的，并且达到put和get都为O(1)复杂度，那么我们引入了双哈希表。</p>
<ul>
<li>第一个哈希表的含义是<strong>HashMap&lt;缓存的key，缓存数据节点的地址&gt;</strong><ul>
<li>第一个哈希表，和lru的实现一样，是用来实现O(1)时间查找key对应的节点。</li>
</ul>
</li>
<li>第一个哈希表的含义是<strong>HashMap&lt;访问频率，链表的头结点的地址&gt;</strong><ul>
<li>这个哈希表的每一个value，都是采用拉链法，挂上了一个缓存数据节点组成的双向链表（链表节点按照访问时间从近到远排序，表头访问时间最近，表尾访问时间最远）。</li>
<li>该哈希表的value值指向链表头部，而这个双向链表内存的，都是目前访问频率为其value对应的key值的缓存数据。</li>
<li>比如key=3的value是一个三个节点的链表，则表示这个链表内的三个缓存节点，访问频次都是3次。</li>
</ul>
</li>
</ul>
<p>一图胜万言：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-07e66e8579884f9a6e2e02cc87c79c8889b.png" alt=""></p>
<p>这样的实现下，我们对于get和put操作就可以：</p>
<ul>
<li><strong>get</strong>：如果第一个哈希表中能查到key，那么取得相应链表节点数据。接下来在第二个哈希表中，把该节点<strong>移到</strong>其访问频率+1位置的链表头部。</li>
<li><strong>put</strong>：如果第一个哈希表中能查找key，那么操作和get(key)一样，只是最后要把新节点的value更新为新value。</li>
<li><strong>当发生淘汰时</strong>：也就是要执行put操作，但是容量已经达到限制时，这时直接找到第二个哈希表中最小引用计数的链表，删除其末尾节点（最晚使用）。之后再添加新节点即可。</li>
</ul>
<blockquote>
<p>容量超限需要删除节点时，删除了第二个哈希表中的项的同时，第一个哈希表中对应的映射也应该删掉。</p>
</blockquote>
<blockquote>
<p>需要在双哈希表之外维护一个额外的min_cnt变量用来保存当前的最小访问频率。因为容量超限需要删除节点时，我们需要O(1)时间找到需要删除的节点。及调用get(min_cnt)来定位到要被删除的那个链表。</p>
</blockquote>
<h1 id="4-Redis中的LFU"><a href="#4-Redis中的LFU" class="headerlink" title="4 Redis中的LFU"></a>4 Redis中的LFU</h1><p>Redis4.0开始，maxmemory_policy淘汰策略添加了两个LFU模式：</p>
<ul>
<li>volatile-lfu：对有过期时间的key采用LFU淘汰算法</li>
<li>allkeys-lfu：对全部key采用LFU淘汰算法</li>
</ul>
<p>使用这两种淘汰策略，便会使用到Redis的LFU算法，一种<strong>近似计数算法</strong>。</p>
<h2 id="4-1-常规LFU算法面临的问题"><a href="#4-1-常规LFU算法面临的问题" class="headerlink" title="4.1 常规LFU算法面临的问题"></a>4.1 常规LFU算法面临的问题</h2><p>在数据请求模式比较稳定（没有对于某个数据突发的高频访问这样的不稳定模式）的情况下，LFU的表现还是很不错的。</p>
<p>但在数据的请求模式大多不稳定的情况下，LFU一般会有这样一些问题：</p>
<ol>
<li><strong>热点数据问题</strong>：热点数据一般只是几天内有较高的访问频次，过了这段时间就没那么大意义去缓存了。但是因为在热点期间他的频次被刷上去了，导致之后很长一段时间内很难被淘汰；</li>
<li><strong>新增数据问题</strong>：如果采用只记录缓存中的数据的访问信息，新加入的高频访问数据在刚加入的时候由于没有累积优势，很容易被淘汰掉；</li>
<li><strong>空间问题</strong>：如果记录全部出现过的数据的访问信息，会占用更多的内存空间。</li>
</ol>
<p>对于上面这些问题，其实也都有一些对应的解决方式，相应的出现了很多LFU的变种。如：Window-LFU、LFU*、LFU-Aging。在Redis的LFU算法实现中，也有其解决方案。</p>
<h2 id="4-2-Redis中的频次计算"><a href="#4-2-Redis中的频次计算" class="headerlink" title="4.2 Redis中的频次计算"></a>4.2 Redis中的频次计算</h2><p>在常规操作中，我们一般会引入一个字段作为计数器，对每个key的访问频次做简单的加法，但这样的实现显然无法规避上述的三个问题：一味做加法，过期的热点数据很难淘汰；新增的数据频次太低，容易被淘汰；Redis的访问频次量级非常大，每个key都维护一个长的字段，空间代价太大。</p>
<p>为了解决这三个问题，Redis的频次计算实现，引入了三个策略：</p>
<ol>
<li><strong>概率量级计数</strong>：该策略可以解决空间问题。<ul>
<li>可配参数server.lfu_log_factor就服务于该策略，它能够影响计数的量级范围，整计数器counter的增长速度，lfu-log-factor越大，counter增长的越慢。</li>
</ul>
</li>
<li><strong>计数衰减</strong>：该策略可以解决热点数据问题。<ul>
<li>可配参数server.lfu-decay-time就服务于该策略，它能够控制LFU计数衰减，是一个以分钟为单位的数值，可以调整counter的减少速度。</li>
</ul>
</li>
<li><strong>新增数据赋值</strong>：该策略可以解决新增数据问题。<ul>
<li>固定常量LFU_INIT_VAL就服务于该策略，其值默认为5，即为新生key的counter设置一个初始频次，默认为5。</li>
</ul>
</li>
</ol>
<h3 id="4-2-1-概率量级计数"><a href="#4-2-1-概率量级计数" class="headerlink" title="4.2.1 概率量级计数"></a>4.2.1 概率量级计数</h3><p>Redis的LFU实现也是需要为每个key维护一个字段来承载该key的访问频次的，而且<strong>这个字段不能太大</strong>，不然Redis这么多key，那么消耗的空间将是一个可怕的数字，同时，本着Redis一贯对空间锱铢必较的心态，能重复利用的字段，我们绝不维护新的字段。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">typedef struct redisObject &#123;</span><br><span class="line">    unsigned type:4;</span><br><span class="line">    unsigned encoding:4;</span><br><span class="line">    unsigned lru:LRU_BITS; &#x2F;* LRU time (relative to global lru_clock) or</span><br><span class="line">                            * LFU data (least significant 8 bits frequency</span><br><span class="line">                            * and most significant 16 bits access time). *&#x2F;</span><br><span class="line">    int refcount;</span><br><span class="line">    void *ptr;</span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure>

<p>看来看去，redisObject结构中，也只有lru字段可以重复利用了，因为淘汰策略是互斥的，Redis同时只能选择一种淘汰策略，要么LRU，要么LFU，要么其他，所以lru字段重复利用不会冲突。</p>
<p>在LRU算法中，24 bits的lru是用来记录LRU time的，<strong>在LFU中使用这个字段，却是分成16 bits与8 bits使用</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">*          16 bits      8 bits</span><br><span class="line">*     +----------------+--------+</span><br><span class="line">*     + Last decr time | LOG_C  |</span><br><span class="line">*     +----------------+--------+</span><br></pre></td></tr></table></figure>

<p>高16 bits用来记录最近一次计数器衰减的时间ldt，单位是分钟，这个我们下文再说。</p>
<p><strong>低8 bits记录计数器数值counter</strong>。8个bit位最大为255，显然如果只是简单的对counter做加法，那8 bit的counter根本无法容纳Redis那动辄百万或千万级别的命中频次。</p>
<p>那么，Redis如何使用8 bit的counter来承载百万或者千万级别的命中频次呢？相关源码在<code>evict.c</code>文件中的<code>LFULogIncr</code>方法中实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* Logarithmically increment a counter. The greater is the current counter value</span><br><span class="line"> * the less likely is that it gets really implemented. Saturate it at 255. *&#x2F;</span><br><span class="line">uint8_t LFULogIncr(uint8_t counter) &#123;</span><br><span class="line">    if (counter &#x3D;&#x3D; 255) return 255;</span><br><span class="line">    &#x2F;&#x2F;这里的rand()方法会生成一个 0 ~ RAND_MAX 之间的随机数，所以r的范围也就是0~1之间。</span><br><span class="line">    double r &#x3D; (double)rand()&#x2F;RAND_MAX;</span><br><span class="line">    double baseval &#x3D; counter - LFU_INIT_VAL;</span><br><span class="line">    if (baseval &lt; 0) baseval &#x3D; 0;</span><br><span class="line">    &#x2F;&#x2F;根据目前counter和server.lfu_log_factor值得出一个p</span><br><span class="line">    double p &#x3D; 1.0&#x2F;(baseval*server.lfu_log_factor+1);</span><br><span class="line">    &#x2F;&#x2F;如果r &lt; p，counter才+1</span><br><span class="line">    if (r &lt; p) counter++;</span><br><span class="line">    return counter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们先看p字段：</p>
<p>对于<code>p=1.0/(baseval*server.lfu_log_factor+1);</code></p>
<p>等价于<code>p=1/((counter−LFU_INIT_VAL)*factor+1);</code></p>
<p>因为LFU_INIT_VAL是常数，所以当counter够大时，近似等于：<code>p=1/(counter*factor+1)</code></p>
<p>factor是个常数，server.lfu_log_factor默认值是10，下图展示了factor不同时，p=f(counter)的函数曲线</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-bc7b790c06e282c599c94a25afdb0d0736c.png" alt=""></p>
<p>紧接着再来看r，r是由random函数随机出来的范围在0~1之间的值，我们可以认为r的值是随机的，那么我们可以认为：</p>
<p>r的值在0 ~ 1范围内，也就是r&lt;=1的概率为100%（1）；</p>
<p>r的值在0 ~ 0.9范围内，也就是r&lt;=0.9的概率为90%（0.9）；</p>
<p>以此类推。</p>
<p>r的值在0 ~ p的范围内，也就是r&lt;=p的概率为p；</p>
<p><strong>所以综上所诉</strong>，Redis的概率量级计数的核心逻辑就是：</p>
<ol>
<li><p><strong>每一次key被访问，counter都有近似<code>p=1/(counter*factor+1)</code>的概率会+1。在factor是常数的情况下，counter+1的概率随着counter值的增大而减小</strong>。</p>
</li>
<li><p><strong>factor值我们设置的越大，则counter+1的概率在同等情况下则会越低，counter字段8 bit一共255的上限也就越不容易被触达，换句话说，factor越大，Redis的counter字段能够记录的访问频次量级也就越高</strong>。</p>
</li>
</ol>
<blockquote>
<p>概率量级计数，就体现在p和factor上，p控制的是counter的概率上升，factor控制的是counter承载的访问量级。</p>
</blockquote>
<p>下表是不同的factor的值能够控制计数代表的量级的范围，当factor为100时，能够最大代表10M，也就是千万级别的命中数。</p>
<table>
<thead>
<tr>
<th align="center">factor</th>
<th align="center">100 hits</th>
<th align="center">1000 hits</th>
<th align="center">100K hits</th>
<th align="center">1M hits</th>
<th align="center">10M hits</th>
</tr>
</thead>
<tbody><tr>
<td align="center">0</td>
<td align="center">104</td>
<td align="center">255</td>
<td align="center">255</td>
<td align="center">255</td>
<td align="center">255</td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">18</td>
<td align="center">49</td>
<td align="center">255</td>
<td align="center">255</td>
<td align="center">255</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">10</td>
<td align="center">18</td>
<td align="center">142</td>
<td align="center">255</td>
<td align="center">255</td>
</tr>
<tr>
<td align="center">100</td>
<td align="center">8</td>
<td align="center">11</td>
<td align="center">49</td>
<td align="center">143</td>
<td align="center">255</td>
</tr>
</tbody></table>
<p>下图是不同factor场景下，不同key的counter字段的值（颜色不同的线）在固定访问频率下随着时间的上升走势。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ddad582bc4e83b730a0c8fff3336ddd3158.png" alt=""></p>
<h3 id="4-2-2-计数衰减"><a href="#4-2-2-计数衰减" class="headerlink" title="4.2.2 计数衰减"></a>4.2.2 计数衰减</h3><p>上一章节我们讲了counter是概率增加，但为了解决热点问题，使热点数据能够随着时间推移慢慢的降低频次，以至于最后淘汰，那么Redis引入了计数衰减的策略。</p>
<p><strong>某个key的counter被衰减的时机是在它被访问的时候</strong>。在缓存被访问时，会更新数据的访问计数，更新的步骤是：</p>
<ol>
<li>先在现有数据的计数上进行计数衰减。</li>
<li>再对完成衰减后的计数进行概率增加。</li>
</ol>
<blockquote>
<p>所以要注意，计数衰减的触发也是被动的，而非Redis主动或者定时触发的。</p>
</blockquote>
<p>计数衰减的实现在LFUDecrAndReturn方法中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* Return the current time in minutes, just taking the least significant</span><br><span class="line"> * 16 bits. The returned time is suitable to be stored as LDT (last decrement</span><br><span class="line"> * time) for the LFU implementation. *&#x2F;</span><br><span class="line">unsigned long LFUGetTimeInMinutes(void) &#123;</span><br><span class="line">    return (server.unixtime&#x2F;60) &amp; 65535;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;* Given an object last access time, compute the minimum number of minutes</span><br><span class="line"> * that elapsed since the last access. Handle overflow (ldt greater than</span><br><span class="line"> * the current 16 bits minutes time) considering the time as wrapping</span><br><span class="line"> * exactly once. *&#x2F;</span><br><span class="line">unsigned long LFUTimeElapsed(unsigned long ldt) &#123;</span><br><span class="line">    &#x2F;&#x2F;计算当前时间和ldt的时间差值，如果now &lt; ldt，默认为过了一个周期了，那么差值应该是65535-ldt+now。</span><br><span class="line">    unsigned long now &#x3D; LFUGetTimeInMinutes();</span><br><span class="line">    if (now &gt;&#x3D; ldt) return now-ldt;</span><br><span class="line">    return 65535-ldt+now;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;* If the object decrement time is reached decrement the LFU counter but</span><br><span class="line"> * do not update LFU fields of the object, we update the access time</span><br><span class="line"> * and counter in an explicit way when the object is really accessed.</span><br><span class="line"> * And we will times halve the counter according to the times of</span><br><span class="line"> * elapsed time than server.lfu_decay_time.</span><br><span class="line"> * Return the object frequency counter.</span><br><span class="line"> *</span><br><span class="line"> * This function is used in order to scan the dataset for the best object</span><br><span class="line"> * to fit: as we check for the candidate, we incrementally decrement the</span><br><span class="line"> * counter of the scanned objects if needed. *&#x2F;</span><br><span class="line">unsigned long LFUDecrAndReturn(robj *o) &#123;</span><br><span class="line">    unsigned long ldt &#x3D; o-&gt;lru &gt;&gt; 8;</span><br><span class="line">    unsigned long counter &#x3D; o-&gt;lru &amp; 255;</span><br><span class="line">    &#x2F;&#x2F;算出该key已经经历过num_periods个周期了</span><br><span class="line">    unsigned long num_periods &#x3D; server.lfu_decay_time ? LFUTimeElapsed(ldt) &#x2F; server.lfu_decay_time : 0;</span><br><span class="line">    if (num_periods)</span><br><span class="line">        counter &#x3D; (num_periods &gt; counter) ? 0 : counter - num_periods;</span><br><span class="line">    return counter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>代码很晦涩，没关系，逻辑其实并不复杂：</p>
<ol>
<li><p>可配参数server.lfu-decay-time所代表的含义是计数衰减的周期长度，单位是分钟。当时间过去一个周期（也就是lfu-decay-time分钟），计数值就会减1。</p>
</li>
<li><p>redisObject结构中的lru字段的高16bit，记录的是该key上次进行衰减的时间。</p>
</li>
<li><p>有上述两个数据可以算出从上次衰减到现在，该key已经经历过n个周期了，这也表示着，key需要先将counter衰减n。</p>
<ul>
<li>n的计算过程如代码所示，即从上次衰减到现在经过的时间除以衰减周期长度 server.lfu_decay_time：</li>
<li><code>unsigned long num_periods = server.lfu_decay_time ? LFUTimeElapsed(ldt) / server.lfu_decay_time : 0;</code></li>
</ul>
</li>
<li><p>通过<code>LFUDecrAndReturn</code>方法得到该key的counter需要衰减的值n，将counter=counter-n，然后再执行概率增加计数的操作。</p>
</li>
</ol>
<h3 id="4-2-3-新增数据赋值"><a href="#4-2-3-新增数据赋值" class="headerlink" title="4.2.3 新增数据赋值"></a>4.2.3 新增数据赋值</h3><p>为了解决新增数据问题，即如果采用只记录缓存中的数据的访问信息，新加入的高频访问数据在刚加入的时候由于没有累积优势，很容易被淘汰掉；</p>
<p>那么对于新增加的key，则不能将他们的counter设为0，Redis为新增的key的counter设置了一个初始值，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">robj *createObject(int type, void *ptr) &#123;</span><br><span class="line">    robj *o &#x3D; zmalloc(sizeof(*o));</span><br><span class="line">    o-&gt;type &#x3D; type;</span><br><span class="line">    o-&gt;encoding &#x3D; OBJ_ENCODING_RAW;</span><br><span class="line">    o-&gt;ptr &#x3D; ptr;</span><br><span class="line">    o-&gt;refcount &#x3D; 1;</span><br><span class="line"></span><br><span class="line">    &#x2F;* Set the LRU to the current lruclock (minutes resolution), or</span><br><span class="line">     * alternatively the LFU counter. *&#x2F;</span><br><span class="line">    if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) &#123;</span><br><span class="line">        o-&gt;lru &#x3D; (LFUGetTimeInMinutes()&lt;&lt;8) | LFU_INIT_VAL;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        o-&gt;lru &#x3D; LRU_CLOCK();</span><br><span class="line">    &#125;</span><br><span class="line">    return o;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>即counter会被初始化为LFU_INIT_VAL，默认5。</p>
<blockquote>
<p>回顾我们上文说道的p=1/((counter−LFU_INIT_VAL)*factor+1)，可以看到，当计数值等于LFU_INIT_VAL时， p=1，也就是说，对于新增的key，下一次访问时，counter增加的概率为100%</p>
</blockquote>
<h2 id="4-3-Redis-LFU回收流程"><a href="#4-3-Redis-LFU回收流程" class="headerlink" title="4.3 Redis LFU回收流程"></a>4.3 Redis LFU回收流程</h2><p>Redis LFU回收流程和Redis LRU的回收流程<strong>一模一样</strong>（有所遗忘可以回顾本文2.3章），<strong>都是采用抽样+回收池的实现方式，不同的是LRU比较的是idle time空闲时间，而LFU比较的是counter访问频次</strong>。故不再赘述。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-hand-o-left" aria-label="accessibility.prev_page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-hand-o-right" aria-label="accessibility.next_page"></i></a>
  </nav>

          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png"
                alt="cherish-ls" />
            
              <p class="site-author-name" itemprop="name">cherish-ls</p>
              <p class="site-description motion-element" itemprop="description">纸上得来终觉浅</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">59</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">26</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">98</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="git@github.com:cherish-ls/cherish-ls.github.io.git" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">cherish-ls</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">408.4k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"cherish"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  
















  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: 'TQhjcmooFXWGQ3qgqUroDKsD-gzGzoHsz',
        appKey: 'zjA9PvG5eljY1JErig8WVQQD',
        placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  

  
  

  

  

  

</body>
</html>
