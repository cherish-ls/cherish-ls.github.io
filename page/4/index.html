<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="纸上得来终觉浅，绝知此事要躬行" />










<meta name="description" content="纸上得来终觉浅">
<meta property="og:type" content="website">
<meta property="og:title" content="cherish">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="cherish">
<meta property="og:description" content="纸上得来终觉浅">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="cherish-ls">
<meta property="article:tag" content="纸上得来终觉浅，绝知此事要躬行">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/"/>





  <title>cherish</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">cherish</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">返朴归真</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/06/MySQL%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/06/MySQL%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%B1%87%E6%80%BB/" itemprop="url">MySQL核心要点汇总</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-06T21:18:34+08:00">
                2020-05-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index">
                    <span itemprop="name">关系型数据库</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/05/06/MySQL%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%B1%87%E6%80%BB/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/05/06/MySQL核心要点汇总/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  11.9k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  43
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-相关概念"><a href="#1-相关概念" class="headerlink" title="1. 相关概念"></a>1. 相关概念</h1><h2 id="1-1-内-外-全联接"><a href="#1-1-内-外-全联接" class="headerlink" title="1.1 内/外/全联接"></a>1.1 内/外/全联接</h2><p>假设有两张表，一张本校的校友信息表 t1，一张两院院士信息表 t2，使用二者的身份证号码（ID字段）来关联（即<code>t1.ID=t2.ID</code>）。</p>
<ul>
<li>内联接：在两张表进行连接查询时，只保留两张表中完全匹配的结果集。<ul>
<li><code>select .... from t1 inner join t2 on t1.ID=t2.ID</code></li>
<li>结果是只保留既是本校校友，又是两院院士的人的信息。</li>
</ul>
</li>
<li>外联接：分为左联接和右联接两种<ol>
<li>左联接：在两张表进行连接查询时，会返回左表所有的行，即使左表在右表中没有匹配的记录。<ul>
<li><code>select .... from t1 left (outer) join t2 on t1.ID=t2.ID</code></li>
<li>结果是返回全部本校校友的记录，部分校友可能同时是院士，其他大部分校友，t2表的相关字段值都为null。</li>
</ul>
</li>
<li>右联接：在两张表进行连接查询时，会返回右表所有的行，即使右表在左表中没有匹配的记录。<ul>
<li><code>select .... from t1 right (outer) join t2 on t1.ID=t2.ID</code></li>
<li>结果是返回全部两院院士的记录，部分院士可能是我校校友，其他大部分院士，t1表的相关字段值都为null。</li>
</ul>
</li>
</ol>
</li>
<li>全联接：在两张表进行连接查询时，返回左表和右表中所有的行（即便没有匹配）。<ul>
<li><code>select .... from t1 full join t2 on t1.ID=t2.ID</code></li>
<li>结果是返回本校校友+两院院士所有人的记录（当然会去重）。</li>
<li>其实也就是left join和right join的并集。</li>
</ul>
</li>
</ul>
<blockquote>
<p>单纯的<code>select * from a,b</code>是笛卡尔乘积。比如a表有5条数据，b表有3条数据，那么最后的结果有5*3=15条数据。但是如果对两个表进行关联:<code>select * from a,b where a.id = b.id</code>意思就变了，此时就等价于：<code>select * from a inner join b on a.id = b.id</code>。即就是内连接。但是这种写法并不符合规范，可能只对某些数据库管用，如sqlserver。推荐最好不要这样写。最好写成inner join的写法。</p>
</blockquote>
<h2 id="1-2-drop、delete与truncate的区别"><a href="#1-2-drop、delete与truncate的区别" class="headerlink" title="1.2 drop、delete与truncate的区别"></a>1.2 drop、delete与truncate的区别</h2><p>SQL中的drop、delete、truncate都表示删除，但是三者有一些差别</p>
<ol>
<li>delete和truncate只删除表的数据不删除表的结构，drop都删除。</li>
<li>一般来说，执行速度方面是 drop&gt; truncate &gt;delete</li>
<li>delete语句是dml，这个操作会放到rollback segement中，事务提交之后才生效; 如果有相应的trigger，执行的时候将被触发。</li>
<li>truncate、drop是ddl，操作立即生效，原数据不放到rollback segment中，不能回滚.。操作不触发trigger.</li>
</ol>
<h2 id="1-3-数据并发问题"><a href="#1-3-数据并发问题" class="headerlink" title="1.3 数据并发问题"></a>1.3 数据并发问题</h2><p>在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。</p>
<ol>
<li><p><strong>脏读（Dirty read）</strong>:</p>
<ul>
<li>针对同一个字段，一个事务（假设事务A）读到了另一个的事务（假设事务B）提交前的数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。</li>
</ul>
</li>
<li><p><strong>丢失修改（Lost to modify）</strong>:</p>
<ul>
<li>指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 </li>
<li>例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。</li>
</ul>
</li>
<li><p><strong>不可重复读（Unrepeatableread）</strong>:</p>
<ul>
<li>一般发生在一个事务要在事务内读取一个字段多次的场景。</li>
<li>事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据和第一次读取的时候不一样了，就是所谓的不可重复读了。</li>
</ul>
</li>
<li><p><strong>幻读（Phantom read）</strong>:</p>
<ul>
<li>幻读与不可重复读类似。也发生在一个事务在事务内部针对某些记录多次查询的情况。</li>
<li>例如在一个事务（A）读取了几行数据，接着另一个并发事务（B）插入并提交了一些数据，并且这些数据符合事务A的where条件时。在第二次的查询中，事务（A）就会发现相比第一次查询，第二次多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。</li>
</ul>
</li>
</ol>
<p>不可重复读和幻读两者有些相似，他们的区别是：<br>|  不可重复读 | 幻读  |<br>| ———— | ———— |<br>| 针对的是update或delete  | 针对的是insert  |<br>| 重点是修改:同样的条件, 你读取过的数据, 再次读取出来发现值不一样了  | 重点在于新增或者删除 (数据条数变化)：同样的条件, 第1次和第2次读出来的记录数不一样  |</p>
<h2 id="1-4-事务隔离级别"><a href="#1-4-事务隔离级别" class="headerlink" title="1.4 事务隔离级别"></a>1.4 事务隔离级别</h2><p>SQL 标准定义了四个隔离级别：</p>
<ol>
<li>READ-UNCOMMITTED(读未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。</li>
<li>READ-COMMITTED(读已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。</li>
<li>REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。</li>
<li>SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-6c4f27430f3b074f1f7eef3e2f7b7ef121e.png" alt=""></p>
<blockquote>
<p>MySQL InnoDB 存储引擎的默认的隔离级别是 REPEATABLE-READ（可重复读）。我们可以通过<code>SELECT @@tx_isolation;</code>命令来查看</p>
</blockquote>
<p>我们知道隔离级别越低，事务请求的锁越少，并发效率越高，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是你要知道的是InnoDB 存储引擎默认使用 REPEATABLE-READ（可重读） 并不会有任何性能损失。</p>
<p>与 SQL 标准不同的地方在于 InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下使用的是<strong>Next-Key Lock 锁算法</strong>，<strong>因此可以避免幻读的产生</strong>，这与其他数据库系统(如 SQL Server) 是不同的。</p>
<p>所以说InnoDB 存储引擎的默认的隔离级别是 REPEATABLE-READ（可重读） <strong>已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE(可串行化) 隔离级别</strong>。</p>
<h1 id="2-数据库设计的三范式"><a href="#2-数据库设计的三范式" class="headerlink" title="2 数据库设计的三范式"></a>2 数据库设计的三范式</h1><h2 id="2-1-第一范式（1NF）"><a href="#2-1-第一范式（1NF）" class="headerlink" title="2.1 第一范式（1NF）"></a>2.1 第一范式（1NF）</h2><p>1NF是对属性的原子性，要求每一列（或者叫字段，属性）具有原子性，不可再分解；</p>
<p>如</p>
<p><code>学生表（学号，姓名，性别，生日）</code></p>
<p>如果认为最后一列还可以再分成（出生年，出生月，出生日），它就不满足第一范式了；</p>
<h2 id="2-2-第二范式（2NF）"><a href="#2-2-第二范式（2NF）" class="headerlink" title="2.2 第二范式（2NF）"></a>2.2 第二范式（2NF）</h2><blockquote>
<p>第二范式是指在满足第一范式的条件下，除主键外的每一列都完全依赖于主键（主要针对于<strong>联合主键</strong>而言）。</p>
</blockquote>
<p>2NF是对记录的惟一性，要求记录有惟一标识，即实体的惟一性，即不存在部分依赖；</p>
<p>举个反例：</p>
<p><code>表（学号、课程号、姓名、学分） 联合主键为学号和课程号</code></p>
<p>这个表明显涵盖了两个信息主体：</p>
<ol>
<li>学生信息：学号和姓名字段属于学生信息，且姓名依赖于学号（学生信息的唯一标识）</li>
<li>课程信息：课程号和学分字段属于课程信息，学分依赖课程号（课程信息的唯一标识）。</li>
</ol>
<p>姓名由学号即可唯一标识，是对主键的部分依赖；<br>学分由课程号即可唯一标示，是对主键的部分依赖；</p>
<p>由于2NF要求<strong>非主键字段必须完全依赖主键</strong>，所以不符合二范式。<br>可能会存在问题：</p>
<ul>
<li>数据冗余:，每条记录都含有相同信息；</li>
<li>删除异常：删除所有学生成绩，就把课程信息全删除了；</li>
<li>插入异常：学生未选课，无法记录进数据库；</li>
<li>更新异常：调整课程学分，所有行都调整。</li>
</ul>
<p>正确做法:</p>
<ul>
<li>学生表：Student(学号, 姓名)；</li>
<li>课程表：Course(课程号, 学分)；</li>
<li>选课关系表：StudentCourse(学号, 课程号, 成绩)。</li>
</ul>
<h2 id="2-3-第三范式（3NF）"><a href="#2-3-第三范式（3NF）" class="headerlink" title="2.3 第三范式（3NF）"></a>2.3 第三范式（3NF）</h2><blockquote>
<p>  第三范式是指在满足第二范式的基础上，每一条数据不能依赖于其他的非主属性，也就是消除了传递依赖关系。</p>
</blockquote>
<p>3NF是对字段的冗余性，要求任何字段不能由其他字段派生出来，它要求字段没有冗余，即不存在传递依赖；</p>
<p>例如</p>
<p><code>表（学号, 姓名, 年龄, 学院名称, 学院电话）</code></p>
<p>因为存在依赖传递: (学号) → (学生)→(所在学院) → (学院电话) 。</p>
<p>可能会存在问题：</p>
<ul>
<li>数据冗余:有重复值；</li>
<li>更新异常：有重复的冗余信息，修改时需要同时修改多条记录，否则会出现数据不一致的情况</li>
</ul>
<p>正确做法：</p>
<ul>
<li>学生：(学号, 姓名, 年龄, 所在学院)；</li>
<li>学院：(学院, 电话)。</li>
</ul>
<h2 id="2-4-反范式化"><a href="#2-4-反范式化" class="headerlink" title="2.4 反范式化"></a>2.4 反范式化</h2><p>一般说来，数据库只需满足第三范式（3NF）就行了。没有冗余的数据库未必是最好的数据库，有时为了提高运行效率，就必须降低范式标准，适当保留冗余数据。达到以空间换时间的目的。</p>
<p>比如：有一张存放商品的基本表，“金额”这个字段的存在，表明该表的设计不满足第三范式，因为“金额”可以由“单价”乘以“数量”得到，说明“金额”是冗余字段。但是，增加“金额”这个冗余字段，可以提高查询统计的速度，这就是以空间换时间的作法。</p>
<h1 id="3-MySql存储引擎简述"><a href="#3-MySql存储引擎简述" class="headerlink" title="3. MySql存储引擎简述"></a>3. MySql存储引擎简述</h1><p>简单来说，存储引擎就是指表的类型以及表在计算机上的存储方式。</p>
<p>存储引擎的概念是MySQL的特点，Oracle中没有专门的存储引擎的概念，Oracle有OLTP和OLAP模式的区分。不同的存储引擎决定了MySQL数据库中的表可以用不同的方式来存储。我们可以根据数据的特点来选择不同的存储引擎。</p>
<p>在MySQL中的存储引擎有很多种，可以通过<code>mysql&gt; show engines;</code>语句来查看。下面重点关注InnoDB、MyISAM、MEMORY这三种。</p>
<h2 id="3-1-InnoDB引擎"><a href="#3-1-InnoDB引擎" class="headerlink" title="3.1 InnoDB引擎"></a>3.1 InnoDB引擎</h2><p>MySQL默认的<strong>事务型</strong>引擎，也是最重要和使用最广泛的存储引擎。在MySQL从3.23.34a版本开始包含InnnoDB。</p>
<p>InnoDB给MySQL的表提供了<strong>事务处理、回滚、崩溃修复能力和多版本并发控制</strong>的事务安全。它是MySQL上<strong>第一个提供外键约束的存储引擎</strong>。而且InnoDB对事务处理的能力，也是其他存储引擎不能比拟的。</p>
<p>InnoDB的性能与<strong>自动崩溃恢复</strong>的特性，使得它在非事务存储需求中也很流行。除非有非常特别的原因需要使用其他的存储引擎，否则应该<strong>优先考虑InnoDB引擎</strong>。</p>
<h2 id="3-2-MyISAM引擎"><a href="#3-2-MyISAM引擎" class="headerlink" title="3.2 MyISAM引擎"></a>3.2 MyISAM引擎</h2><p>在MySQL 5.1 及之前的版本，MyISAM是默认引擎。MyISAM提供的大量的特性，包括<strong>全文索引</strong>、<strong>压缩</strong>、空间函数（GIS）等，但MyISAM并<strong>不支持事务以及行级锁</strong>，而且一个毫无疑问的缺陷是<strong>崩溃后无法安全恢复</strong>。正是由于MyISAM引擎的缘故，即使MySQL支持事务已经很长时间了，在很多人的概念中MySQL还是非事务型数据库。尽管这样，它并不是一无是处的。对于只读的数据，或者表比较小，可以忍受修复操作，则依然可以使用MyISAM（但请不要默认使用MyISAM，而是应该默认使用InnoDB）</p>
<h2 id="3-3-MEMORY引擎"><a href="#3-3-MEMORY引擎" class="headerlink" title="3.3 MEMORY引擎"></a>3.3 MEMORY引擎</h2><p>MEMORY是MySQL中一类特殊的存储引擎。它使用存储在内存中的内容来创建表，而且<strong>数据全部放在内存中</strong>。这些特性与前面的两个很不同。</p>
<p>每个基于MEMORY存储引擎的表实际对应一个磁盘文件。该文件的文件名与表名相同，类型为frm类型。该文件中只存储表的结构。而其数据文件，都是存储在内存中，这样有利于数据的快速处理，提高整个表的效率。值得注意的是，服务器需要有足够的内存来维持MEMORY存储引擎的表的使用。如果不需要了，可以释放内存，甚至删除不需要的表。</p>
<p>MEMORY默认使用哈希索引。速度比使用B型树索引快。当然如果你想用B型树索引，可以在创建索引时指定。</p>
<p>注意，MEMORY用到的很少，因为它是把数据存到内存中，如果内存出现异常就会影响数据。如果重启或者关机，所有数据都会消失。因此，基于MEMORY的表的生命周期很短，一般是一次性的。</p>
<h2 id="3-4-如何合适的选择存储引擎"><a href="#3-4-如何合适的选择存储引擎" class="headerlink" title="3.4 如何合适的选择存储引擎"></a>3.4 如何合适的选择存储引擎</h2><p><img src="https://oscimg.oschina.net/oscnet/up-3127dd066a45c9fa1de2c57f273d5d0df6b.png" alt=""></p>
<ul>
<li><p>有以下要求，则适合采用InnoDB：</p>
<ul>
<li>需要对事务的完整性要求比较高（比如银行）</li>
<li>要求实现并发控制（比如售票）</li>
<li>如果需要频繁的更新、删除操作的数据库，也可以选择InnoDB，因为支持事务的提交（commit）和回滚（rollback）。 </li>
</ul>
</li>
<li><p>有以下要求，则适合采用MyISAM：</p>
<ul>
<li>如果表主要是用于插入新记录和读出记录，那么选择MyISAM能实现处理高效率。</li>
<li>如果应用对数据的完整性、并发性要求比较低，也可以使用。</li>
</ul>
</li>
<li><p>有以下要求，则适合采用MEMORY：</p>
<ul>
<li>如果需要很快的读写速度，对数据的安全性要求较低，且数据量很小时，可以选择MEMOEY。</li>
</ul>
</li>
</ul>
<h2 id="3-5-MyISAM与InnoDB区别"><a href="#3-5-MyISAM与InnoDB区别" class="headerlink" title="3.5 MyISAM与InnoDB区别"></a>3.5 MyISAM与InnoDB区别</h2><table>
<thead>
<tr>
<th>项目</th>
<th>InnoDB</th>
<th>MyISAM</th>
</tr>
</thead>
<tbody><tr>
<td>存储结构</td>
<td>所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。</td>
<td>每个MyISAM在磁盘上存储成三个文件。分别为：表定义文件、数据文件、索引文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。</td>
</tr>
<tr>
<td>存储空间</td>
<td>需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。</td>
<td>MyISAM支持支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。当表在创建之后并导入数据之后，不会再进行修改操作，可以使用压缩表，极大的减少磁盘的空间占用。</td>
</tr>
<tr>
<td>可移植性、备份及恢复</td>
<td>免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。</td>
<td>数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。</td>
</tr>
<tr>
<td>事务支持</td>
<td>提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。</td>
<td>强调的是性能，每次查询具有原子性,其执行速度比InnoDB类型更快，但是不提供事务支持。</td>
</tr>
<tr>
<td>AUTO_INCREMENT</td>
<td>InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。</td>
<td>可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。</td>
</tr>
<tr>
<td>锁</td>
<td>支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE中指定主键是有效的，非主键的WHERE都会锁全表的。</td>
<td>只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。</td>
</tr>
<tr>
<td>全文索引</td>
<td>原来不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。后来从InnoDB1.2.x版本（MySQL 5.6版本）起，InnoDB存储引擎开始支持全文索引</td>
<td>支持 FULLTEXT类型的全文索引</td>
</tr>
<tr>
<td>表主键</td>
<td>如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值。</td>
<td>允许没有任何索引和主键的表存在，索引都是保存行的地址。</td>
</tr>
<tr>
<td>表的具体行数</td>
<td>没有保存表的总行数，如果使用<code>select count(*) from table；</code>就会遍历整个表，消耗相当大，但是在加了where条件后，myisam和innodb处理的方式都一样。</td>
<td>保存有表的总行数，如果<code>select count(*) from table;</code>会直接取出出该值。</td>
</tr>
<tr>
<td>CRUD操作</td>
<td>如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。</td>
<td>如果执行大量的SELECT，MyISAM是更好的选择。</td>
</tr>
<tr>
<td>外键</td>
<td>支持</td>
<td>不支持</td>
</tr>
</tbody></table>
<h1 id="4-MySql索引"><a href="#4-MySql索引" class="headerlink" title="4. MySql索引"></a>4. MySql索引</h1><p>我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。</p>
<p>在数据之外，数据库系统维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-289e357d2d12e60c93f6e63fcbcc69877e1.png" alt=""></p>
<p>上图展示了一种可能的索引方式。左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。</p>
<p>为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在O(log2n)的复杂度内获取到相应数据。</p>
<blockquote>
<p>虽然这是一个货真价实的索引，但是实际的数据库系统几乎没有使用二叉查找树或其进化品种红黑树（red-black tree）实现的，原因会在下文介绍。</p>
</blockquote>
<h2 id="4-1-索引的优缺点"><a href="#4-1-索引的优缺点" class="headerlink" title="4.1 索引的优缺点"></a>4.1 索引的优缺点</h2><p>优点：</p>
<ul>
<li>可以快速检索，减少I/O次数，加快检索速度；</li>
<li>根据索引分组和排序，可以加快分组和排序；</li>
</ul>
<p>缺点：</p>
<ul>
<li>索引本身也是表，因此会占用存储空间，一般来说，索引表占用的空间的数据表的1.5倍；</li>
<li>索引表的维护和创建需要时间成本，这个成本随着数据量增大而增大；</li>
<li>构建索引会降低数据表的修改操作（删除，添加，修改）的效率，因为在修改数据表的同时还需要修改索引表；</li>
</ul>
<h2 id="4-2-索引的分类"><a href="#4-2-索引的分类" class="headerlink" title="4.2 索引的分类"></a>4.2 索引的分类</h2><h3 id="4-2-1-按类型分类"><a href="#4-2-1-按类型分类" class="headerlink" title="4.2.1 按类型分类"></a>4.2.1 按类型分类</h3><ol>
<li>聚集索引<ul>
<li>主键索引；<ul>
<li>数据列不允许重复，不允许为NULL，一个表只能有一个主键。</li>
</ul>
</li>
</ul>
</li>
<li>二级索引（又称辅助索引、非聚簇索引）<ul>
<li>唯一索引；<ul>
<li>约束数据列不允许重复，允许为NULL值</li>
<li>一个表允许组合多个列创建唯一索引，这时约束的是：不同记录，被唯一索引约束的这多个列不能让完全相同</li>
</ul>
</li>
<li>普通索引（又叫辅助索引）；<ul>
<li>可以通过ALTER TABLE table_name ADD INDEX index_name (column);创建普通索引</li>
<li>会对该列创建索引。</li>
</ul>
</li>
<li>组合索引(又称联合索引，复合索引)；<ul>
<li>即普通索引的多字段版本</li>
<li>可以通过ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);创建组合索引</li>
<li>如下图，可以理解成把几个字段拼接起来的一个普通索引</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-c7dcce083913fdfd6536e40ec10b13ade5f.png" alt=""></li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="4-2-2-按按数据结构分类"><a href="#4-2-2-按按数据结构分类" class="headerlink" title="4.2.2 按按数据结构分类"></a>4.2.2 按按数据结构分类</h3><ul>
<li>BTree索引<ul>
<li>下文详解</li>
</ul>
</li>
<li>B+Tree索引；<ul>
<li>下文详解</li>
</ul>
</li>
<li>哈希索引；<ul>
<li>只有memory存储引擎支持哈希索引，哈希索引用索引列的值计算该值的hashCode，然后在hashCode相应的位置存储该值所在行数据的物理位置。</li>
<li>因为使用散列算法，因此访问速度非常快，但是一个值只能对应一个hashCode，而且是散列的分布方式，因此哈希索引不支持范围查找和排序的功能。</li>
</ul>
</li>
<li>全文索引；<ul>
<li>通过建立倒排索引来实现，查询效率比like有很大提升。</li>
<li>5.6版本前的MySQL自带的全文索引只能用于MyISAM存储引擎，如果是其它数据引擎，那么全文索引不会生效。5.6版本之后InnoDB存储引擎开始支持全文索引</li>
<li>在MySQL中，全文索引支队英文有用，目前对中文还不支持。5.7版本之后通过使用ngram插件开始支持中文。</li>
</ul>
</li>
</ul>
<h3 id="4-2-3-聚簇索引和非聚簇索引的区别（针对InnoDB）"><a href="#4-2-3-聚簇索引和非聚簇索引的区别（针对InnoDB）" class="headerlink" title="4.2.3 聚簇索引和非聚簇索引的区别（针对InnoDB）"></a>4.2.3 聚簇索引和非聚簇索引的区别（针对InnoDB）</h3><p>假设我们有如下表</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b04827a8539b202102f96172b5913a65965.png" alt=""></p>
<p>mysql对ID生成了聚簇索引，我们再对k字段生成普通索引（非聚簇），如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3fcb682ce6c4f03d0698881525f3c32f251.png" alt=""></p>
<blockquote>
<p><strong>其中R代表一整行的记录</strong>。</p>
</blockquote>
<p>从图中不难看出，聚簇索引和非聚簇索引的区别是：非聚簇索引的叶子节点存放的是<strong>主键的值</strong>，而聚簇索引的叶子节点存放的是<strong>整行数据</strong>。</p>
<p>根据这两种结构我们来进行下查询，看看他们在查询上有什么区别。</p>
<ol>
<li><p>如果查询语句是 select * from table where ID = 100，即主键查询的方式，则只需要搜索 ID 这棵 B+树。</p>
</li>
<li><p>如果查询语句是 select * from table where k = 1，即非主键的查询方式，则先搜索k索引树，得到ID=100，再到ID索引树搜索一次，这个过程也被称为<strong>回表</strong>。</p>
</li>
</ol>
<blockquote>
<p>回表是非常重要的概念，需要敲黑板划重点记住。其过程就如下图所示：<br><img src="https://oscimg.oschina.net/oscnet/up-f8dece791a80588e740e4bad6e8cccc607f.png" alt=""></p>
</blockquote>
<blockquote>
<p>什么非主键索引结构叶子节点存储的是主键值？<br>一是保证一致性，更新数据的时候只需要更新主键索引树，二是节省存储空间。</p>
</blockquote>
<h3 id="4-2-4-为什么建议使用主键自增的索引"><a href="#4-2-4-为什么建议使用主键自增的索引" class="headerlink" title="4.2.4 为什么建议使用主键自增的索引"></a>4.2.4 为什么建议使用主键自增的索引</h3><p>自增的主键，插入到索引的时候，直接在最右边插入就可以了</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d26d47c59b00d24a6bf8efc2fc3cf99d5bd.png" alt=""></p>
<p>但是如果插入的是 ID = 350 的一行数据，由于 B+ 树是有序的，那么需要将下面的叶子节点进行移动，腾出位置来插入 ID = 350 的数据，这样就会比较消耗时间，如果刚好 R4 所在的数据页已经满了，需要进行页分裂操作，这样会更加糟糕。</p>
<p>所以使用自增主键，每次插入的 ID 都会比前面的大，那么就可以避免这种情况。</p>
<h2 id="4-3-索引的数据结构"><a href="#4-3-索引的数据结构" class="headerlink" title="4.3 索引的数据结构"></a>4.3 索引的数据结构</h2><p>索引的数据结构，常见的是B树和B+树，MySql的索引使用的是B+树，关于B树一家子的分析，可以详见下文：<a href="https://my.oschina.net/lscherish/blog/4257330" target="_blank" rel="noopener" title="B树/B+树分析">B树/B+树分析</a></p>
<p>不过虽然都是使用B+树来做数据结构，但在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的（不过至少都是B+树）。</p>
<h3 id="4-3-1-MyISAM索引实现"><a href="#4-3-1-MyISAM索引实现" class="headerlink" title="4.3.1 MyISAM索引实现"></a>4.3.1 MyISAM索引实现</h3><p>MyISAM引擎使用B+Tree作为索引结构，<strong>其主键索引和普通索引在结构上没有区别</strong>，叶节点的data域存放的是数据记录的地址。</p>
<h4 id="4-3-1-1-MyISAM主键索引"><a href="#4-3-1-1-MyISAM主键索引" class="headerlink" title="4.3.1.1 MyISAM主键索引"></a>4.3.1.1 MyISAM主键索引</h4><p>如下图，这时一个针对主键col1字段的索引结构图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-95589fff5abe03cb617fecfdc3bb7ca40e7.png" alt=""></p>
<p>可以看出MyISAM的索引文件仅仅保存数据记录的地址。</p>
<h4 id="4-3-1-2-MyISAM普通索引"><a href="#4-3-1-2-MyISAM普通索引" class="headerlink" title="4.3.1.2 MyISAM普通索引"></a>4.3.1.2 MyISAM普通索引</h4><p>在MyISAM中，主索引和普通索引（Secondary key）在结构上没有任何区别，<strong>只是主索引要求key是唯一的</strong>，而普通索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cf329acb011c774d082ce93aff5943de24e.png" alt=""></p>
<p>同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。</p>
<p>发现没有？MyISAM的索引方式，跟我们上文说的非聚簇索引十分相像（一个是存放id，一个是存放地址）。所以MyISAM索引的实现方式是非聚簇索引。</p>
<h3 id="4-3-2-InnoDB索引实现"><a href="#4-3-2-InnoDB索引实现" class="headerlink" title="4.3.2 InnoDB索引实现"></a>4.3.2 InnoDB索引实现</h3><p>虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。对，InnoDB的索引是聚簇式的：<strong>InnoDB的数据文件本身就是索引文件</strong>，树的叶节点data域保存了完整的数据记录。</p>
<h4 id="4-3-2-1-InnoDB主键索引实现"><a href="#4-3-2-1-InnoDB主键索引实现" class="headerlink" title="4.3.2.1 InnoDB主键索引实现"></a>4.3.2.1 InnoDB主键索引实现</h4><p>我们先来看 InnoDB的主键索引，这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0febdd2fe5f4a8e1b6fb2682691f1809eef.png" alt=""></p>
<blockquote>
<p>因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。</p>
</blockquote>
<h4 id="4-3-2-2-InnoDB普通索引实现"><a href="#4-3-2-2-InnoDB普通索引实现" class="headerlink" title="4.3.2.2 InnoDB普通索引实现"></a>4.3.2.2 InnoDB普通索引实现</h4><p>在MyISAM中主索引和普通索引（Secondary key）在结构上没有任何区别，但InnoDB中，普通索引和主键索引是不同的，前文我们也介绍过，InnoDB的普通索引是非聚簇式的。</p>
<p>例如，图11为定义在Col3上的一个辅助索引：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e8635aba2790f0fd15594ce95bfb1dc97da.png" alt=""></p>
<p>图中的15,18这些数字，就是col3所对应的<strong>主键值</strong>，普通索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。</p>
<blockquote>
<p>了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。</p>
</blockquote>
<p>最后来一张图总结一下InnoDB和Mylsam两种不同索引的结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-36fd77ae6ff2ce44045e7c313f7c102add4.png" alt=""></p>
<h3 id="4-3-3-联合索引的数据结构"><a href="#4-3-3-联合索引的数据结构" class="headerlink" title="4.3.3 联合索引的数据结构"></a>4.3.3 联合索引的数据结构</h3><p>我们知道了Mysql的索引采用B+树，那么，联合索引的B+树长什么样呢？？</p>
<h4 id="4-3-3-1-MylSAM的联合索引"><a href="#4-3-3-1-MylSAM的联合索引" class="headerlink" title="4.3.3.1  MylSAM的联合索引"></a>4.3.3.1  MylSAM的联合索引</h4><p>假如我们有一张表</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-05ed253aaa6cac66ae76bd4d9c06610ffba.png" alt=""></p>
<p>那么，联合索引的B+树结构是长这样的：</p>
<pre><code>- ![](https://oscimg.oschina.net/oscnet/up-96d55ea6fae1c299fc33c64c57ece2ce911.png)</code></pre><blockquote>
<p>注意，这是MyISAM的联合索引，也就是说，叶子节点的key是索引列b,c,d的组合，value是指向表记录的内存地址。如果是InnoDB的联合索引，那么叶子结点应该key是b,c,d的组合，value是表的pk，也就是a字段。</p>
</blockquote>
<p>即每个元素的key，都是b,c,d三个字段的组合。那么不同元素之间的排序是依照什么规则呢？第一列的值大小吗？</p>
<p>答案是：先判断 b 再判断 c 然后是 d，即优先级为b&gt;c&gt;d。</p>
<h4 id="4-3-3-2-InnoDB的联合索引"><a href="#4-3-3-2-InnoDB的联合索引" class="headerlink" title="4.3.3.2  InnoDB的联合索引"></a>4.3.3.2  InnoDB的联合索引</h4><p>有一张表test，这张表除了主键id外，还有a，b,  c 三列</p>
<p>假设给这三个字段建一个复合索引 index_abc (a, b, c)，那么其B+树的结构如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b049e18954547cf3acdcd6866261f8c81ce.png" alt=""></p>
<p>key的排序同理，先判断 a 再判断 b 然后是 c，即优先级为b&gt;c&gt;d。</p>
<h2 id="4-4-索引生效条件"><a href="#4-4-索引生效条件" class="headerlink" title="4.4 索引生效条件"></a>4.4 索引生效条件</h2><p>我们创建了索引，但很多时候，我们发现我们的查询语句无法使用到索引，基于此，我们首先要了解索引的命中规则。</p>
<p>那么怎么知道我们写的sql语句是否有使用到索引呢，可以使用<code>explain</code>命令，直接在sql语句前加explain执行：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-835f37250d6a7bf6e9409110997e2494d0d.png" alt=""></p>
<p>explain执行结果关注以下几个字段：</p>
<ol>
<li>select_type:<ul>
<li>查询的类型，主要是区别普通查询和联合查询、子查询之类的复杂查询<ul>
<li>SIMPLE：查询中不包含子查询或者UNION</li>
<li>查询中若包含任何复杂的子部分，最外层查询则被标记为：PRIMARY</li>
<li>在SELECT或WHERE列表中包含了子查询，该子查询被标记为：SUBQUERY</li>
</ul>
</li>
</ul>
</li>
<li>possible_keys<ul>
<li>表示查询时可能使用的索引。如果是空的，没有相关的索引。这时要提高性能，可通过检验WHERE子句，看是否引用某些字段，或者检查字段不是适合索引</li>
</ul>
</li>
<li>key<ul>
<li>显示sql执行过程中实际使用的键或索引，如果为null则表示未使用任何索引，必须进行优化。</li>
</ul>
</li>
<li>rows<ul>
<li>rows是指这次查找数据所内循环的次数。</li>
</ul>
</li>
<li>Extra:<ul>
<li>执行情况的说明和描述。包含不适合在其他列中显示但十分重要的额外信息</li>
</ul>
</li>
<li>type<ul>
<li>type意味着类型，这里的type官方全称是“join type”，意思是“连接类型”,这样很容易给人一种错觉觉得必须需要俩个表以上才有连接类型。事实上这里的连接类型并非字面那样的狭隘，</li>
<li>它更确切的说是一种数据库引擎查找表的一种方式，在《高性能mysql》一书中作者更是觉得称呼它为访问类型更贴切一些。</li>
<li>mysql5.7中type的类型达到了14种之多，这里只记录和理解最重要且经常遇见的六种类型，它们分别是<code>all&lt;index&lt;range&lt;ref&lt;eq_ref&lt;const</code>。从左到右，它们的效率依次是增强的。</li>
<li>撇开sql的具体应用环境以及其他因素，你应当尽量优化你的sql语句，使它的type尽量靠右，但实际运用中还是要综合考虑各个方面的。</li>
</ul>
</li>
</ol>
<h3 id="4-4-1-explain的type字段类型"><a href="#4-4-1-explain的type字段类型" class="headerlink" title="4.4.1 explain的type字段类型"></a>4.4.1 explain的type字段类型</h3><ol>
<li><strong>all</strong>：这便是所谓的“全表扫描”，如果是在一个查找数据项的sql中出现了all类型，那通常意味着你的sql语句处于一种最原生的状态，有很大的优化空间。all是一种非常暴力和原始的查找方法，非常的耗时而且低效。</li>
<li><strong>index</strong>：这种连接类型只是另外一种形式的全表扫描，<strong>只不过它的扫描顺序是按照索引的顺序</strong>。这种扫描根据索引然后回表取数据，和all相比，他们都是取得了全表的数据，而且index要先读索引而且要回表随机取数据</li>
<li><strong>range</strong>：range指的是有范围的索引扫描，相对于index的全索引扫描，它有范围限制，因此要优于index。关于range比较容易理解，需要记住的是出现了range，则一定是基于索引的。同时除了显而易见的between，and以及’&gt;’,’&lt;’外，in和or也是索引范围扫描。</li>
<li><strong>ref</strong>：出现该连接类型的条件是： 查找条件列使用了索引而且不为主键和unique。其实，意思就是虽然使用了索引，但该索引列的值并不唯一，有重复（使用了普通索引的意思）。这样即使使用索引快速查找到了第一条数据，仍然不能停止，要进行目标值附近的小范围扫描。但它的好处是它并不需要扫全表，因为索引是有序的，即便有重复值，也是在一个非常小的范围内扫描。</li>
<li><strong>ref_eq</strong>：ref_eq 与 ref相比牛的地方是，它知道这种类型的查找结果集只有一个。什么情况下结果集只有一个呢！那便是使用了<strong>主键或者唯一性索引</strong>进行查找的情况。比如根据学号查找某一学校的一名同学，在没有查找前我们就知道结果一定只有一个，所以当我们首次查找到这个学号，便立即停止了查询。这种连接类型每次都进行着精确查询，无需过多的扫描，因此查找效率更高，当然列的唯一性是需要根据实际情况决定的。</li>
<li><strong>const</strong>：通常情况下，如果将一个主键放置到where后面作为条件查询，mysql优化器就能把这次查询优化转化为一个常量。即直接按主键或唯一键读取。</li>
<li><strong>NULL</strong>：不用访问表或者索引，直接就能得到结果，如select 1 from test where 1</li>
</ol>
<blockquote>
<p>看起来const和ref_eq貌似是一样的啊，都是使用主键或者唯一性索引，其实eq_ref是用于联表查询的情况，按联表的主键或唯一键联合查询。</p>
</blockquote>
<h3 id="4-4-2-索引失效场景"><a href="#4-4-2-索引失效场景" class="headerlink" title="4.4.2 索引失效场景"></a>4.4.2 索引失效场景</h3><p>很多时候，我们在列上建了索引，查询条件也是索引列，但最终执行计划没有走它的索引。那到底哪些场景，会导致索引失效呢？</p>
<ol>
<li><p>列与列对比</p>
<ul>
<li>某个表中，有两列（id和c_id）都建了单独索引，下面这种查询条件不会走索引</li>
<li><code>select * from test where id=c_id;</code></li>
</ul>
</li>
<li><p>存在NULL值条件</p>
<ul>
<li>我们在设计数据库表时，应该尽力避免NULL值出现，如果非要不可避免的要出现NULL值，也要给一个DEFAULT值</li>
<li><code>select * from test where id=c_id;</code></li>
</ul>
</li>
<li><p>NOT条件</p>
<ul>
<li>我们知道建立索引时，给每一个索引列建立一个条目，如果查询条件为等值或范围查询时，索引可以根据查询条件去找对应的条目。反过来当查询条件为非时，索引定位就困难了，执行计划此时可能更倾向于全表扫描，这类的查询条件有：&lt;&gt;、NOT、not exists<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span> <span class="keyword">where</span> <span class="keyword">id</span>&lt;&gt;<span class="number">500</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span> <span class="keyword">where</span> <span class="keyword">not</span> <span class="keyword">in</span> (<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">0</span>);</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span> <span class="keyword">where</span> <span class="keyword">not</span> <span class="keyword">exists</span> (<span class="keyword">select</span> <span class="number">1</span> <span class="keyword">from</span> test_02 <span class="keyword">where</span> test_02.id=test.id);</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>LIKE通配符的前匹配</p>
<ul>
<li>当使用模糊搜索时，尽量采用后置的通配符，例如：name%，因为走索引时，其会从前去匹配索引列，这时候是可以找到的，如果采用前匹配，那么查索引就会很麻烦，比如查询所有姓张的人，就可以去搜索’张%’。相反如果你查询所有叫‘明’的人，那么只能是%明。这时候索引如何定位呢？前匹配的情况下，执行计划会更倾向于选择全表扫描。后匹配可以走INDEX RANGE SCAN。</li>
<li><code>select * from test where name like &#39;张%&#39;;</code></li>
</ul>
</li>
<li><p>条件上对列使用函数</p>
<ul>
<li>查询条件上尽量不要对索引列使用函数，比如下面这个SQL——这样是不会走索引的，因为索引在建立时会和计算后可能不同，无法定位到索引。</li>
<li><code>select * from test where upper(name)=&#39;SUNYANG&#39;;</code></li>
<li>但如果查询条件不是对索引列进行计算，那么依然可以走索引。比如</li>
<li><code>select * from test where name=upper(&#39;sunyang&#39;);</code></li>
</ul>
</li>
<li><p>数据类型的转换</p>
<ul>
<li>当查询条件存在隐式转换时，索引会失效。比如在数据库里id存的number类型，但是在查询时，却用了下面的形式：</li>
<li><code>select * from sunyang where id=&#39;123&#39;;</code></li>
</ul>
</li>
<li><p>谓词运算</p>
<ul>
<li>我们在上面说，不能对索引列进行函数运算，这也包括加减乘除的谓词运算，这也会使索引失效。建立一个sunyang表，索引为id，看这个SQL：</li>
<li><code>select * from sunyang where id/2=15;</code></li>
<li>这里很明显对索引列id进行了’/2’除二运算，这时候就会索引失效，这种情况应该改写为：</li>
<li><code>select * from sunyang where id=30;</code></li>
</ul>
</li>
<li><p>or连接中包含非独立索引</p>
<ul>
<li>先看如下这个sql：</li>
<li><code>SELECT * from t WHERE id = 1 or uid = 2;</code></li>
<li>如果id和uid都有单独的索引，那么mySql优化器会采用index merge 技术使其走索引。index merge 技术简单说就是在用OR，AND连接的多个查询条件时，可以分别使用前后查询中的索引，然后将它们各自的结果合并交集或并集。</li>
<li><strong>但如果uid列上没有单独的索引，那么这个sql将不会走索引，即便id上有主键索引。</strong></li>
</ul>
</li>
</ol>
<h3 id="4-4-3-联合索引生效条件（最左前缀原则）"><a href="#4-4-3-联合索引生效条件（最左前缀原则）" class="headerlink" title="4.4.3 联合索引生效条件（最左前缀原则）"></a>4.4.3 联合索引生效条件（最左前缀原则）</h3><p>上文中我们介绍了联合索引的数据结构，对于index(b,c,d)是长这样的：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-96d55ea6fae1c299fc33c64c57ece2ce911.png" alt=""></p>
<p>因为联合索引中的元素key都是一个组合值&lt;b,c,d&gt;，且排序依据的优先级是b&gt;c&gt;d，所以联合索引的生效条件，要满足最左前缀原则。我们看如下sql：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> t1 <span class="keyword">WHERE</span> b = <span class="number">1</span> <span class="keyword">and</span> c = <span class="number">2</span> <span class="keyword">and</span> d = <span class="number">3</span>; //走索引</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> t1 <span class="keyword">WHERE</span> b = <span class="number">1</span> <span class="keyword">and</span> c = <span class="number">2</span>                  //走索引</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> t1 <span class="keyword">WHERE</span> b = <span class="number">1</span>                                  //走索引</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> t1 <span class="keyword">WHERE</span> c = <span class="number">2</span> <span class="keyword">and</span> d = <span class="number">3</span>;                 //不走索引</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> t1 <span class="keyword">WHERE</span> d = <span class="number">3</span>;                                 //走索引</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> t1 <span class="keyword">WHERE</span> b = <span class="number">1</span> <span class="keyword">and</span> d = <span class="number">3</span>                 //走部分索引，至少会走到b = <span class="number">1</span>的子树上。</span><br><span class="line"></span><br><span class="line">//范围查询</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> t1 <span class="keyword">WHERE</span> b &lt; <span class="number">1</span>;                                  //走索引</span><br><span class="line">SELECT * from t1 WHERE b &lt; 1 and c &lt; 2 and d&gt;3;   //走部分索引，b&lt;1走了索引，后面两个条件无法走索引。（索引最多用于一个范围列）</span><br></pre></td></tr></table></figure>

<p>这就是最左前缀原则，还是比较好理解的，需要注意的是索引最多用于一个范围列（且只能是最左的列）。</p>
<p>不过大多数时候，mySql优化器会按照现有的索引来优化sql语句的where条件顺序，比如<code>SELECT * from t1 WHERE  c = 2 and b = 1</code>就会被优化为<code>SELECT * from t1 WHERE b = 1 and c = 2</code>，使得这条sql可以走索引。</p>
<h2 id="4-5-索引优化"><a href="#4-5-索引优化" class="headerlink" title="4.5 索引优化"></a>4.5 索引优化</h2><h3 id="4-5-1-索引的选择性"><a href="#4-5-1-索引的选择性" class="headerlink" title="4.5.1 索引的选择性"></a>4.5.1 索引的选择性</h3><p>既然索引可以加快查询速度，那么是不是只要是查询语句需要，就建上索引？答案是否定的。因为索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，MySQL在运行时也要消耗资源维护索引，因此索引并不是越多越好。一般两种情况下不建议建索引。</p>
<ol>
<li><p>表记录比较少:</p>
<ul>
<li>例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描就好了。至于多少条记录才算多，这个个人有个人的看法，我个人的经验是以2000作为分界线，记录数不超过 2000可以考虑不建索引，超过2000条可以酌情考虑索引。</li>
</ul>
</li>
<li><p>索引的选择性较低。</p>
<ul>
<li>所谓索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值：</li>
<li><code>Index Selectivity = Cardinality / #T</code></li>
<li>显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。例如，employees.titles表，如果title字段经常被单独查询，是否需要建索引，我们看一下它的选择性：</li>
<li><code>SELECT count(DISTINCT(title))/count(*) AS Selectivity FROM employees.titles;</code></li>
</ul>
</li>
</ol>
<h3 id="4-5-2-前缀索引"><a href="#4-5-2-前缀索引" class="headerlink" title="4.5.2 前缀索引"></a>4.5.2 前缀索引</h3><p>有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销。</p>
<p>下面以employees.employees表为例介绍前缀索引的选择和使用。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1e10e78d3b5a8ab5317c3469f7b21c27edc.png" alt=""></p>
<p>如果我们需要频繁按名字搜索员工，这样显然效率很低，因此我们可以考虑建索引。有两种选择，建<first_name>或&lt;first_name, last_name&gt;，看下两个索引的选择性：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">SELECT count(DISTINCT(first_name))&#x2F;count(*) AS Selectivity FROM employees.employees;</span><br><span class="line">+-------------+</span><br><span class="line">| Selectivity |</span><br><span class="line">+-------------+</span><br><span class="line">|      0.0042 |</span><br><span class="line">+-------------+</span><br><span class="line">SELECT count(DISTINCT(concat(first_name, last_name)))&#x2F;count(*) AS Selectivity FROM employees.employees;</span><br><span class="line">+-------------+</span><br><span class="line">| Selectivity |</span><br><span class="line">+-------------+</span><br><span class="line">|      0.9313 |</span><br><span class="line">+-------------+</span><br></pre></td></tr></table></figure>

<p><first_name>显然选择性太低，&lt;first_name, last_name&gt;选择性很好，但是first_name和last_name加起来长度为30，有没有兼顾长度和选择性的办法？可以考虑用first_name和last_name的前几个字符建立索引，例如&lt;first_name, left(last_name, 3)&gt;，看看其选择性：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SELECT count(DISTINCT(concat(first_name, left(last_name, 3))))&#x2F;count(*) AS Selectivity FROM employees.employees;</span><br><span class="line">+-------------+</span><br><span class="line">| Selectivity |</span><br><span class="line">+-------------+</span><br><span class="line">|      0.7879 |</span><br><span class="line">+-------------+</span><br></pre></td></tr></table></figure>

<p>选择性还不错，但离0.9313还是有点距离，那么把last_name前缀加到4：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SELECT count(DISTINCT(concat(first_name, left(last_name, 4))))&#x2F;count(*) AS Selectivity FROM employees.employees;</span><br><span class="line">+-------------+</span><br><span class="line">| Selectivity |</span><br><span class="line">+-------------+</span><br><span class="line">|      0.9007 |</span><br><span class="line">+-------------+</span><br></pre></td></tr></table></figure>

<p>这时选择性已经很理想了，而这个索引的长度只有18，比&lt;first_name, last_name&gt;短了接近一半，我们把这个前缀索引建上：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE employees.employees</span><br><span class="line">ADD INDEX &#96;first_name_last_name4&#96; (first_name, last_name(4));</span><br></pre></td></tr></table></figure>

<p>此时再执行一遍按名字查询，比较分析一下与建索引前的结果：<a href="https://www.cnblogs.com/mydriverc/p/7086523.html" target="_blank" rel="noopener" title="MYSQL中使用SHOW PROFILE命令分析性能">MYSQL中使用SHOW PROFILE命令分析性能</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SHOW PROFILES;</span><br><span class="line">+----------+------------+---------------------------------------------------------------------------------+</span><br><span class="line">| Query_ID | Duration   | Query                                                                           |</span><br><span class="line">+----------+------------+---------------------------------------------------------------------------------+</span><br><span class="line">|       87 | 0.11941700 | SELECT * FROM employees.employees WHERE first_name&#x3D;&#39;Eric&#39; AND last_name&#x3D;&#39;Anido&#39; |</span><br><span class="line">|       90 | 0.00092400 | SELECT * FROM employees.employees WHERE first_name&#x3D;&#39;Eric&#39; AND last_name&#x3D;&#39;Anido&#39; |</span><br><span class="line">+----------+------------+---------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>

<p>性能的提升是显著的，查询速度提高了120多倍。</p>
<p>前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。</p>
<h3 id="4-5-3-覆盖索引"><a href="#4-5-3-覆盖索引" class="headerlink" title="4.5.3 覆盖索引"></a>4.5.3 覆盖索引</h3><p>我们知道，联合索引的B+树是长这个样子的(InnoDB版本，index_abc为(a,b,c)的联合索引)：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b049e18954547cf3acdcd6866261f8c81ce.png" alt=""></p>
<p>那么假如我们有如下的语句：</p>
<p><code>select a,b,c from test where b&gt;3</code></p>
<p>请问这句话走不走索引呢？</p>
<p>答案是：走索引</p>
<p>where b&gt;3 根据最左前缀原则明明不会命中index_abc啊，为什么这条语句会走索引呢？？</p>
<p>因为这句sql，不用回表，这会极大的提高查询性能。</p>
<p>为什么不用回表？因为对比联合索引的结构图我们可以看到，该句sql select的三个字段，都是联合索引的索引字段，这使得联合索引index_abc的叶子结点上就已经能够得到a,b,c三个字段了，用不着回表就足够把需要的a,b,c数据都查出来。</p>
<p>但where b&gt;3不满足最左前缀原则啊！那么索引是怎么走的呢？</p>
<p>答案是，<strong>遍历B+树上的所有节点</strong>。是的，因为不满足最左前缀，所以该句sql无法很高效的利用索引来将性能达到极致，但是遍历B+树上的所有节点仍然比全表扫描要快得多，因为B+树多叉的特性，其节点数量远远小于表记录的数量。</p>
<p>这种索引叫做<strong>覆盖索引</strong>，即现有的索引能够覆盖select的字段，那么就可以通过遍历索引树节点，且无需回表的方式，来提高查询性能。</p>
<p>理解了覆盖索引的含义，那么举一反三，我们可以知道：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select a,b from test where c&gt;3     &#x2F;&#x2F;走索引</span><br><span class="line">select id,a,b from test where c&gt;3  &#x2F;&#x2F;走索引，别忘了联合索引的叶子节点上除了联合索引的索引列，还有主键id</span><br><span class="line">select a,b,d from test where c&gt;3   &#x2F;&#x2F;不走索引，因为d不在index_abc的覆盖范围内</span><br><span class="line">select a,b,c from test where a&gt;3   &#x2F;&#x2F;走索引，且还能满足最左前缀原则，性能最高。</span><br></pre></td></tr></table></figure>

<p>所以在select的字段不多的时候，我们可以考虑创建这几个字段的联合索引，来促使sql走覆盖索引，提高查询性能。</p>
<h3 id="4-5-4-索引下推"><a href="#4-5-4-索引下推" class="headerlink" title="4.5.4 索引下推"></a>4.5.4 索引下推</h3><p>对于user_table表，我们现在有（username,age）联合索引。</p>
<p>如果现在有一个需求，查出名称中以“张”开头且年龄小于等于10的用户信息，语句如下：</p>
<p><code>select * from user_table where username like &#39;张%&#39; and age &gt; 10</code></p>
<p>那么我们可以推测出来，语句有两种执行可能：</p>
<ol>
<li>根据（username,age）联合索引查询出所有满足名称以“张”开头的叶子节点，得到pk，<strong>然后回表查询出相应的全行数据</strong>，然后再在结果中筛选出满足年龄小于等于10的用户数据</li>
<li>根据（username,age）联合索引查询所有满足名称以“张”开头的叶子节点，<strong>然后再对这些叶子节点筛选出年龄小于等于10的叶子节点</strong>，得到pk，之后再回表查询全行数据。</li>
</ol>
<p>明显的，<strong>第二种方式需要回表查询的全行数据比较少</strong>，这就是mysql的索引下推，即<strong>where条件中的字段如果能被某个联合索引覆盖</strong>（和覆盖索引有点像），那么直接在联合索引中完成过滤操作，缩小范围，最后再做回表操作。</p>
<p>mysql默认启用索引下推，我们也可以通过修改系统变量optimizer_switch的index_condition_pushdown标志来控制<br><code>SET optimizer_switch = &#39;index_condition_pushdown=off&#39;;</code></p>
<hr>
<h1 id="参考材料"><a href="#参考材料" class="headerlink" title="参考材料"></a>参考材料</h1><ol>
<li><a href="https://segmentfault.com/a/1190000013695030" target="_blank" rel="noopener" title="数据库逻辑设计之三大范式通俗理解，一看就懂，书上说的太晦涩">数据库逻辑设计之三大范式通俗理解，一看就懂，书上说的太晦涩</a></li>
<li>《高性能MySQL》</li>
<li><a href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html" target="_blank" rel="noopener" title="MySQL索引背后的数据结构及算法原理">MySQL索引背后的数据结构及算法原理</a></li>
<li><a href="https://blog.csdn.net/dennis211/article/details/78170079" target="_blank" rel="noopener" title="mysql中explain的type的解释">mysql中explain的type的解释</a></li>
<li><a href="https://www.cnblogs.com/CNYYGJ/p/12677690.html" target="_blank" rel="noopener" title="左匹配原则，聚集索引，回表查询，索引覆盖 你真的懂了吗">左匹配原则，聚集索引，回表查询，索引覆盖 你真的懂了吗</a></li>
<li><a href="https://blog.csdn.net/mccand1234/article/details/95799942" target="_blank" rel="noopener" title="索引下推（5.6版本+）">索引下推（5.6版本+）</a></li>
<li><a href="https://www.jianshu.com/p/35588ecf33c1" target="_blank" rel="noopener" title="mysql的联合索引的B+树到底张什么样子？">mysql的联合索引的B+树到底张什么样子？</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/28/B%E6%A0%91-B-%E6%A0%91%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/28/B%E6%A0%91-B-%E6%A0%91%E5%88%86%E6%9E%90/" itemprop="url">B树/B+树分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-28T22:39:54+08:00">
                2020-04-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%A0%91-%E5%A0%86/" itemprop="url" rel="index">
                    <span itemprop="name">树/堆</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/04/28/B%E6%A0%91-B-%E6%A0%91%E5%88%86%E6%9E%90/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/04/28/B树-B-树分析/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  5.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  20
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>目前我们常见的动态查找树主要有：二叉查找树（Binary Search Tree），平衡二叉查找树（Balanced Binary Search Tree），红黑树(Red-Black Tree )，这三者是典型的二叉树结构，利用二分法，可以使其查询的时间复杂度为O(log2N)，即与树的深度相关。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0dcba6005c20f21c6a6e966b9f239b7bc91.png" alt=""></p>
<p>但二叉树一个节点中包含有一个元素，和指向两个子节点的指针，在现实生活中，未免有些太“奢侈”了。为了降低树的深度，提高查找效率，我们完全可以采用多叉树结构（由于树节点元素数量是有限的，自然该节点的子树数量也就是有限的）来得到一棵更加“矮胖”的树，以适应我们日益增长的数据量和查询性能要求，在这种背景下，B树和他的亲戚们应运而生。</p>
<h1 id="1-B树"><a href="#1-B树" class="headerlink" title="1. B树"></a>1. B树</h1><p>B-tree（B-tree树即B树，B即Balanced，平衡的意思）这棵神奇的树是在Rudolf Bayer, Edward M. McCreight(1970)写的一篇论文《Organization and Maintenance of Large Ordered Indices》中首次提出的（wikipedia中：<a href="http://en.wikipedia.org/wiki/B-tree" target="_blank" rel="noopener" title="http://en.wikipedia.org/wiki/B-tree">http://en.wikipedia.org/wiki/B-tree</a>，阐述了B-tree名字来源以及相关的开源地址）。</p>
<p>B树属于多叉树，又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者B树和B+树的数据结构。</p>
<blockquote>
<p>强调一下，有的文章里出现的B-树，就是B树。因为B树的原英文名称为B-tree，而国内很多人喜欢把B-tree译作B-树，其实，这是个非常不好的直译，很容易让人产生误解。如人们可能会以为B-树是一种树，而B树又是一种一种树。而事实上是，B-tree就是指的B树。</p>
</blockquote>
<p>什么是B树？抛出一大堆概念前，我们先看看他长什么样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4ab23420bac3cd2b0d9278357cf27adb754.png" alt=""></p>
<p>这里面，每个字母，都表示一个键值对<code>[key,value]</code>，在关系型数据库的使用场景中，<strong>key一般是索引值</strong>（如果是主键索引的话，那就是ID字段，如果是普通索引，那就是索引对应的字段值，如果是联合索引，可以简单理解为对应多个字段的拼接），<strong>value一般是指向行数据的指针（聚簇索引是这样）或者主键id（非聚簇索引）</strong>；</p>
<p>结合该图，我们可以归纳出B树的规则：</p>
<ol>
<li>节点容量：每个节点，都可以容纳多个键值对。</li>
<li>排序方式：所有节点键值对是按key递增次序排列，并遵循左小右大原则；</li>
<li>层级结构：所有叶子节点均在同一层</li>
<li>子树指针：节点中每个键值对的两侧，都可以放置指针（不一定都有值，可以是null），如果有值，则左边指向左子树（key都比当前key小），右边指向右子树（key都比当前key大）<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-45013c901275cb3600f245d8c75f79590fd.png" alt=""></li>
</ul>
</li>
</ol>
<p>B树种，每个节点最多可以容纳多少个键值对呢？这当然不可能是无限的，在数据结构的定义中，我们引入如下概念来描述：</p>
<ol>
<li>度（degree），在树中，每个节点的子树个数就称为该节点的度。（注意是子树数量，而不是键值对的数量）</li>
<li>阶（order），在树中，一个节点可以拥有的最大子树数量称为阶。（注意是子树数量，而不是键值对的数量）</li>
</ol>
<p>然而上述的规则，只能得到一个B树，却不一定得到一个平衡的B树，极端一点，下图这样的树，它也可以是个B树，但这显然不是我们想要的。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-11c5ae696f01bc75d91131d6ffb2a9dfeeb.png" alt=""></p>
<p>对于一个M阶的平衡的B树，除了上述的规则之外，我们还要加上如下的约束：</p>
<ol>
<li>根节点至少有两颗子树</li>
<li>除根节点和叶子结点外，其他节点至少应该有m/2个子树。</li>
<li>每个节点的键值对数量k，应该<code>m-1≥k≥ceil(m/2)-1</code>。</li>
</ol>
<blockquote>
<p>ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2</p>
</blockquote>
<p>如下图，就是一个5阶的平衡B树，4≥k≥2。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-bb258827f7c35e85442858c7e596f2e2524.png" alt=""></p>
<p>注意，每个节点中的键值对，value都是指向实际data的指针，像下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1ebfa206ae65baff44ff3be6ad33826a6cb.png" alt=""></p>
<h2 id="1-1-B树的查询"><a href="#1-1-B树的查询" class="headerlink" title="1.1 B树的查询"></a>1.1 B树的查询</h2><p><img src="https://oscimg.oschina.net/oscnet/up-a9ce1d66b48acaafe781167587318d9c0f0.png" alt=""></p>
<p>如上图我要从上图中找到E字母，查找流程如下</p>
<ol>
<li><p>获取根节点的关键字进行比较，当前根节点关键字为M，E&lt;M（26个字母顺序），所以往找到指向左边的子节点（二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点）；</p>
</li>
<li><p>拿到关键字D和G，D&lt;E&lt;G 所以直接找到D和G中间的节点；</p>
</li>
<li><p>拿到E和F，因为E=E 所以直接返回关键字和指针信息（如果树结构里面没有包含所要查找的节点则返回null）；</p>
</li>
</ol>
<h2 id="1-2-B树的插入"><a href="#1-2-B树的插入" class="headerlink" title="1.2 B树的插入"></a>1.2 B树的插入</h2><p>一棵平衡的B树之所以能维持其平衡性，B树的插入和删除算法功不可没，我们先来看下B树如何应对记录的插入。</p>
<p>对于一个m阶的平衡的B树，从上文我们知道，需要保持其每个节点的键值对数量k为：<code>m-1≥k≥ceil(m/2)-1</code>，新的记录一般是插入在叶子节点上，为了保持这个数量和树的平衡性，我们规定：</p>
<ol>
<li>还是按照key递增次序排列，遵循左小右大的原则，在叶子节点上找到新元素的定位。</li>
<li>若插入时，插入的节点元素个数小于m-1，则该元素直接插入。</li>
<li>否则，将该节点的元素分裂。</li>
</ol>
<p>我们下面以5阶B树为例子，在5阶B树中，结点最多有4个键值对，最少有2个键值对。（下面我们把键值对称为元素）</p>
<ol>
<li>插入树的第一批元素，A，C，G，N，因为数量不超过4，所以刚好能放在一个节点里面：<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-0af274b789dd1f16f170fc83968f07eb356.png" alt=""></li>
</ul>
</li>
<li>当试着插入H时，节点发现空间不够（4阶B树，一个节点最多放4个元素），以致将其<strong>分裂</strong>成2个节点，移动中间元素G上移到新的根节点中，比G元素小的A和C留在当前节点中，而比G元素大的H和N放置新的其右邻居节点中。如下图：<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-cbd8d929ac323b575bf7d75becdfacf44a8.png" alt=""></li>
</ul>
</li>
<li>接下来插入E，K，Q，因为都不触及上界，所以不需要任何分裂操作<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-e9af49d254a060491b461731484c692dc6c.png" alt=""></li>
</ul>
</li>
<li>插入M（在K和N之间）就会导致一次分裂，注意M恰好是中间关键字元素，以致向上移到父节点中<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-a90c8160743bcd04518ca54bb903db6c700.png" alt=""></li>
</ul>
</li>
<li>插入F，W，L，T不需要任何分裂操作<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-d0df1d26e4a539e449f182883079b6e000f.png" alt=""></li>
</ul>
</li>
<li>插入Z时，最右的叶子节点空间满了，需要进行分裂操作，中间元素T上移到父节点中。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-c901bb0b11e87bc7ce2f19966758b8f74e2.png" alt=""></li>
</ul>
</li>
<li>插入D时，导致最左边的叶子节点被分裂，D恰好也是中间元素，上移到父节点中，然后字母P，R，X，Y陆续插入不需要任何分裂操作<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-33e4f1cbd03fa5a95705511b5fa003df45c.png" alt=""></li>
</ul>
</li>
<li>最后，当插入S时，含有[N,P,Q,R]的节点需要分裂，把中间元素Q上移到父节点中，但是情况来了，父节点中空间已经满了，无法加入Q了，所以也要进行分裂，将父节点中的中间元素M上移到新形成的根结点中。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-6d015f6544f424661fdc345f7b017b3bbf4.png" alt=""></li>
</ul>
</li>
</ol>
<h2 id="1-3-B树的删除"><a href="#1-3-B树的删除" class="headerlink" title="1.3 B树的删除"></a>1.3 B树的删除</h2><p>B树的删除比插入要更复杂一些，但总体而言，为了保持树的平衡，还是有以下的原则：</p>
<p>分为如下几种情况：</p>
<ol>
<li><p>要删除的记录d在叶子节点上</p>
<ul>
<li><p>1.1  如果该节点删除了该元素d后元素数量k仍然大于等于ceil(m/2)-1</p>
<blockquote>
<p>那么这种情况最简单，直接删除元素d和其对应的指针即可。这种情况，我们称为<strong>元素直删</strong></p>
</blockquote>
</li>
<li><p>1.2 如果该节点删除了元素d后k小于ceil(m/2)-1，那么这时也分两种情况</p>
<ul>
<li><p>1.2.1 与该节点相邻的兄弟节点，有任一节点，其k大于等于ceil(m/2)。（这表示即便k-1，也仍然大于等于ceil(m/2)-1）</p>
<blockquote>
<p>那么这种情况，我们应该向兄弟节点，借一个元素过来，但不是简单的借，因为要保证B树元素从左到右递增的顺序，故而借法是有门道的，我们暂称为<strong>元素租借</strong>。</p>
</blockquote>
</li>
<li><p>1.2.2 与该节点相邻的兄弟节点，都没有多余的元素可以借出去，即其k都等于ceil(m/2)-1</p>
<blockquote>
<p>那么这种情况，删除元素d后，我们应该和兄弟节点合并，这样k1=ceil(m/2)-1-1和k2=ceil(m/2)-1,k1+k2还是小于m，符合B树的平衡约束（这也是为什么k的下限是ceil(m/2)-1的原因），这种情况，我们称为<strong>元素合并</strong></p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
<li><p>要删除的记录d在非叶子节点上</p>
<ul>
<li><blockquote>
<p>那么这种情况，我们应该在d指针指向的子树中找到一个元素f来替代d的位置，同时在子树中删除f（如果f的删除引起了<code>m-1≥k≥ceil(m/2)-1</code>的不满足，那么操作方法按照<code>情况1：要删除的记录d在叶子节点上</code>来处理），这种情况，我们称为<strong>元素顶替</strong></p>
</blockquote>
</li>
</ul>
</li>
</ol>
<p>总结之后，我们发现，删除记录的核心操作，就在<strong>元素直删</strong>，<strong>元素租借</strong>，<strong>元素合并</strong>和<strong>元素顶替</strong>这四个操作步骤之间，直删元素比较简单，我们不多说，剩下的，三种操作步骤，我们来理一下：</p>
<p>我们有一个5阶的b树，原始状态长这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-dbe6fba9b6d67cc51aa034d00863633519b.png" alt=""></p>
<ol>
<li><strong>元素顶替</strong><ul>
<li>我们先反着来，先删除位于非叶子节点上的记录27</li>
<li>这时候，需要从27的左右指针指向的两棵子树中找元素来置换27，左子树是<code>23,24,26</code>，右子树是<code>28,29</code></li>
<li>为了保证b树从左到右增序的顺序，所以有资格被置换的元素只有26和28。</li>
<li>b树删除的大部分实现，都是采用<strong>后继顶替优先原则</strong>，即27被删除，则拿27的后继28来顶替。</li>
<li>将28元素替到27原来的位置，同时将右子节点中的28删去，如下图：<br><img src="https://oscimg.oschina.net/oscnet/up-85fdbd40c1a754b1940a8c3edf02992f702.png" alt=""></li>
<li><code>28,29</code>节点删去28之后，显然k小于了ceil(m/2)-1=2，这时候，<code>29</code>有两个兄弟节点：<code>23,24,26</code>和<code>31,32</code></li>
<li>如果<code>29</code>向<code>23,24,26</code>求援，就会引发<strong>元素租借</strong>的情况，反之，向<code>31,32</code>求援，就会引发<strong>元素合并</strong>的情况</li>
</ul>
</li>
</ol>
<blockquote>
<p>其实向哪边求援都可以，实现不同，最终最多导致B树的形态会稍不一样，但肯定的是，他们都是平衡的树。</p>
</blockquote>
<ol start="2">
<li><p><strong>元素租借</strong></p>
<ul>
<li>重申一下， <strong>元素顶替</strong>操作结束后，B树长这样</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-85fdbd40c1a754b1940a8c3edf02992f702.png" alt=""></li>
<li>假如<code>29</code>向<code>23,24,26</code>求援，那么<code>23,24,26</code>明显有“余粮”，就会触发租借元素的情况。</li>
<li><code>23,24,26</code>不能直接将任意一个元素放到<code>29</code>中来，<code>23,24,26</code>任意元素都比28元素小，如果放置在28元素的右子节点上，就违背了左小右大的原则。</li>
<li>那怎么借呢？既然两个当事人<code>23,24,26</code>和<code>29</code>分别是28元素的左右子节点，那就让28元素进入<code>29</code>，26元素替代28元素的位置，这样就皆大欢喜了。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-7e820bffda4330e8a49b4f6dcfe7761c2ad.png" alt=""></li>
</ul>
</li>
<li><p><strong>元素合并</strong></p>
<ul>
<li>重申一下， <strong>元素顶替</strong>操作结束后，B树长这样</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-85fdbd40c1a754b1940a8c3edf02992f702.png" alt=""></li>
<li>假如<code>29</code>向<code>31,32</code>求援，那么<code>31,32</code>明显没有“余粮”，那么就会引发<strong>元素合并</strong>的情况。</li>
<li><code>29</code>和<code>31,32</code>不能直接合并，因为30元素还在父节点上，按照左小右大的原则，30元素一定要在29元素和31元素之间</li>
<li>那怎么合并呢？既然两个当事人 <code>29</code>和<code>31,32</code>分别是30元素的左右子节点，那就让30元素与<code>29</code>和<code>31,32</code>一起加入合并，这样就皆大欢喜了。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-ff3953493f06bb17b382e8bc1a3d38adf6a.png" alt=""></li>
</ul>
</li>
</ol>
<hr>
<p>这就结束了么？不是的，大家注意到没有，合并元素操作，其实相当于在父节点中删去了一个元素，如果这一次的删除，导致了父节点的元素数量小于ceil(m/2)-1怎么办？</p>
<p>我们来看这种情况，现在我们的原图长这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ff3953493f06bb17b382e8bc1a3d38adf6a.png" alt=""></p>
<ol>
<li><p>接着删除key为40的记录，删除后结果如下图所示。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-7459240a23aa224c93bbfb382960001664c.png" alt=""></li>
</ul>
</li>
<li><p>删完后就剩39一个元素了，没话说，找个兄弟节点合并呗，合并结果如下，可以看到，对于原来的<code>36,41</code>节点来说，相当于36元素被删除了，导致<code>41</code>节点不符合约束。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-752976b81e53a4afd84139727851c16e5a3.png" alt=""></li>
</ul>
</li>
<li><p>这时候，其实有两种策略</p>
<ul>
<li>一种是采用<strong>元素顶替</strong>操作：删了我的36，那就拿39顶替呗。</li>
<li>还有一种是向兄弟节点<code>22,26</code>求援，这时要根据兄弟节点的“余粮”情况，酌情触发<strong>元素合并</strong>或者<strong>元素租借</strong>。</li>
<li>那到底是采用第一种方案好还是第二种方案好呢？</li>
<li><strong>答案是第二种，因为第二种情况，可能触发元素合并</strong>，只要触发元素合并，就有可能降低树的高度，使得B树不仅平衡，而且更加“矮胖”，使查找效率更高。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-71b65cb9f29444227d3fbb8a8e9b84d9130.png" alt=""></li>
</ul>
</li>
</ol>
<blockquote>
<p>所以总结一句话，因为元素合并导致的父节点元素数量不符合约束，执行策略时，优先向可能触发<strong>元素合并</strong>的方向靠拢，有利于使树的高度降低。</p>
</blockquote>
<h2 id="1-4-B树的优点"><a href="#1-4-B树的优点" class="headerlink" title="1.4 B树的优点"></a>1.4 B树的优点</h2><p>如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。</p>
<h1 id="2-B-树"><a href="#2-B-树" class="headerlink" title="2. B+树"></a>2. B+树</h1><p>B-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。</p>
<p>B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。为什么说B+树查找的效率要比B树更高、更稳定；我们先看看两者的区别：</p>
<ol>
<li>B+树的<strong>非叶子节点不保存关键字记录的指针</strong>，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加；</li>
<li>B+树<strong>叶子节点保存了父节点的所有关键字记录的指针</strong>，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样；</li>
<li>B+树<strong>叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针</strong>。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-d16ff524d920d5b2a808b41aedbd6c256b5.png" alt=""></p>
<h2 id="2-1-B-树的插入"><a href="#2-1-B-树的插入" class="headerlink" title="2.1 B+树的插入"></a>2.1 B+树的插入</h2><p>B+树的插入操作和B树的插入操作大同小异，即都满足：</p>
<ol>
<li>还是按照key递增次序排列，遵循左小右大的原则，在叶子节点上找到新元素的定位。</li>
<li>若插入时，插入的节点元素个数小于m-1，则该元素直接插入。</li>
<li>否则，将该节点的元素分裂。</li>
</ol>
<p>但B+树的叶子节点，会包含所有的元素（不像B树，有些元素在叶子节点上，有些元素在非叶子节点上），所以插入操作有一些许的差异。</p>
<p>我们下面还是以5阶B+树为例子，在5阶B+树中，结点最多有4个元素，最少有2个元素。</p>
<ol>
<li><p>空树中插入5：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-533ee1cfa033ba1ce6dd6e4fc9af90c2d7e.png" alt=""></li>
</ul>
</li>
<li><p>依次插入8，10，15：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-dd36b3e0400e00aea397caac07683e5014a.png" alt=""></li>
</ul>
</li>
<li><p>插入16，</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-22a6217fb1ebcb7245d74fb5b4b92659a2e.png" alt=""></li>
<li>这时超过了关键字的个数限制，所以要进行分裂。在叶子结点分裂时，分裂出来的左节点2个记录，右节点3个记录，中间key成为索引结点中的key，分裂后当前节点指向了父节点（根节点）。结果如下图所示：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-f03ece76b29d638675bbc7c937b7b34ee73.png" alt=""></li>
<li><blockquote>
<p>当然我们还有另一种分裂方式，给左结点3个记录，右结点2个记录，此时索引结点中的key就变为15。不同实现而已，本质差不多。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>继续插入17</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-d0a8d9b2c71ffd1a692dd88fc44ec6bca10.png" alt=""></li>
</ul>
</li>
<li><p>插入18，插入后当前节点的关键字个数大于5，进行分裂。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-0ea3104f7c970ceb6bba681de50de17f63d.png" alt=""></li>
<li>分裂成两个节点，左节点2个记录，右节点3个记录，关键字16进位到父节点（索引类型）中，将当前结点的指针指向父结点。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-f92dccd11f24b2ddbb8200c36386da6375d.png" alt=""></li>
</ul>
</li>
<li><p>插入若干数据后：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-40118bf9f9ac718d72d7512dab23e9e83d7.png" alt=""></li>
</ul>
</li>
<li><p>在上图中插入7，结果如下图所示</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-d9bcc83498f32e2b879edfef356dafcaa62.png" alt=""></li>
<li>此时当前节点的关键字个数超过4，需要分裂。左节点2个记录，右节点3个记录。分裂后关键字7进入到父节点中，将当前结点的指针指向父节点</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-24fbbe8a4fa67721cc8a833a73f4d097ec8.png" alt=""></li>
<li>当前结点的关键字个数超过4，需要继续分裂。左结点2个关键字，右结点2个关键字，关键字16进入到父结点中，将当前结点指向父结点，结果如下图所示：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-c2532b2da7da86911713593d79715fbc13f.png" alt=""></li>
</ul>
</li>
</ol>
<h2 id="2-2-B-树的删除"><a href="#2-2-B-树的删除" class="headerlink" title="2.2 B+树的删除"></a>2.2 B+树的删除</h2><p>回顾上文的B树的删除，我们知道B树有元素直删，元素租借，元素合并和元素顶替这四个操作场景，B+树与B树大同小异，几乎没有区别。只不过B+树没有元素顶替</p>
<blockquote>
<p>B+树没有元素顶替，是因为B+树的叶子节点，有所有的键值对信息，所以不存在删除的键值对不是叶子节点的情况。</p>
</blockquote>
<p>我们下面还是以5阶B+树为例子，在5阶B+树中，结点最多有4个元素，最少有2个元素。</p>
<p>初始状态如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7a9ce40e582bd61f21ceea7a2c5c425afc3.png" alt=""></p>
<ol>
<li><p><strong>元素直删</strong></p>
<ul>
<li>在上图基础上删除22</li>
<li>删除后叶子结点中key的个数大于等于2，删除结束</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-cab4eaee78777158a52dca0e9a554519d4a.png" alt=""></li>
</ul>
</li>
<li><p><strong>元素租借</strong></p>
<ul>
<li>在元素直删完了之后的基础上，再删除15，得到下图：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-ccdd113bc8eaa609f57b6b27d1f8e094971.png" alt=""></li>
<li>删除后当前结点只有一个元素，不满足条件，而兄弟结点有三个元素（注意，当前节点的兄弟节点只有<code>[7,8,9]</code>），则可以向兄弟节点借一个元素过来。当然，根据排序原则，只能借9。</li>
<li>9元素去到<code>[10]</code>节点之后，那么索引也要相应的更改，否则也不满足排序原则，即原来非叶子节点中的10改为9：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-48d63a5170d2cece2d2e75cdabbd24d0cf9.png" alt=""></li>
</ul>
</li>
<li><p><strong>元素合并</strong></p>
<ul>
<li>在元素租借完了之后，我们再删除7，删除后的结果如下图所示：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-ea526d3b627c7f71a782ceec9b797b1da95.png" alt=""></li>
<li>可以看到，删除完了以后，当前节点元素个数小于2，且左右节点的元素数量都是2，即都没有富余的元素。</li>
<li>这时候我们选择元素合并，可以选择和左兄弟合并，也可以和右兄弟合并，这里我们选择左兄弟。</li>
<li>合并的时候我们前文说过，为了保证顺序，兄弟节点还会将父节点中对应的元素一起纳入合并，即<code>[5,6]</code>、<code>[8]</code>会和父节点中的7一起合并，不过这次删除的是7，所以7不存在了，故而，得到：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-bd7d531937d2ff85149f47b4cfa4abd8e33.png" alt=""></li>
<li>不过注意，因为7索引的删除，导致了父节点只剩下了一个元素9，这显然不符合数量约束。</li>
<li><code>[9]</code>的兄弟节点也没有余粮，则只能拉着父节点的元素16，和右兄弟<code>[18,20]</code>合并。得到下图：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-800c466ff5b23af3ababd1500a297fb1fc2.png" alt=""></li>
</ul>
</li>
</ol>
<blockquote>
<p>其实说是没有元素顶替，但为了便于理解，也可以用元素顶替的思路来看最后这个删除操作：<br>1.因为删除的是7，7也在非叶子节点上，所以7删除了，要从子节点中找一个元素来顶替。<br>2.不论是8顶替上去还是6顶替上去，都会使得有个子节点数量不符合，触发元素合并。<br>3.这时候左右节点的元素+他们关联的父节点的元素合并，得到的结果，还是<code>[5,6,8]</code></p>
</blockquote>
<h2 id="2-3-B-树的优点"><a href="#2-3-B-树的优点" class="headerlink" title="2.3 B+树的优点"></a>2.3 B+树的优点</h2><ol>
<li><p>B+树的层级更少：相较于B树，B+每个非叶子节点存储的元素数更多（因为B+树的非叶子节点不存data，相同容量下可容纳的元素更多），使得B+树相对于B树更加“矮胖”，即B+树的层级更少<strong>所以查询数据更快</strong>；</p>
</li>
<li><p>B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定。不像B树，有时候在非叶子节点上找到，那就相对快，有时候在叶子节点上找到，那就相对慢。</p>
</li>
<li><p>B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。</p>
</li>
<li><p>B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。</p>
</li>
</ol>
<h2 id="2-4-为什么B-树比B树更适合做数据库索引？"><a href="#2-4-为什么B-树比B树更适合做数据库索引？" class="headerlink" title="2.4 为什么B+树比B树更适合做数据库索引？"></a>2.4 为什么B+树比B树更适合做数据库索引？</h2><p>其实理由也正是基于上诉的优势而言，不过我们把语义按照数据库索引适配性的角度转化一下：</p>
<ol>
<li><p>B+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。</p>
</li>
<li><p>B+树的查询效率更加稳定：由于非叶节点并不是最终指向文件内容的节点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根节点到叶子节点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。</p>
</li>
<li><p>对范围查询的适配性好：在数据库中基于范围的查询是非常频繁的，B树不支持这样的操作或者说效率太低。而B+树只需要去遍历叶子节点的链表，就可以实现整棵树的范围查询。</p>
</li>
<li><p>全节点遍历更快：由于B+树的数据都存储在叶子节点中，分支节点均为索引，方便扫库，只需要扫一遍叶子节点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。</p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/09/Redis%E7%9A%84%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/09/Redis%E7%9A%84%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E4%BB%8B%E7%BB%8D/" itemprop="url">Redis的缓存雪崩/缓存穿透/缓存预热+布隆过滤器介绍</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-09T23:10:36+08:00">
                2020-04-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index">
                    <span itemprop="name">中间件</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/04/09/Redis%E7%9A%84%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E4%BB%8B%E7%BB%8D/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/04/09/Redis的缓存雪崩-缓存穿透-缓存预热-布隆过滤器介绍/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Redis作为当下最主流的数据缓存中间件，在实际的运作过程中，有如下几个场景需要特别注意：</p>
<h1 id="1-缓存雪崩"><a href="#1-缓存雪崩" class="headerlink" title="1. 缓存雪崩"></a>1. 缓存雪崩</h1><ul>
<li>有时：<ul>
<li>缓存<strong>集中</strong>过期失效。(例如：我们短时间设置大量数据的缓存时采用了相同的过期时间，就会在同一时刻出现<strong>大面积</strong>的缓存过期)</li>
</ul>
</li>
<li>由于<ul>
<li>大量的原本应该访问缓存的请求都因为缓存失效而降级到查询数据库了</li>
</ul>
</li>
<li>导致<ul>
<li>短时间内对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。</li>
</ul>
</li>
<li>解决办法<ul>
<li>加锁：大多数系统设计者考虑用加锁（ 最多的解决方案）或者请求队列的方式来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。</li>
<li>分散过期时间：还有一个简单方案就是将缓存失效时间分散开，比如加一个随机因子，使过期时间离散。</li>
</ul>
</li>
</ul>
<h1 id="2-缓存穿透"><a href="#2-缓存穿透" class="headerlink" title="2. 缓存穿透"></a>2. 缓存穿透</h1><p>缓存穿透又叫缓存击穿</p>
<ul>
<li>有时：<ul>
<li>请求查询一个数据库不存在的数据</li>
</ul>
</li>
<li>由于<ul>
<li>我们查询数据库结果为空的时候，不会把这个空结果放入缓存</li>
</ul>
</li>
<li>导致<ul>
<li>每次查询一个不存在的数据，都不会命中缓存（因为这样的缓存不存在）。促使请求都会降级到数据库上，就像缓存被击穿了一样。</li>
<li>假如有恶意攻击，就可以利用这个漏洞，对数据库造成压力，甚至压垮数据库。即便是采用UUID，也是很容易找到一个不存在的KEY，进行攻击。</li>
</ul>
</li>
<li>解决办法<ul>
<li>缓存空值：如果从数据库查询的对象为空，也放入缓存，只是设定的缓存过期时间较短，比如设置为60秒。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-285596d7081eb41f0b086b576e3c8c9f2dc.png" alt=""></li>
</ul>
</li>
<li><strong>布隆过滤器（Bloom Filter）</strong>：推荐！将所有可能存在的key都插入到Bloom Filter中，这样肯定不存在的key就可以被Bloom Filter过滤。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-bbe545bafc0b2bd1db268f4236a6779dd05.png" alt=""></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="2-1-布隆过滤器"><a href="#2-1-布隆过滤器" class="headerlink" title="2.1 布隆过滤器"></a>2.1 布隆过滤器</h2><p>布隆过滤器（Bloom Filter）由Burton Howard Bloom在1970年提出，是一种<strong>空间效率高的概率型数据结构</strong>。它专门用来<strong>快速判断一个元素是否在一个集合中</strong>。听起来是很稀松平常的需求，为什么要使用BF这种数据结构呢？</p>
<h3 id="2-1-1-背景"><a href="#2-1-1-背景" class="headerlink" title="2.1.1 背景"></a>2.1.1 背景</h3><p>回想一下，我们平常在检测集合中是否存在某元素时，都会采用比较的方法。考虑以下情况：</p>
<ul>
<li>如果集合用线性表存储，查找的时间复杂度为<code>O(n)</code>。</li>
<li>如果用平衡BST（如AVL树、红黑树）存储，时间复杂度为<code>O(logn)</code>。</li>
<li>如果用哈希表存储，并用链地址法与平衡BST解决哈希冲突（参考JDK8的HashMap实现方法），时间复杂度也要有<code>O[log(n/m)]</code>，m为哈希分桶数。</li>
</ul>
<p>总而言之，当集合中元素的数量极多时，不仅查找会变得很慢，而且占用的空间也会大到无法想象。Bloom Filter就是解决这个矛盾的利器。</p>
<h3 id="2-1-2-原理"><a href="#2-1-2-原理" class="headerlink" title="2.1.2 原理"></a>2.1.2 原理</h3><ul>
<li><p>Bloom Filter是由一个长度为m的bit数组（bit array）与k个哈希函数（hash function）组成的数据结构。bit数组均初始化为0，所有哈希函数都可以分别把输入数据尽量均匀地散列。</p>
<ul>
<li><p>如下图：假设m=10，k=2，即有f1和f2两个哈希函数。</p>
</li>
<li><p><img src="https://oscimg.oschina.net/oscnet/up-d44d0129d59f8e447fc3a001b8b812ee5f7.png" alt=""></p>
</li>
</ul>
</li>
<li><p>当要插入一个元素时，将其数据分别输入k个哈希函数，产生k个哈希值。以哈希值作为位数组中的下标，将所有k个对应的比特置为1。</p>
<ul>
<li>如下图，假设输入的数据是N1，经过计算f1(N1)得到的数值得为2，f2(N1)得到的数值为5，则将数组下标为2和下表为5的位置置为1</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-f206e03a7c921beb284aecceef5f23c15bc.png" alt=""></li>
</ul>
</li>
<li><p>当要查询（即判断是否存在）一个元素时，同样将其数据输入哈希函数，然后检查对应的k个比特。如果有任意一个比特为0，表明该元素一定不在集合中。如果所有比特均为1，表明该集合有（较大的）可能性在集合中。</p>
<ul>
<li>假设这时候查询N存不存在，将其带入f1和f2，得到结果r1和r2，分别检查r1和r2下标对应的bit数组元素值，假设为b1和b2<ul>
<li>b1和b2有任意一个比特为0，表明该元素一定不在集合中。</li>
<li>b1和b2均为1，表明该集合有（较大的）可能性在集合中。</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>为什么不是一定在集合中呢？因为一个比特被置为1有可能会受到其他元素的影响，这就是所谓“假阳性”（false positive）。相对地，“假阴性”（false negative）在BF中是绝不会出现的。</p>
</blockquote>
<p>下图示出一个m=18, k=3的BF示例。集合中的x、y、z三个元素通过3个不同的哈希函数散列到位数组中。当查询元素w时，因为有一个比特为0，因此w不在该集合中。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-84458ab74b6816feec64b038c115d9b28e3.png" alt=""></p>
<h3 id="2-1-3-优缺点"><a href="#2-1-3-优缺点" class="headerlink" title="2.1.3 优缺点"></a>2.1.3 优缺点</h3><p>BF的优点是显而易见的：</p>
<ol>
<li>不需要存储数据本身，只用比特表示，因此空间占用相对于传统方式有巨大的优势，并且能够保密数据；</li>
<li>时间效率也较高，插入和查询的时间复杂度均为O(k)；</li>
<li>哈希函数之间相互独立，可以在硬件指令层面并行计算。</li>
</ol>
<p>但是，它的缺点也同样明显：</p>
<ol>
<li>存在假阳性的概率，不适用于任何要求100%准确率的情境；（缓存击穿就不需要100%过滤不存在的key，所以适合）</li>
<li>只能插入和查询元素，不能删除元素，这与产生假阳性的原因是相同的。我们可以简单地想到通过计数（即将一个比特扩展为计数值）来记录元素数，但仍然无法保证删除的元素一定在集合中。</li>
</ol>
<p>所以，Bloom Filter在对查准度要求没有那么苛刻，而对时间、空间效率要求较高的场合非常合适，另外，由于它不存在假阴性问题，所以用作“不存在”逻辑的处理时有奇效。目前来看，他有如下三个使用场景:</p>
<ul>
<li>网页爬虫对URL的去重，避免爬取相同的URL地址</li>
<li>反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱（同理，垃圾短信）</li>
<li>缓存穿透，将所有可能存在的数据缓存放到布隆过滤器中，当黑客访问不存在的缓存时迅速返回避免缓存及DB挂掉。</li>
</ul>
<h3 id="2-1-4-假阳性率的计算"><a href="#2-1-4-假阳性率的计算" class="headerlink" title="2.1.4 假阳性率的计算"></a>2.1.4 假阳性率的计算</h3><p>假阳性是Bloom Filter最大的痛点，因此有必要权衡，比如计算一下假阳性的概率。为了简单一点，就假设我们的哈希函数选择位数组中的比特时，都是等概率的。当然在设计哈希函数时，也应该尽量满足均匀分布。</p>
<ul>
<li><p>在位数组长度m的BF中插入一个元素，它的其中一个哈希函数会将某个特定的比特置为1。因此，在插入元素后，该比特仍然为0的概率是：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-c6d9536a6350ebd08be15c8777a21b5d5a2.png" alt=""></li>
</ul>
</li>
<li><p>现有k个哈希函数，并插入n个元素，自然就可以得到该比特仍然为0的概率是：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-e7078b9bc6588c968d8027e79bd5d782915.png" alt=""></li>
</ul>
</li>
<li><p>反过来讲，它已经被置为1的概率就是：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-83013d18edb412ecc14882fe8bd098a2946.png" alt=""></li>
</ul>
</li>
<li><p>也就是说，如果在插入n个元素后，我们用一个不在集合中的元素来检测，那么被误报为存在于集合中的概率（也就是所有哈希函数对应的比特都为1的概率）为：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-948420588b11a4ab1cabb542d33676a7aa0.png" alt=""></li>
</ul>
</li>
<li><p>当n比较大时，根据重要极限公式，可以近似得出假阳性率：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-9ab7a60f7a6e8918ac55b27afe328f8a999.png" alt=""></li>
</ul>
</li>
</ul>
<p>所以，在哈希函数的个数k一定的情况下：</p>
<ul>
<li>位数组长度m越大，假阳性率越低；</li>
<li>已插入元素的个数n越大，假阳性率越高。</li>
</ul>
<blockquote>
<p>有一些框架内已经内建了BF的实现，免去了自己实现的烦恼。比如Guava 27.0.1版本的源码，BF的具体逻辑位于com.google.common.hash.BloomFilter类中</p>
</blockquote>
<h1 id="3-缓存预热"><a href="#3-缓存预热" class="headerlink" title="3. 缓存预热"></a>3. 缓存预热</h1><ul>
<li>定义<ul>
<li>缓存预热是一个比较常见的概念，即系统上线后，将相关的缓存数据直接加载到缓存系统。这样用户就可以直接查询事先被预热的缓存数据，避免在用户请求的时候，先查询数据库，然后再将数据缓存。</li>
</ul>
</li>
</ul>
<ul>
<li>解决思路<ol>
<li>直接写个缓存刷新开关，上线时手工操作下；</li>
<li>数据量不大，可以在项目启动的时候自动进行加载；</li>
<li>定时刷新缓存；</li>
</ol>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/08/TCP%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/08/TCP%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/" itemprop="url">TCP协议分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-08T22:01:51+08:00">
                2020-04-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机协议和技术</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%8A%80%E6%9C%AF/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/" itemprop="url" rel="index">
                    <span itemprop="name">网络协议</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/04/08/TCP%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/04/08/TCP协议分析/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  16.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  59
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-TCP协议概述"><a href="#1-TCP协议概述" class="headerlink" title="1. TCP协议概述"></a>1. TCP协议概述</h1><p>TCP协议，全称Transmission Control Protocol（传输控制协议），是一种<strong>全双工通信</strong>、<strong>面向连接的</strong>、<strong>可靠的</strong>、<strong>基于字节流的</strong>传输层通信协议。</p>
<ol>
<li><p>全双工通信：即建立TCP连接之后，通信双方都可以发送数据。</p>
</li>
<li><p>面向连接：意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。</p>
<ul>
<li>这一过程与打电话很相似，先拨号振铃，等待对方摘机说“喂”，然后才说明是谁。</li>
</ul>
</li>
<li><p>可靠：IP层并不保证数据报一定被正确地递交到接收方，TCP负责在超时或者传输失败后，重传没有递交成功的数据报。</p>
<ul>
<li>即使被正确递交的数据报，也可能存在错序的问题，这也是TCP的责任，它必须把接收到的数据报重新装配成正确的顺序。</li>
</ul>
</li>
<li><p>基于字节流：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序传来的数据块看成是一连串的无结构的字节流。由TCP传递给IP的信息单位称为报文段或段（segment）</p>
<ul>
<li>TCP有一个缓冲，TCP发送报文时，是将应用层数据写入TCP缓冲区中，然后由TCP协议来控制发送这里面的数据，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。如果应用程序一次只发送一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。</li>
<li>发送的状态是按字节流的方式发送的，跟应用层写下来的报文长度没有任何关系，所以说是流。</li>
</ul>
</li>
</ol>
<blockquote>
<p>面向字节流的概念，打个比方：<br>一个蓄水池，有出水口和进水口，开几次进水口和开几次出水口是没有必然联系的，也就是说你可以只进一次水，然后分10次出完（即一次write，可以分10次read读取）。另外，水池里的水接多少就会少多少；往里面进多少水，就会增加多少水，但是不能超过水池的容量，多出的水会溢出。</p>
</blockquote>
<p>同时，作为网络协议中举足轻重的传输层协议，TCP协议有这些优秀的机制保证其最为重视的数据可靠性：</p>
<ol>
<li>超时重传</li>
<li>拥塞处理</li>
<li>滑动窗口</li>
</ol>
<p>我们将在后面的篇幅中介绍他们。</p>
<h2 id="1-1-TCP和UDP的区别"><a href="#1-1-TCP和UDP的区别" class="headerlink" title="1.1 TCP和UDP的区别"></a>1.1 TCP和UDP的区别</h2><p>和UDP相比，TCP协议有如下差异：</p>
<table>
<thead>
<tr>
<th>TCP</th>
<th>UDP</th>
</tr>
</thead>
<tbody><tr>
<td>面向连接（如打电话要先拨号建立连接）</td>
<td>无连接（发送数据之前不需要建立连接）</td>
</tr>
<tr>
<td>传输可靠（通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达）</td>
<td>传输不可靠（尽最大努力交付，即不保证可靠交付）</td>
</tr>
<tr>
<td>面向字节流（把数据看成一连串无结构的字节流）</td>
<td>面向报文（无脑传递上下层的报文）</td>
</tr>
<tr>
<td>适合传输大量数据</td>
<td>适合传输少量数据</td>
</tr>
<tr>
<td>全双工的可靠信道</td>
<td>不可靠信道</td>
</tr>
<tr>
<td>首部开销20字节</td>
<td>首部开销8个字节</td>
</tr>
<tr>
<td>连接只能是点到点</td>
<td>支持一对一，一对多，多对一和多对多的交互通信</td>
</tr>
<tr>
<td>速度慢（需要建立连接、发送确认包等））</td>
<td>速度快</td>
</tr>
<tr>
<td>对系统资源的要求较多</td>
<td>对系统资源的要求较少</td>
</tr>
</tbody></table>
<h2 id="1-2-TCP协议应用场景"><a href="#1-2-TCP协议应用场景" class="headerlink" title="1.2 TCP协议应用场景"></a>1.2 TCP协议应用场景</h2><p>TCP协议是运输层协议，其服务对象自然是应用层。</p>
<p>TCP主要应用在：要求通信数据可靠时，即数据要准确无误地传递给对方如：</p>
<ol>
<li>传输文件：HTTP、HTTPS、FTP等协议；</li>
<li>传输邮件：POP、SMTP等协议</li>
<li>万维网：HTTP协议</li>
<li>文件传输：FTP协议</li>
<li>电子邮件：SMTP协议</li>
<li>远程终端接入：TELNET协议</li>
</ol>
<h2 id="1-3-如何保证可靠性"><a href="#1-3-如何保证可靠性" class="headerlink" title="1.3 如何保证可靠性"></a>1.3 如何保证可靠性</h2><p>TCP通过下列方式来提供可靠性：</p>
<ol>
<li><p>缓冲区：基于缓冲区，应用数据被分割成TCP认为最适合发送的数据块。</p>
</li>
<li><p>超时重传：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。</p>
</li>
<li><p>接收确认：当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒。</p>
</li>
<li><p>校验：TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段（希望发端超时并重发）。</p>
</li>
<li><p>重新排序：既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。如果必要，TCP将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层。</p>
</li>
<li><p>既然IP数据报会发生重复，TCP的接收端必须丢弃重复的数据。</p>
</li>
<li><p>TCP还能提供流量控制。TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲区溢出。</p>
</li>
</ol>
<h2 id="1-4-TCP连接的实质"><a href="#1-4-TCP连接的实质" class="headerlink" title="1.4 TCP连接的实质"></a>1.4 TCP连接的实质</h2><p>我们都知道TCP是面向连接的服务，所有要通过TCP进行通信的应用都要先建立连接才能通信，在通信完毕之后要记得关闭连接。但是TCP连接到底是什么东西呢？</p>
<p>这里先说结论，连接实际上是操作系统内核的一种数据结构，称为TCP控制块（TCB），对于linux而言是tcp_sock结构。不光连接，连数据包也是由一个数据结构来控制，linux里面称为sk_buff结构。</p>
<h3 id="1-4-1-为什么要有TCB"><a href="#1-4-1-为什么要有TCB" class="headerlink" title="1.4.1 为什么要有TCB"></a>1.4.1 为什么要有TCB</h3><ul>
<li><p>当应用希望写数据时，</p>
<ul>
<li>不是直接向网卡驱动发数据，而是经过先放入到一个socket发送缓冲区中</li>
<li>然后根据一定算法（达到一定数量或者调用flush之后），缓冲区中的数据就会被网卡从缓冲区中拷贝出来，再层层封装，最后经过物理层传输。</li>
</ul>
</li>
<li><p>当网卡收到数据时</p>
<ul>
<li>会通过DMA直接发送到内存缓冲区中（网卡驱动提前向操作系统申请的一块内存，并且驱动会提前告诉网卡这块内存的地址（注意是物理地址）和大小。如果没有这块内存缓冲区，那么网卡会直接将数据丢掉）</li>
<li>然后给CPU发送一个中断信号，通知操作系统一个数据包到了。</li>
<li>数据包要先经过校验，分用等操作，到了TCP层，处理程序此时根据TCP首部中的端口号选择一个socket，并将其载荷数据拷贝进socket接收缓冲区。</li>
<li>根据TCP首部中的端口号选择一个socket，如何选择呢？这里TCP是利用连接<strong>四元组&lt;源IP地址，源端口号，目标IP地址，目标端口号&gt;</strong>，并以这个四元组为key，查找hash表找到对应的socket的socket结构指针，并利用该指针找到对应socket的接收缓冲区，并将载荷数据拷贝进去。</li>
</ul>
</li>
</ul>
<blockquote>
<p>所以到这里，我们就应该知道，每个socket结构必须要有自己独立的发送缓冲区和接收缓冲区</p>
</blockquote>
<h3 id="1-4-2-什么是Socket"><a href="#1-4-2-什么是Socket" class="headerlink" title="1.4.2 什么是Socket"></a>1.4.2 什么是Socket</h3><p>socket是什么呢，实际上socket是对TCP/IP协议的封装，它的出现只是使得程序员更方便地使用TCP/IP协议栈而已。socket本身并不是协议，它是<strong>应用层与TCP/IP协议族通信的中间软件抽象层，是一组调用接口（TCP/IP网络的API函数）</strong></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-238e16f14108123af496a6e952926908689.png" alt=""></p>
<p>或者换句话说，<strong>socket是TCP/IP协议实现的封装，和暴露给应用层的函数</strong>。他将网络底层复杂的实现统统隐藏，给应用程序方便的使用接口。</p>
<p>在网络通信方面，socket也有很多种，根据不同协议的实现，也有TCP通信的Socket，UDP通信的DatagramSocket，以及与SSL相关JSSE中的SSLSocket，以及这些非阻塞的SocketChannel,DatagramChannel,SSLEngine在安全方面，JCA,JCE,JAAS等等</p>
<h3 id="1-4-3-HTTP短连接和长连接"><a href="#1-4-3-HTTP短连接和长连接" class="headerlink" title="1.4.3 HTTP短连接和长连接"></a>1.4.3 HTTP短连接和长连接</h3><p>对于HTTP 1.0的http标准而言，默认连接是短连接，什么是短连接？就是服务器当发送完最后一个字节的数据之后将关闭连接，也就是回收tcp_sock结构，这样，如果客户端再发送数据给服务器，将直接丢弃。即使此时客户端还有这样的结构，但是我们说连接已经关闭或者已经断了。</p>
<p>HTTP 1.1引入了长连接的概念，并把它搞成了默认的连接方式。什么是长连接？就是当完成一个业务之后，socket结构并不回收。这样，只要在socket结构还存在的时候，客户端发送的任何数据，服务器都可以收到，这就是所谓的长连接。</p>
<h1 id="2-TCP的首部"><a href="#2-TCP的首部" class="headerlink" title="2. TCP的首部"></a>2. TCP的首部</h1><p>TCP数据被封装在一个IP数据报中</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7c3a2ac388604594ca4646e53a3c1dbc488.png" alt=""></p>
<blockquote>
<p>注意：TCP的包是没有IP地址的，那是IP层上的事。TCP只负责源端口和目标端口的维护。</p>
</blockquote>
<h2 id="2-1-源端口和目的端口"><a href="#2-1-源端口和目的端口" class="headerlink" title="2.1 源端口和目的端口"></a>2.1 源端口和目的端口</h2><p><strong>源端口</strong>和<strong>目的端口</strong>：各占16位2个字节，分别存放源端口号和目的端口号。用于寻找发端和收端应用进程。这两个值加上IP首部中的源端IP地址和目的端IP地址，能唯一确定一个TCP连接。</p>
<h2 id="2-2-序号"><a href="#2-2-序号" class="headerlink" title="2.2 序号"></a>2.2 序号</h2><p><strong>序号</strong>：简称seq（sequence number），占32位4个字节。序号范围是[0，2^32 - 1]，共2^32 （即4294967296）个序号。序号增加到2^32-1后，下一个序号就又回到0。</p>
<ul>
<li>TCP是面向字节流的。在一个TCP连接中传送的字节流中的每一个<strong>字节</strong>都按顺序编号。</li>
<li>TCP会话建立后，会话的<strong>每一端</strong>都自己维护一个32位（bit）的序号，该序号被用来跟踪该端发送的数据量。这个端每发送一个字节的数据，它维护的序号+1；</li>
<li><strong>当一个TCP会话开启时，它两端的初始序号都是随机的，可能是0和2^32 - 1(即4,294,967,295)之间的任意值</strong></li>
<li>TCP会话的某一端在发送报文段时，会将计算出的报文段<strong>数据</strong>的第一个字节的序号写入首部的序号字段中。</li>
<li>首部中的序号字段值则是指的是<strong>本报文段所发送的数据的第一个字节的序号</strong>。</li>
<li>例如，一报文段的序号是301，而数据共有100字节。这就表明：本报文段的数据的第一个字节的序号是301，最后一个字节的序号是400。<ul>
<li>显然，下一个报文段（如果还有的话）的数据序号应当从401开始，即下一个报文段的序号字段值应为401。这个字段的序号也叫“报文段序号”。</li>
</ul>
</li>
</ul>
<blockquote>
<p>TCP会话建立后，每一端都要各自初始化一个seq，<strong>这个初始的seq称作ISN（Inital Sequence Number）</strong></p>
</blockquote>
<blockquote>
<p>TCP会话的任意端的ISN为什么要是随机的而不是写死的呢？试想：假如连接建好后始终用1来做ISN，如果client发了30个segment过去，但是网络断了，于是 client重连，又用了1做ISN，但是之前连接的那些包到了，于是就被当成了新连接的包，此时，client的Sequence Number 可能是3，而Server端认为client端的这个号是30了。全乱了。</p>
</blockquote>
<blockquote>
<p>RFC793中说，ISN会和一个假的时钟绑在一起，这个时钟会在每4微秒对ISN做加一操作，直到超过2^32，又从0开始。这样，一个ISN的周期大约是4.55个小时。因为，我们假设我们的TCP Segment在网络上的存活时间不会超过Maximum Segment Lifetime（缩写为MSL – Wikipedia语条），所以，只要MSL的值小于4.55小时，那么，我们就不会重用到ISN。</p>
</blockquote>
<h2 id="2-3-确认号"><a href="#2-3-确认号" class="headerlink" title="2.3 确认号"></a>2.3 确认号</h2><p><strong>确认号</strong>：简称Ack（acknowledgement number），占32位4个字节，是期望收到对方下一个报文段的第一个数据字节的序号。仅当控制位ACK = 1时确认号字段才有效。</p>
<ul>
<li>例如，B正确收到了A发送过来的一个报文段，其序号字段值是501，而数据长度是200字节（序号501~700），这表明B正确收到了A发送的到序号700为止的数据。</li>
<li>因此，B期望收到A的下一个数据序号是701，于是B在发送给A的确认报文段中把确认号置为701。注意，现在确认号不是501，也不是700，而是701。</li>
<li>总之：B给A发送的报文确认号为= N，则表明：到序号N-1为止的所有数据B都已正确收到。</li>
</ul>
<blockquote>
<p>确认号（acknowledgement number）简称Ack序号，不要将确认序号Ack与下面即将介绍的控制位中的ACK搞混了。</p>
</blockquote>
<h2 id="2-4-数据偏移"><a href="#2-4-数据偏移" class="headerlink" title="2.4 数据偏移"></a>2.4 数据偏移</h2><p><strong>数据偏移</strong>：占32位4个字节，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远。这个字段实际上是指出TCP<strong>报文段的首部长度</strong>。</p>
<ul>
<li>由于首部中还有长度不确定的选项字段，因此数据偏移字段是必要的，但应注意，“数据偏移”的单位是32位字（即以4字节的字为计算单位）。</li>
<li>由于4位二进制数能表示的最大十进制数字是15，因此数据偏移的最大值是60字节，这也是TCP首部的最大字节（即选项长度不能超过40字节）。<h2 id="2-4-保留"><a href="#2-4-保留" class="headerlink" title="2.4 保留"></a>2.4 保留</h2></li>
</ul>
<p><strong>保留</strong>：占6位，保留为今后使用，但目前应置为0 。</p>
<h2 id="2-6-6个控制位"><a href="#2-6-6个控制位" class="headerlink" title="2.6 6个控制位"></a>2.6 6个控制位</h2><p><strong>6个控制位</strong>：用来说明本报文段的性质。</p>
<ol>
<li><p><strong>紧急URG（URGent）</strong> 当URG=1时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快发送（相当于高优先级的数据），而不要按原来的排队顺序来传送。</p>
<ul>
<li>例如，已经发送了很长的一个程序要在远地的主机上运行。但后来发现了一些问题，需要取消该程序的运行，因此用户从键盘发出中断命令。如果不使用紧急数据，那么这两个字符将存储在接收TCP的缓存末尾。只有在所有的数据被处理完毕后这两个字符才被交付接收方的应用进程。这样做就浪费了很多时间。</li>
<li>当URG置为1时，发送应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍然是普通数据。这时要与首部中紧急指针（Urgent Pointer）字段配合使用。</li>
</ul>
</li>
<li><p><strong>确认ACK（ACKnowledgment）</strong> 仅当ACK = 1时确认号字段才有效，当ACK = 0时确认号无效。TCP规定，在连接建立后所有的传送的报文段都必须把ACK置为1。</p>
</li>
<li><p><strong>推送 PSH（PuSH）</strong> 当两个应用进程进行交互式的通信时，有时在一端的应用进程希望在键入一个命令后立即就能收到对方的响应。在这种情况下，TCP就可以使用推送（push）操作。这时，发送方TCP把PSH置为1，并立即创建一个报文段发送出去。<strong>接收方TCP收到PSH=1的报文段，就尽快地（即“推送”向前）交付接收应用进程。而不用再等到整个缓存都填满了后再向上交付</strong>。</p>
</li>
<li><p><strong>复位RST（ReSeT）</strong> 当RST=1时，表示TCP连接中出现了严重错误（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立传输连接。RST置为1还用来拒绝一个非法的报文段或拒绝打开一个连接。</p>
</li>
<li><p><strong>同步SYN（SYNchronization）</strong> 在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN=1和ACK=1，因此SYN置为1就表示这是一个连接请求或连接接受报文。</p>
</li>
<li><p><strong>终止FIN（FINis，意思是“完”“终”）</strong> 用来释放一个连接。当FIN=1时，表明此报文段的发送发的数据已发送完毕，并要求释放运输连接。</p>
</li>
</ol>
<blockquote>
<p>ACK和SYN将在下节详述。</p>
</blockquote>
<h2 id="2-7-窗口"><a href="#2-7-窗口" class="headerlink" title="2.7 窗口"></a>2.7 窗口</h2><p><strong>窗口</strong>：占16位2字节。窗口值是【0，2^16-1（65535）】之间的整数。<strong>窗口值告诉对方：从本报文段首部中的确认号算起，我目前允许你发送的数据量（以字节为单位）是这个值的量</strong>。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，窗口值作为接收方让发送方设置其发送窗口的依据。TCP的流量控制由连接的每一端通过声明的窗口大小来提供。</p>
<h2 id="2-8-检验和"><a href="#2-8-检验和" class="headerlink" title="2.8 检验和"></a>2.8 检验和</h2><p><strong>检验和</strong>：占16位2字节。检验和字段检验的范围包括首部和数据这两部分。和UDP用户数据报一样，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部（<strong>具体过程可见《UDP协议分析》一文的校验过程</strong>）。伪首部的格式和UDP用户数据报的伪首部一样。但应把伪首部第4个字段中的17改为6（TCP的协议号是6）；把第5字段中的UDP中的长度改为TCP长度。接收方收到此报文段后，仍要加上这个伪首部来计算检验和。若使用TPv6,则相应的伪首部也要改变。</p>
<h2 id="2-9-紧急指针"><a href="#2-9-紧急指针" class="headerlink" title="2.9 紧急指针"></a>2.9 紧急指针</h2><p><strong>紧急指针</strong>：占16位2字节。紧急指针仅在URG=1时才有意义，它指出本报文段中的紧急数据的字节数（紧急数据排在数据的最前面，紧急数据结束后就是普通数据） 。</p>
<ul>
<li>因此，在紧急指针指出了紧急数据的末尾在报文段中的位置（紧急指针是一个正的偏移量，和序号字段中的值相加表示紧急数据最后一个字节的序号。）。当所有紧急数据都处理完时，TCP就告诉应用程序恢复到正常操作。值得注意的是，即使窗口为0时也可以发送紧急数据。<h2 id="2-10-选项"><a href="#2-10-选项" class="headerlink" title="2.10 选项"></a>2.10 选项</h2></li>
</ul>
<p><strong>选项</strong>：长度可变，最长可达4字节。当没有使用“选项”时，TCP的首部长度是20字节。</p>
<ol>
<li>TCP最初只规定了一种选项，即最大报文段长度MSS（Maximum Segment Szie），在连接建立的时候，即在发送SYN段的时候，同时会将MSS发送给对方（MSS选项只能出现在SYN段中！！！），<strong>告诉对端他期望接收的TCP报文段数据部分最大长度</strong>。<ul>
<li>注意MSS这个名词含义。MSS是每一个TCP报文段中的数据字段的最大长度。数据字段加上TCP首部才等于整个的TCP报文段。所以MSS并不是整个TCP报文段的最大长度，而是“TCP报文段长度减去TCP首部长度”。</li>
</ul>
</li>
<li>窗口扩大选项：窗口扩大选项是为了扩大窗口。我们知道，TCP首部中窗口字段长度是16位，因此最大的窗口大小为64K字节。虽然这对早期的网络是足够用的，但对于包含卫星信道的网络，传播时延和宽带都很大，要获得高吞吐量需要更大的窗口大小。<ul>
<li>窗口扩大选项占3字节，其中有一个字节表示移位值S。新的窗口值等于TCP首部中的窗口位数从16增大到（16+S）。移位值允许使用的最大值是14，相当于窗口最大值增大到2（16+14）-1=230-1。</li>
<li>窗口扩大选项可以在双方初始建立TCP连接时进行协商。如果连接的某一端实现了窗口扩大，当它不再需要扩大其窗口时，可发送S=0选项，使窗口大小回到16。</li>
</ul>
</li>
<li>时间戳选项：时间戳选项占10字节，其中最主要的字段是时间戳字段（4字节）和时间戳回送回答字段（4字节）。时间戳选项有以下两个概念：<ul>
<li>用来计算往返时间RTT。发送方在发送报文段时把当前时钟的时间值放入时间戳字段，接收方在确认该报文段时把时间戳字段复制到时间戳回送回答字段。因此，发送方在收到确认报文后，可以准确地计算出RTT来。</li>
<li>用于处理TCP序号超过2^32 的情况，这又称为防止序号绕回PAWS。我们知道，TCP报文段的序号只有32位，而每增加2 ^32 个序号就会重复使用原来用过的序号。当使用高速网络时，在一次TCP连接的数据传送中序号很可能被重复使用。<ul>
<li>例如，当使用1.5Mbit/s的速度发送报文段时，序号重复要6小时以上。但若用2.5Gbit/s的速率发送报文段，则不到14秒钟序号就会重复。为了使接收方能够把新的报文段和迟到很久的报文段区分开，则可以在报文段中加上这种时间戳。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-7ada90d37ad88cecc0f6abc535d49d3afde.png" alt=""></p>
<p>每个选项的开始是1字节kind字段，说明选项的类型。kind字段为0和1的选项仅占1个字节。其他的选项在kind字节后还有len字节。它说明的长度是指总长度，包括kind字节和len字节。</p>
<h1 id="3-TCP连接的建立与终止"><a href="#3-TCP连接的建立与终止" class="headerlink" title="3. TCP连接的建立与终止"></a>3. TCP连接的建立与终止</h1><p>TCP是一个面向连接的协议。无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。</p>
<blockquote>
<p>一个TCP连接需要四个元组来表示是同一个连接（src_ip, src_port, dst_ip, dst_port）准确说是五元组，还有一个是协议。但因为这里只是说TCP协议，所以，这里我只说四元组。</p>
</blockquote>
<p>前面我们介绍的TCP的首部字段，其中有三个字段，和TCP的连接有密切关系，他们分别是</p>
<ol>
<li><p>序号（sequence number）：Seq序号，前面说过，tcp会话中的端会对它发送的每个字节进行编号，一个报文段的序号值=本报文段所发送的数据的第一个字节的序号。</p>
</li>
<li><p>确认号（acknowledgement number）：Ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，Ack=Seq+1。</p>
</li>
<li><p>标志位（Flags）：共6个，即URG、ACK、PSH、RST、SYN、FIN等。其中重点是：</p>
<ul>
<li>SYN：表示发起一个新连接。</li>
<li>ACK：表示确认序号有效。（其实是用来确认接收到的数据）（注意，这个ACK和确认号Ack不要搞混！！！！）</li>
<li>FIN：表示释放一个连接。</li>
</ul>
</li>
</ol>
<p>下图是Wireshark中截出的一段tcp交互的seq和ack变化过程。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-922d63a4f387ec7844f4e507d0da1728b37.png" alt=""></p>
<blockquote>
<p>Wireshark的seq展示的是相对序号，即以ISN=0为基准的序号相对值。并不是ISN就这么刚好是0</p>
</blockquote>
<h2 id="3-1-TCP连接的建立——三次握手"><a href="#3-1-TCP连接的建立——三次握手" class="headerlink" title="3.1 TCP连接的建立——三次握手"></a>3.1 TCP连接的建立——三次握手</h2><p>所谓的三次握手即TCP连接的建立。这个连接必须是一方主动打开，另一方被动打开的。以下为客户端主动发起连接的图解：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4c580376d1c99db1a4cfbf33fde066cbd49.png" alt=""></p>
<ul>
<li><p>客户端A的TCP向服务端发出连接请求报文段，其首部中的SYN控制位应置为1，并选择序号x（前面说过，一个端的序号初始值是随机的，我们姑且认为它是x），表明传送数据时的第一个数据字节的序号是x。</p>
<ul>
<li>此时客户端进入SYN-SENT状态。</li>
</ul>
</li>
<li><p>服务端B的TCP收到连接请求报文段后，如同意，则发回确认：</p>
<ul>
<li>服务端B在确认报文段中应将SYN置为 1，其确认号ACK置位为x + 1，同时自己这端也会给这个确认报文段写入序号=y。</li>
<li>此时服务端进入SYN-RCVD状态</li>
</ul>
</li>
<li><p>客户端A收到此报文段后，向服务端B给出确认，其确认号置为 y + 1。</p>
<ul>
<li>客户端的TCP通知上层应用进程，连接已经建立。客户端进入ESTABLISHED状态</li>
<li>当运行服务器进程的服务器主机B的TCP收到客户端主机A的确认后，也通知其上层应用进程，连接已经建立。服务端也进入ESTABLISHED状态</li>
</ul>
</li>
</ul>
<blockquote>
<p>由于客户对报文段进行了编号，它知道哪些序号是期待的，哪些序号是过时的。当客户发现报文段的序号是一个过时的序号时，就会拒绝该报文段，这样就不会造成重复连接。</p>
</blockquote>
<h2 id="3-2-TCP连接的终止——四次分手"><a href="#3-2-TCP连接的终止——四次分手" class="headerlink" title="3.2 TCP连接的终止——四次分手"></a>3.2 TCP连接的终止——四次分手</h2><p>数据传输结束后，通信双方都可以释放连接。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4315377ecfaa3273f699ec6718dbf8e4d5a.png" alt=""></p>
<p>看起来比较简单，说是四次分手，<strong>其实就是FIN-ACK的交互，由主动方和被动方先后各执行了一次而已</strong>。上图已经直观展示的过程我们不再赘述，下面说一些比较值得注意的点：</p>
<h3 id="3-2-1-2MSL等待状态"><a href="#3-2-1-2MSL等待状态" class="headerlink" title="3.2.1 2MSL等待状态"></a>3.2.1 2MSL等待状态</h3><p>TIME_WAIT状态也称为2MSL等待状态。主动关闭的端（即上图中的客户端）在发送最后一个ACK的时候，没有立刻关闭，而是等待了2个MSL的时间才关闭。</p>
<p>MSL（Maximum Segment Lifetime），指的是一个报文段最大的生存时间，即一个报文段被丢弃前在网络内的最长时间。我们知道这个时间是有限的，因为TCP报文段以IP数据报在网络内传输，而IP数据报则有限制其生存时间的TTL字段。不过不同的TCP实现由不同的MSL设置，我们不去管他到底是何值，只要知道它控制着报文段在网络中的最长生存时间，<strong>如果超过MSL时间报文段还没到达彼端，那么它将被丢弃</strong>。</p>
<p>之所以A端在发送最后一个ACK后还要等待2MSL的时间才关闭，<strong>是因为假如最后一个ACK丢失了，B端会等待ACK超时，然后再重发一个FIN过来，如果A端立刻关闭，它就可能无法响应到这个重发的FIN。只有等待2MSL后A段没有收到B端重发的FIN，A端才会关闭。</strong></p>
<h3 id="3-2-2-半关闭链接"><a href="#3-2-2-半关闭链接" class="headerlink" title="3.2.2 半关闭链接"></a>3.2.2 半关闭链接</h3><p>TCP提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。这就是所谓的半关闭。</p>
<p>显示了一个半关闭的典型例子。假设左方的客户端开始半关闭。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3fb926c3cf588c58785d3d3c0eefd7c58bf.png" alt=""></p>
<ul>
<li><p>初始端发出的FIN，接着是另一端对这个FIN的ACK报文段。<strong>因为接收半关闭的一方仍能发送数据（这是半关闭的基础）</strong>。</p>
</li>
<li><p>我们只显示一个数据报文段和一个ACK报文段，但可能发送了许多数据报文段。</p>
</li>
<li><p>当收到半关闭的一端在完成它的数据传送后，将发送一个FIN关闭这个方向的连接，这将传送一个文件结束符给发起这个半关闭的应用进程。当对第二个FIN进行确认后，这个连接便彻底关闭了。</p>
</li>
</ul>
<h2 id="3-3-总结"><a href="#3-3-总结" class="headerlink" title="3.3 总结"></a>3.3 总结</h2><ul>
<li><p>建连接为什么需要三次握手？</p>
<ul>
<li>因为通信的双方要互相通知对方自己的ISN（也就上图中的 x 和 y）——所以需要两端各发出一个SYN（全称Synchronize Sequence Numbers，顾名思义，就是用来同步对方自己的ISN的）。ISN后续要作为数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序。</li>
<li>而光有SYN还不够，<strong>发端还要确认对端真的收到了我SYN，而不是我发出去SYN就了事</strong>，所以还有最后一个ACK</li>
</ul>
</li>
<li><p>断连接为什么需要四次挥手</p>
<ul>
<li>因为TCP是全双工的，所以，发送方和接收方都需要各一次的Fin和Ack。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。</li>
<li>其实仔细看，挥手比起握手之所以多了一次，主要是收到第一个fin包后单独回复了一个ack包，如果能回复fin+ack那么四次挥手也就变成三次了。</li>
<li>之所以被动端没有在收到fin后回复fin+ack，是因为在CLOSE_WAIT状态阶段，被动端需要去通知应用进程，会有一些时间消耗，所以先回发一个ack，等应用进程确定关闭后，再发送一个fin。否则如果应用进程没有关闭，至少还能维持一个半关闭链接。</li>
<li>如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-2d31a376256d1ac00ef996f1dd52e1a1716.png" alt=""></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="4-TCP数据的交互"><a href="#4-TCP数据的交互" class="headerlink" title="4 TCP数据的交互"></a>4 TCP数据的交互</h1><p>我们已经在前文的叙述中大概知道了TCP的数据传输，是通过数据和ack的相互交替来确认的，TCP连接的任意一端发送数据，都会捎带一个seq（数据的第一个字节的序号），接收端接收到数据后，返回ACK（控制位）=1，Ack（确认号）=seq+len</p>
<blockquote>
<p>注意，Ack=seq+len，表示的不是它要确认的data的最后一个字节的序号，而是它希望下次接收到的第一个序号。<br>比如，seq=90，len=1，那这唯一的1字节的data，它的序号就是90，Ack=90+1=91，表示它希望下次接受的第一个序号是从91开始。</p>
</blockquote>
<p><img src="https://oscimg.oschina.net/oscnet/up-b4dc1e5e539de60fa74de2a09388dc8eed0.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6c51c255feef37912a51dd9cd89563a46fc.png" alt=""></p>
<h2 id="4-1-捎带确认Delay-ACK"><a href="#4-1-捎带确认Delay-ACK" class="headerlink" title="4.1 捎带确认Delay ACK"></a>4.1 捎带确认Delay ACK</h2><p>通常TCP在接收到数据时并不立即发送ACK，相反，它推迟发送，以便将ACK与需要沿该方向发送的数据（<strong>这个数据可以是应用数据，也可以是另外一个同方向的ACK</strong>）一起发送（有时称这种现象为数据捎带确认），这样做的目的是尽量减少发往网络的报文，以提高传输的效率，节省网络资源。</p>
<p>为了防止产生超时重传，绝大多数情况下，这个等待时间为200ms，超过了200ms，如果没有数据要一起发送，就直接发送ACK报文。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-90e28e43ca3cd1c372709181d9faa0e1687.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2af49e8f61011242f212c658fcd97318e78.png" alt=""></p>
<h2 id="4-2-累计确认和Duplicate-ACK"><a href="#4-2-累计确认和Duplicate-ACK" class="headerlink" title="4.2 累计确认和Duplicate ACK"></a>4.2 累计确认和Duplicate ACK</h2><p>在TCP会话中，发送方对段的发送速度有时候非常快，比如发送方发了A,B,C,D四个段；段A含字节0到10，段B含字节11到20，段C含字节21到30，段D包含字节31到40</p>
<p>接受方成功收到段A，段B，段D，只有段C丢失了。那么接受方<strong>发回一个包含确认序号21的ACK</strong>（而不是分别给段A和段B都回复一个ACK，等于是把段A和段B的ACK合并了一样），发送方收到这个合并的ACK，就知道字节0到20(段A，段B)都成功收到。</p>
<p>通过累积确认的方式，在发送方快速发包的场景，一个ACK可以直接确认<strong>接收方接收到的连续序号的好几个段</strong>，这样减少报文段的传输。</p>
<blockquote>
<p>注意，如果段C没有收到，那么段D即便收到了，接收方也不会回复段D的ACK，因为一旦回复段D的ACK，就表示段D以前的数据都收到了，但其实段C还没收到。</p>
</blockquote>
<p>因为段C丢失，之后接收端即便接收到段E，段F等数据，也只会重复回复确认序号21的ACK，这时我们可以看到，因为段C丢失，接收端重复发送了很多次Ack=21，这种ACK我们称之为<strong>冗余ACK（duplicate ACK）</strong>。</p>
<h2 id="4-3-Nagle算法"><a href="#4-3-Nagle算法" class="headerlink" title="4.3 Nagle算法"></a>4.3 Nagle算法</h2><p>在TCP传输数据流中，存在两种类型的TCP报文段，一种包含成块数据（通常是满长度的，利用缓存，使报文一次发送就携带一个报文段最多容纳的字节数），另一种则包含交互数据（通常只有携带几个字节数据）。</p>
<p>对于成块数据的报文段，TCP采用正常的流程发送即可，因为数据利用率很高。而对于交互数据的报文段（也就是ACK），数据利用率就显得很低（因为ACK一般就一个IP头和TCP头），在网络环境不好的情况下容易加重网络负担。所以TCP必须对交互数据单独处理</p>
<p><strong>nagle算法用于处理小报文段（微小分组）的发送问题，其核心思想是允许网络中最多只能有一个小分组被发送，而待发送的其它小分组会被重新分组成一个”较大的”小分组，等收到上一个小分组的应答后再发送</strong>。</p>
<p>比如客户端需要依次向服务器发送大小为1,2,3,1,2字节的5个分组</p>
<p>在没有开启nagle算法的情况下，这些小分组会被依次发送（不需要等待上一个小分组的应答，因为没启动nagle），总共发送的报文段（分组）个数为5</p>
<p>当开启nagle算法时，客户端首先发送大小为1字节的第一个分组，随后其它分组到达发送缓冲区，由于上一个分组的应答还没有收到，所以TCP会先缓存新来的这4个小分组，并将其重新分组，组成一个大小为8(2+3+1+2)字节的”较大的”小分组。当第一个小分组的应答收到后，客户端将这个8字节的分组发送。总共发送的报文段（分组）个数为2。</p>
<blockquote>
<p>将套接字描述符设置TCP_NODELAY选项可以禁止nagle算法</p>
</blockquote>
<h2 id="4-4-超时重传"><a href="#4-4-超时重传" class="headerlink" title="4.4 超时重传"></a>4.4 超时重传</h2><p>TCP提供可靠的运输层。它使用的方法之一就是确认从另一端收到的数据。但数据和确认都有可能会丢失。TCP通过在发送时设置一个定时器来解决这种问题。如果当定时器溢出时还没有收到确认，它就重传该数据。对任何实现而言，关键之处就在于超时和重传的策略，即怎样决定超时间隔和如何确定重传的频率。</p>
<p>下图是一个超时重传的例子：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-09a3bb4827e8903f8b42dacd0385e2d814c.png" alt=""></p>
<ul>
<li>第1、2和3行表示正常的TCP连接建立的过程</li>
<li>第4行是“hello,world”（12个字符加上回车和换行）的传输过程</li>
<li>第5行是其确认。接着我们从svr4拔掉了以太网电缆</li>
<li>第6行表示“andhi”将被发送。第7~18行是这个报文段的12次重传过程，</li>
<li>而第19行则是发送方的TCP最终放弃并发送一个复位信号的过程。</li>
</ul>
<p>连续重传之间不同的时间差，我们整理后发现他们分别为1.5、3、6、12、24、48和多个64秒。这个倍乘关系被称为“指数退避(exponentialbackoff)”。也就是说，每一次超时，等待的时间都会翻倍，直到等待时间为64秒为止。</p>
<p>首次分组传输（第6行，24.480秒）与复位信号传输（第19行，566.488秒）之间的时间差约为9分钟，该时间在目前的TCP实现中，大多数是不可变的。也就是大多数的TCP实现都要尝试9分钟才会放弃。</p>
<h2 id="4-5-选择确认"><a href="#4-5-选择确认" class="headerlink" title="4.5 选择确认"></a>4.5 选择确认</h2><h3 id="4-5-1-SACK"><a href="#4-5-1-SACK" class="headerlink" title="4.5.1 SACK"></a>4.5.1 SACK</h3><p>我们知道累计确认，不会越过接收方未接受到的序号进行确认，如前例中的ABCD四个段，段A含字节0到10，段B含字节11到20，段C含字节21到30，段D包含字节31到40。</p>
<p>段C未收到，那么是不会返回确认号为41的ACK的。即便接收方已经收到了段D。</p>
<p>这种情况下，发送方只接收到了ack=21，那对于发送方而言，它可以有两种理解：</p>
<ol>
<li>段C丢失了</li>
<li>段C和段D都丢失了</li>
</ol>
<p>这时为了保险起见，发送方可能会重传段C和段D，但我们知道其实段D是没有必要重传的。</p>
<p><strong>为了解决这个问题，TCP实现引入了选择确认机制。</strong></p>
<p>选择确认全称叫做Selective Acknowledgment(SACK)，这种方式需要在TCP首部的选项中里加一个SACK的字段，它的工作原理也十分简单，一目了然：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4b6f8eb48e958728610987dacca173647ef.png" alt=""></p>
<p>这样，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些没有到。</p>
<p>选择确认的数据包长这样：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0374b03864f3bd117915b947228b916fa2c.png" alt=""></p>
<ol>
<li>这个确认包只有tcp首部，没有数据部分</li>
<li>Kind：SACK（5）用来表示这是选择确认（SACK），该字段占用一个字节。</li>
<li>Length表示tcp选项长度，占用一个字节，左边界和右边界各占用4字节，也就是说这里总共用掉了10字节。</li>
<li>其中left edge表示接收方接收到的数据块中的左边界位置（起始字节）</li>
<li>right edge可以理解为接收方接收到的数据块中的结束位置（右边界）</li>
</ol>
<p>也就是说，通过左边界和右边界我们可以指明一个数据块的位置。那么我们可以根据捕获的数据报中的确认号丢失的数据块中的起始字节，也就是要重传的起始字节，再结合接收窗口，左边界和右边界。我们可以推出接收窗口中的已经接收到的数据块，和未接收到的数据块：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-de3184da09ab090ed97fa9c1d071303a2e9.png" alt=""></p>
<p>这样，发送方在进行选择性重传时，会从2336611189字节的位置开始重传。注意：对于已经接收到的字节数据块（2336631881 - 2336693150）是不会被重传的。</p>
<blockquote>
<p>在前面学习TCP首部的时候我们知道，TCP首部中的选项部分最大是40字节，选择确认选项左边界和右边界在指明一个数据块时就用掉了8字节，那么指明4个数据块就用掉了32字节，再加上Kind：SACK（5）和Length两个字段占用的2字节，最终只剩下了6字节，换句话说，TCP选项的选择确认选项最多也就只能指明4个数据块</p>
</blockquote>
<h3 id="4-5-2-Duplicate-SACK"><a href="#4-5-2-Duplicate-SACK" class="headerlink" title="4.5.2 Duplicate SACK"></a>4.5.2 Duplicate SACK</h3><p>Duplicate SACK又称D-SACK，其主要使用了SACK来告诉发送方有哪些数据被重复接收了。</p>
<p>作为对比，SACK是告诉发送方，接受方已经收到了哪些数据，不要混淆。</p>
<p>那什么样的SACK是D-SACK呢？</p>
<p>答案是：</p>
<ol>
<li><p>如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK</p>
<ul>
<li>假如发送端已经收到了一个ACK报文，内容为：[Ack=4000, SACK=5000-5500, 4500-5500]，Ack=4000表示序号为4000以前的字节都收到了，这时候再看选项中的SACK=3000-3500，那么很显然，SACK框定的字节范围是已经被确认的范围，那么这个SACK是D-SACK，3000-3500也就是被重传的数据段。</li>
</ul>
</li>
<li><p>如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK</p>
<ul>
<li>假如发送端收到一个[Ack=4000,SACK=5000-5500, 4500-5500]，那么第二个段的区间4500-5500，覆盖了第一个段的区间5000-5500，这表示该SACK是个D-SACK，5000-5499段是重复收到的。</li>
</ul>
</li>
</ol>
<p>D-SACK在如下场景发挥比较积极的作用：</p>
<ol>
<li>ACK丢包<ul>
<li>如果一个发送端发送序号为3000-3999的段，却没收到对应的ACK，那么过一段时间发送端重传该段，紧接着却收到了[Ack=4000,SACK=3000-3999]，那么发送端就知道，之前的那个ACK丢失了。</li>
</ul>
</li>
<li>发送延误<ul>
<li>发送端发送序号为1000-1499的段，这个段因为网络延迟，导致接收端迟迟没有收到。发送端继续发送后面的段，但接收端因为没有收到1000-1499的段，所以只会回复[Ack=1500]</li>
<li>发送端收到3次[Ack=1500]，就会重传这个1000-1499的段，在重传的期间，接收端也收到了姗姗来迟的原来的1000-1499的段，这时面对重传的新段，接收端返回了[Ack=4000, SACK=1000-1499]</li>
<li>发送端通过这个D-SACK，就知道之前发出去的段，是因为网络延迟才迟到的。</li>
</ul>
</li>
</ol>
<p>可见，引入了D-SACK，有这么几个好处：</p>
<ol>
<li><p>可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。</p>
</li>
<li><p>是不是自己的timeout太小了，导致重传。</p>
</li>
<li><p>网络上出现了先发的包后到的情况（又称reordering）</p>
</li>
<li><p>网络上是不是把我的数据包给复制了。</p>
</li>
</ol>
<h1 id="5-RTT算法"><a href="#5-RTT算法" class="headerlink" title="5 RTT算法"></a>5 RTT算法</h1><p>从前文的TCP重传机制我们知道Timeout的设置对于重传非常重要：</p>
<ul>
<li>设长了，重发就慢，丢了老半天才重发，没有效率，性能差；</li>
<li>设短了，会导致可能并没有丢就重发。于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。</li>
</ul>
<p>而且，这个超时时间在不同的网络的情况下，根本没有办法设置一个死的值。由于路由器和网络流量均会变化，因此我们认为这个时间可能经常会发生变化，TCP应该跟踪这些变化并相应地改变其超时时间。</p>
<p>我们把这里的超时时间命名为RTO（Retransmission TimeOut），为了动态地设置RTO，TCP引入了RTT的概念——Round Trip Time，<strong>也就是一个数据包从发出去到回来的时间</strong>。</p>
<p>听起来似乎很简单，好像就是在发送端发包时记下t0，然后接收端再把这个ack回来时再记一个t1，于是RTT = t1 – t0。但其实没那么简单，这只是一个<strong>采样</strong>，不能代表普遍情况。</p>
<h2 id="5-1-经典算法"><a href="#5-1-经典算法" class="headerlink" title="5.1 经典算法"></a>5.1 经典算法</h2><p>RFC793中定义的经典算法是这样的：</p>
<ol>
<li><p>首先，先<strong>采样</strong>RTT，记下最近好几次的RTT值。</p>
</li>
<li><p>然后做平滑计算SRTT（ Smoothed RTT）。公式为：（其中的 α 取值在0.8 到 0.9之间，这个算法英文叫Exponential weighted moving average，中文叫：加权移动平均）</p>
</li>
</ol>
<p><code>SRTT = ( α * SRTT ) + ((1- α) * RTT)</code></p>
<ol>
<li>开始计算RTO。公式如下：</li>
</ol>
<p><code>RTO = min [UBOUND,  max [ LBOUND,   (β * SRTT) ]  ]</code></p>
<pre><code>其中：
UBOUND是最大的timeout时间，上限值
LBOUND是最小的timeout时间，下限值
β 值一般在1.3到2.0之间。</code></pre><h2 id="5-2-Karn-Partridge-算法"><a href="#5-2-Karn-Partridge-算法" class="headerlink" title="5.2 Karn / Partridge 算法"></a>5.2 Karn / Partridge 算法</h2><p>但是上面的这个算法在重传的时候会出有一个终极问题——你是用第一次发数据的时间和ack回来的时间做RTT样本值，还是用重传的时间和ACK回来的时间做RTT样本值？</p>
<p>这个问题无论你选那头都是按下葫芦起了瓢。 如下图所示：</p>
<ul>
<li><p>情况（a）是ack没回来，所以重传。如果你计算第一次发送和ACK的时间，那么，明显算大了。</p>
</li>
<li><p>情况（b）是ack回来慢了，但是导致了重传，但刚重传不一会儿，之前ACK就回来了。如果你是算重传的时间和ACK回来的时间的差，就会算短了。</p>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-e601aab8b8345e819d0be3da0cee0083ecb.png" alt=""></p>
<p>所以1987年的时候，搞了一个叫Karn / Partridge算法，这个算法的最大特点是——忽略重传，不把重传的RTT做采样（你看，你不需要去解决不存在的问题）。</p>
<p>但是，这样一来，又会引发一个大BUG——如果在某一时间，网络闪动，突然变慢了，产生了比较大的延时，这个延时导致要重传所有的包（因为之前的RTO很小，所以很容易就超时），于是，因为重传的不算，所以，RTO就不会被更新，导致包仍非常容易超时，这是一个灾难。 </p>
<p>于是Karn算法用了一个取巧的方式——只要一发生重传，就对现有的RTO值翻倍（这就是所谓的 Exponential backoff），很明显，这种死规矩对于一个需要估计比较准确的RTT也不靠谱。</p>
<h2 id="5-3-Jacobson-Karels-算法"><a href="#5-3-Jacobson-Karels-算法" class="headerlink" title="5.3 Jacobson / Karels 算法"></a>5.3 Jacobson / Karels 算法</h2><p>前面两种算法用的都是“加权移动平均”，这种方法最大的毛病就是如果RTT有一个大的波动的话，很难被发现，因为被平滑掉了。所以，1988年，又有人推出来了一个新的算法，这个算法叫Jacobson / Karels Algorithm（参看RFC6289）。这个算法引入了最新的RTT的采样和平滑过的SRTT的差距做因子来计算。</p>
<p>我们每次<strong>采样</strong>，都能得到一个新的RTT，即RTT[新]，除此之外，还引入了</p>
<ol>
<li>SRTT（Smoothed RTT）——平滑 RTT</li>
<li>DevRTT（Deviation RTT）——滑 RTT 和真实的差距</li>
</ol>
<p>这二者的值，每次采样之后都会更新，于是得到公式如下：</p>
<p><code>SRTT[新] = SRTT[旧] + α ( RTT[新] – SRTT[旧] ) —— 计算平滑 RTT</code></p>
<p><code>DevRTT[新] = ( 1-β ) * DevRTT + β * ( | RTT[新] - SRTT[旧]  | ) ——计算平滑 RTT 和真实的差距（加权移动平均）</code></p>
<p><code>RTO= µ * SRTT + ∂ * DevRTT</code></p>
<p>其中：α、β、μ、∂ 是可以调整的参数，在 RFC6298 中给出了对应的参考值，而在Linux下，α = 0.125，β = 0.25， μ = 1，∂ = 4；</p>
<blockquote>
<p>Jacobson / Karels算法在被用在今天的TCP协议中（Linux的源代码在：tcp_rtt_estimator）。</p>
</blockquote>
<h1 id="6-滑动窗口"><a href="#6-滑动窗口" class="headerlink" title="6 滑动窗口"></a>6 滑动窗口</h1><h2 id="6-1-背景"><a href="#6-1-背景" class="headerlink" title="6.1 背景"></a>6.1 背景</h2><p>我们知道TCP正常的交互是这样的：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d7f1cb4dffbb5fa40972503bbaec49f1503.png" alt=""></p>
<p>这带来了一个问题：吞吐量非常的低。我们发完包1，一定要等确认包1.我们才能发送第二个包。</p>
<p>那如何提高吞吐量？我们可不可以连发几个包等他一起确认呢？</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7692e692bb6f30ce6b27ee7c87b04e86023.png" alt=""></p>
<p>这样确实可以提高吞吐量，发送两个包，所花的时间只是原来一个来回的时间。</p>
<p>但是，新的问题又来了，如果我一次把太多的包连发，超过了接收端的处理上限，导致中途一直重传超时的包，即占用了带宽，又提高不了太多的吞吐量，如何制定最优解呢？TCP实现了一种被称为滑动窗口的流控机制</p>
<h2 id="6-2-发送窗口和接受窗口"><a href="#6-2-发送窗口和接受窗口" class="headerlink" title="6.2 发送窗口和接受窗口"></a>6.2 发送窗口和接受窗口</h2><p>滑动窗口解决的是TCP流量控制的问题，即如果接收端和发送端对数据包的处理速度不同，如何让双方达成一致。</p>
<p>我们知道TCP是全双工的协议，会话的双方都可以同时接收和发送数据。TCP会话的双方都各自维护一个<strong>发送窗口（本质是一个缓存）</strong> 和一个 <strong>接收窗口（本质是一个缓存）</strong> 。</p>
<ul>
<li>各自的<strong>接收窗口大小取决于应用、系统、硬件的限制（TCP传输速率不能大于应用的数据处理速率）</strong>。</li>
<li>各自的发送窗口的大小，则取决于<strong>对端</strong>的接收窗口。</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-9679d08b92cf441e4e938245430a4aea2a9.png" alt=""></p>
<p>在TCP的首部中，我们知道有个窗口（Window Size）字段，它是指接收端的窗口大小（单位字节），即接收窗口的大小。用来告知发送端自己所能接收的数据量，从而达到一部分流控的目的。</p>
<p>同时，选项中还有一个窗口扩展选项（Window Scaling)，前文我们也简单介绍过。窗口扩展选项和窗口字段，这二者由接收端通知发送端，最终确定了发送端的发送窗口大小。</p>
<p>因为接受窗口不是恒定的，所以在会话中，接收端可以不断的通知发端改变窗口大小。</p>
<p>假设，我们设定两边的接受窗口为20*MSS（Maxitum Segment Size），那么我们一个窗口，就可以发送20个满数据的段。如下图（方框内的数字为段的编号）：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-dabdb246da118fbdb57ec82e179ecc68f64.png" alt=""></p>
<p>其中发送端的段可以分成以下四类</p>
<ol>
<li>已发送，已收到ACK</li>
<li><strong>已发送，未收到ACK</strong>（属于发送窗口）</li>
<li><strong>未发送，但允许发送</strong>（属于发送窗口）</li>
<li>未发送，但不允许发送</li>
</ol>
<p>接收端的段可以分成以下三类</p>
<ol>
<li>已接收</li>
<li><strong>未接收但允许接收</strong>（属于接收窗口）</li>
<li>未接收而且不允许接收</li>
</ol>
<h2 id="6-3-滑动机制"><a href="#6-3-滑动机制" class="headerlink" title="6.3 滑动机制"></a>6.3 滑动机制</h2><ol>
<li><p>发送窗口只有收到发送窗口内的段的ACK确认，才会移动发送窗口的左边界。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-946e095931c35d0a80c6c45f6e0cb5ec7d2.png" alt=""></li>
</ul>
</li>
<li><p>接收窗口只有在前面所有的段都确认的情况下才会移动左边界。当在前面还有段未接收到，但先收到后面段的情况下，窗口不会移动，也不对窗口外的段进行确认。以此确保对端会对这些数据重传。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-4afa13df8020772655f1b44a468790dfda8.png" alt=""></li>
<li>没有收到G的情况下，窗口不会左移，就算收到窗口外的段，也不会进行确认</li>
</ul>
</li>
<li><p>遵循累计确认、选择确认等规则。</p>
</li>
</ol>
<h2 id="6-4-滑动过程"><a href="#6-4-滑动过程" class="headerlink" title="6.4 滑动过程"></a>6.4 滑动过程</h2><p>flash来自一个模拟TCP滑动窗口的动画：<a href="http://www.exa.unicen.edu.ar/catedras/comdat1/material/Filminas3_Practico3.swf" target="_blank" rel="noopener" title="动画地址">动画地址</a></p>
<ol>
<li><p>假定窗口大小为4*MSS，首先发送端发送A,B,C,D四个包，但是A,B丢失，只有C,D到达接收端。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-8109151f2ca10f0c6c5abd0c8774be9c575.png" alt=""></li>
</ul>
</li>
<li><p>接收端没有收到A，所以不回复ACK包。发送端重传的A,B,C,D四个包。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-e2b5a2ab1460977ca81a8e7c2b06a95df45.png" alt=""></li>
</ul>
</li>
<li><p>这次发送端重传的A,B,C,D四个包全都到达了，接收端先获得A，发ACK包A，但是中途丢失；接收端获得B后，根据累计确认的原则，发D的ACK包，然后窗口滑动。再次获得C,D后，连续回复2个D的ACK包，其中C对应的ACK包丢失。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-f1a81ca52edc05a9f46dcb444c3824b9d60.png" alt=""></li>
</ul>
</li>
<li><p>发送端连收2个D的ACK包，说明4个包对方都已收到，窗口滑动，发E,F,G,H包，其中G包丢失。现在整个序列的状态：ABCD是已发送已确认，EFGH是已发送未确认，I~S是不能发送。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-3555fd95fd6e8faeffdeb0ae13375cae18f.png" alt=""></li>
</ul>
</li>
<li><p>收端先收到E，发E的ACK包；收到F后发F的ACK包；未收到G；收到H，还是发F的ACK包。不幸的是，后两个ACK包全都丢失。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-6623f269f126fd0fb5cd19f1baaaf954e8b.png" alt=""></li>
</ul>
</li>
<li><p>送端收到E的ACK包，窗口向右滑动一位，发送I包，然后再发送F,G,H，其中F丢失。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-e8f2ba5ab327822f79d50e6e967fdd25895.png" alt=""></li>
</ul>
</li>
<li><p>接收端获得I，因为没有G，只好回复F的ACK包(不过紧接着这个包丢了)。还好，接收端相继收到G,H包。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-de01d1b06c6fc7422615569cf37c00c7798.png" alt=""></li>
</ul>
</li>
<li><p>接收端根据累计确认，连发两个I包，其中H的ACK丢失。窗口向右滑动。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-dbe0cb2f7a9b9c97322a234015aeeb02c60.png" alt=""></li>
</ul>
</li>
<li><p>发送端接收I的ACK包后，向右滑动四位。发送J,K,L,M四个包，后面不再分析。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-673c5f49f65170fec5d562a36873a83c936.png" alt=""></li>
</ul>
</li>
</ol>
<p>我们之前说过，在会话过程中，窗口大小也是随时可能发生改变的，下图就展示了一次动态的滑动窗口变动过程：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e0a4aec2b9558a73c2e5ad4ca06c6899a3e.png" alt=""></p>
<p>我们可以看到：</p>
<ol>
<li>发送方不必发送一个全窗口大小的数据。</li>
<li>正如从报文段7到报文段8中变化的那样，窗口的大小可以减小，但是窗口的右边沿却不能够向左移动</li>
<li>接收方在发送一个 ACK前不必等待窗口被填满。在前面我们看到许多实现每收到两个报文段就会发送一个ACK。</li>
</ol>
<h2 id="6-5-零窗口（Zero-Window）"><a href="#6-5-零窗口（Zero-Window）" class="headerlink" title="6.5 零窗口（Zero Window）"></a>6.5 零窗口（Zero Window）</h2><p><img src="https://oscimg.oschina.net/oscnet/up-7a3eaba1fbc9ee71fb59571821a6c77b3f2.png" alt=""></p>
<p>上图，我们可以看到一个处理缓慢的Server（接收端）是怎么把Client（发送端）的TCP Sliding Window给降成0的。此时，你一定会问，如果Window变成0了，TCP会怎么样？是不是发送端就不发数据了？是的，发送端就不发数据了，你可以想像成“Window Closed”，那你一定还会问，如果发送端不发数据了，接收方一会儿Window size 可用了，怎么通知发送端呢？</p>
<p>解决这个问题，TCP使用了Zero Window Probe技术，缩写为ZWP，也就是说，发送端在窗口变成0后，会发ZWP的包给接收方，让接收方来ack他的Window尺寸，一般这个值会设置成3次，第一次大约30-60秒（不同的实现可能会不一样）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。</p>
<h2 id="6-6-糊涂窗口综合症（Silly-Window-Syndrome）"><a href="#6-6-糊涂窗口综合症（Silly-Window-Syndrome）" class="headerlink" title="6.6 糊涂窗口综合症（Silly Window Syndrome）"></a>6.6 糊涂窗口综合症（Silly Window Syndrome）</h2><p>我们知道，发送端的发送窗口大小是受馈于接收端通知的接收窗口大小的，如果接收方太忙了，来不及取走Receive Windows里的数据，那么，就会导致发送方窗口越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的window，而我们的发送方会义无反顾地发送<strong>这几个字节</strong>。</p>
<p>要知道，我们的TCP+IP头有40个字节，为了<strong>几个字节</strong>，要达上这么大的开销，这太不经济了。糊涂窗口综合症这个现象<strong>就像是你本来可以坐200人的飞机里只做了一两个人</strong>。 要解决这个问题也不难，就是避免对小的window size做出响应，直到有足够大的window size再响应，这个思路可以同时实现在sender和receiver两端。</p>
<ul>
<li>如果这个问题是由Receiver端引起的，那么就会使用David D Clark’s 方案。在receiver端，如果收到的数据导致window size小于某个值，可以直接ack(0)回sender，这样就把window给关闭了，也阻止了sender再发数据过来，等到receiver端处理了一些数据后windows size 大于等于了MSS（以太网MSS为1500字节），或者，receiver buffer有一半为空，就可以把window打开让send 发送数据过来。</li>
<li>如果这个问题是由Sender端引起的，那么就会使用前文介绍的Nagle’s算法。我们知道这个算法的思路也是延时处理，积攒数据，等于一架飞机在等待客人，以便一次能多拉一些人。</li>
</ul>
<h1 id="7-拥塞控制"><a href="#7-拥塞控制" class="headerlink" title="7 拥塞控制"></a>7 拥塞控制</h1><p>上面我们知道了，TCP通过Sliding Window来做流控（Flow Control），但是TCP觉得这还不够，因为Sliding Window需要依赖于连接的发送端和接收端，其并不知道网络中间发生了什么。</p>
<p>TCP的设计者觉得，一个伟大而牛逼的协议仅仅做到流控并不够，因为流控只是网络模型4层以上的事，TCP的还应该更聪明地知道整个网络上的事。</p>
<p>如果网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是，这个情况就会进入恶性循环被不断地放大。</p>
<p>试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。这是一个灾难。</p>
<p>所以，TCP不能忽略网络上发生的事情，而无脑地一个劲地重发数据，对网络造成更大的伤害。对此TCP的设计理念是：<strong>TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了</strong>。</p>
<p>拥塞控制为发送方增加了另一个窗口：<strong>拥塞窗口</strong>(congestionwindow)，记为cwnd。它以字节为单位，和接收方通告发送方的窗口（我们叫做通告窗口）一起，控制发送方的窗口大小——<strong>发送方取拥塞窗口与通告窗口中的最小值作为发送上限</strong>。拥塞窗口是发送方使用的流量控制，而通告窗口则是接收方使用的流量控制。</p>
<p>TCP拥塞控制算法发展的过程中出现了如下几种不同的思路：</p>
<ol>
<li>基于丢包的拥塞控制：将丢包视为出现拥塞，采取缓慢探测的方式，逐渐增大拥塞窗口，当出现丢包时，将拥塞窗口减小，如Reno、Cubic等。</li>
<li>基于时延的拥塞控制：将时延增加视为出现拥塞，延时增加时增大拥塞窗口，延时减小时减小拥塞窗口，如Vegas、FastTCP等。</li>
<li>基于链路容量的拥塞控制：实时测量网络带宽和时延，认为网络上报文总量大于带宽时延乘积时出现了拥塞，如BBR。</li>
<li>基于学习的拥塞控制：没有特定的拥塞信号，而是借助评价函数，基于训练数据，使用机器学习的方法形成一个控制策略，如Remy。</li>
</ol>
<h2 id="7-1-Reno算法"><a href="#7-1-Reno算法" class="headerlink" title="7.1 Reno算法"></a>7.1 Reno算法</h2><p>Reno现有的众多拥塞控制算法的基础，它将拥塞控制的过程分为四个阶段：</p>
<ol>
<li><strong>慢启动</strong></li>
<li><strong>拥塞避免</strong></li>
<li><strong>快速重传</strong></li>
<li><strong>快速恢复</strong></li>
</ol>
<p>这四个阶段的相关算法和处理策略不是一天都搞出来的，这个四阶段算法的发展经历了很多时间，到今天都还在优化中。</p>
<p>Reno算法将收到ACK这一信号作为拥塞窗口增长的依据，在早期低带宽、低时延的网络中能够很好的发挥作用，但是随着网络带宽和延时的增加，Reno的缺点就渐渐体现出来了，发送端从发送报文到收到ACK经历一个RTT，在高带宽延时（High Bandwidth-Delay Product，BDP）网络中，RTT很大，导致拥塞窗口增长很慢，传输速度需要经过很长时间才能达到最大带宽，导致带宽利用率将低。</p>
<p>适用场景：适用于低延时、低带宽的网络。</p>
<h3 id="7-1-1-慢启动（Slow-Start）"><a href="#7-1-1-慢启动（Slow-Start）" class="headerlink" title="7.1.1 慢启动（Slow Start）"></a>7.1.1 慢启动（Slow Start）</h3><p>首先，我们来看一下TCP的慢启动。慢启动的意思是，刚刚加入网络的连接，一点一点地提速，不要一上来便无脑向网络发送多个报文段，把现有的传输秩序搞乱。</p>
<p>慢启动的算法如下：</p>
<ol>
<li><p>连接建好的开始先初始化cwnd = 1个MSS，表明可以传一个MSS大小的数据。</p>
</li>
<li><p>每当收到一个ACK，cwnd+1，即相当于每轮次（一个RTT，无拥塞情况下共可收到cwnd个ACK）发送窗口增加一倍，呈指数增长</p>
<ul>
<li><strong>换句话说，一次交互cwnd * 2;</strong></li>
</ul>
</li>
<li><p>还有一个慢启动门限ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法”（下文介绍）</p>
</li>
</ol>
<p>所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT也会短，那么，这个慢启动就一点也不慢。下图说明了这个过程：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-48981739b1cce1dabb79d1837b1e0f20583.png" alt=""></p>
<blockquote>
<p>这里需要提一下的是一篇Google的论文《An Argument for Increasing TCP’s Initial Congestion Window》（<a href="http://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/36640.pdf）" target="_blank" rel="noopener">http://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/36640.pdf）</a><br>Linux 3.0后采用了这篇论文的建议——把cwnd 初始化成了 10个MSS。<br>而Linux 3.0以前，比如2.6，Linux采用了RFC3390，cwnd是跟MSS的值来变的，如果MSS&lt; 1095，则cwnd = 4；如果MSS&gt;2190，则cwnd=2；其它情况下，则是3。</p>
</blockquote>
<h3 id="7-1-2-拥塞避免"><a href="#7-1-2-拥塞避免" class="headerlink" title="7.1.2 拥塞避免"></a>7.1.2 拥塞避免</h3><p>前面说过，还有一个ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下：</p>
<ul>
<li>收到一个ACK时，cwnd = cwnd + 1/cwnd，即相当于每轮次（一个RTT，无拥塞情况下共可收到cwnd个ACK）发送窗口+1 * MSS，呈线性增长<ul>
<li><strong>换句话说，一次交互cwnd + 1 * MSS ;</strong></li>
</ul>
</li>
</ul>
<p>这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。</p>
<p>所以我们可以看到：</p>
<ul>
<li>当cwnd&lt;ssthresh时，使用慢开始算法。</li>
<li>当cwnd&gt;ssthresh时，改用拥塞避免算法。</li>
</ul>
<h3 id="7-1-3快速重传"><a href="#7-1-3快速重传" class="headerlink" title="7.1.3快速重传"></a>7.1.3快速重传</h3><p>在介绍拥塞发生时tcp选择的策略时，我们要先了解快速重传策略。</p>
<h4 id="7-1-3-1-快速重传策略"><a href="#7-1-3-1-快速重传策略" class="headerlink" title="7.1.3.1 快速重传策略"></a>7.1.3.1 快速重传策略</h4><p>现有的超时重传机制，还有一些问题：</p>
<ul>
<li>当一个报文段丢失时，会等待一定的超时周期然后才重传分组，增加了端到端的时延。</li>
<li>当一个报文段丢失时，在其等待超时的过程中，可能会出现这种情况：其后的报文段已经被接收端接收但却迟迟得不到确认，发送端会认为也丢失了，从而引起不必要的重传，既浪费资源也浪费时间。</li>
</ul>
<p>幸运的是，由于TCP采用的是累计确认机制，即当接收端收到比期望序号大的报文段时，便会重复发送最近一次确认的报文段的确认信号，我们称之为冗余ACK（duplicate ACK）。<br>如图所示，报文段1成功接收并被确认ACK 2，接收端的期待序号为2，当报文段2丢失，报文段3失序到来，与接收端的期望不匹配，接收端重复发送冗余ACK 2。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7536f9cee4486e13802d9341b33ceb16d0b.png" alt=""></p>
<p>这样，<strong>如果在超时重传定时器溢出之前，接收到连续的三个重复冗余ACK</strong>（其实是收到4个同样的ACK，第一个是正常的，后三个才是冗余的），发送端便知晓哪个报文段在传输过程中丢失了，于是<strong>重发该报文段，不需要等待超时重传定时器溢出</strong>，大大提高了效率。这便是快速重传机制。</p>
<blockquote>
<p>为什么需要3次冗余ACK才会触发快速重传？因为即使发送端是按序发送，由于TCP包是封装在IP包内，IP包在传输时乱序，意味着TCP包到达接收端也是乱序的，乱序的话也会造成接收端发送冗余ACK。如果阈值设置的过小，那么快速重传机制很容易被乱序引发的冗余ACK干扰。</p>
</blockquote>
<h4 id="7-1-3-2-拥塞发生时的策略选择"><a href="#7-1-3-2-拥塞发生时的策略选择" class="headerlink" title="7.1.3.2 拥塞发生时的策略选择"></a>7.1.3.2 拥塞发生时的策略选择</h4><p>如果慢启动和拥塞避免算法，仍然无法避免TCP连接进入拥塞状态（发生丢包的情况），那么这时，就要采取非常手段了。</p>
<p>对于丢包，我们知道有两种情况会发生：</p>
<ol>
<li>收到3个duplicate ACK</li>
<li>还没收到3个duplicate ACK，就RTO超时</li>
</ol>
<p>这两种情况下，TCP选择的算法也不一样，我们先讲比较严重的情况2，再讲程度稍好的情况1。（情况1还能收到3个ACK，情况2直接连ACK都超时或者丢了，网络拥塞更严重）</p>
<ul>
<li>情况2：还没收到3个duplicate ACK，就RTO超时<ul>
<li>设置sshthresh =  cwnd /2</li>
<li>cwnd 重置为 1</li>
<li>如此一来，cwnd必然小于sshthresh，进入慢启动过程</li>
</ul>
</li>
<li>情况1：收到3个duplicate ACK<ul>
<li>那毫无疑问，快速重传继续，重发数据段。</li>
<li>cwnd = cwnd /2</li>
<li>sshthresh = cwnd</li>
<li>进入快速恢复算法——Fast Recovery</li>
</ul>
</li>
</ul>
<p>上面我们可以看到RTO超时后，sshthresh会变成cwnd的一半，这意味着，如果cwnd&lt;=sshthresh时出现的丢包，那么TCP的sshthresh就会减少一半，然后等cwnd又很快地以指数级增长爬到cwnd=sshthresh这个地方时，就会成慢慢的线性增长。</p>
<p>我们可以看到，TCP是怎么通过这种强烈地震荡快速而小心得找到网站流量的平衡点的。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fce15fccd5fb400c4e7c3731a978b75171e.png" alt=""></p>
<h3 id="7-1-4-快速恢复（Fast-Recovery）"><a href="#7-1-4-快速恢复（Fast-Recovery）" class="headerlink" title="7.1.4 快速恢复（Fast Recovery）"></a>7.1.4 快速恢复（Fast Recovery）</h3><p>这个算法定义在RFC5681。快速重传和快速恢复算法一般同时使用（都在情况1中），因为情况1还有ACK能回来，说明了网络还不是那么的糟糕，所以没有必要像RTO超时那么强烈。</p>
<blockquote>
<p>注意，正如前面所说，进入Fast Recovery之前，cwnd 和 sshthresh已被更新：<code>cwnd = cwnd /2</code>以及<code>sshthresh = cwnd</code></p>
</blockquote>
<p>然后，真正的Fast Recovery算法如下：</p>
<ul>
<li>cwnd = sshthresh  + 3 * MSS （3的意思是确认有3个数据包被收到了）</li>
<li>重传Duplicated ACKs指定的数据包，这时会有两种结果<ul>
<li>如果再收到 duplicated Acks，那么cwnd = cwnd +1</li>
<li>如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。</li>
</ul>
</li>
</ul>
<h2 id="7-2-Vegas算法"><a href="#7-2-Vegas算法" class="headerlink" title="7.2 Vegas算法"></a>7.2 Vegas算法</h2><p>该算法的论文是《<a href="http://www.cs.cmu.edu/~srini/15-744/F02/readings/BP95.pdf" target="_blank" rel="noopener" title="TCP Vegas: End to End Congestion Avoidance on a Global Internet">TCP Vegas: End to End Congestion Avoidance on a Global Internet</a>》</p>
<p>Vegas将时延RTT的增加作为网络出现拥塞的信号，RTT增加，拥塞窗口减小，RTT减小，拥塞窗口增加。</p>
<p>具体来说，Vegas通过比较实际吞吐量和期望吞吐量来调节拥塞窗口的大小：</p>
<p>期望吞吐量：<code>Expected  = cwnd /  BaseRTT</code><br>实际吞吐量：<code>Actual = cwnd / RTT，diff = (Expected-Actual) * BaseRTT</code></p>
<p>其中，BaseRTT是所有观测来回响应时间的最小值，一般是建立连接后所发的第一个数据包的RTT，cwnd是目前的拥塞窗口的大小。</p>
<p>Vegas定义了两个阈值a，b，当diff &gt; b时，拥塞窗口减小，当a &lt;= diff &lt;=b时，拥塞窗口不变，当diff &lt; a时，拥塞窗口增加。</p>
<p>Vegas算法采用RTT的改变来判断网络的可用带宽，能精确地测量网络的可用带宽，效率比较好。但是，网络中Vegas与其它算法共存的情况下，基于丢包的拥塞控制算法会尝试填满网络中的缓冲区，导致Vegas计算的RTT增大，进而降低拥塞窗口，使得传输速度越来越慢，因此Vegas未能在Internet上普遍采用。</p>
<p>适用场景：适用于网络中只存在Vegas一种拥塞控制算法，竞争公平的情况。</p>
<hr>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol>
<li><a href="https://coolshell.cn/articles/11564.html" target="_blank" rel="noopener" title="TCP 的那些事儿（上）">TCP 的那些事儿（上）</a></li>
<li><a href="http://jm.taobao.org/2017/06/08/20170608/" target="_blank" rel="noopener" title="就是要你懂 TCP">就是要你懂 TCP</a></li>
<li><a href="https://blog.csdn.net/yao5hed/article/details/81046945" target="_blank" rel="noopener" title="解析TCP之滑动窗口(动画演示)">解析TCP之滑动窗口(动画演示)</a></li>
<li><a href="https://blog.csdn.net/qq_35733751/article/details/80157509" target="_blank" rel="noopener" title="tcp可靠传输——选择确认选项（SACK）">tcp可靠传输——选择确认选项（SACK）</a></li>
<li><a href="https://coolshell.cn/articles/11609.html" target="_blank" rel="noopener" title="TCP 的那些事儿（下）">TCP 的那些事儿（下）</a></li>
<li><a href="https://ee.lbl.gov/papers/congavoid.pdf" target="_blank" rel="noopener" title="Congestion Avoidance and Control">Congestion Avoidance and Control</a></li>
<li><a href="https://blog.csdn.net/smilesundream/article/details/71149434" target="_blank" rel="noopener" title="TCP拥塞控制——慢开始与拥塞避免算法">TCP拥塞控制——慢开始与拥塞避免算法</a></li>
<li><a href="https://www.cnblogs.com/lolau/p/9188476.html" target="_blank" rel="noopener" title="浅谈TCP拥塞控制算法">浅谈TCP拥塞控制算法</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/18/UDP%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/03/18/UDP%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/" itemprop="url">UDP协议分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-18T23:08:31+08:00">
                2020-03-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机协议和技术</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%8A%80%E6%9C%AF/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/" itemprop="url" rel="index">
                    <span itemprop="name">网络协议</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/03/18/UDP%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/03/18/UDP协议分析/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-UDP的概述"><a href="#1-UDP的概述" class="headerlink" title="1. UDP的概述"></a>1. UDP的概述</h1><p>UDP是User Datagram Protocol（用户数据报协议）的缩写，它是传输层的协议，功能即为在IP的数据报服务之上增加了最基本的服务：复用和分用以及差错检测。</p>
<p>UDP提供<strong>不可靠</strong>的服务（它把应用程序传给IP层的数据发送出去，但是并不保证它们能到达目的地。），具有TCP所没有的优势：</p>
<ol>
<li><p>UDP无连接，时间上不存在建立连接需要的时延。空间上，TCP需要在端系统中维护连接状态，需要一定的开销。此连接装入包括接收和发送缓存，拥塞控制参数和序号与确认号的参数。UCP不维护连接状态，也不跟踪这些参数，开销小。空间和时间上都具有优势。</p>
<ul>
<li>举个例子：</li>
<li>DNS如果运行在TCP之上而不是UDP，那么DNS的速度将会慢很多。</li>
<li>HTTP使用TCP而不是UDP，是因为对于基于文本数据的Web网页来说，可靠性很重要。</li>
<li>同一种专用应用服务器在支持UDP时，一定能支持更多的活动客户机。</li>
</ul>
</li>
<li><p>分组首部开销小，TCP首部20字节，UDP首部8字节。</p>
</li>
<li><p>UDP没有拥塞控制，应用层能够更好的控制要发送的数据和发送时间，网络中的拥塞控制也不会影响主机的发送速率。某些实时应用要求以稳定的速度发送，能容忍一些数据的丢失，但是不能允许有较大的时延（比如实时视频，直播等）</p>
</li>
<li><p>UDP提供尽最大努力的交付，不保证可靠交付。所有维护传输可靠性的工作需要用户在应用层来完成。没有TCP的确认机制、重传机制。如果因为网络原因没有传送到对端，UDP也不会给应用层返回错误信息</p>
</li>
<li><p>UDP是<strong>面向报文</strong>的，对应用层交下来的报文，添加首部后直接向下交付为IP层，<strong>既不合并，也不拆分，保留这些报文的边界</strong>。对IP层交上来UDP用户数据报，在去除首部后就<strong>原封不动</strong>地交付给上层应用进程，报文不可分割，是UDP数据报处理的最小单位。</p>
<ul>
<li>正是因为这样，UDP显得不够灵活，不能控制读写数据的次数和数量。比如我们要发送100个字节的报文，我们调用一次sendto函数就会发送100字节，对端也需要用recvfrom函数一次性接收100字节，不能使用循环每次获取10个字节，获取十次这样的做法。</li>
</ul>
</li>
</ol>
<blockquote>
<p>UDP常用于一次性传输比较少量数据的网络应用，如DNS，SNMP等，因为对于这些应用，若是采用TCP，为连接的创建，维护和拆除带来不小的开销。UDP也常用于多媒体应用（如IP电话，实时视频会议，流媒体等）数据的可靠传输对他们而言并不重要，TCP的拥塞控制会使他们有较大的延迟，也是不可容忍的</p>
</blockquote>
<h1 id="2-UDP首部格式"><a href="#2-UDP首部格式" class="headerlink" title="2. UDP首部格式"></a>2. UDP首部格式</h1><p>UDP数据报分为首部和用户数据部分，整个UDP数据报作为IP数据报的数据部分封装在IP数据报中，UDP数据报文结构如图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e908c0de675aebde70a8526a34b0a8b28b4.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-e8ab3a0fb55985d612c74f805d60ac2d071.png" alt=""></p>
<p>UDP首部有8个字节，由4个字段构成，每个字段都是两个字节，</p>
<ol>
<li><strong>源端口</strong>： 源端口号，需要对方回信时选用，不需要时全部置0.</li>
<li><strong>目的端口</strong>：目的端口号，在终点交付报文的时候需要用到。</li>
<li><strong>长度</strong>：记录UDP的数据报的长度（包括首部+数据），单位是字节，其最小值为8（表示只有首部，没有数据）</li>
<li><strong>校验和</strong>：UDP检验和是一个端到端的检验和。它由发送端计算，然后由接收端验证。其目的是为了发现UDP首部和数据在发送端到接收端之间是否发生变动，有则丢弃。UDP中该字段是可选的（TCP是必须的），当源主机不想计算校验和，则直接令该字段全为0。</li>
</ol>
<blockquote>
<p>当传输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交给应用进程。如果接收方UDP发现收到的报文中的目的端口号不正确（不存在对应端口号的应用进程0,），就丢弃该报文，并由ICMP发送“端口不可达”差错报文给对方</p>
</blockquote>
<h1 id="3-UDP校验"><a href="#3-UDP校验" class="headerlink" title="3 UDP校验"></a>3 UDP校验</h1><p>UDP检验和的基本计算方法与IP首部检验和计算方法相类似（16bit字的二进制反码和）。</p>
<p>在计算校验和的时候，<strong>需要在UDP数据报之前增加12字节的伪首部</strong>，伪首部并不是UDP真正的首部。只是在计算校验和，<strong>临时添加在UDP数据报的前面，得到一个临时的UDP数据报</strong>。校验和就是按照这个临时的UDP数据报计算的。<strong>伪首部既不向下传送也不向上递交，而仅仅是为了计算校验和</strong>。这样的校验和，既检查了UDP数据报，又对IP数据报的源IP地址和目的IP地址进行了检验。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0aa926db9d0b0919605e1f1b85dfb9593fc.png" alt=""></p>
<p>校验过程如下：</p>
<ol>
<li><p>发送方首先把全零放入校验和字段并且添加伪首部</p>
</li>
<li><p>把UDP数据报看成是由许多16位的子串连接起来，若UDP数据报的数据部分不是偶数个字节，则要在数据部分末尾增加一个填充字节(全零字节，此字节不发送）。</p>
</li>
<li><p>按照二进制反码计算出这些16位字的和。</p>
</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-ee8f3ba02186185dec3ca2f68ddd542ea22.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/17/TCP-IP%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%A7%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/03/17/TCP-IP%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%A7%88/" itemprop="url">TCP/IP协议学习导览</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-17T23:04:04+08:00">
                2020-03-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机协议和技术</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%8A%80%E6%9C%AF/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/" itemprop="url" rel="index">
                    <span itemprop="name">网络协议</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/03/17/TCP-IP%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%A7%88/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/03/17/TCP-IP协议学习导览/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  7.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  26
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>从字面意义上讲，有人可能会认为TCP/IP是指TCP和IP两种协议。实际生活当中有时也确实就是指这两种协议。然而在很多情况下，它只是利用IP进行通信时所必须用到的协议群的统称。具体来说，IP或ICMP、TCP或UDP、TELNET或FTP、以及HTTP等都属于TCP/IP协议。</p>
<blockquote>
<p>该文章主要为《TCP-IP详解卷1：协议》归纳笔记</p>
</blockquote>
<h1 id="1-网络的分层"><a href="#1-网络的分层" class="headerlink" title="1. 网络的分层"></a>1. 网络的分层</h1><p>网络协议通常分不同层次进行开发，每一层分别负责不同的通信功能。一个协议族，比如TCP/IP，是一组不同层次上的多个协议的组合。TCP/IP通常被认为是一个四层的协议系统。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b92eb0a4ab7d64b99b88d4acb7760baed51.png" alt=""></p>
<ol>
<li><p>链路层</p>
<ul>
<li>有时也称作<strong>数据链路层或网络接口层</strong>，通常包括操作系统中的设备驱动程序和计算机中对应的网络接口卡。它们一起处理与电缆（或其他任何传输媒介）的物理接口细节。</li>
</ul>
</li>
<li><p>网络层</p>
<ul>
<li>有时也称作互联网层，处理分组在网络中的活动，例如分组的选路。在TCP/IP协议族中，网络层协议包括<strong>IP</strong>协议（网际协议），<strong>ICMP协议</strong>（Internet互联网控制报文协议），以及<strong>IGMP协议</strong>（Internet组管理协议）。</li>
</ul>
</li>
<li><p>运输层</p>
<ul>
<li>主要为两台主机上的应用程序提供端到端的通信。在TCP/IP协议族中，有两个互不相同的传输协议：<strong>TCP（传输控制协议）和UDP（用户数据报协议）。</strong></li>
<li>TCP为两台主机提供高可靠性的数据通信。它所做的工作包括把应用程序交给它的数据分成合适的小块交给下面的网络层，确认接收到的分组，设置发送最后确认分组的超时时钟等。由于运输层提供了高可靠性的端到端的通信，因此应用层可以忽略所有这些细节。</li>
<li>而另一方面，UDP则为应用层提供一种非常简单的服务。它只是把称作数据报的分组从一台主机发送到另一台主机，但并不保证该数据报能到达另一端。任何必需的可靠性必须由应用层来提供。</li>
</ul>
</li>
<li><p>应用层</p>
<ul>
<li>负责处理特定的应用程序细节。几乎各种不同的TCP/IP实现都会提供下面这些通用的应用程序：<ul>
<li>Telnet 远程登录。</li>
<li>FTP 文件传输协议。</li>
<li>SMTP 简单邮件传送协议。</li>
<li>SNMP 简单网络管理协议。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="2-TCP-IP协议的分层"><a href="#2-TCP-IP协议的分层" class="headerlink" title="2. TCP/IP协议的分层"></a>2. TCP/IP协议的分层</h1><p>在TCP/IP协议族中，有很多种协议。如下图</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-11d2a0a828cf310ade2987c70bc46b159d1.png" alt=""></p>
<ul>
<li><strong>TCP</strong>和<strong>UDP</strong>是两种最为著名的运输层协议，二者都使用IP作为网络层协议。TCP提供一种可靠的运输层服务，而UDP是不可靠的，它不能保证数据报能安全无误地到达最终目的。</li>
<li><strong>IP</strong>是网络层上的主要协议，同时被TCP和UDP使用。TCP和UDP的每组数据都通过端系统和每个中间路由器中的IP层在互联网中进行传输。</li>
<li><strong>ICMP</strong>是IP协议的附属协议。IP层用它来与其他主机或路由器交换错误报文和其他重要信息。</li>
<li><strong>IGMP</strong>是Internet组管理协议。它用来把一个UDP数据报多播到多个主机。</li>
<li><strong>ARP</strong>（地址解析协议）和<strong>RARP</strong>（逆地址解析协议）是某些网络接口（如以太网和令牌环网）使用的特殊协议，用来转换IP层和网络接口层使用的地址。</li>
</ul>
<h1 id="3-网络基础概念"><a href="#3-网络基础概念" class="headerlink" title="3. 网络基础概念"></a>3. 网络基础概念</h1><h2 id="3-1-IP地址——互联网的地址"><a href="#3-1-IP地址——互联网的地址" class="headerlink" title="3.1 IP地址——互联网的地址"></a>3.1 IP地址——互联网的地址</h2><p>互联网上的每个接口必须有一个唯一的Internet地址（也称作IP地址）。IP地址长32bit。IP地址具有一定的结构，五类不同的互联网地址格式如图</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a3dda773efe24cf65854d9da0a2a76db966.png" alt=""></p>
<p>总体来说，IP地址由<strong>网络号</strong>和<strong>主机号</strong>组成，网络号相当于某个网络的编号，主机号相当于<strong>相同网络内</strong>的主机编号。只有相同网络地址的两台主机才能通信，因此不同网络地址的主机，需要借助路由器转发才能通信。</p>
<p>这些32位的地址通常写成四个十进制的数，其中每个整数对应一个字节。这种表示方法称作“点分十进制表示法（Dotteddecimalnotation）”。例如，140.252.13.33就是一个B类地址。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-35ef928a25d5723986baf23183d9b16a8c7.png" alt=""></p>
<h3 id="3-1-1-子网寻址"><a href="#3-1-1-子网寻址" class="headerlink" title="3.1.1 子网寻址"></a>3.1.1 子网寻址</h3><p>现在所有的主机都要求支持子网编址。不是把IP地址看成由单纯的一个网络号和一个主机号组成，<strong>而是把主机号再分成一个子网号和一个主机号</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6fd30a8d60771bbc85cffb0224c664c47ae.png" alt=""></p>
<p>子网的出现是基于以下原因：</p>
<ul>
<li>因为A类和B类地址为主机号分配了太多的空间，可分别容纳的主机数为2^24-2和2^16-2。事实上，在一个网络中人们并不安排这么多的主机</li>
<li>随着互联的发展IPV4地址资源可能会耗尽，如果不划分子网直接将一个C类地址分给一个企业，C类地址可容纳256台主机，但是可能该企业只有20台计算机，这就造成极大浪费</li>
<li>减少网络流量，优化网络性能：隔离数据在整个网络内广播，提高信息传输速率。</li>
</ul>
<h3 id="3-1-2-子网掩码"><a href="#3-1-2-子网掩码" class="headerlink" title="3.1.2 子网掩码"></a>3.1.2 子网掩码</h3><p>子网掩码又叫网络掩码，我们现在把主机号拆分成子网号和主机号了，那拆分后，<strong>IP地址的哪些位是表示子网号，哪些位是表示主机号呢</strong>？我们需要有一种方式来标识它。这就是子网掩码。</p>
<p>子网掩码是一个32bit的值，其中值为1的比特用来标识网络号和子网号，为0的比特用来标识主机号。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4a592bcafbb0ae0fe4df866829865ce0b03.png" alt=""></p>
<h2 id="3-2-域名"><a href="#3-2-域名" class="headerlink" title="3.2 域名"></a>3.2 域名</h2><p>尽管通过IP地址可以识别主机上的网络接口，进而访问主机，但是人们最喜欢使用的还是主机名。在TCP/IP领域中，域名系统（DNS）是一个分布的数据库，由它来提供IP地址和主机名之间的映射信息。</p>
<h2 id="3-3-封装"><a href="#3-3-封装" class="headerlink" title="3.3 封装"></a>3.3 封装</h2><p>每个分层中，都会对所发送的数据附加一个首部，在这个首部中包含了该层必要的信息，如发送的目标地址以及协议相关信息。通常，为协议提供的信息为包首部，所要发送的内容为数据。在下一层的角度看，从上一层收到的包全部都被认为是本层的数据。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b91718c00fef8cde14bf35da7006952d67a.png" alt=""></p>
<blockquote>
<p>TCP传给IP的数据单元称作TCP报文段或简称为TCP段（TCP segment）。IP传给链路层的数据单元称作IP数据报(IP datagram)。通过以太网传输的比特流称作帧(Frame)。</p>
</blockquote>
<h2 id="3-4分用"><a href="#3-4分用" class="headerlink" title="3.4分用"></a>3.4分用</h2><p>当目的主机收到一个以太网数据帧时，<strong>数据就开始从协议栈中由底向上升，同时去掉各层协议加上的报文首部</strong>。每层协议盒都要去<strong>检查报文首部中的协议标识，以确定接收数据的上层协议</strong>。这个过程称作分用（Demultiplexing）。如下图</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2d7f05206f7e8ce1ac051eaf8449c9df6dc.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-990eeeb4d3a2545ae5170522df23b2dc87f.png" alt=""></p>
<h2 id="3-5-端口"><a href="#3-5-端口" class="headerlink" title="3.5 端口"></a>3.5 端口</h2><p>正常情况下，IP能锁定一台物理机器，对应着一张网卡，外界发来的数据包网卡都会接收。网卡给程序提供了接口，你监听一下我，要是有消息来了，我就转发给你。这样应用程序就能收到数据了。</p>
<p>紧接着问题来了，一台物理机器上有无数个程序，每个程序都需要监听网卡接发数据，如果网卡把接收到的数据都转发给所有的程序，那么程序将会被大量本不是发送给自己的数据淹没。</p>
<p>为了隔离不同程序的数据，我们添加了一个标识：端口，来作为区分。如果程序A的端口是8080，那么我收到有8080标识的数据，就只会转发给程序A，以此类推。</p>
<h2 id="3-6-MTU"><a href="#3-6-MTU" class="headerlink" title="3.6 MTU"></a>3.6 MTU</h2><p>最大传输单元（Maximum Transmission Unit，MTU）是指一种通信协议的某一层上面所能通过的最大数据包大小（以字节为单位）。</p>
<p>如果在IP层要传输一个数据报比链路层的MTU还大，那么IP层就会对这个数据报进行分片。一个数据报会被分为若干片，每个分片的大小都小于或者等于链路层的MTU值。</p>
<p>当同一网络上的主机互相进行通信时，该网络的MTU对通信双方非常重要。但当主机间要通过很多网络才能通信时，对通信双方最重要的是通信路径中最小的MTU，因为在通信路径上不同网络的链路层MTU不同。<strong>通信路径中最小的MTU被称为路径MTU</strong>(木桶原理)。</p>
<p>网络中一些常见链路层协议MTU的缺省数值如下：</p>
<ul>
<li>FDDI协议：4352字节</li>
<li>以太网（Ethernet）协议：1500字节</li>
<li>PPPoE（ADSL）协议：1492字节</li>
<li>X.25协议（Dial Up/Modem）：576字节</li>
<li>Point-to-Point：4470字节</li>
</ul>
<h2 id="3-7-IP分片"><a href="#3-7-IP分片" class="headerlink" title="3.7 IP分片"></a>3.7 IP分片</h2><p>因为有MTU的存在，我们要对长度大于MTU的IP数据报进行分片。</p>
<p>任何时候<strong>IP层</strong>接收到一份要发送的IP数据报时，它要判断向本地哪个接口发送数据（选路），并查询该接口获得其MTU。IP把MTU与数据报长度进行比较，如果需要则进行分片。分片可以发生在原始发送端主机上，也可以发生在中间路由器上。</p>
<p>把一份IP数据报分片以后，只有到达目的地才进行重新组装。重新组装由<strong>目的端的IP层</strong>来完成，其目的是使分片和重新组装过程对运输层（TCP和UDP）是透明的。</p>
<p>IP首部中，有如下这些字段和分片操作有关：</p>
<ol>
<li><p>标识字段：标识字段是IP数据报的唯一主键，同一个数据报分出来的分片，拥有相同的标识字段。在重新组装的时候，通过这个字段，目的端IP层可以知道哪些分片原来是一体的。</p>
</li>
<li><p>片偏移字段：该字段指的是该片的数据在原始数据报中，离开始处的偏移量。通过它，在组装时，可以确定各个分片的次序。</p>
</li>
<li><p>标志字段“不分片”位：还是标志字段中有一个比特称作“不分片”位。如果将这一比特置1，IP将不对数据报进行分片。这时如果遇到IP数据报长度大于MTU的场景，则会把数据报丢弃并发送一个ICMP差错报文给起始端。</p>
</li>
</ol>
<h1 id="4-链路层协议"><a href="#4-链路层协议" class="headerlink" title="4. 链路层协议"></a>4. 链路层协议</h1><p>在TCP/IP协议族中，链路层主要有三个目的：</p>
<ol>
<li>为IP模块发送和接收IP数据报；</li>
<li>为ARP模块发送ARP请求和接收ARP应答；</li>
<li>为RARP发送RARP请求和接收RARP应答。</li>
</ol>
<p>TCP/IP支持多种不同的链路层协议，这取决于网络所使用的硬件，如以太网、令牌环网、FDDI（光纤分布式数据接口）及RS-232串行线路</p>
<p>链路层的协议数据单元是<strong>帧</strong>——IP层（网络层）的数据报添加首部和尾部，即可封装成帧。</p>
<p>帧主要有两种封装格式IEEE 802封装和以太网封装，其中<strong>以太网封装格式是目前的主流</strong>。除此之外，还有SLIP（Serial Line IP）封装和PPP（点对点协议）封装。</p>
<h2 id="4-1-IEEE-802封装和以太网封装"><a href="#4-1-IEEE-802封装和以太网封装" class="headerlink" title="4.1 IEEE 802封装和以太网封装"></a>4.1 IEEE 802封装和以太网封装</h2><p><img src="https://oscimg.oschina.net/oscnet/up-0f5eeeb15e0ff49992da35f360f7eb1838f.png" alt=""></p>
<ul>
<li><p><strong>IEEE802.2/802.3封装协议</strong></p>
<ol>
<li>两个<strong>6字节</strong>的<strong>目的地址和源地址</strong>，这个地址指的是物理地址，也就是MAC地址(48bit)。ARP和RARP协议对32bit的IP地址和48bit的硬件地址进行映射。</li>
<li><strong>2字节</strong>的<strong>长度字段</strong>，值为后续数据的字节长度，但不包括CRC检验码。</li>
<li>3字节的802.2LLC，<ol>
<li><strong>目的服务访问点</strong>（DestinationServiceAccessPoint,DSAP）和<strong>源服务访问点</strong>（SourceServiceAccessPoint,SSAP）的值都设为0xaa。</li>
<li><strong>Ctrl字段</strong>的值设为3。</li>
</ol>
</li>
<li>一共5字节的802.2SNAP。<ol>
<li>3个字节<strong>orgcode字段</strong>都置为0。</li>
<li>2字节的<strong>类型字段</strong>，和以太网帧格式一样，其比较常见的类型字段为：0X0800（IP帧），0X0806（ARP请求/应答帧），0X8035（PARP请求/应答帧），0X8137（NovellIPX），0X809b（AppleTalk）。</li>
</ol>
</li>
<li>数据</li>
<li>CRC，<strong>CRC字段</strong>用于帧内后续字节差错的循环冗余码检验（检验和）（它也被称为FCS或帧检验序列）。</li>
</ol>
</li>
<li><p><strong>以太网封装协议（RFC 894）</strong></p>
<ol>
<li>两个<strong>6字节</strong>的<strong>目的地址和源地址</strong>，这个地址指的是物理地址，也就是MAC地址(48bit)。ARP和RARP协议对32bit的IP地址和48bit的硬件地址进行映射。</li>
<li>2字节的<strong>类型字段</strong>，其比较常见的类型字段为：0X0800（IP帧），0X0806（ARP请求/应答帧），0X8035（PARP请求/应答帧），0X8137（NovellIPX），0X809b（AppleTalk）。</li>
<li>数据</li>
<li>CRC，<strong>CRC字段</strong>用于帧内后续字节差错的循环冗余码检验（检验和）（它也被称为FCS或帧检验序列）。</li>
</ol>
</li>
</ul>
<h2 id="4-2-SLIP：串行线路IP封装协议"><a href="#4-2-SLIP：串行线路IP封装协议" class="headerlink" title="4.2 SLIP：串行线路IP封装协议"></a>4.2 SLIP：串行线路IP封装协议</h2><p>SLIP的全称是Serial Line IP。它是一种在串行线路上对IP数据报进行封装的简单形式，在RFC1055中有详细描述。SLIP适用于家庭中每台计算机几乎都有的RS-232串行端口和高速调制解调器接入Internet。</p>
<p>其封装规则十分简单，一图道尽：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5edf018ce466031e243f2c0ec1c5dd6c485.png" alt=""></p>
<ol>
<li>给IP数据报的前后端都加上一个称作END（0xc0）的特殊字符。</li>
<li>END（0xc0）SLIP协议中是特殊字符，所以如果IP报文中某个字符为END（0xc0），那么就要连续传输两个字节0xdb和0xdc来取代它。</li>
<li>0xdb这个特殊字符被称作SLIP的ESC字符，如果IP报文中某个字符为SLIP的ESC字符，那么就要连续传输两个字节0xdb和0xdd来取代它。</li>
</ol>
<p>SLIP是一种简单的帧封装方法，还有一些值得一提的<strong>缺陷</strong>：</p>
<ol>
<li>因为缺少源地址字段，SLIP没有办法把本端的IP地址通知给另一端，所以每一端必须知道对方的IP地址。。</li>
<li>数据帧中没有类型字段，如果一条串行线路用于SLIP，那么它不能同时使用其他协议。</li>
<li>SLIP没有在数据帧中加上检验和（类似于以太网中的CRC字段）。如果SLIP传输的报文被线路噪声影响而发生错误，只能通过上层协议来发现</li>
</ol>
<h2 id="4-3-PPP：点对点封装协议"><a href="#4-3-PPP：点对点封装协议" class="headerlink" title="4.3 PPP：点对点封装协议"></a>4.3 PPP：点对点封装协议</h2><p>同样作为常用于低速的串行链路的封装协议，PPP（Point to Point Protocol）点对点协议修改了SLIP协议中的所有缺陷。如图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-292e5ecec943da43f8c798b1558e0f3f64e.png" alt=""></p>
<ol>
<li>每一帧都以<strong>标志字符</strong>0x7e开始和结束。</li>
<li>一个字节的<strong>地址字段</strong>，值始终是0xff。</li>
<li>一个字节的<strong>控制字段</strong>，值始终是0x03。</li>
<li><strong>协议字段</strong>，类似于以太网中类型字段的功能。<ul>
<li>值为0x0021时，表示信息字段是一个IP数据报；</li>
<li>值为0xc021时，表示信息字段是链路控制数据；</li>
<li>值为0x8021时，表示信息字段是网络控制数据。</li>
</ul>
</li>
<li>数据</li>
<li><strong>CRC字段</strong>（或FCS，帧检验序列）是一个循环冗余检验码，以检测数据帧中的错误。</li>
</ol>
<p>PPP比SLIP具有下面这些优点：</p>
<ol>
<li>PPP支持在单根串行线路上运行多种协议，不只是IP协议；</li>
<li>每一帧都有循环冗余检验；</li>
<li>通信双方可以进行IP地址的动态协商(使用IP网络控制协议)；</li>
<li>与CSLIP类似，对TCP和IP报文首部进行压缩；</li>
<li>链路控制协议可以对多个数据链路选项进行设置。为这些优点付出的代价是在每一帧的首部增加3个字节，当建立链路时要发送几帧协商数据，以及更为复杂的实现。</li>
</ol>
<h1 id="5-网络层协议"><a href="#5-网络层协议" class="headerlink" title="5. 网络层协议"></a>5. 网络层协议</h1><h2 id="5-1-IP协议"><a href="#5-1-IP协议" class="headerlink" title="5.1 IP协议"></a>5.1 IP协议</h2><p>IP是TCP/IP协议族中最为核心的协议。所有的TCP、UDP、ICMP及IGMP数据都以IP数据报格式传输。</p>
<p>IP提供<strong>不可靠</strong>、<strong>无连接</strong>的数据报传送服务</p>
<ul>
<li>不可靠（unreliable）的意思是它<strong>不能保证IP数据报能成功地到达目的地</strong>。IP仅提供最好的传输服务。如果发生某种错误时，如某个路由器暂时用完了缓冲区，IP有一个简单的错误处理算法：丢弃该数据报，然后发送ICMP消息报给信源端。任何要求的可靠性必须由上层来提供（如TCP）。</li>
<li>无连接（connectionless）这个术语的意思是IP并不维护任何关于后续数据报的状态信息。<strong>每个数据报的处理是相互独立的</strong>。这也说明，IP数据报可以不按发送顺序接收。如果一信源向相同的信宿发送两个连续的数据报（先是A，然后是B），每个数据报都是独立地进行路由选择，可能选择不同的路线，因此B可能在A到达之前先到达。</li>
</ul>
<h3 id="5-1-1-IP首部"><a href="#5-1-1-IP首部" class="headerlink" title="5.1.1 IP首部"></a>5.1.1 IP首部</h3><p>IP数据报的格式如下图所示。普通的IP首部长为20个字节，即160位（不包含选项字段）。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b5c16d7c7963e9a676df4af41971b566f1e.png" alt=""></p>
<ol>
<li><strong>版本号</strong>，目前是4或者6，我们平常看到的IPv4和IPv6由此区分。</li>
<li><strong>首部长度</strong>，指的是首部（包括任何选项）有多少个4字节（32bit）的数目（也就是首部总位数/32）。由于它每个bit位代表4个字节，且是一个4bit字段，因此首部最长为60个字节。</li>
<li><strong>服务类型</strong>，共8bit，其中：<ul>
<li>3bit优先权字段(现在已被忽略)，默认值是000</li>
<li>4bit的TOS子字段，其值分布和含义如下：<ul>
<li>1000 – minimize delay #<strong>最小延迟</strong>：对应于对延迟敏感的应用，如telnet和人login</li>
<li>0100 – maximize throughput #<strong>最大吞吐量</strong>：对应于对吞吐量要求比较高的应用，如FTP文件应用，对文件传输吞吐量有比较高的要求。</li>
<li>0010 – maximize reliability #<strong>最高可靠性</strong>：对网络传输可靠性要求高的应用，如使用SNMP的应用、路由协议等等。</li>
<li>0001 – minimize monetary cost #<strong>最小费用</strong>：如NNTP这种用户网络新闻等。</li>
<li>0000 – normal service #一般服务</li>
</ul>
</li>
<li>1bit未用位，但必须置0。</li>
</ul>
</li>
<li><strong>总长度字段</strong>，16bit，是指整个IP数据报的长度，以字节为单位。</li>
<li><strong>标识字段</strong>，16bit，唯一地标识主机发送的每一份数据报，也就是主机发送报文的id，通常每发送一份报文它的值就会加1。如果IP报文在数据链路层被分片了，那么每一个片里面的这个id字段相同。</li>
<li><strong>标志字段</strong>，3bit，第一位保留，第二位置为1，标识禁止分片，这时候如果IP报文大于MTU，IP模块就会丢弃报文；第3位表示更多分片，如果分片了的话，最后一个分片置为1，其他都是0，类似于一个结束标记</li>
<li><strong>分片偏移字段</strong>，是分片相对于原始IP报文开始处的偏移，单位是bit，故而实际偏移的字节数为该值 * 8，因此，除了最后一个报文之外，其它的报文长度必须是8的整数倍，否则报文不连续。</li>
<li><strong>TTL（time-to-live）生存时间字段</strong>，表示数据报可以经过最多多少个路由器。其初始值由源主机设置（通常为32或64），每经过一个路由器，值减1。值为0时，数据报就被丢弃，并发送ICMP报文通知源主机。该字段是为了防止出现路由循环而设。</li>
<li><strong>协议字段</strong>，指在上层（TCP/IP的传输层）使用的协议，可能的协议有UDP、TCP、ICMP、IGMP、IGP等。TCP协议为6，UDP协议为17，ICMP为1。</li>
<li><strong>首部校验和</strong>，用于检验IP报文头部在传播的过程中是否出错，主要校验报文头中是否有某一个或几个bit被污染或修改了。<ul>
<li>首先把检验和字段置为0。以抓包得到的该首部为例：<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-56ae92b4a4735c455e500848f2c66430fa7.png" alt=""></li>
</ul>
</li>
<li>然后，对首部中<strong>每16bit</strong>进行二进制反码求和，结果存在检验和字段中。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-d28dd4972d26fdd4772ad77b4f0c83e1f1b.png" alt=""></li>
</ul>
</li>
<li>当收到一份IP数据报后，同样对首部中每个16bit进行二进制反码的求和。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-d9b94b7a21ca5204a4aa50bf7a468a6d61f.png" alt=""></li>
</ul>
</li>
<li>由于接收方在计算过程中包含了发送方存在首部中的检验和，因此，如果首部在传输过程中没有发生任何差错，那么接收方计算的结果应该为全1（也就是0xffff）。如果结果不是全1（即检验和错误），那么IP就丢弃收到的数据报。</li>
<li>ICMP、IGMP、UDP和TCP都采用相同的检验和算法</li>
</ul>
</li>
<li><strong>源IP地址</strong>，32位，4个字节，每一个字节为0～255之间的整数</li>
<li><strong>目的IP地址</strong>，32位，4个字节，每一个字节为0～255之间的整数</li>
<li><strong>选项</strong>，是数据报中的一个可变长的可选信息。选项可用于：<ul>
<li>安全和处理限制（用于军事领域）</li>
<li>记录路径（让每个路由器都记下它的IP地址）</li>
<li>时间戳（让每个路由器都记下它的IP地址和时间）</li>
<li>宽松的源站选路（为数据报指定一系列必须经过的IP地址）</li>
<li>严格的源站选路（与宽松的源站选路类似，但是要求只能经过指定的这些地址，不能经过其他的地址）。</li>
</ul>
</li>
</ol>
<blockquote>
<p>选项字段很少被使用，并非所有的主机和路由器都支持这些选项。选项字段一直都是以32bit作为界限，在必要的时候插入值为0的填充字节。这样就保证IP首部始终是32bit的整数倍（这是首部长度字段所要求的）。</p>
</blockquote>
<h2 id="5-2-ARP协议和RARP协议"><a href="#5-2-ARP协议和RARP协议" class="headerlink" title="5.2 ARP协议和RARP协议"></a>5.2 ARP协议和RARP协议</h2><p>ARP协议是“Address Resolution Protocol”（地址解析协议）的缩写。在以太网环境中，数据的传输所依懒的是MAC地址而非IP地址，ARP协议的作用是<strong>将已知的IP地址转换为MAC地址</strong>。</p>
<p>RARP协议是“Reverse Address Resolution Protocol”（反向地址转换协议）的缩写。具有本地磁盘的系统引导时，一般是从磁盘上的配置文件中读取 IP地址。但是无盘机，如X终端或无盘工作站，则需要采用其他方法来获得IP地址。RARP协议的作用就是<strong>将已知的MAC地址转换为IP地址</strong></p>
<h3 id="5-2-1-协议原理"><a href="#5-2-1-协议原理" class="headerlink" title="5.2.1 协议原理"></a>5.2.1 协议原理</h3><h4 id="5-2-1-1-APR原理"><a href="#5-2-1-1-APR原理" class="headerlink" title="5.2.1.1 APR原理"></a>5.2.1.1 APR原理</h4><p>ARP发送一份称作ARP请求的以太网数据帧给以太网上的每个主机。这个过程称作广播，如下图的虚线所示。ARP请求数据帧中包含目的主机的IP地址（假设主机名为bsdi），其意思是“如果你是这个IP地址的拥有者，请回答你的硬件地址。”</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-18c73d5a678a5c9fff90572f89992f48f5f.png" alt=""></p>
<p>目的主机的ARP层收到这份广播报文后，识别出这是发送端在寻问它的IP地址，于是发送一个ARP应答。这个ARP应答包含IP地址及对应的硬件地址。收到ARP应答后，使ARP进行请求—应答交换的IP数据报现在就可以传送了。</p>
<h4 id="5-2-1-2-RAPR原理"><a href="#5-2-1-2-RAPR原理" class="headerlink" title="5.2.1.2 RAPR原理"></a>5.2.1.2 RAPR原理</h4><p>同理：</p>
<p>网络上的每个系统都具有唯一的硬件地址，它是由网络接口生产厂家配置的。无盘系统的RARP实现过程是从接口卡上读取唯一的硬件地址，然后发送一份RARP请求（一帧在网络上广播的数据），请求某个主机响应这个无盘系统的IP地址（在RARP应答中）。从而得到这个MAC地址对应的IP地址</p>
<h3 id="5-2-2-ARP高速缓存"><a href="#5-2-2-ARP高速缓存" class="headerlink" title="5.2.2 ARP高速缓存"></a>5.2.2 ARP高速缓存</h3><p>ARP高效运行的关键是由于每个主机上都有一个ARP高速缓存。这个高速缓存存放了最近Internet地址到硬件地址之间的映射记录，从中直接读取，缓解链路压力。高速缓存中每一项的生存时间一般为20分钟，起始时间从被创建时开始算起</p>
<p>我们可以用arp命令来检查ARP高速缓存。参数-a的意思是显示高速缓存中所有的内容。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ arp -a</span><br><span class="line">&gt; sun (140.252.13.33) at 8:0:20:3:f6:42</span><br><span class="line">&gt; svr4 (140.252.13.34) at 0:0:c0:c2:9b:26</span><br></pre></td></tr></table></figure>

<p><img src="https://oscimg.oschina.net/oscnet/up-a74affe098a2b2dcb35b0974ea9fdfdb920.png" alt=""></p>
<h3 id="5-2-3-ARP-RARP的分组格式"><a href="#5-2-3-ARP-RARP的分组格式" class="headerlink" title="5.2.3 ARP/RARP的分组格式"></a>5.2.3 ARP/RARP的分组格式</h3><p>在以太网上解析IP地址时，ARP/RARP请求和应答分组的格式如图所示</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-83112c312c9096d76aaca2d6f38bf459b20.png" alt=""></p>
<ol>
<li><strong>目标mac地址</strong>：ARP请求的目的以太网地址，全1时，代表广播地址。</li>
<li><strong>源mac地址</strong>：发送ARP请求的以太网地址。</li>
<li><strong>帧类型</strong>：以太网帧类型表示后面的数据类型，ARP请求和ARP应答此字段为：0x0806。</li>
<li><strong>硬件类型</strong>：硬件类型字段表示硬件地址的类型。它的值为1即表示以太网地址。</li>
<li><strong>协议类型</strong>：表示要映射的协议地址类型。它的值为0x0800即表示IP地址。它的值与包含IP数据报的以太网数据帧中的类型字段的值相同，这是有意设计的</li>
<li><strong>硬件地址长度、协议地址长度</strong>：表示硬件地址长度和协议地址长度，MAC地址占6字节，IP地址占4字节。</li>
<li><strong>操作类型</strong>：值为1，表示进行ARP请求；值为2，表示进行ARP应答；值为3，表示进行RARP请求；值为4，表示进行RARP应答。</li>
<li><strong>发送端以太网地址和协议地址</strong>：发送端的硬件地址（在本例中是以太网地址）和协议地址（IP地址）</li>
<li><strong>目的端的硬件地址和目的端的协议地址</strong>：目的端的硬件地址（在本例中是以太网地址）和协议地址（IP地址）。（这是重复数据，在以太网的数据帧报头中和ARP请求数据帧中都有发送端的硬件地址。）</li>
</ol>
<blockquote>
<p>对于一个ARP/RARP请求来说，除<strong>目的端硬件地址</strong>外的所有其他的字段，都已经有填充值。当系统收到一份目的端为本机的ARP请求报文后，它就把硬件地址填进去，然后用两个目的端地址分别替换两个发送端地址，并把操作字段置为2，最后把它发送回去。</p>
</blockquote>
<blockquote>
<p>ARP/RARP二者的分组格式，除了操作类型字段以外，其他字段都一样</p>
</blockquote>
<h2 id="5-3-ICMP协议"><a href="#5-3-ICMP协议" class="headerlink" title="5.3 ICMP协议"></a>5.3 ICMP协议</h2><p>ICMP协议，全称是Internet Control Message Protocol，意思是Internet控制消息协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息（可以理解为回来报信的信鸽）。<strong>控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息</strong>。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。</p>
<p>ICMP 的内容是放在IP数据包的数据部分里来互相交流的。也就是，从ICMP的报文格式来说，ICMP 是IP 的上层协议。但是，正如RFC所记载的，ICMP是分担了IP的一部分功能。所以，被认为是与IP 同层的协议。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-c77afda8e8ee65a9872da5f221ef6696631.png" alt=""></p>
<h3 id="5-3-1-ICMP的分类"><a href="#5-3-1-ICMP的分类" class="headerlink" title="5.3.1 ICMP的分类"></a>5.3.1 ICMP的分类</h3><p>在RFC，将ICMP 大致分成两种功能：</p>
<ol>
<li>差错报文：在IP数据包被对方的计算机处理的过程中，发生了某些错误时被使用。不仅传送发生了错误这个事实，也传送错误原因等消息。</li>
<li>查询报文：是在送信方的计算机向对方计算机询问信息时被使用。被询问内容的种类非常丰富，如：目标IP地址的机器是否存在，调查自己网络的子网掩码，取得对方机器的时间信息等。</li>
</ol>
<h3 id="5-3-2-ICMP的报文"><a href="#5-3-2-ICMP的报文" class="headerlink" title="5.3.2 ICMP的报文"></a>5.3.2 ICMP的报文</h3><p><img src="https://oscimg.oschina.net/oscnet/up-de1e6079bd0c3c227e27a4f1d830e2219fe.png" alt=""></p>
<p>如上图，我们将完整的IP首部+ICMP报文都展示了出来，IP首部各字段，前文已经有过描述。</p>
<p>用来传送ICMP报文的IP数据包上实际上有不少字段。但是实际上与ICMP协议相关的只有7个子段。</p>
<ol>
<li>协议：ICMP协议的IP数据包，该字段为1；</li>
<li>源IP 地址：顾名思义，不再赘述。</li>
<li>目的IP 地址：顾名思义，不再赘述。</li>
<li>生存时间：TTL，不再赘述。</li>
</ol>
<p>上述这四个包含在IP 首部的字段。</p>
<ol start="5">
<li>类型；</li>
<li>代码；</li>
<li>选项数据；</li>
</ol>
<p>上述这三个包含在ICMP数据部分的字段。</p>
<p>其中<strong>类型</strong>和<strong>代码</strong>字段是ICMP报文的核心，这两个字段的组合，可以用来标识ICMP的差错报文和查询报文的大多数场景，如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-80196ab227699291306a266fcf45c9b7c36.png" alt=""></p>
<p>至于选项数据字段，当ICMP需要传送额外数据时，则放置在选项数据字段中。</p>
<h1 id="6-运输层协议"><a href="#6-运输层协议" class="headerlink" title="6. 运输层协议"></a>6. 运输层协议</h1><h2 id="6-1-TCP协议"><a href="#6-1-TCP协议" class="headerlink" title="6.1 TCP协议"></a>6.1 TCP协议</h2><p>详见文章《TCP协议分析》</p>
<h2 id="6-2-UDP协议"><a href="#6-2-UDP协议" class="headerlink" title="6.2 UDP协议"></a>6.2 UDP协议</h2><p>详见文章《UDP协议分析》</p>
<hr>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://developer.51cto.com/art/201906/597961.htm" target="_blank" rel="noopener" title="太厉害了，终于有人能把TCP/IP协议讲的明明白白了！">太厉害了，终于有人能把TCP/IP协议讲的明明白白了！</a></p>
<p><a href="https://blog.csdn.net/sj349781478/article/details/74058939" target="_blank" rel="noopener" title="以太网协议封装格式">以太网协议封装格式</a></p>
<p><a href="https://www.cnblogs.com/iiiiher/p/8513748.html" target="_blank" rel="noopener" title="完全理解icmp协议">完全理解icmp协议</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/20/ElasticSearch%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E8%AF%A6%E8%A7%A3%EF%BC%88index-type-doc-node-shard-replica-segment%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/20/ElasticSearch%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E8%AF%A6%E8%A7%A3%EF%BC%88index-type-doc-node-shard-replica-segment%EF%BC%89/" itemprop="url">ElasticSearch核心概念详解（index/type/doc/node/shard/replica/segment）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-02-20T23:01:01+08:00">
                2020-02-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index">
                    <span itemprop="name">中间件</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/ElasticSearch/" itemprop="url" rel="index">
                    <span itemprop="name">ElasticSearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/02/20/ElasticSearch%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E8%AF%A6%E8%A7%A3%EF%BC%88index-type-doc-node-shard-replica-segment%EF%BC%89/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/02/20/ElasticSearch核心概念详解（index-type-doc-node-shard-replica-segment）/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  9.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  33
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>ElasticSearch，简称ES，是一个基于Lucene的搜索服务器。要想了解ES，必须先了解Lucene。</p>
<h2 id="数据和搜索"><a href="#数据和搜索" class="headerlink" title="数据和搜索"></a>数据和搜索</h2><p>我们知道，生活中我们有两类的数据：</p>
<ol>
<li><strong>结构化数据</strong>：也称作行数据，是由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。指具有固定格式或有限长度的数据，如数据库，元数据等。</li>
<li><strong>非结构化数据</strong>：又可称为全文数据，不定长或无固定格式，不适于由数据库二维表来表现，包括所有格式的办公文档、XML、HTML、word文档，邮件，各类报表、图片和咅频、视频信息等。</li>
</ol>
<p>根据两种数据分类，搜索也相应的分为两种：<strong>结构化数据搜索</strong>和<strong>非结构化数据搜索</strong>。对于结构化数据，因为它们具有特定的结构，所以我们一般都是可以通过关系型数据库（mysql，oracle等）的二维表（table）的方式存储和搜索，也可以建立索引。</p>
<p>对于非结构化数据，也即对全文数据的搜索主要有两种方法：<strong>顺序扫描法</strong>，<strong>全文检索</strong>。</p>
<ol>
<li><strong>顺序扫描</strong>：通过文字名称也可了解到它的大概搜索方式，即按照顺序扫描的方式查询特定的关键字。例如给你一张报纸，让你找到该报纸中“平安”的文字在哪些地方出现过。你肯定需要从头到尾把报纸阅读扫描一遍然后标记出关键字在哪些版块出现过以及它的出现位置。</li>
</ol>
<p>这种方式无疑是最耗时的最低效的，如果报纸排版字体小，而且版块较多甚至有多份报纸，等你扫描完你的眼睛也差不多了。</p>
<ol start="2">
<li><strong>全文搜索</strong>：对非结构化数据顺序扫描很慢，我们是否可以进行优化？把我们的非结构化数据想办法弄得有一定结构不就行了吗？将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。</li>
</ol>
<p>这种方式就构成了全文检索的基本思路。这部分从非结构化数据中提取出的然后重新组织的信息，我们称之<strong>索引</strong>。这种方式的主要工作量在前期索引的创建，但是对于后期搜索却是快速高效的。</p>
<h2 id="Lucene"><a href="#Lucene" class="headerlink" title="Lucene"></a>Lucene</h2><p>通过对生活中数据的类型作了一个简短了解之后，我们知道关系型数据库的SQL检索是处理不了这种非结构化数据的。这种非结构化数据的处理需要依赖全文搜索，而目前市场上开放源代码的最好全文检索引擎工具包就属于 apache 的 Lucene了。</p>
<p>但是 Lucene 只是一个工具包，它不是一个完整的全文检索引擎。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。</p>
<p>目前以 Lucene 为基础建立的开源可用全文搜索引擎主要是 Solr 和 Elasticsearch。</p>
<p>Solr 和 Elasticsearch 都是比较成熟的全文搜索引擎，能完成的功能和性能也基本一样。但是 ES 本身就具有分布式的特性和易安装使用的特点，而Solr的分布式需要借助第三方来实现，例如通过使用ZooKeeper来达到分布式协调管理。</p>
<p>不管是 Solr 还是 Elasticsearch 底层都是依赖于 Lucene，而 Lucene 能实现全文搜索主要是因为它实现了<strong>倒排索引</strong>的查询结构。（稍后展开）</p>
<h1 id="1-ES基本概念详解"><a href="#1-ES基本概念详解" class="headerlink" title="1. ES基本概念详解"></a>1. ES基本概念详解</h1><p>ElasticSearch提供了一个分布式多用户能力的<strong>全文搜索引擎</strong>，基于RESTful web接口。Elasticsearch是用Java语言开发的，并作为Apache许可条款下的开放源码发布，是一种流行的企业级搜索引擎。</p>
<p>ElasticSearch用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。其官方客户端在Java、.NET（C#）、PHP、Python、Apache Groovy、Ruby和许多其他语言中都是可用的。根据DB-Engines的排名显示，Elasticsearch是最受欢迎的企业搜索引擎，其次是Apache Solr，也是基于Lucene。</p>
<p>不过，Elasticsearch不仅仅是Lucene和全文搜索，我们还能这样去描述它：</p>
<ul>
<li>分布式的实时文件存储，每个字段都被索引并可被搜索</li>
<li>分布式的实时分析搜索引擎</li>
<li>可以扩展到上百台服务器，处理PB级结构化或非结构化数据</li>
</ul>
<p>es和lucene，solr一样，都是无模式的基于列式的存储格式，这和大多数的NoSQL数据库是一样的，非常灵活，下面我们通过一张图，来看下关系型数据库映射到es里面，对应的名词关系</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6d546ac1f5a76da02b2d7b943ca778010e9.png" alt=""></p>
<h2 id="1-1-Index"><a href="#1-1-Index" class="headerlink" title="1.1 Index"></a>1.1 Index</h2><p>Index，索引，是文档(Document)的容器，是一类文档的集合。</p>
<p>ElasticSearch将它的数据存储在一个或多个索引（index）中。索引就像数据库，可以向索引写入文档或者从索引中读取文档</p>
<p>索引这个词在 ElasticSearch 会有两种意思:</p>
<ol>
<li><p>索引(名词)</p>
<ul>
<li>类比传统的关系型数据库领域来说，<strong>索引相当于SQL中的一个数据库(Database)</strong>。索引由其名称(<strong>必须为全小写字符</strong>)进行标识。</li>
</ul>
</li>
<li><p>索引(动词)</p>
<ul>
<li><strong>保存一个文档到索引(名词)的过程</strong>。这非常类似于SQL语句中的 INSERT关键词。如果该文档已存在时那就相当于数据库的UPDATE。</li>
</ul>
</li>
</ol>
<h2 id="1-2-Type"><a href="#1-2-Type" class="headerlink" title="1.2 Type"></a>1.2 Type</h2><p>Type，类型，可以理解成关系数据库中Table（虽然不完全一致）。用于区分同一个集合中的不同细分。</p>
<p>但和Table不同的是，不同表中的字段可以同名，但他们还是独立的，比如表A的a字段可以是VARCHAR类型，表B的a字段可以是INT类型。</p>
<p>而不同类型的同名字段，他们其实是同一个字段，所以无法独立，实际上，es在底层，也是将不同type的字段都映射为扁平的模式。而不是为每种type分配单独的映射空间。</p>
<p>这导致了type不适合于描述完全不同类型的数据 ，如type A有a，b，c三个字段，type B有d，e，f三个字段，那么这种情况建议不要使用type。</p>
<p>A { a,b,c}和B{b,c,d}这种情况才适用，即<strong>二者间大部分的数据是相同的</strong>，这种情况下，es的扁平化映射，可以复用这部分重合的数据。</p>
<p>之前的版本中，索引和文档中间还有个类型的概念，每个索引下可以建立多个类型，文档存储时需要指定index和type。从6.0.0开始单个索引中只能有一个类型，</p>
<p>7.0.0以后将将不建议使用，8.0.0 以后完全不支持。</p>
<h3 id="1-2-1弃用该概念的原因："><a href="#1-2-1弃用该概念的原因：" class="headerlink" title="1.2.1弃用该概念的原因："></a>1.2.1弃用该概念的原因：</h3><p>我们虽然可以通俗的去理解Index比作 SQL 的 Database，Type比作SQL的Table。但这并不准确，因为如果在SQL中，Table 之前相互独立，同名的字段在两个表中毫无关系。</p>
<p>但是在ES中，同一个Index 下不同的 Type 如果有同名的字段，他们会被Luecence当作同一个字段 ，并且他们的定义必须相同。所以我觉得Index现在更像一个表，而Type字段则并没有多少意义。</p>
<p>目前Type已经被Deprecated，在7.0开始，一个索引只能建一个Type为<code>_doc</code></p>
<h2 id="1-3-Document"><a href="#1-3-Document" class="headerlink" title="1.3 Document"></a>1.3 Document</h2><p>Document，文档，Index 里面单条的记录称为Document。<strong>等同于关系型数据库表中的行</strong>。</p>
<p>我们来看下一个文档的源数据</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fb0733a15d98fe88fbb22b4ea3898cc37c0.png" alt=""></p>
<ul>
<li><p><code>_index</code>文档所属索引名称。</p>
</li>
<li><p><code>_type</code>文档所属类型名。</p>
</li>
<li><p><code>_id</code>Doc的主键。在写入的时候，可以指定该Doc的ID值，如果不指定，则系统自动生成一个唯一的UUID值。</p>
</li>
<li><p><code>_version</code>文档的版本信息。Elasticsearch通过使用version来保证对文档的变更能以正确的顺序执行，避免乱序造成的数据丢失。</p>
</li>
<li><p><code>_seq_no</code>严格递增的顺序号，每个文档一个，Shard级别严格递增，保证后写入的Doc的<code>_seq_no</code>大于先写入的Doc的_seq_no。</p>
</li>
<li><p><code>primary_term</code>primary_term也和<code>_seq_no</code>一样是一个整数，每当Primary Shard发生重新分配时，比如重启，Primary选举等，_primary_term会递增1</p>
</li>
<li><p><code>found</code>查询的ID正确那么ture, 如果 Id 不正确，就查不到数据，found字段就是false。</p>
</li>
<li><p><code>_source</code>文档的原始JSON数据。</p>
</li>
</ul>
<h1 id="2-ES分布式概念详解"><a href="#2-ES分布式概念详解" class="headerlink" title="2. ES分布式概念详解"></a>2. ES分布式概念详解</h1><h2 id="2-1-集群-cluster"><a href="#2-1-集群-cluster" class="headerlink" title="2.1 集群(cluster)"></a>2.1 集群(cluster)</h2><p>ElasticSearch集群实际上是一个分布式系统，它需要具备两个特性：</p>
<ul>
<li><p>高可用性</p>
<ul>
<li>服务可用性：允许有节点停止服务；</li>
<li>数据可用性：部分节点丢失，不会丢失数据；</li>
</ul>
</li>
<li><p>可扩展性</p>
<ul>
<li>随着请求量的不断提升，数据量的不断增长，系统可以将数据分布到其他节点，实现水平扩展；</li>
</ul>
</li>
</ul>
<p>一个集群中可以有一个或者多个节点；</p>
<p>我们采用集群健康值来衡量一个集群的状态</p>
<ol>
<li><code>green</code>：所有主要分片和复制分片都可用</li>
<li><code>yellow</code>：所有主要分片可用，但不是所有复制分片都可用</li>
<li><code>red</code>：不是所有的主要分片都可用</li>
</ol>
<blockquote>
<p>当集群状态为 red，它仍然正常提供服务，它会在现有存活分片中执行请求，我们需要尽快修复故障分片，防止查询数据的丢失；</p>
</blockquote>
<h2 id="2-2-节点-Node"><a href="#2-2-节点-Node" class="headerlink" title="2.2 节点(Node)"></a>2.2 节点(Node)</h2><p>es集群是通过多台服务器来搭建，它们拥有一个共同的clustername比如叫做“escluster”，每台服务器叫做一个节点，用于存储数据并提供集群的搜索和索引功能。</p>
<p>节点拥有自己的唯一名字，默认在节点启动时会生成一个uuid作为节点名，该名字也可以手动指定。</p>
<p>单个集群可以由任意数量的节点组成。如果只启动了一个节点，则会形成一个单节点的集群。其配置文件如下：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">集群名称，用于定义哪些<span class="selector-tag">elasticsearch</span>节点属同一个集群。</span><br><span class="line"><span class="selector-tag">cluster</span><span class="selector-class">.name</span>: <span class="selector-tag">bigdata</span></span><br><span class="line">节点名称，用于唯一标识节点，不可重名</span><br><span class="line"><span class="selector-tag">node</span><span class="selector-class">.name</span>: <span class="selector-tag">server3</span></span><br><span class="line">设置索引的分片数,默认为5 </span><br><span class="line"><span class="selector-tag">index</span><span class="selector-class">.number_of_shards</span>: 5 </span><br><span class="line">设置索引的副本数,默认为1: </span><br><span class="line"><span class="selector-tag">index</span><span class="selector-class">.number_of_replicas</span>: 1</span><br></pre></td></tr></table></figure>

<p>节点是一个ElasticSearch的实例，其本质就是一个Java进程；一台机器上可以运行多个ElasticSearch实例，但是建议在生产环境中一台机器上只运行一个ElasticSearch实例；</p>
<h3 id="2-2-3-节点的类型"><a href="#2-2-3-节点的类型" class="headerlink" title="2.2.3 节点的类型"></a>2.2.3 节点的类型</h3><h3 id="2-2-1-四种普通节点"><a href="#2-2-1-四种普通节点" class="headerlink" title="2.2.1 四种普通节点"></a>2.2.1 四种普通节点</h3><p>在es节点的yml文件中可以配置节点的类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conf&#x2F;elasticsearch.yml:</span><br><span class="line">	node.master: true&#x2F;false</span><br><span class="line">	node.data: true&#x2F;false</span><br></pre></td></tr></table></figure>

<p>其中node.master配置表示节点是否具有成为主节点的资格节点。</p>
<blockquote>
<p>此属性的值为true，并不意味着这个节点就是主节点。因为真正的主节点，是由多个具有主节点资格的节点进行选举产生的。所以，这个属性只是代表这个节点是不是具有主节点选举资格。</p>
</blockquote>
<p>node.data配置表示节点是否存储数据。</p>
<p>node.master和node.data的取值可以有四种情况，表示四种节点类型。</p>
<ul>
<li><p><code>node.master: true</code>并且<code>node.data: true</code></p>
<ul>
<li>这种组合表示这个节点即有成为主节点的资格，又存储数据。这个时候如果某个节点被选举成为了真正的主节点，那么他还要存储数据，这样对于这个节点的压力就比较大了。<strong>elasticsearch默认每个节点都是这样的配置</strong>，在测试环境下这样做没问题。实际工作中建议不要这样设置，这样相当于主节点和数据节点的角色混合到一块了。</li>
</ul>
</li>
<li><p><code>node.master: false</code>并且<code>node.data: true</code></p>
<ul>
<li>这种组合表示这个节点没有成为主节点的资格，也就不参与选举，只会存储数据。这个节点我们称为<strong>data(数据)节点</strong>。在集群中需要单独设置几个这样的节点负责存储数据，后期提供存储和查询服务</li>
</ul>
</li>
<li><p><code>node.master: true</code>并且<code>node.data: false</code></p>
<ul>
<li>这种组合表示这个节点不会存储数据，有成为主节点的资格，可以参与选举，有可能成为真正的主节点。对于master节点而言，这样的配置是最适合的。</li>
</ul>
</li>
<li><p><code>node.master: false</code>并且<code>node.data: false</code></p>
<ul>
<li>这种组合表示这个节点即不会成为主节点，也不会存储数据，这个节点的意义是作为一个<strong>client(客户端)节点</strong>，主要是针对海量请求的时候，这些节点负责处理用户请求，实现请求转发，负载均衡等功能。</li>
</ul>
</li>
</ul>
<h3 id="2-2-2-master节点"><a href="#2-2-2-master节点" class="headerlink" title="2.2.2 master节点"></a>2.2.2 master节点</h3><p>拥有选举成为master节点资格的节点经过选举，成为了master节点，</p>
<p>Elasticsearch中的master并不像mysql、hadoop集群的master那样，它既不是集群数据的唯一流入点，也不是所有元数据的存放点。所以，一般情况下Elasticsearch的Master负载是很低的。</p>
<p>master集群的主要工作有：</p>
<ol>
<li><p>同步集群状态：集群状态信息，由master节点进行维护，并且同步到集群中所有节点。也就是说集群中的任何节点都存储着集群状态信息（经过master的同步），但只有Master能够改变信息。我们可以通过接口读取它，如：/_cluster/state</p>
<ul>
<li><p>集群状态中包括：</p>
<ol>
<li>集群层面的设置</li>
<li>集群内有哪些节点的信息</li>
<li>各索引的设置，映射，分析器和别名等设置</li>
<li>索引内各分片所在的节点位置</li>
</ol>
</li>
</ul>
</li>
<li><p>集群状态的修改：集群状态的修改通过Master节点完成，比如索引的创建删除，mapping的修改等等。</p>
<ul>
<li>我们知道配置项dynamic=true表示对于未mapping的新字段，es会尝试猜测该字段的类型，并mapping它。此时数据节点需要跟Master通信，通知Master修改Mapping。这个时候的index写入是阻塞的。等Master修改了集群状态之后，再同步到所有节点，才可以继续写入。</li>
</ul>
</li>
</ol>
<h3 id="2-2-4-master选举"><a href="#2-2-4-master选举" class="headerlink" title="2.2.4 master选举"></a>2.2.4 master选举</h3><p>详见另一篇文章<a href="https://my.oschina.net/lscherish/blog/3167953" target="_blank" rel="noopener" title="ElasticSearch Master选举机制浅析">ElasticSearch Master选举机制浅析</a></p>
<h2 id="2-3-分片-Shared"><a href="#2-3-分片-Shared" class="headerlink" title="2.3 分片(Shared)"></a>2.3 分片(Shared)</h2><p>分片是什么？简单来讲就是咱们在ES中所有数据的文件块，也是<strong>数据的最小单元块</strong>，整个ES集群的核心就是对所有分片进行分布、索引、负载、路由等操作，来达到惊人的速度。</p>
<p>文档存储在分片中，然后分片分配到集群中的节点上。当集群扩容或缩小，Elasticsearch 将会自动在节点间迁移分片，以使集群保持平衡。</p>
<blockquote>
<p>假设 IndexA 有2个分片，我们向 IndexA 中插入10条数据 (10个文档)，那么这10条数据会尽可能平均的分为5条存储在第一个分片，剩下的5条会存储在另一个分片中。</p>
</blockquote>
<p>一个分片(shard)是一个最小级别“<strong>工作单元(worker unit)</strong>”，大多数情况下，它只是保存了索引中所有数据的<strong>一部分</strong>。</p>
<blockquote>
<p>这类似于 MySql 的分库分表。</p>
</blockquote>
<h3 id="2-3-1-分片的种类"><a href="#2-3-1-分片的种类" class="headerlink" title="2.3.1 分片的种类"></a>2.3.1 分片的种类</h3><p><strong>一个分片就是一个运行的 lucene 实例</strong>，一个节点可以包含多个分片，这些分片可以是：</p>
<ul>
<li><p>主分片（<strong>primary shard</strong>）</p>
<ul>
<li>用于解决数据<strong>水平扩展</strong>的问题，一个索引的所有数据是分布在所有主分片之上的（<strong>每个主分片承担一部分数据</strong>，主分片又分布在不同的节点上）</li>
<li>一个索引的主分片数量只能在创建时指定，<strong>es默认情况下数量为5</strong>，主分片数量一经指定<strong>后期无法修改</strong>，除非对数据进行重新构建索引（reindex操作）。</li>
</ul>
</li>
<li><p>副分片（<strong>replica shard</strong>）</p>
<ul>
<li>用于解决<strong>数据高可用</strong>的问题，一个副本分片即一个主分片的拷贝，其数量可以动态调整，通过增加副本分片也可以实现提升系统<strong>读性能</strong>的作用。</li>
<li>副本分片还可以实现es的<strong>故障转移</strong>，如果持有主分片的节点挂掉了，一个副本分片就会晋升为主分片的角色。<ul>
<li>为了达到故障转移的作用，主分片和其<strong>对应的</strong>副本分片是不会在同一个节点上的。</li>
</ul>
</li>
<li>对文档的新建、索引和删除请求都是写操作，必须在主分片上面完成之后才能被复制到相关的副本分片。<ul>
<li>为了提高写入的能力，ES这个过程是并发写的，同时为了解决并发写的过程中数据冲突的问题，ES 通过乐观锁的方式控制，每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。一旦所有的副本分片都报告写成功才会向协调节点报告成功，协调节点向客户端报告成功。</li>
</ul>
</li>
<li>es默认情况下为每个主分片创造一个副本</li>
</ul>
</li>
</ul>
<h3 id="2-3-2-分片的优势"><a href="#2-3-2-分片的优势" class="headerlink" title="2.3.2 分片的优势"></a>2.3.2 分片的优势</h3><ol>
<li><strong>突破单节点容量上限</strong>，例如我们有10TB大小的总文档，分成20个分片分布于10台节点上，那么每个节点只需要1T的容量即可。</li>
<li><strong>服务高可用</strong>，由于有副本分片的存在，只要不是存储某个文档的node全挂了，那么这个文档数据就不会丢。副本分片提供了灾备的能力。</li>
<li><strong>故障转移</strong>，当主分片节点故障后，可升级一个副分片为新的主分片来应对节点故障。</li>
<li><strong>扩展性能</strong>，通过在所有replicas上并行搜索来提高读性能.由于replicas上的数据是近实时的(near realtime),因此所有replicas都能提供搜索功能,通过设置合理的replicas数量可以极高的提高搜索吞吐量</li>
</ol>
<h3 id="2-3-3-分片的配置"><a href="#2-3-3-分片的配置" class="headerlink" title="2.3.3 分片的配置"></a>2.3.3 分片的配置</h3><p>创建 IndexName 索引时候，在 Mapping 中可以如下设置分片 (curl)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PUT indexName</span><br><span class="line">&#123;</span><br><span class="line">	&quot;settings&quot;: &#123;</span><br><span class="line">		...</span><br><span class="line">		&quot;number_of_shards&quot;: 5,</span><br><span class="line">		&quot;number_of_replicas&quot;: 1</span><br><span class="line">		...</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">curl -H "Content-Type: application/json" -XPUT localhost:9200/indexName -d '</span><br><span class="line">&#123;</span><br><span class="line">	"settings": &#123;</span><br><span class="line">		...</span><br><span class="line">		"number_of_shards": 5,</span><br><span class="line">		"number_of_replicas": 1</span><br><span class="line">		...</span><br><span class="line">	&#125;</span><br><span class="line">&#125;'</span><br></pre></td></tr></table></figure>

<p>当索引创建完成的时候，主分片的数量就固定了，但是复制分片的数量可以随时调整，根据需求扩大或者缩小规模。如把复制分片的数量从原来的 1 增加到 2 ：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -H "Content-Type: application/json" -XPUT localhost:9200/indexName/_settings -d '</span><br><span class="line">&#123;</span><br><span class="line">    "number_of_replicas": 2</span><br><span class="line">&#125;'</span><br></pre></td></tr></table></figure>
<h3 id="2-3-4-分片数量"><a href="#2-3-4-分片数量" class="headerlink" title="2.3.4 分片数量"></a>2.3.4 分片数量</h3><p>对于生产环境中分片的设定，需要提前做好容量规划，因为主分片数是在索引创建时预先设定的，后续无法修改。</p>
<p>那么分片的数量是否越大越好呢？答案当然是否定的。</p>
<ul>
<li><strong>分片数设置过小</strong><ul>
<li>导致后续无法通过增加节点进行水平扩展。</li>
<li>导致分片的数据量太大，数据在重新分配时耗时；</li>
</ul>
</li>
<li><strong>分片数设置过大</strong><ul>
<li>每个分片都是一个小的lucene索引，会消耗相应的资源;</li>
<li>影响搜索结果的相关性打分，影响统计结果的准确性；</li>
<li>单个节点上过多的分片，会导致资源浪费，同时也会影响性能（每个搜索请求会调度到索引的每个分片中.但当分片位于同一个节点，就会开始竞争相同的硬件资源时, 性能便会逐步下降）；</li>
</ul>
</li>
</ul>
<blockquote>
<p>默认情况下，ES会为每个索引创建5个分片，即使是在单机环境下。这种冗余被称作过度分配（Over Allocation），目前看来这么做完全没有必要，仅在散布文档到分片和处理查询的过程中就增加了更多的复杂性，好在ES的优秀性能掩盖了这一点。但我们要知道在单机环境下配置5个分片是没有必要的。</p>
</blockquote>
<p>分片的数量和大小没有定例，可以参考官方的文档<a href="https://www.elastic.co/cn/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster" target="_blank" rel="noopener" title="我在 Elasticsearch 集群内应该设置多少个分片？">我在 Elasticsearch 集群内应该设置多少个分片？</a>，提取核心要素就是：</p>
<ol>
<li>“我应该有多少个分片？”<ul>
<li>答： 每个节点的分片数量应该保持在保持在低于每1GB堆内存对应集群的分片在20-25之间。</li>
<li>也就是shared number/node GBs &lt;20 或shared number/node GBs &lt;25，即shared number&lt;20 * node GBs 或 shared number&lt;25 * node GBs</li>
</ul>
</li>
<li>“我的分片应该有多大”？ <ul>
<li>答：分片大小为50GB通常被界定为适用于各种用例的极限，即不应该超过50GB。但实际上，根据经验，小于30GB更为合理</li>
</ul>
</li>
</ol>
<h3 id="2-3-5-分片和副本的分布"><a href="#2-3-5-分片和副本的分布" class="headerlink" title="2.3.5 分片和副本的分布"></a>2.3.5 分片和副本的分布</h3><p>配置一套高可用的集群，我们必须要了解es集群的数据分布和负载原理，我们先来看下es如何分布分片。</p>
<h4 id="2-3-5-1-主分片分布"><a href="#2-3-5-1-主分片分布" class="headerlink" title="2.3.5.1 主分片分布"></a>2.3.5.1 主分片分布</h4><p>假设我们只有三个主分片：</p>
<ul>
<li><strong>单机分片分布：</strong><ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-a0972163fdd585eb36a511f6bef04b07db1.png" alt=""></li>
</ul>
</li>
<li><strong>2个节点分片分布：</strong><ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-3469208ba209324551593faa0deb7686a3a.png" alt=""></li>
</ul>
</li>
<li><strong>3个节点分片分布：</strong><ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-c3b26a1f81c483e827284c297fa003681bd.png" alt=""></li>
</ul>
</li>
<li><strong>9个节点分片分布：</strong><ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-b9ed932890be90ea010a491301df5e2f41a.png" alt=""></li>
</ul>
</li>
</ul>
<p>可以看到，<strong>es尽量根据我们指定的分片数来平均分配到各个节点上</strong></p>
<h4 id="2-3-5-2-副本分布"><a href="#2-3-5-2-副本分布" class="headerlink" title="2.3.5.2 副本分布"></a>2.3.5.2 副本分布</h4><p>假设我们有3个节点，3个主分片，和若干个副本（下图边框有粗有细，粗的是主分片，细的是副本分片）</p>
<ul>
<li><strong>1个副本</strong><ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-a7dfac0e040e4da5ebefcc631c88dd7d111.png" alt=""></li>
</ul>
</li>
<li><strong>2个副本</strong><ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-275de0214674ffdb42ea21c4ef76ab192bf.png" alt=""></li>
</ul>
</li>
<li><strong>3个副本</strong><ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-daf2170fb6ed87cc747bc86c97849c09d42.png" alt=""></li>
</ul>
</li>
</ul>
<p>可以看到，es依旧尽量根据我们指定的主副分片数来平均分配到各个节点上，但是<strong>不会把存着相同数据的主副分片放在同一个节点上</strong>。</p>
<p>如果分片数量太多（如3个副本的情况），由于此时每台机器都已经占满自己的3个分片了，所以此时需要增加新的机器来存放每个主分片的第三个副本，如果没有新的机器。es不会允许同一个节点有多余的分片，所以提示了Unassigned，表示这些分片未指定。</p>
<h4 id="2-3-5-3-多个索引的分片分布"><a href="#2-3-5-3-多个索引的分片分布" class="headerlink" title="2.3.5.3 多个索引的分片分布"></a>2.3.5.3 多个索引的分片分布</h4><p><img src="https://oscimg.oschina.net/oscnet/up-638c00b3e77cfcf2ac50f3213fde5ad0454.png" alt=""></p>
<h3 id="2-3-6-分片分配策略和原理"><a href="#2-3-6-分片分配策略和原理" class="headerlink" title="2.3.6 分片分配策略和原理"></a>2.3.6 分片分配策略和原理</h3><p>详见<a href="https://www.easyice.cn/archives/248#gatewayAllocator" target="_blank" rel="noopener" title="ELASTICSEARCH ALLOCATION 分析">ELASTICSEARCH ALLOCATION 分析</a></p>
<h3 id="2-3-7-读写数据时的分片路由"><a href="#2-3-7-读写数据时的分片路由" class="headerlink" title="2.3.7 读写数据时的分片路由"></a>2.3.7 读写数据时的分片路由</h3><p>加入我们有一个拥有3个节点的集群，共拥有12个分片，其中有4个主分片（S0、S1、S2、S3）和8个副本分片（R0、R1、R2、R3），每个主分片对应两个副本分片，节点1是主节点（Master节点）负责整个集群的状态。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0e2de5975f04452b7f5d9a6192da6db57aa.png" alt=""></p>
<h4 id="2-3-7-1-对特定doc的读写操作"><a href="#2-3-7-1-对特定doc的读写操作" class="headerlink" title="2.3.7.1 对特定doc的读写操作"></a>2.3.7.1 对特定doc的读写操作</h4><p>写数据是只能写在主分片上，然后同步到副本分片。这里有四个主分片，<strong>数据是根据什么规则写到特定分片上的呢？这条索引数据为什么被写到S0上而不写到S1或S2上？那条数据为什么又被写到S3上而不写到S0上了？</strong></p>
<p>首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的：</p>
<p><code>shard = hash(routing) % number\_of\_primary_shards</code></p>
<p>routing 是一个可变值，默认是文档的 <code>_id</code> ，也可以设置成一个自定义的值。routing 通过 hash 函数生成一个数字，然后这个数字再除以 <code>number_of_primary_shards</code> （主分片的数量）后得到余数 。这个在 0 到 numberofprimary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。</p>
<blockquote>
<p><strong>这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。</strong></p>
</blockquote>
<p>由于在ES集群中每个节点通过上面的计算公式都知道集群中的文档的存放位置，所以每个节点都有处理读写请求的能力。</p>
<p>在一个写请求被发送到某个节点后，该节点即为前面说过的协调节点，协调节点会根据路由公式计算出需要写到哪个分片上，再将请求转发到该分片的主分片节点上。</p>
<p>假如此时数据通过路由计算公式取余后得到的值是 shard = hash(routing) % 4 = 0，则具体流程如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-bc10db22d8ebc5cf5d2b6e4d40d25faebc7.png" alt=""></p>
<ol>
<li><p>客户端向ES1节点（协调节点）发送写请求，通过路由计算公式得到值为0，则当前数据应被写到主分片S0上。</p>
</li>
<li><p>ES1节点将请求转发到S0主分片所在的节点ES3，ES3接受请求并写入到磁盘。</p>
</li>
<li><p>并发将数据复制到两个副本分片R0上，其中通过乐观并发控制数据的冲突。一旦所有的副本分片都报告成功，则节点ES3将向协调节点报告成功，协调节点向客户端报告成功。</p>
</li>
</ol>
<h4 id="2-3-7-2-搜索时的读操作"><a href="#2-3-7-2-搜索时的读操作" class="headerlink" title="2.3.7.2 搜索时的读操作"></a>2.3.7.2 搜索时的读操作</h4><p>es最强大的是做全文检索</p>
<ol>
<li><p>客户端发送请求到一个coordinate node。</p>
</li>
<li><p>协调节点将搜索请求转发到所有的shard对应的primary shard 或 replica shard ，都可以。</p>
</li>
<li><p>query phase：每个shard将自己的搜索结果（其实就是一些doc id）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。</p>
</li>
<li><p>fetch phase：接着由协调节点根据doc id去各个节点上拉取实际的document数据，最终返回给客户端。</p>
</li>
</ol>
<p>写请求是写入primary shard，然后同步给所有的replica shard</p>
<p>读请求可以从primary shard 或者 replica shard 读取，采用的是随机轮询算法。</p>
<h2 id="2-4-段（segment）"><a href="#2-4-段（segment）" class="headerlink" title="2.4 段（segment）"></a>2.4 段（segment）</h2><p>数据被分配到特定的分片和副本上之后，最终是存储到磁盘上的，这样在断电的时候就不会丢失数据。</p>
<p>具体的存储路径可在配置文件 <code>../config/elasticsearch.yml</code>中进行设置，默认存储在安装目录的data文件夹下。建议不要使用默认值，因为若ES进行了升级，则有可能导致数据全部丢失。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">path.data: &#x2F;path&#x2F;to&#x2F;data  &#x2F;&#x2F;索引数据</span><br><span class="line">path.logs: &#x2F;path&#x2F;to&#x2F;logs  &#x2F;&#x2F;日志记录</span><br></pre></td></tr></table></figure>

<p>segment是实现ES近实时搜索的关键，是数据索引（动词）过程中的重要载体。在说segment前，我们先要了解ES数据的存储和检索原理。</p>
<h3 id="2-4-1-倒排索引"><a href="#2-4-1-倒排索引" class="headerlink" title="2.4.1 倒排索引"></a>2.4.1 倒排索引</h3><ul>
<li><p>倒排索引的不可变好处</p>
<ul>
<li>不需要锁，提升了并发能力，避免锁的问题  </li>
<li>数据不变，一直保存在OS cache中，只要cache内存足够  </li>
<li>filter cache一直驻留在内存  </li>
<li>可以压缩，节省cpu和io开销<br>这个对应的就是primary shard的数量不变，不能修改field的属性（将date改成text）</li>
</ul>
</li>
<li><p>倒排索引不可变的坏处</p>
<ul>
<li>每次都需要重新构建整个索引</li>
</ul>
</li>
</ul>
<h3 id="2-4-2-倒排索引的不变性"><a href="#2-4-2-倒排索引的不变性" class="headerlink" title="2.4.2 倒排索引的不变性"></a>2.4.2 倒排索引的不变性</h3><p>写到磁盘的倒序索引是不变的：<strong>写到磁盘后，倒排索引就再也不变</strong>。</p>
<p>这会有很多好处：</p>
<ol>
<li>不需要添加锁。如果你从来不用更新索引，那么你就不用担心多个进程在同一时间改变索引。</li>
<li>因为不变，所以可以很好的做缓存。只要内核有足够的缓存空间，绝大多数的读操作会直接从内存而不需要经过磁盘。这大大提升了性能。</li>
<li>写一个单一的大的倒序索引可以让数据压缩，减少了磁盘I/O的消耗以及缓存索引所需的RAM。</li>
</ol>
<p>然而，索引的不变性也有缺点。<strong>如果你想让新修改过的文档可以被搜索到，你必须重新构建整个索引</strong>。</p>
<p>我们来试想一下这样一个场景：对于一个索引内的所有文档，我们将其分词，建立了一个很大的倒排索引，并将其写入磁盘中。</p>
<p>如果索引有更新，那就需要重新全量创建一个索引来替换原来的索引。这种方式在数据量很大时效率很低，并且由于创建一次索引的成本很高，更无法保证时效性。</p>
<h3 id="2-4-3-分段存储"><a href="#2-4-3-分段存储" class="headerlink" title="2.4.3 分段存储"></a>2.4.3 分段存储</h3><p>如何在不丢失不变形的好处下让倒序索引可以更改？答案是：使用不只一个的索引。 新添额外的索引来反映新的更改来替代重写所有倒序索引的方案。</p>
<p>为了解决这个问题，Lucene引入了段（segment）的概念，简单来说，一个段segment存储着若干个文档，以及这些文档的索引信息（如词频，词向量，域（field）索引等），也就是说，一个segment是一个完整的倒序索引的子集。</p>
<blockquote>
<p>segment文件中存储的内容，可见<a href="https://www.cnblogs.com/buxiangbuliang/p/9275501.html" target="_blank" rel="noopener" title="【Lucene】Lucene 学习之索引文件结构">【Lucene】Lucene 学习之索引文件结构</a></p>
</blockquote>
<p>所以现在index在Lucene中的含义就是多个segments的集合。文档被成功存储的整个过程如下：</p>
<ol>
<li><p><strong>延迟写策略</strong></p>
<ul>
<li>如果每次将数据写入磁盘，磁盘的I/O消耗会严重影响性能。故而Lucene采用延迟写策略，新的文档建立时首先在内存中建立索引buffer：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-155993f01f84b6ca529f6cd82232533cebd.png" alt=""></li>
</ul>
</li>
<li><p><strong>Refresh</strong></p>
<ul>
<li>当达到默认的时间（1秒钟）或者内存的数据达到一定量时，会触发一次刷新（Refresh），将内存中的数据整合，生成到一个新的段。</li>
<li>此时，按理来说，应该将新生成的段刷进磁盘当中，但是将新的segment提交到磁盘需要fsync来保障物理写入。fsync是很耗时的，它不能在每次文档更新时就被调用，否则性能会很低。</li>
<li><strong>在内存和磁盘之间是文件系统缓存</strong>，于是，ES先将新生成的段先写入到内核的文件系统缓存中，这个过程很轻量。</li>
<li>默认情况下每个分片会每秒自动refresh一次。可以通过参数<code>index.refresh_interval</code>来修改这个刷新间隔</li>
<li>我们也可以手动触发 refresh，<ul>
<li><code>POST/_refresh</code> 刷新所有索引。</li>
<li><code>POST/nba/_refresh</code>刷新指定的索引。</li>
</ul>
</li>
<li>在这个阶段，新生成的segment（下图灰色）虽然还未写入磁盘，但已经能够被搜索了，这也是es近实时搜索的原理。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-9d79bd8369c408074f7c5b1d09428f33e0d.png" alt=""></li>
</ul>
</li>
<li><p><strong>Flush</strong></p>
<ul>
<li><strong>新增的段被刷新到磁盘中</strong>。</li>
<li>段被写入到磁盘后会生成一个<strong>提交点</strong>，提交点是一个用来记录所有提交后段信息的文件。</li>
<li>一般Flush的时间间隔会比较久，默认30分钟，或者当translog（后文介绍）达到了一定的大小（超过512M），也会触发flush操作。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-71b2db0e3ad2006e3ddb191c753d5621d81.png" alt=""></li>
</ul>
</li>
</ol>
<blockquote>
<p>这里的<strong>内存使用的是ES的JVM内存</strong>，而<strong>文件缓存系统使用的是操作系统的内存</strong>。</p>
</blockquote>
<blockquote>
<p>新的数据会继续的被写入内存，但内存中的数据并不是以段的形式存储的，因此不能提供检索功能。由内存刷新到文件缓存系统的时候会生成了新的段，并将段打开以供搜索使用，而不需要等到被刷新到磁盘。</p>
</blockquote>
<blockquote>
<p>注意，在内存中的新文档不一定能够被索引，只有生成段后，新文档才可以被索引。</p>
</blockquote>
<p>以上是新增文档操作，删除和更新操作过程有些类似：</p>
<ul>
<li>删除，由于不可修改，所以对于删除操作，不会把文档从旧的段中移除，而是通过新增一个 <code>.del</code>文件，文件中会列出这些被删除文档的段信息。<ul>
<li>这个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。</li>
</ul>
</li>
<li>更新，不能修改旧的段来进行反映文档的更新，其实更新相当于是删除和新增这两个动作组成。<ul>
<li>会将旧的文档在 <code>.del</code>文件中标记删除，然后文档的新版本被索引到一个新的段中。</li>
<li>可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就会被移除。</li>
</ul>
</li>
</ul>
<h3 id="2-4-4-事务日志（Translog）"><a href="#2-4-4-事务日志（Translog）" class="headerlink" title="2.4.4 事务日志（Translog）"></a>2.4.4 事务日志（Translog）</h3><p>虽然通过延时写的策略可以减少数据往磁盘上写的次数，提升了整体的写入能力，但是我们知道文件缓存系统也是内存空间，属于操作系统的内存，只要是内存都存在断电或异常情况下丢失数据的危险。</p>
<p>为了避免丢失数据，Elasticsearch添加了<strong>事务日志（Translog）</strong>，事务日志记录了所有还没有持久化到磁盘的数据。添加了事务日志后整个写索引的流程如下图所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-de73b4c4125c117ac994bf3fba7c249e0d1.png" alt=""></p>
<ul>
<li>一个新文档被索引（动词）之后，先被写入到内存中，但是为了防止数据的丢失，会<strong>追加一份数据到事务日志中</strong>。不断有新的文档被写入到内存，同时也会不断被记录到事务日志中。这时新数据还不能被检索和查询。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-1d8d535fcccc9ffa0ad322e32c2a4126b91.png" alt=""></li>
</ul>
</li>
<li>当达到默认的刷新时间或内存中的数据达到一定量后，<strong>会触发一次refresh</strong>，将内存中的数据以一个新段形式刷新到文件缓存系统中并清空内存。这时虽然新段未被提交到磁盘，但是可以提供文档的检索功能且不能被修改。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-75e39cae236d7e2b714df71c59110211639.png" alt=""></li>
</ul>
</li>
<li>随着新文档索引不断被写入，当日志数据大小超过512M或者时间超过30分钟时，<strong>会触发一次flush</strong>。内存中的数据被写入到一个新段同时被写入到文件缓存系统，文件系统缓存中数据通过 fsync 刷新到磁盘中，生成提交点，日志文件被删除，创建一个空的新日志。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-67cd1c2287040e1cb59cc4051dc2b56b6f0.png" alt=""><h3 id="2-4-5-es写操作总结"><a href="#2-4-5-es写操作总结" class="headerlink" title="2.4.5 es写操作总结"></a>2.4.5 es写操作总结</h3></li>
</ul>
</li>
</ul>
<ol>
<li>先写入内存buffer，在buffer里的时候数据是搜索不到的；同时将数据写入translog日志文件。</li>
<li>如果buffer快满了，或者到一定时间，就会将内存buffer数据refresh 到一个新的segment file中，但是此时数据不是直接进入segment file磁盘文件，而是先进入os cache。这个过程就是 refresh。</li>
<li>每隔1秒钟，es将buffer中的数据写入一个新的segment file，每秒钟会写入一个新的segment file，这个segment file中就存储最近1秒内 buffer中写入的数据。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-45714517c4af324ce1eba2f227ef81df32f.png" alt=""></p>
<h3 id="2-4-6-段合并"><a href="#2-4-6-段合并" class="headerlink" title="2.4.6 段合并"></a>2.4.6 段合并</h3><p>由于自动刷新流程（refresh）每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦，比如每一个段都会消耗文件句柄、内存和cpu运行周期。更重要的是，每个搜索请求都必须轮流检查每个段然后合并查询结果，所以段越多，搜索也就越慢。</p>
<p>Elasticsearch通过在后台定期进行<strong>段合并</strong>来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。段合并的时候会将那些<strong>旧的已删除文档从文件系统中清除</strong>。被删除的文档不会被拷贝到新的大段中。合并的过程中不会中断索引和搜索。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3d4c071b8381e9828b93a3036abb886dfed.png" alt=""></p>
<p>段合并在进行索引和搜索时会自动进行，合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中，这些段既可以是未提交的也可以是已提交的。合并结束后老的段会被删除，新的段被 flush 到磁盘，同时写入一个包含新段且排除旧的和较小的段的新提交点，新的段被打开可以用来搜索。</p>
<p>段合并的计算量庞大， 而且还要吃掉大量磁盘 I/O，段合并会拖累写入速率，如果任其发展会影响搜索性能。Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。</p>
<h2 id="2-5-集群健康状态"><a href="#2-5-集群健康状态" class="headerlink" title="2.5 集群健康状态"></a>2.5 集群健康状态</h2><ul>
<li><p>green</p>
<ul>
<li>所有的主分片和副本分片都正常运行。</li>
</ul>
</li>
<li><p>yellow</p>
<ul>
<li>所有的主分片都正常运行，但不是所有的副本分片都正常运行。这意味着存在单点故障风险</li>
</ul>
</li>
<li><p>red</p>
<ul>
<li>有主分片没能正常运行。</li>
</ul>
</li>
</ul>
<hr>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol>
<li><p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/getting-started.html" target="_blank" rel="noopener" title="Elasticsearch权威指南">Elasticsearch权威指南</a></p>
</li>
<li><p><a href="https://www.jianshu.com/p/28d5e38e3ca7" target="_blank" rel="noopener" title="elasticsearch5.x集群HA原理(shards、replicas)">elasticsearch5.x集群HA### 2.3.3 分片和副本的分布</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/qdhxhz/p/11448451.html" target="_blank" rel="noopener" title="Elasticsearch(4)--- 基本概念(Index、Type、Document、集群、节点、分片及副本、倒排索引)">Elasticsearch(4)— 基本概念(Index、Type、Document、集群、节点、分片及副本、倒排索引)</a></p>
</li>
<li><p><a href="https://www.jianshu.com/p/cc06f9adbe82" target="_blank" rel="noopener" title="【ES】ElasticSearch 深入分片">【ES】ElasticSearch 深入分片</a></p>
</li>
<li><p><a href="https://blog.csdn.net/weixin_33775582/article/details/91425787" target="_blank" rel="noopener" title="Elasticsearch分片">Elasticsearch分片</a></p>
</li>
<li><p><a href="https://blog.csdn.net/J_bean/article/details/80147277" target="_blank" rel="noopener" title="elasticsearch节点(角色)类型解释：node.master和node.data">elasticsearch节点(角色)类型解释：node.master和node.data</a></p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/1488535" target="_blank" rel="noopener" title="全文搜索引擎Elasticsearch，这篇文章给讲透了">全文搜索引擎Elasticsearch，这篇文章给讲透了</a></p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/18/ElasticSearch-Master%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6%E6%B5%85%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/18/ElasticSearch-Master%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6%E6%B5%85%E6%9E%90/" itemprop="url">ElasticSearch Master选举机制浅析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-02-18T22:59:20+08:00">
                2020-02-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index">
                    <span itemprop="name">中间件</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/ElasticSearch/" itemprop="url" rel="index">
                    <span itemprop="name">ElasticSearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/02/18/ElasticSearch-Master%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6%E6%B5%85%E6%9E%90/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/02/18/ElasticSearch-Master选举机制浅析/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  8
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在ElasticSearch集群中，master负责处理集群层面配置的变更和同步工作，所有yml文件配置<code>node.master: true</code>的节点都有资格经过选举成为master节点</p>
<p><strong>es集群的master选举采用Bully算法</strong></p>
<h1 id="Bully算法"><a href="#Bully算法" class="headerlink" title="Bully算法"></a>Bully算法</h1><p>Leader选举的基本算法之一。</p>
<p>它假定所有节点都有一个惟一的ID，该ID对节点进行排序。 任何时候的当前Leader都是参与集群的最高id节点。</p>
<p>具体来说，Bully算法要求每个节点都投票给ID最高的那个节点，通过这一强制性的条件，让集群非常简单的协调一致。</p>
<p>该算法的优点是易于实现，但是，当拥有最大ID的节点处于不稳定状态的场景下会有问题，例如Master负载过重而假死，集群拥有第二大ID的节点被选为新主，这时原来的Master恢复，再次被选为新主，然后又假死…</p>
<p>而且该算法会有脑裂的问题。</p>
<p>elasticsearch通过<strong>控制触发时机来解决反复去世的问题，即当前的Master失效才会触发选举。</strong></p>
<p>同时es又<strong>要求法定得票人数过半</strong>才能选出master，以此来解决脑裂。</p>
<blockquote>
<p>es实际上是从具有master资格的节点中选id最小的节点作为master，而不是id最大的节点</p>
</blockquote>
<h1 id="选举触发时机"><a href="#选举触发时机" class="headerlink" title="选举触发时机"></a>选举触发时机</h1><ol>
<li>集群启动：<ul>
<li>后台启动线程去ping集群中的节点，按照上述策略从具有master资格的节点中选举出master</li>
</ul>
</li>
<li>Master失效<ul>
<li>非Master节点运行的MasterFaultDetection检测到Master失效，在其注册的listener中执行handleMasterGone，执行rejoin操作，重新选主。注意，即使一个节点认为Master失效，也会进入选主流程。</li>
</ul>
</li>
</ol>
<p>我们需要在候选集群中的节点的配置文件中设置参数 <code>discovery.zen.munimum_master_nodes</code>的值，这个参数表示<strong>在选举主节点时需要参与选举的候选主节点的节点数</strong>，默认值是1，官方建议取值 <code>(master_eligibel_nodes/2)+1</code>，其中 <code>master_eligibel_nodes</code>为候选主节点的个数。</p>
<p>这样做既能防止脑裂现象的发生，也能最大限度地提升集群的高可用性，因为只要不少于discovery.zen.munimum_master_nodes个候选节点存活，选举工作就能正常进行。当小于这个值的时候，无法触发选举行为，集群无法使用，不会造成分片混乱的情况。</p>
<h1 id="选举过程"><a href="#选举过程" class="headerlink" title="选举过程"></a>选举过程</h1><p>Master选举主要逻辑在<code>ZenDiscovery.findMaster（基于es 5.2版本）</code>中：</p>
<ol>
<li><p><strong>开始</strong></p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> DiscoveryNode <span class="title">findMaster</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	logger.trace(<span class="string">"starting to ping"</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>每个节点ping集群下的其他节点，等待所有节点的返回。</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//pingAndWait用于获取其他节点的状态，这里只介绍下大致实现，不再展开具体源码：</span></span><br><span class="line"><span class="comment">//pingAndWait主要是使用上面介绍的ZenPing去ping配置中的所有host</span></span><br><span class="line"><span class="comment">//通过函数名称可以知道这是个同步调用，同步的具体实现和ElasticSearch大部分需要等待</span></span><br><span class="line"><span class="comment">//远程通信返回的行为类似，采用计数器记录发送的请求个数，每次有请求响应时递减计数器，</span></span><br><span class="line"><span class="comment">//当计数器递减为0时表示所有请求都得到了响应。</span></span><br><span class="line">List&lt;ZenPing.PingResponse&gt; fullPingResponses = pingAndWait(pingTimeout).toList();</span><br><span class="line"><span class="keyword">if</span> (fullPingResponses == <span class="keyword">null</span>) &#123;</span><br><span class="line">	logger.trace(<span class="string">"No full ping responses"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (logger.isTraceEnabled()) &#123;</span><br><span class="line">	StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">	<span class="keyword">if</span> (fullPingResponses.size() == <span class="number">0</span>) &#123;</span><br><span class="line">		sb.append(<span class="string">" &#123;none&#125;"</span>);</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">for</span> (ZenPing.PingResponse pingResponse : fullPingResponses) &#123;</span><br><span class="line">			sb.append(<span class="string">"\n\t--&gt; "</span>).append(pingResponse);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	logger.trace(<span class="string">"full ping responses:&#123;&#125;"</span>, sb);</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="keyword">final</span> DiscoveryNode localNode = clusterService.localNode();</span><br><span class="line">	</span><br><span class="line"><span class="comment">// add our selves</span></span><br><span class="line"><span class="keyword">assert</span> fullPingResponses.stream().map(ZenPing.PingResponse::node)</span><br><span class="line">	.filter(n -&gt; n.equals(localNode)).findAny().isPresent() == <span class="keyword">false</span>;</span><br><span class="line"><span class="comment">//在获取的装填集中加入当前节点自己的状态，因为自己也需要加入选举，也可能被选举为主节点</span></span><br><span class="line">fullPingResponses.add(<span class="keyword">new</span> ZenPing.PingResponse(localNode, <span class="keyword">null</span>, clusterService.state()));</span><br></pre></td></tr></table></figure></li>
<li><p><strong>根据其他节点的返回，过滤掉没有资格参加选举的节点</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// filter responses</span></span><br><span class="line"><span class="comment">// 过滤PingResponse, 排除掉client节点，单纯的data节点</span></span><br><span class="line"><span class="keyword">final</span> List&lt;ZenPing.PingResponse&gt; pingResponses = filterPingResponses(fullPingResponses, masterElectionIgnoreNonMasters, logger);</span><br></pre></td></tr></table></figure></li>
<li><p><strong>根据反馈，收集当前集群已经存在的master塞入activeMasters</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//activeMasters用来记录当前已经存在的主节点</span></span><br><span class="line">List&lt;DiscoveryNode&gt; activeMasters = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span> (ZenPing.PingResponse pingResponse : pingResponses) &#123;</span><br><span class="line">	<span class="comment">// We can't include the local node in pingMasters list, otherwise we may up electing ourselves without</span></span><br><span class="line">	<span class="comment">// any check / verifications from other nodes in ZenDiscover#innerJoinCluster()</span></span><br><span class="line">	<span class="comment">//如果返回的信息表明自己当前已经是主节点，那么不会把自己加入到activeMasters中去</span></span><br><span class="line">	<span class="keyword">if</span> (pingResponse.master() != <span class="keyword">null</span> &amp;&amp; !localNode.equals(pingResponse.master())) &#123;</span><br><span class="line">		activeMasters.add(pingResponse.master());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>根据反馈，收集当前集群已经存在的具有选举资格的node塞入masterCandidates</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">	</span><br><span class="line"><span class="comment">// nodes discovered during pinging</span></span><br><span class="line"><span class="comment">//masterCandidates用来记录配置为可以成为主节点的候选节点</span></span><br><span class="line">List&lt;ElectMasterService.MasterCandidate&gt; masterCandidates = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"><span class="comment">//这里将返回节点中配置为可以作为主节点的节点加入候选节点中</span></span><br><span class="line"><span class="keyword">for</span> (ZenPing.PingResponse pingResponse : pingResponses) &#123;</span><br><span class="line">	<span class="comment">//这里要注意isMasterNode并不是说明该节点是不是主节点，而是表明该节点能不能成为主节点</span></span><br><span class="line">	<span class="keyword">if</span> (pingResponse.node().isMasterNode()) &#123;</span><br><span class="line">		masterCandidates.add(<span class="keyword">new</span> ElectMasterService.MasterCandidate(pingResponse.node(), pingResponse.getClusterStateVersion()));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>如果集群中已经有master，那么加入它，否则，开始选举</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//如果当前存在的主节点列表activeMasters为空，则从候选节点列表masterCandidates中选取主节点</span></span><br><span class="line"><span class="keyword">if</span> (activeMasters.isEmpty()) &#123;</span><br><span class="line">	<span class="comment">//判断是否有足够的候选节点</span></span><br><span class="line">	<span class="keyword">if</span> (electMaster.hasEnoughCandidates(masterCandidates)) &#123;</span><br><span class="line">		<span class="comment">//进行节点选举</span></span><br><span class="line">		<span class="keyword">final</span> ElectMasterService.MasterCandidate winner = electMaster.electMaster(masterCandidates);</span><br><span class="line">		logger.trace(<span class="string">"candidate &#123;&#125; won election"</span>, winner);</span><br><span class="line">		<span class="keyword">return</span> winner.getNode();</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">// if we don't have enough master nodes, we bail, because there are not enough master to elect from</span></span><br><span class="line">		logger.trace(<span class="string">"not enough master nodes [&#123;&#125;]"</span>, masterCandidates);</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;<span class="comment">//activeMasters不为空，表示当前集群已经有master了</span></span><br><span class="line">	<span class="keyword">assert</span> !activeMasters.contains(localNode) : <span class="string">"local node should never be elected as master when other nodes indicate an active master"</span>;</span><br><span class="line">	<span class="comment">//如果当前存在的主节点列表activeMasters不为空，则从中选取主节点</span></span><br><span class="line">	<span class="comment">// lets tie break between discovered nodes</span></span><br><span class="line">	<span class="keyword">return</span> electMaster.tieBreakActiveMasters(activeMasters);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>如果集群中现在没有master，那么选出master</strong></p>
<ul>
<li><p>选举主要算法集中在electMaster.electMaster()方法中，我们来看下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Elects a new master out of the possible nodes, returning it. Returns &lt;tt&gt;null&lt;/tt&gt;</span></span><br><span class="line"><span class="comment"> * if no master has been elected.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> MasterCandidate <span class="title">electMaster</span><span class="params">(Collection&lt;MasterCandidate&gt; candidates)</span> </span>&#123;</span><br><span class="line">	<span class="comment">//保证有足够的候选者，逻辑是判断有资格参选的node数量大于yml配置的minimumMasterNodes</span></span><br><span class="line">	<span class="function"><span class="keyword">assert</span> <span class="title">hasEnoughCandidates</span><span class="params">(candidates)</span></span>;</span><br><span class="line">	List&lt;MasterCandidate&gt; sortedCandidates = <span class="keyword">new</span> ArrayList&lt;&gt;(candidates);</span><br><span class="line">	<span class="comment">//对候选者进行排序，</span></span><br><span class="line">	sortedCandidates.sort(MasterCandidate::compare);</span><br><span class="line">	<span class="comment">//取队首的node即为master</span></span><br><span class="line">	<span class="keyword">return</span> sortedCandidates.get(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * compares two candidates to indicate which the a better master.</span><br><span class="line"> * A higher cluster state version is better</span><br><span class="line"> *</span><br><span class="line"> * @return -1 if c1 is a batter candidate, 1 if c2.</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static int compare(MasterCandidate c1, MasterCandidate c2) &#123;</span><br><span class="line">	&#x2F;&#x2F; we explicitly swap c1 and c2 here. the code expects &quot;better&quot; is lower in a sorted</span><br><span class="line">	&#x2F;&#x2F; list, so if c2 has a higher cluster state version, it needs to come first.</span><br><span class="line">	&#x2F;&#x2F;先根据节点的clusterStateVersion比较，clusterStateVersion越大，优先级越高。</span><br><span class="line">	&#x2F;&#x2F;这是为了保证新Master拥有最新的clusterState(即集群的meta)，避免已经commit的meta变更丢失。</span><br><span class="line">	&#x2F;&#x2F;因为Master当选后，就会以这个版本的clusterState为基础进行更新。</span><br><span class="line">	int ret &#x3D; Long.compare(c2.clusterStateVersion, c1.clusterStateVersion);</span><br><span class="line">	if (ret &#x3D;&#x3D; 0) &#123;</span><br><span class="line">		&#x2F;&#x2F;clusterStateVersion相同时，进入compareNodes，其内部按照节点的Id比较(Id为节点第一次启动时随机生成)</span><br><span class="line">		ret &#x3D; compareNodes(c1.getNode(), c2.getNode());</span><br><span class="line">	&#125;</span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">	</span><br><span class="line">&#x2F;** master nodes go before other nodes, with a secondary sort by id **&#x2F;</span><br><span class="line"> private static int compareNodes(DiscoveryNode o1, DiscoveryNode o2) &#123;</span><br><span class="line"> 	&#x2F;&#x2F;isMasterNode方法是判断该节点yml文件是否配置了data.master&#x3D;true，即是否有资格参选</span><br><span class="line">	&#x2F;&#x2F;有资格参选的优先（其实从findMaster进入这里，所有的node都是有资格的）</span><br><span class="line">	if (o1.isMasterNode() &amp;&amp; !o2.isMasterNode()) &#123;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	if (!o1.isMasterNode() &amp;&amp; o2.isMasterNode()) &#123;</span><br><span class="line">		return 1;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;根据id排序升序排序</span><br><span class="line">	return o1.getId().compareTo(o2.getId());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>如果集群中已经有master，找到这个master</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** selects the best active master to join, where multiple are discovered */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> DiscoveryNode <span class="title">tieBreakActiveMasters</span><span class="params">(Collection&lt;DiscoveryNode&gt; activeMasters)</span> </span>&#123;</span><br><span class="line">	<span class="comment">//同理，也是默认id最小的node就是master</span></span><br><span class="line">	<span class="keyword">return</span> activeMasters.stream().min(ElectMasterService::compareNodes).get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h1 id="选举过程简图"><a href="#选举过程简图" class="headerlink" title="选举过程简图"></a>选举过程简图</h1><p><img src="https://oscimg.oschina.net/oscnet/up-47d023a3bf701279690cbff187a131b0e4d.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/21/Raft%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/21/Raft%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/" itemprop="url">Raft算法分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-01-21T22:52:18+08:00">
                2020-01-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95-%E7%90%86%E8%AE%BA/" itemprop="url" rel="index">
                    <span itemprop="name">分布式算法&理论</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95-%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%92%8C%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/" itemprop="url" rel="index">
                    <span itemprop="name">分布式事务和数据一致性</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/01/21/Raft%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/01/21/Raft算法分析/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  4.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  17
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在了解Ratf算法前，我们需要了解如下的一些概念名词：</p>
<ol>
<li><p>状态机复制 (State Machine Replication)</p>
<ul>
<li>在分布式系统设计中，需要遵循CAP理论，如果我们要让一个服务具有容错能力，那么会让一个服务的多个副本同时运行在不同的节点上。此时，<strong>状态的改变</strong>就需要在各个副本之间做同步，实现这种同步方法就是所谓的状态机复制（State Machine Replication）。</li>
<li>状态机复制的理论基础是：如果集群里的每一个节点上都运行着相同的确定性状态机S，并且所有的状态机刚开始都处于同样的初始状态s0，那么给予这些状态机相同的输入序列: {i1, i2, i3, i4, i5, i6, …, in}, 这些状态机必然会经过相同的状态转换路径: s0-&gt;s1-&gt;s2-&gt;s3-&gt;…-&gt;sn最终达到相同的状态sn, 同时生成相同的输出序列 {o1(s1), o2(s2), o3(s3), …, on(sn)}。（典型的例子就是Redis的AOF和MySQL集群的binlog）</li>
<li>在执行输入序列I的过程中，根据同步方式的不同，系统就有了强一致性和最终一致性。如果我们要求对于序列I中的每一个in, <strong>都需要所有的服务副本确认执行了in，才能执行in+1</strong>，那么这个系统就是强一致性的系统。如果我们取消掉这个限制，仅仅要求所有的服务副本执行相同的输入序列I，但是完全各自独立执行，而不需要在中间同步，那么就有了最终一致性（各服务都会达到相同的最终状态，但是达到的时间不确定）。</li>
</ul>
</li>
<li><p>拜占庭将军问题</p>
<ul>
<li>问题很简单，拜占庭帝国要攻打一个城池，兵分多路，城池很难攻下，要多路军队同时进攻才能攻下，为了完成目标，各路的将军需要通过信使来约定一个攻打的时间，而信使有可能死亡或者叛变（传递假消息）。</li>
<li>基于以上的问题，我们需要在行动时达成共识。互联网上，每台计算机都是一个个完全相等的节点，只能靠通信来协调，没有权威背书或信任，是一个急需解决的问题。</li>
</ul>
</li>
</ol>
<blockquote>
<p>拜占庭将军问题的本质：如何让众多完全平等的节点针对某一状态达成共识。</p>
</blockquote>
<h1 id="Raft算法"><a href="#Raft算法" class="headerlink" title="Raft算法"></a>Raft算法</h1><p>拜占庭将军问题是分布式领域最复杂、最严格的容错模型。但在日常工作中使用的分布式系统面对的问题不会那么复杂，更多的是计算机故障挂掉了，或者网络通信问题而没法传递信息，这种情况不考虑计算机之间互相发送恶意信息，极大简化了系统对容错的要求，最主要的是达到一致性。</p>
<p>所以将拜占庭将军问题根据常见的工作上的问题进行简化：<strong>假设将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成一致性决定？</strong></p>
<p>对于这个简化后的问题，有许多解决方案，第一个被证明的共识算法是 Paxos，由拜占庭将军问题的作者 Leslie Lamport 在1990年提出，最初以论文难懂而出名，后来这哥们在2001重新发了一篇简单版的论文 <a href="https://link.jianshu.com?t=%255Bhttps%3A%2F%2Flamport.azurewebsites.net%2Fpubs%2Fpaxos-simple.pdf%255D%28https%3A%2F%2Flamport.azurewebsites.net%2Fpubs%2Fpaxos-simple.pdf%29" target="_blank" rel="noopener">Paxos Made Simple</a>，然而还是挺难懂的。</p>
<p>因为 Paxos 难懂，难实现，所以斯坦福大学的教授在2014年发表了新的分布式协议 Raft。与 Paxos 相比，Raft 有着基本相同运行效率，但是更容易理解，也更容易被用在系统开发上。paxos见我的另一篇文章<a href="https://my.oschina.net/lscherish/blog/3086518" target="_blank" rel="noopener" title="分布式一致性理论和paxos算法">分布式一致性理论和paxos算法</a></p>
<p>Raft算法主要分为如下几个关键步骤：</p>
<ul>
<li><strong>leader选举</strong>：<ul>
<li>Raft开始时在集群中选举出Leader负责日志复制的管理；</li>
</ul>
</li>
<li><strong>日志复制</strong>：<ul>
<li>Leader接受来自客户端的事务请求（日志），并将它们复制给集群的其他节点，然后负责通知集群中其他节点提交日志，Leader负责保证其他节点与他的日志同步。</li>
</ul>
</li>
<li><strong>故障转移</strong>：<ul>
<li>当Leader宕掉后集群其他节点会发起选举选出新的Leader；</li>
</ul>
</li>
</ul>
<p>raft算法有如下特点：</p>
<ul>
<li>强leader语义：<ul>
<li>相比其他一致性算法，Raft使用增强形式的leader语义。举个例子，日志只能由leader复制给其它节点。这简化了日志复制需要的管理工作，使得Raft易于理解。</li>
</ul>
</li>
<li>leader的选择：<ul>
<li>Raft使用随机计时器来选择leader，它的实现只是在心跳机制(任何一致性算法中都必须实现)上多做了一点“文章”，不会增加延迟和复杂性。</li>
</ul>
</li>
<li>关系改变：<ul>
<li>Raft使用了一个新机制joint consensus允许集群动态在线扩容，保障Raft的可持续服务能力。</li>
</ul>
</li>
</ul>
<h2 id="1-Ratf名词速览"><a href="#1-Ratf名词速览" class="headerlink" title="1 Ratf名词速览"></a>1 Ratf名词速览</h2><h3 id="1-1-Raft节点状态"><a href="#1-1-Raft节点状态" class="headerlink" title="1.1 Raft节点状态"></a>1.1 Raft节点状态</h3><p>从拜占庭将军的故事映射到分布式系统上，每个将军相当于一个分布式网络节点，每个节点有<strong>三种状态：Follower（跟随者），Candidate（候选者），Leader（领导者）</strong>，状态之间是互相转换的，可以参考下图，具体的后面说。</p>
<p><img src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=2542550312,1610670251&fm=26&gp=0.jpg" alt=""></p>
<h3 id="1-2-term任期"><a href="#1-2-term任期" class="headerlink" title="1.2 term任期"></a>1.2 term任期</h3><p>从上面可以看出，哪个节点做leader是大家投票选举出来的，每个leader工作一段时间，然后选出新的leader继续负责。这和民选社会的选举很像，每一届新的履职期称之为一届任期，在raft协议中，也是这样的，对应的术语叫<strong>term</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fcbf54411bab45c59179187008e2b0bb6d3.png" alt=""></p>
<p>上图蓝色表示选举期，绿色表示履职期。</p>
<p>每个任期都有一个对应的整数与之关联，称为“任期号”，任期号用单词“Term”表示，这个值是一个严格递增的整数值。</p>
<p>如果一个candidate在一次选举中赢得leader，那么这个节点将在这个任期中担任leader的角色。但并不是每个任期都一定对应有一个leader的，比如上面的t3中，可能在选举超时到来之前都没有产生一个新的leader，那么此时将递增任期号开始一次新的选举。</p>
<h2 id="2-Raft算法流程"><a href="#2-Raft算法流程" class="headerlink" title="2. Raft算法流程"></a>2. Raft算法流程</h2><h3 id="2-1-leader选举"><a href="#2-1-leader选举" class="headerlink" title="2.1 leader选举"></a>2.1 leader选举</h3><h4 id="2-1-1-心跳机制"><a href="#2-1-1-心跳机制" class="headerlink" title="2.1.1 心跳机制"></a>2.1.1 心跳机制</h4><p>raft算法是使用<strong>心跳机制</strong>来触发leader选举的。</p>
<p>在节点刚开始启动时，初始状态是follower状态。一个follower状态的节点，只要一直收到来自leader或者candidate的正确RPC消息的话，将一直保持在follower状态。</p>
<p>leader节点通过周期性的发送心跳请求（一般使用带有空数据的AppendEntries RPC来进行心跳）来维持着leader节点状态。</p>
<h4 id="2-1-2-选举超时（election-timeout）"><a href="#2-1-2-选举超时（election-timeout）" class="headerlink" title="2.1.2 选举超时（election timeout）"></a>2.1.2 选举超时（election timeout）</h4><p>每个follower有一个选举超时（election timeout）定时器，这个定时器的值，对于每个节点都是不同的，<strong>其值在150ms到300ms之前随机</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-016776da4a64b5dd9d1153b7f5092d46aa8.png" alt=""></p>
<p>如果某个节点在这个定时器超时之前都没有收到来自leader的心跳请求，那么该follower将认为当前集群中没有leader了，<strong>它会改变自己的状态为candidate</strong>，如下图Node A。然后开启一个新的term，节点本地的任期号term+1。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3031d5fce27f4dfa56678ec53d1996b1948.png" alt=""></p>
<h4 id="2-1-3-请求投票（RequestVote）"><a href="#2-1-3-请求投票（RequestVote）" class="headerlink" title="2.1.3 请求投票（RequestVote）"></a>2.1.3 请求投票（RequestVote）</h4><p>成为candidate的节点，会先投自己一票，然后并行给其他节点发送请求投票的消息RequestVote RPCs</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-00e140d80ed7a32d3b2c37a2e9f81aee907.png" alt=""></p>
<p>那么一个节点在接收到RequestVote RPCs时，它会遵循以下约束来决定是否将票投给请求的发送者。</p>
<ol>
<li>在任一任期内，单个节点最多只能投一票</li>
<li>候选人知道的信息不能比自己的少（这一部分，后面介绍log replication和safety的时候会详细介绍）</li>
<li>first-come-first-served 先来先得</li>
</ol>
<p>如果一个节点在接收到RequestVote RPCs时，上述约束都满足，<strong>那么他将投发送者一票，重置自己的election timeout，并给予响应。</strong></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-582e3bffc1f4b8d9559d2fc6b91e21bab71.png" alt=""></p>
<h4 id="2-1-4-票仓分布"><a href="#2-1-4-票仓分布" class="headerlink" title="2.1.4 票仓分布"></a>2.1.4 票仓分布</h4><p>对于一个candidate而言，它发出了请求RequestVote RPCs后，就开始等待其他节点的回复，这时可能会有三种结果：</p>
<ol>
<li><p>全局就它一个candidate，其他的节点election timeout还没结束就接到了它的RequestVote RPCs，那么这时，这个candidate无疑会获得大多数票，成为新的leader。</p>
<p> <img src="https://oscimg.oschina.net/oscnet/up-5935fb3ed30c681c368121b30b33d0c37ca.png" alt=""></p>
</li>
<li><p>有多个节点<strong>或先后或同时</strong>成为了candidate，但基于“每个节点一个任期内只能投一票”和“先到先得”的约束，以及请求的通信时间的随机性，还是有一个candidate运气好，获得了超过半数的票。</p>
</li>
</ol>
<ul>
<li>那么这个新的leader胜选后，会广播心跳，其他candidate发现心跳中携带的term信息不低于自己，知道有已经有leader被选举出来了，于是放弃选举，转换成follower。</li>
</ul>
<ol start="3">
<li>有多个节点<strong>或先后或同时</strong>成为了candidate，但票数分布均匀，没有任何节点获得超过半数的票（这种情况称作split vote）。<ul>
<li><img src="https://img2018.cnblogs.com/blog/1089769/201812/1089769-20181216202546810-1327167758.png" alt=""></li>
<li>此时所有的candidate都在等待能使自己选票超过半数的响应，等啊等，直到超时后重新发起选举。</li>
<li>如果出现split vote的情况，那么就延长了系统不可用的时间（没有leader是不能处理客户端写请求的），因此raft才引入randomized election timeouts来尽量避免平票情况。同时，leader-based 共识算法中，节点的数目都是奇数个，尽量保证majority的出现。</li>
</ul>
</li>
</ol>
<h4 id="2-1-5-诞生leader"><a href="#2-1-5-诞生leader" class="headerlink" title="2.1.5 诞生leader"></a>2.1.5 诞生leader</h4><p>一个leader诞生以后，就像我们在前文<em>2.1.1 心跳机制</em>所述的那样，<strong>在这个新的任期内每隔heartBeat timeout时间，不停的向follower发送心跳请求（append entries）</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-737045f80305af36b81c50bfdc6952cd71c.png" alt=""></p>
<p>而每个follower则维持着自己的election timeout计时器，如果election timeout时间内没有收到来自leader的心跳，那么说明leader故障。将自己变成candidate，并开始下次选举。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9c878faedc64dd14284548e3b6b739f6f5e.png" alt=""></p>
<h3 id="2-2-日志复制（Log-Replication）"><a href="#2-2-日志复制（Log-Replication）" class="headerlink" title="2.2 日志复制（Log Replication）"></a>2.2 日志复制（Log Replication）</h3><p>前文我们说过了<strong>状态机复制(State Machine Replication)</strong>，状态机复制有多种实现，在Raft中，也有一套基于Append-Only Log的状态机复制实现。</p>
<p>Raft 是分布式一致性算法，保证的实际上是多台机器上数据的一致性。前面讨论的 leader 选举，其实都是为了保证日志复制的一致性而做的前提。Raft的状态机复制实现，我们称作日志复制（Log Replication）。</p>
<blockquote>
<p>Leader 选举只是为了保证日志相同的辅助工作。实际上，在更为学术的 Paxos 里面，是没有 leader 的概念的（大部分 Paxos 的实现通常会加入 leader 机制提高性能）。</p>
</blockquote>
<p>这里的日志，指的是命令日志，对于客户端发来的命令请求，leader会将其封装成一个Log Entry作为传输的载体。</p>
<p>在 Raft 中，leader会接收客户端的所有需求（follower会将写请求转发给leader），leader会将数据以Log Entry的方式通过AppendEntries RPC同步给所有followers</p>
<p>只要超过半数以上的follower反馈成功（返回ack），这条日志就成功提交了。如果RPC请求超时，leader就不停的进行AppendEntries RPC重试。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3d5c64ec78bb30781abc5d3932c1013c62b.png" alt=""></p>
<p><strong>简单来说，保证复制日志相同，才是分布式一致性算法的最终任务</strong>。</p>
<h4 id="2-2-1-Log和Log-Entry"><a href="#2-2-1-Log和Log-Entry" class="headerlink" title="2.2.1 Log和Log Entry"></a>2.2.1 Log和Log Entry</h4><p>Raft中每个节点，都会维护一个本地Log数组，其数据结构如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-bcaab5cd935fc5a5dd0834e80980e3cea12.png" alt=""></p>
<p>其构成有：</p>
<ul>
<li>创建日志时的任期号（用来检查节点日志是否出现不一致的情况）</li>
<li>状态机需要执行的指令（真正的内容）</li>
<li>索引：整数索引，表示日志条目在日志数组中位置</li>
</ul>
<p>上图显示，共有 8 条日志，提交了 7 条。提交的日志都将通过状态机持久化到磁盘中，防止宕机。</p>
<h4 id="2-2-2-一致性校验"><a href="#2-2-2-一致性校验" class="headerlink" title="2.2.2 一致性校验"></a>2.2.2 一致性校验</h4><p>然后谈谈主从日志的一致性问题，这个是分布式一致性算法要解决的根本问题。</p>
<p>Raft 主从日志的一致性，这个最终的目标，可以分解成<strong>一个假设</strong>和一个<strong>充分条件</strong>。</p>
<ul>
<li><p><strong>我们可以假设</strong>：如果在不同的日志中的两个日志条目的<code>任期号</code> 和 <code>索引下标</code> 相同，那么他们的指令就是相同的。</p>
<blockquote>
<p>leader 最多在一个任期里的一个日志索引位置创建一条日志条目，而所有follower的日志来源都是leader，日志条目在日志的位置从来不会改变，所以基本上可以用任期号和索引下标当做Log Entry的主键</p>
</blockquote>
</li>
<li><p><strong>那么，主从日志一致性的充分条件可以是</strong>：如果在不同节点的日志里， 任意2个拥有相同的任期号和索引的日志条目，他们之前的日志项都是相同的，那么这些节点的日志就都是一致的。</p>
</li>
</ul>
<p>达成了上述的这个充分条件，就达成了主从日志一致的最终条件，那如何达成这个充分条件呢？Raft引入了一种<strong>一致性校验</strong>约束。</p>
<p><strong>每次 RPC 发送附加日志时，leader 会把当前这条日志Entry的前一个日志Entry的下标和任期号一起发送给 follower，如果 follower 发现发来前一个日志Entry的下标和任期号和自己队尾的日志Entry不匹配，那么就拒绝接受这条日志，这个称之为一致性校验</strong></p>
<p>如果每一步都严格遵守该校验，就达成了主从日志一致的最终条件。</p>
<h4 id="2-2-3-日志复制过程"><a href="#2-2-3-日志复制过程" class="headerlink" title="2.2.3 日志复制过程"></a>2.2.3 日志复制过程</h4><p>有了这个一致性校验，我们再反过头来看下日志复制的过程。</p>
<p>在Raft协议中有两个主要的消息，一个是在第二节讲到的RequestVote RPC，用于选主投票时leader发出的消息。一个就是AppendEntries RPC，用于心跳和日志复制。对于心跳，只需要发送空内容的AppendEntries RPC就可以了，我们主要关注日志复制的消息，看看Raft是怎么操作的。</p>
<ol>
<li><p>leader接受客户端的操作请求，如“将X赋值为3”。</p>
<ul>
<li>假如leader当前的任期为term1，那么leader就会向自己本地log的最后添加一个entry，比如索引为K，内容为“term1：X赋值为3”。</li>
</ul>
</li>
<li><p>leader向集群中其他follower并行发送AppendEntries RPC消息。这个消息里面包含：</p>
<ol>
<li>这个新的entry和索引，即“term1：X赋值为3”和K。</li>
<li>前一个entry的内容和索引，比如“term1：Y赋值为2”和K-1。</li>
</ol>
</li>
<li><p>当一个follower收到一个AppendEntries RPC消息时，会查看自己本地的log中的K-1位置的entry的内容。（一致性校验）</p>
<ul>
<li><p>假如本地log中K-1位置的entry内容与接收到的来自leader的K-1的entry内容一致（下标和任期号一致），那么就将leader发来的K位置的entry保存在自己的K位置（当然要做并发控制），并返回true，告诉leader保存成功了</p>
</li>
<li><p>假如本地log中K-1位置的entry内容与接收到的来自leader的K-1的entry内容不一致（下标和任期号不一致），那么就返回false，告诉leader不一致。</p>
</li>
</ul>
</li>
<li><p>leader收到消息。</p>
<ul>
<li>如果得到的反馈为true，即某个follower保存成功了，那么这个Log Entry的复制完成。</li>
<li>否则，见下文2.2.4 特殊情况的日志复制过程。</li>
</ul>
</li>
<li><p>leader得到了超过半数的follower反馈的true消息，leader会执行这条Log Entry中的命令，并反馈客户端该命令已经提交，同时向其他follower广播这条Log Entry被commit的消息。</p>
</li>
<li><p>follower接收到Log Entry被commit的消息，执行该Log Entry中的命令。在当前日志被提交的过程中，如果leader先前的某些日志还没有被提交，则将会一同提交。</p>
</li>
</ol>
<blockquote>
<p>在Raft中，一切以leader为主。因此本地日志不是最新的话，就不能成为leader。因此在选主的时候，会进行日志比较。假如在投票阶段，一个follower收到的选主请求中，包含的日志信息比自己的要旧，那么也会拒绝给这个请求投赞成票。如何比较新旧呢？一是看任期term，一是看最后一个entry的索引号。任期大的新，任期相同的索引大的新。</p>
</blockquote>
<h4 id="2-2-4-特殊情况的日志复制过程"><a href="#2-2-4-特殊情况的日志复制过程" class="headerlink" title="2.2.4 特殊情况的日志复制过程"></a>2.2.4 特殊情况的日志复制过程</h4><p>上面说的都是日志在正常情况下的表现，没有考虑到一些异常情况。</p>
<p>即，正常情况下，leader和follower的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。但如果我们将leader或者follower崩溃的情况考虑进来，那么将可能会出现三种情况：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-49a8f26aa515f308e4feaba3cf7109e118a.png" alt=""></p>
<ol>
<li>follower缺失当前leader上存在的日志条目。如a，b</li>
<li>follower存在当前leader不存在的日志条目。如c，d(比如旧的leader仅仅将AppendEntries RPC消息发送到一部分follower就崩溃掉，然后新的当选leader的服务器恰好是没有收到该AppendEntries RPC消息的服务器)</li>
<li>或者follower即缺失当前leader上存在的日志条目，也存在当前leader不存在的日志条目。如e，f</li>
</ol>
<p>这种情况如何处理呢？</p>
<p>Raft 给出了一个方案（补丁）</p>
<blockquote>
<p>强制follower直接复制leader的日志（意味着follower中的和leader冲突的日志将被覆盖）。</p>
</blockquote>
<p>要使得follower的日志和leader进入一致状态，<strong>leader必须找到follower最后一条和leader匹配的日志，然后从这条日志开始，用leader的日志条目，覆盖follower的日志条目</strong></p>
<p>依据这个方案，上图中的 a follower和b follower从队尾直接复制即可。c follower最后一个条目将被覆盖，d follower最后2个任期为7的条目将被覆盖，e最后2个任期为4的条目将被覆盖，f 则比较厉害，需要覆盖下标为3之后的所有条目。</p>
<p>实现逻辑如下：</p>
<ul>
<li><p>leader向集群中的follower发送AppendEntries RPC，内容为最新的Log Entry和其索引K，以及前一个Log Entry及其索引K-1，这里不再赘述。</p>
</li>
<li><p>一致性检验失败，follower向leader反馈false。</p>
</li>
<li><p>leader会将K自减1，然后再次重新发AppendEntries RPC给失败的follower，直到follower返回true。那么此时的K，<strong>就是follower最后一条和leader匹配的日志的下标</strong>。</p>
</li>
</ul>
<blockquote>
<p>最坏的情况是K=0时才得到true回复，这表示follower的Log和leader完全不一致。K=0得到的回复一定是true，因为没有K-1了</p>
</blockquote>
<ul>
<li>此时leader将<strong>匹配的位置和最新的位置中间的内容</strong>都发送给follower，follower会将接收到的内容，并<strong>覆盖</strong>到对应的位置。</li>
</ul>
<blockquote>
<p>实际上leader对每个follower都维护了一个nextIndex字段，来存上述过程中一直递减的K值，描述中我没有引入nextIndex字段的概念，力求精简，以便理解。</p>
</blockquote>
<hr>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/software444/article/details/89787410" target="_blank" rel="noopener" title="状态机复制 (State Machine Replication)">状态机复制 (State Machine Replication)</a><br><a href="https://www.cnblogs.com/aibabel/p/10973585.html" target="_blank" rel="noopener" title="Raft算法详解">Raft算法详解</a></p>
<p><a href="https://blog.csdn.net/shangsongwww/article/details/90287565" target="_blank" rel="noopener" title="Raft算法原理">Raft算法原理</a><br><a href="https://www.cnblogs.com/cbkj-xd/p/12152222.html" target="_blank" rel="noopener" title="Raft算法之日志复制">Raft算法之日志复制</a></p>
<p><a href="https://blog.csdn.net/snail_ren/article/details/80588370" target="_blank" rel="noopener" title="Raft协议详解（一）前言：子问题分解">Raft协议详解（一）前言：子问题分解</a></p>
<p><a href="https://www.jianshu.com/p/b28e73eefa88" target="_blank" rel="noopener" title="Raft 日志复制 Log replication">Raft 日志复制 Log replication</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/08/Redis%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%9E%8B-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/08/Redis%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%9E%8B-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/" itemprop="url">Redis事件模型/主从复制/哨兵模型/集群模式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-01-08T22:48:41+08:00">
                2020-01-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index">
                    <span itemprop="name">中间件</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/01/08/Redis%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%9E%8B-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/01/08/Redis事件模型-主从复制-哨兵模型-集群模式/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  15.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  57
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-Redis的事件模型"><a href="#1-Redis的事件模型" class="headerlink" title="1. Redis的事件模型"></a>1. Redis的事件模型</h1><p>Redis服务器需要处理两类事件：文件事件和时间事件。</p>
<h2 id="1-1-文件事件"><a href="#1-1-文件事件" class="headerlink" title="1.1 文件事件"></a>1.1 文件事件</h2><p>Redis服务器通过<strong>套接字</strong>与客户端进行连接，<strong>而文件事件就是服务器对套接字操作的抽象</strong>。</p>
<p>Redis基于Reactor模式开发了网络事件处理器，由四部分组成：<strong>套接字、I/O多路复用程序、文件事件分派器以及事件处理器</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4f1ecfb38834ecc1e56da223851c70253d1.png" alt=""></p>
<ul>
<li><p>套接字：当有一个套接字准备好执行连接应答、写入、读取、关闭等操作时，就会产生一个文件事件（多个套接字就会有多个文件事件产生；</p>
<ul>
<li>事件类型有AE_READABLE和AE_WRITABLE<ul>
<li>如果客户端对套接字执行write或close操作，或者客户端对服务端的监听套接字执行connect操作，那么产生一个AE_READABLE事件。</li>
<li>如果客户端对套接字执行read操作，那么产生一个AE_WRITABLE事件。</li>
<li>如果一个事件既可读又可写，则先处理AE_READABLE事件，再处理AE_WRITABLE事件。</li>
</ul>
</li>
</ul>
</li>
<li><p>I/O多路复用程序：负责监听多个套接字，并向文件事件分派器传送产生事件的套接字。</p>
<ul>
<li>I/O多路复用程序会将产生的所有事件的套接字放在一个队列中，以有序（sequentially）、同步（synchronously）、每次一个的方式向文件事件分派器传送套接字，只有一个套接字的事件处理完成后才会再发下一个：<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-63c1d7f685fe82c9b6de8a1db0cf63425b1.png" alt=""></li>
</ul>
</li>
<li>I/O多路复用的功能是<strong>evport、epoll、kqueue和select这些常见的I/O多路复用函数</strong>的包装。Redis会在编译时自动选择系统中性能最高的I/O多路复用函数。<strong>默认实现是epoll</strong>。关于I/O多路复用可见本博客文章《详解IO多路复用和其三种模式——select/poll/epoll》<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-9e0589e377a8ff80d66c0ddef54da95b6d9.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li><p>文件事件分派器</p>
<ul>
<li>接收I/O多路复用程序传来的套接字，根据套接字产生的事件类型，调用相应事件处理器</li>
</ul>
</li>
<li><p>文件事件处理器</p>
<ul>
<li>连接应答处理器：acceptTCPhandler<ul>
<li>对连接服务器的各个客户端进行应答</li>
<li>Redis初始化时，将监听套接字的AE_READABLE事件与该处理器关联</li>
<li>客户端连接服务器时，监听套接字产生AE_READABLE事件，触发该处理器执行。</li>
<li>服务器将会创建一个redisClient结构的实例，并添加进自身的RedisServer结构的clients链表中。</li>
<li>处理器对客户端请求进行应答，并创建客户端套接字，将客户端套接字的AE_READABLE事件与命令请求处理器关联。</li>
</ul>
</li>
<li>命令请求处理器：readQueryFromClient<ul>
<li>接收客户端传来的命令请求</li>
<li>客户端成功连接服务器后，连接应答处理器将该客户端套接字的AE_READABLE事件与命令请求处理器关联</li>
<li>客户端向服务器发送命令请求时，客户端套接字产生AE_READABLE事件</li>
<li>命令请求处理器读取命令内容，传给相关程序执行。</li>
</ul>
</li>
<li>命令回复处理器：sendReplyToClient<ul>
<li>向客户端返回命令执行结果</li>
<li>服务器有命令执行结果要传送给客户端时，将客户端套接字的AE_WRITABLE事件始终与该处理器关联</li>
<li>客户端准备好接收命令执行结果时，客户端套接字产生AE_WRITABLE事件，触发命令回复处理器执行。</li>
<li>将全部回复写入套接字后，关联解除</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-e1c7b32c5ca809d372507522a169da2effa.png" alt=""></p>
<h2 id="1-2-时间事件"><a href="#1-2-时间事件" class="headerlink" title="1.2 时间事件"></a>1.2 时间事件</h2><p>一个时间事件包括三要素：</p>
<ul>
<li>id<ul>
<li>时间时间的全局唯一表示，新事件id大于旧事件。</li>
</ul>
</li>
<li>when<ul>
<li>毫秒精度的unix时间戳，记录了时间事件的到达时间。</li>
</ul>
</li>
<li>timeproc（时间事件处理器）<ul>
<li>时间事件处理器，一个函数，时间事件到达时，服务器调用对应处理器来执行。</li>
</ul>
</li>
</ul>
<p>时间事件分为两类：</p>
<ul>
<li><p>定时事件：让一段程序在指定时间后执行一次。</p>
<ul>
<li>定时事件的处理器返回值是固定的数值，存在ae.h/AE_NOMORE中，如果一个事件的返回为该值，那么该事件在到达一次后，就会被删除</li>
</ul>
</li>
<li><p>周期事件：让一段程序每隔一段指定时间就执行一次。</p>
<ul>
<li>周期事件的处理器返回值是非ae.h/AE_NOMORE的值，这时，返回值会覆写when值。让这个时间过一段时间再次到达，以此类推。</li>
</ul>
</li>
</ul>
<p>服务器将时间事件都放在一个无序链表中（不是按时间顺序排序，而是按照ID排序，新产生的时间事件放在链表的表头），每次时间事件执行器运行时，processTimeEvents函数遍历整个链表，查找所有已经到达的时间事件，并调用相应的事件处理器。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a1b2a265b2286571ce9313c80598511599a.png" alt=""></p>
<h3 id="1-2-1-serverCron函数"><a href="#1-2-1-serverCron函数" class="headerlink" title="1.2.1 serverCron函数"></a>1.2.1 serverCron函数</h3><p>时间时间最典型的实例就是serverCron函数，它平均100毫秒执行一次，负责Redis定期对自身资源和状态的调整，包括：</p>
<ul>
<li>更新服务器的统计信息：时间，内存，数据库占用情况</li>
<li>清理过期键值对</li>
<li>关闭失效的连接</li>
<li>尝试进行aof\rdb持久化操作</li>
<li>对从服务器进行定期同步</li>
<li>集群模式下的定期同步，连接测试</li>
</ul>
<h2 id="1-3-事件调度与执行"><a href="#1-3-事件调度与执行" class="headerlink" title="1.3 事件调度与执行"></a>1.3 事件调度与执行</h2><p>aeProcessEvents函数负责何时处理文件事件、何时处理时间事件，以及花费多久的时间<br><img src="https://oscimg.oschina.net/oscnet/up-afd39c7736ceb3cb769fdfd7d588e8943d6.png" alt=""></p>
<p>将aeProcessEvents函数放置在循环中，加上初始化、清理函数，就构成了redis服务器的主函数</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-39f2148ba5785661a77fbdecd5375a765a6.png" alt=""></p>
<blockquote>
<p>文件事件和时间事件是合作关系，服务器会轮流处理这两种事件，并且处理过程中也不会抢占线程。因此时间事件的实际处理时间要比设定的时间晚一些。</p>
</blockquote>
<h1 id="2-Redis主从复制"><a href="#2-Redis主从复制" class="headerlink" title="2. Redis主从复制"></a>2. Redis主从复制</h1><p>关系数据库通常会使用一个主服务器向多个从服务器发送更新，并使用从服务器来处理所有的读请求，Redis采用了同样方法来实现自己的复制特性。</p>
<h2 id="2-1-旧版复制功能"><a href="#2-1-旧版复制功能" class="headerlink" title="2.1 旧版复制功能"></a>2.1 旧版复制功能</h2><p><strong>Redis 2.8以前采用的复制都为旧版复制，主要使用SYNC命令同步复制</strong>，SYNC存在很大的缺陷严重消耗主服务器的资源以及大量的网络连接资源。Redis 2.8之后采用PSYNC命令替代SYNC，解决完善这些缺陷，但在介绍新版复制功能之前，必须先介绍旧版复制过程，这样才能更好地形成对比。</p>
<p>复制功能有两种模式，分为<strong>同步sync</strong>与<strong>命令传播（command propagate）</strong>，两个过程配合执行才能实现Redis复制。</p>
<ul>
<li>SYNC命令同步操作<ul>
<li>通过从服务器发送到SYNC命令给 <em>主服务器</em></li>
<li><em>主服务器</em> 执行BGSAVE命令，在后台生成RDB文件，并从现在开始将所有写命令记录进缓冲区</li>
<li>并发送给 <em>从服务器</em>，同时发送缓冲区保存的所有写命令给 <em>从服务器</em>。</li>
<li><em>从服务器</em> 清空之前数据并执行解释RDB文件，然后执行缓冲区的写命令。</li>
<li>保持数据基本一致（还需要命令传播过程才能保持一致）</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-cfd59b02030b3f463de3d8e6ee7d4fa1e63.png" alt=""></li>
</ul>
</li>
<li>命令传播操作：<ul>
<li>在同步之后，<em>主服务器</em> 仍然在不断的接受写命令，这会导致好不容易一致的主从状态再次不一致。</li>
<li>通过发送让主从服务器不一致的命令（主服务器接收到的新写命令）给从服务器并执行，让主从服务器的数据库重新回到一致状态。</li>
</ul>
</li>
</ul>
<blockquote>
<p>SYNC命令的缺陷：如果因为网络问题，导致主从断开链接一段时间，那么重新同步的时候， SYNC无法做到断点继续，而是仍要清空之前数据，并重新开始复制操作。</p>
</blockquote>
<p>SYNC命令非常消耗资源，原因有三点：</p>
<ol>
<li><p>主服务器执行BGSAVE命令生成RDB文件，这个生成过程会大量消耗主服务器资源（CPU、内存和磁盘I/O资源）</p>
</li>
<li><p>主服务器需要将自己生成的RBD文件发送给从从服务器，这个发送操作会消耗主从服务器大量的网络资源（带宽与流量）</p>
</li>
<li><p>接收到RDB文件你的从服务器需要载入RDB文件，载入期间从服务器会因为阻塞而导致没办法处理命令请求。</p>
</li>
</ol>
<h2 id="2-2-新版复制功能"><a href="#2-2-新版复制功能" class="headerlink" title="2.2 新版复制功能"></a>2.2 新版复制功能</h2><p>为了解决旧版本中断线情况下SYNC低效问题，在Redis 2.8之后使用PSYNC命令代替SYNC命令执行复制同步操作，自然PSYNC具备完整重同步和部分重同步模式</p>
<ul>
<li>完整重同步：跟旧版复制基本是一致的，可以理解为“全量”复制。</li>
<li>部分重同步：在命令传播阶段，<strong>断线重复制</strong>只需要发送主服务器<strong>在断开期间执行的写命令</strong>给从服务器即可，可以理解为“增量”复制。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-6b85f71f0d739997ec61cae37975871ef3b.png" alt=""></li>
</ul>
</li>
</ul>
<h2 id="2-3-复制的实现"><a href="#2-3-复制的实现" class="headerlink" title="2.3 复制的实现"></a>2.3 复制的实现</h2><p>Redis不管是旧版还是新版，复制的实现都可以分为七个步骤，流程图如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9844df2ae892d6aa2f0eb9bbfe8e2dc0a94.png" alt=""></p>
<ol>
<li>设置主服务的地址与端口<ul>
<li>当客户端向从服务器发送一下命令时或者在配置文件中配置slaveof选项</li>
<li><code>127.0.0.1:12345&gt; SLAVEOF 127.0.0.1 6379</code></li>
</ul>
</li>
<li>建立套接字连接<ul>
<li>从服务器根据设置的套接字创建连向主服务器的套接字连接<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-cea89403237d39529cf8fe68b1aac463c01.png" alt=""></li>
</ul>
</li>
<li>主服务器接收从服务器的套接字连接之后，为该套接字创建响应的客户端状态，并将此时的从服务器看做是主服务器的客户端，也就是该从服务器同时具备服务器与客户端两个身份。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-6c6228d79603ed7e8091349805b818b0477.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>发送PING命令<ul>
<li>从服务器成为主服务器的客户端之后，做的第一件事就是向主服务器发送PING命令。PING命令主要有两种作用：<ol>
<li>虽然建立了套接字连接，但是还未使用过，通过发送PING命令检查套接字的读写状态是否正常</li>
<li>通过发送PING命令检查主服务器能否正常处理命令请求</li>
</ol>
</li>
<li>从服务器在发送PING命令之后将遇到以下三种情况的其中一种：<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-d8186e4f60ecb5a5f4a3d94a6953b0c0f69.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>身份验证<ul>
<li>从服务器接收到主服务器返回的“PONG”回复，接下来就需要考虑身份验证的事。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-693b46071c249bb5a9ec8795a47317135ac.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>发送端口信息<ul>
<li>在身份验证步骤之后，从服务器将执行命令<code>REPLCONF listening-port &lt;port&gt;</code>，向主服务器发送从服务器的监听端口号。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-cca80560a551e9d92bb2561bc4beac8b8f7.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>同步<ul>
<li>就是上述所指的同步操作，从服务器向主服务器发送PSYNC命令，执行同步操作，值得注意的是开始只有从服务器是主服务器的客户端，但是执行同步操作之后，主服务器也会成为从服务器的客户端。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-7297be982c2757e9849b1d018d7e14a69a4.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>命令传播<ul>
<li>主从服务器就会进入命令传播阶段，主服务器只要将自己执行的写命令发送给从服务器，而从服务器只要一直执行并接收主服务器发来的写命令（上述已经介绍过，这里不过多介绍）</li>
</ul>
</li>
</ol>
<h1 id="3-Redis哨兵模型"><a href="#3-Redis哨兵模型" class="headerlink" title="3. Redis哨兵模型"></a>3. Redis哨兵模型</h1><p><strong>Sentinel(哨兵、哨岗)是Redis 的高可用性的解决方案</strong>：有一个或多个Sentinel实例组成的Sentinel系统可以<strong>监视任意多个主服务器，以及这些主服务器属下的所有从服务器</strong>，并在被监视的主服务器进入下线状态时，<strong>自动将下线主服务器属下的某个从服务器升级为主服务器</strong>，然后由新的主服务器代替已下线的主服务器继续处理命令请求。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-74b74416d8986d2bc2260d9848302bd26c5.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2e8b33cdecf632546ed70b2a91e16901f44.png" alt=""></p>
<blockquote>
<p>在替换了新的主服务器之后，如果之前下线的主服务器上线了，就会被降为新的主服务器的从服务器。</p>
</blockquote>
<h2 id="3-1-Sentinel的启动"><a href="#3-1-Sentinel的启动" class="headerlink" title="3.1 Sentinel的启动"></a>3.1 Sentinel的启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ redis-sentinel &#x2F;path&#x2F;to&#x2F;your&#x2F;sentinel.conf</span><br><span class="line">或者</span><br><span class="line">$ redis-sentinel &#x2F;path&#x2F;to&#x2F;your&#x2F;sentinel.conf --sentinel</span><br></pre></td></tr></table></figure>

<p>这两个命令都能启动Sentinel，效果都是一样的。</p>
<p>Sentinel启动后，会有五个步骤：</p>
<ol>
<li><p><strong>初始化服务器</strong></p>
<ul>
<li><strong>Sentinel的本质是一个运行在特殊模式下的Redis服务器</strong>，因此启动时必须对其进行初始化，但是由于Sentinel与普通的服务器不同，<strong>它的初始化需要执行的操作也不同</strong>。</li>
<li>下表是Sentinel 模式下Redis服务器的主要功能的使用情况</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-d17c827a40ef959aa665c9f24c9b1bbe054.png" alt=""></li>
</ul>
</li>
<li><p><strong>使用Sentinel专用代码</strong></p>
<ul>
<li>启动Sentinel的第二步，就是将普通Redis服务器使用的代码替换成Sentinel专用的代码。</li>
<li>比如 普通Redis服务器使用 redis.h/REDIS_SERVERPORT常量作为服务端口(#define REDIS_SERVERPORT 6379),使用 redis.h/redisCommandTable 作为服务器的命令表。</li>
<li>而Sentinel使用 reids.h/REDIS_SENTINEL_PORT 常量作为服务器端口，默认26379，使用 redis.h/sentinelcmds 作为服务器的命令表</li>
</ul>
</li>
<li><p><strong>初始化Sentinel状态</strong></p>
<ul>
<li>接下来，服务器会初始化一个 sentinel.c/sentinelState 结构(简称“Sentinel状态”)，这个结构保存了服务器所有和Sentinel功能有关的状态，服务器的一般状态仍然由 redis.h/redisServer 结构保存：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">typedef struct sentinelState&#123;</span><br><span class="line">	&#x2F;&#x2F; 当前纪元，用于实现故障转移</span><br><span class="line">	uint64_t current_epoch;</span><br><span class="line">	&#x2F;&#x2F; 保存了所有被这个 Sentinel监视的主服务器</span><br><span class="line">	&#x2F;&#x2F; 字典的键是主服务器的名字</span><br><span class="line">	&#x2F;&#x2F; 字典的值是一个指向 sentinelRedisInstance 结构的指针</span><br><span class="line">	dict *masters;</span><br><span class="line">	&#x2F;&#x2F; 是否进入了 TILT 模式</span><br><span class="line">	int tilt;</span><br><span class="line">	&#x2F;&#x2F; 目前正在执行的脚本数量</span><br><span class="line">	int running_scripts;</span><br><span class="line">	&#x2F;&#x2F; 进入 TILT 模式的时间</span><br><span class="line">	mstime_t tilt_start_time;</span><br><span class="line">	&#x2F;&#x2F; 最后一次执行事件处理器的时间</span><br><span class="line">	mstime_t previous_time;</span><br><span class="line">	&#x2F;&#x2F; 一个 FIFO 队列，包含了所有需要执行的用户脚本</span><br><span class="line">	list *scripts_queue;</span><br><span class="line">&#125;sentinel;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p><strong>初始化Sentinel状态的 masters 属性</strong></p>
<ul>
<li><p>接下来要做的是将sentinel状态的 masters 属性进行初始化，上面已经说过了，masters 里面保存的是所有被监视的主服务器的信息。master属性是字典，键是主服务器的名字，值是一个指向 sentinelRedisInstance 结构的指针。</p>
</li>
<li><p>我们先介绍一下 sentinelRedisInstance 结构(简称“实例结构”)，这个结构代表着一个被Sentinel监视的Redis服务器实例，可以是主服务器、从服务器或者另外一个Sentinel.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line">ypedef struct sentinelRedisInstance &#123;</span><br><span class="line">	&#x2F;&#x2F; 标识值，记录了当前Redis实例的类型和状态</span><br><span class="line">	int flags;      &#x2F;* See SRI_... defines *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 实例的名字</span><br><span class="line">	&#x2F;&#x2F; 主节点的名字由用户在配置文件中设置</span><br><span class="line">	&#x2F;&#x2F; 从节点以及Sentinel节点的名字由Sentinel自动设置，格式为：ip:port</span><br><span class="line">	char *name;     &#x2F;* Master name from the point of view of this sentinel. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F;实例的运行 ID</span><br><span class="line">	char *runid;    &#x2F;* Run ID of this instance, or unique ID if is a Sentinel.*&#x2F;</span><br><span class="line">	&#x2F;&#x2F;配置纪元，用于实现故障转移</span><br><span class="line">	uint64_t config_epoch;  &#x2F;* Configuration epoch. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F;实例的地址:ip和port</span><br><span class="line">	sentinelAddr *addr; &#x2F;* Master host. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F;实例的连接，有可能是被Sentinel共享的</span><br><span class="line">	instanceLink *link; &#x2F;* Link to the instance, may be shared for Sentinels. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 最近一次通过 Pub&#x2F;Sub 发送信息的时间</span><br><span class="line">	mstime_t last_pub_time;   &#x2F;* Last time we sent hello via Pub&#x2F;Sub. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 只有被Sentinel实例使用</span><br><span class="line">	&#x2F;&#x2F; 最近一次接收到从Sentinel发送来hello的时间</span><br><span class="line">	mstime_t last_hello_time; &#x2F;* Only used if SRI_SENTINEL is set. Last time</span><br><span class="line">								 we received a hello from this Sentinel</span><br><span class="line">								 via Pub&#x2F;Sub. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 最近一次回复SENTINEL is-master-down的时间                             </span><br><span class="line">	mstime_t last_master_down_reply_time; &#x2F;* Time of last reply to</span><br><span class="line">											 SENTINEL is-master-down command. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 实例被判断为主观下线的时间                                         </span><br><span class="line">	mstime_t s_down_since_time; &#x2F;* Subjectively down since time. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 实例被判断为客观下线的时间</span><br><span class="line">	mstime_t o_down_since_time; &#x2F;* Objectively down since time. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 实例无响应多少毫秒之后才会被判断为主观下线（subjectively down）</span><br><span class="line">	mstime_t down_after_period; &#x2F;* Consider it down after that period. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 从实例获取INFO命令回复的时间</span><br><span class="line">	mstime_t info_refresh;  &#x2F;* Time at which we received INFO output from it. *&#x2F;</span><br><span class="line"></span><br><span class="line">	&#x2F;* Role and the first time we observed it.</span><br><span class="line">	 * This is useful in order to delay replacing what the instance reports</span><br><span class="line">	 * with our own configuration. We need to always wait some time in order</span><br><span class="line">	 * to give a chance to the leader to report the new configuration before</span><br><span class="line">	 * we do silly things. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 实例的角色 </span><br><span class="line">	int role_reported;</span><br><span class="line">	&#x2F;&#x2F; 角色更新的时间</span><br><span class="line">	mstime_t role_reported_time;</span><br><span class="line">	&#x2F;&#x2F; 最近一次从节点的主节点地址变更的时间</span><br><span class="line">	mstime_t slave_conf_change_time; &#x2F;* Last time slave master addr changed. *&#x2F;</span><br><span class="line"></span><br><span class="line">	&#x2F;* Master specific. *&#x2F;</span><br><span class="line">	 &#x2F;*----------------------------------主节点特有的属性----------------------------------*&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 其他监控相同主节点的Sentinel</span><br><span class="line">	dict *sentinels;    &#x2F;* Other sentinels monitoring the same master. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 如果当前实例是主节点，那么slaves保存着该主节点的所有从节点实例</span><br><span class="line">	&#x2F;&#x2F; 键是从节点命令，值是从节点服务器对应的sentinelRedisInstance</span><br><span class="line">	dict *slaves;       &#x2F;* Slaves for this master instance. *&#x2F;</span><br><span class="line">	  &#x2F;&#x2F; 判定该主节点客观下线（objectively down）的投票数</span><br><span class="line">	&#x2F;&#x2F; 由SENTINEL monitor &lt;master-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;配置</span><br><span class="line">	unsigned int quorum;&#x2F;* Number of sentinels that need to agree on failure. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; SENTINEL parallel-syncs &lt;master-name&gt; &lt;number&gt; 选项的值</span><br><span class="line">	&#x2F;&#x2F; 在执行故障转移操作时，可以同时对新的主服务器进行同步的从服务器数量</span><br><span class="line">	int parallel_syncs; &#x2F;* How many slaves to reconfigure at same time. *&#x2F;</span><br><span class="line">	  &#x2F;&#x2F; 连接主节点和从节点的认证密码</span><br><span class="line">	char *auth_pass;    &#x2F;* Password to use for AUTH against master &amp; slaves. *&#x2F;</span><br><span class="line"></span><br><span class="line">	&#x2F;* Slave specific. *&#x2F;</span><br><span class="line">	&#x2F;*----------------------------------从节点特有的属性----------------------------------*&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 从节点复制操作断开时间</span><br><span class="line">	mstime_t master_link_down_time; &#x2F;* Slave replication link down time. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 按照INFO命令输出的从节点优先级</span><br><span class="line">	int slave_priority; &#x2F;* Slave priority according to its INFO output. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 故障转移时，从节点发送SLAVEOF &lt;new&gt;命令的时间</span><br><span class="line">	mstime_t slave_reconf_sent_time; &#x2F;* Time at which we sent SLAVE OF &lt;new&gt; *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 如果当前实例是从节点，那么保存该从节点连接的主节点实例</span><br><span class="line">	struct sentinelRedisInstance *master; &#x2F;* Master instance if it&#39;s slave. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; INFO命令的回复中记录的主节点的IP</span><br><span class="line">	char *slave_master_host;    &#x2F;* Master host as reported by INFO *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; INFO命令的回复中记录的主节点的port</span><br><span class="line">	int slave_master_port;      &#x2F;* Master port as reported by INFO *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; INFO命令的回复中记录的主从服务器连接的状态</span><br><span class="line">	int slave_master_link_status; &#x2F;* Master link status as reported by INFO *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 从节点复制偏移量</span><br><span class="line">	unsigned long long slave_repl_offset; &#x2F;* Slave replication offset. *&#x2F;</span><br><span class="line"></span><br><span class="line">	&#x2F;* Failover *&#x2F;</span><br><span class="line">	 &#x2F;*----------------------------------故障转移的属性----------------------------------*&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 如果这是一个主节点实例，那么leader保存的是执行故障转移的Sentinel的runid</span><br><span class="line">	&#x2F;&#x2F; 如果这是一个Sentinel实例，那么leader保存的是当前这个Sentinel实例选举出来的领头的runid</span><br><span class="line">	char *leader;       &#x2F;* If this is a master instance, this is the runid of</span><br><span class="line">						   the Sentinel that should perform the failover. If</span><br><span class="line">						   this is a Sentinel, this is the runid of the Sentinel</span><br><span class="line">						   that this Sentinel voted as leader. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; leader字段的纪元                       </span><br><span class="line">	uint64_t leader_epoch; &#x2F;* Epoch of the &#39;leader&#39; field. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 当前执行故障转移的纪元</span><br><span class="line">	uint64_t failover_epoch; &#x2F;* Epoch of the currently started failover. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 故障转移操作的状态</span><br><span class="line">	int failover_state; &#x2F;* See SENTINEL_FAILOVER_STATE_* defines. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 故障转移操作状态改变的时间</span><br><span class="line">	mstime_t failover_state_change_time;</span><br><span class="line">	&#x2F;&#x2F; 最近一次故障转移尝试开始的时间</span><br><span class="line">	mstime_t failover_start_time;   &#x2F;* Last failover attempt start time. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F;  更新故障转移状态的最大超时时间</span><br><span class="line">	mstime_t failover_timeout;      &#x2F;* Max time to refresh failover state. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 记录故障转移延迟的时间</span><br><span class="line">	mstime_t failover_delay_logged; &#x2F;* For what failover_start_time value we</span><br><span class="line">									   logged the failover delay. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 晋升为新主节点的从节点实例                                   </span><br><span class="line">	struct sentinelRedisInstance *promoted_slave; &#x2F;* Promoted slave instance. *&#x2F;</span><br><span class="line">	&#x2F;* Scripts executed to notify admin or reconfigure clients: when they</span><br><span class="line">	 * are set to NULL no script is executed. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 通知admin的可执行脚本的地址，如果设置为空，则没有执行的脚本 </span><br><span class="line">	char *notification_script;</span><br><span class="line">	 &#x2F;&#x2F; 通知配置的client的可执行脚本的地址，如果设置为空，则没有执行的脚本</span><br><span class="line">	char *client_reconfig_script;</span><br><span class="line">	&#x2F;&#x2F; 缓存INFO命令的输出 </span><br><span class="line">	sds info; &#x2F;* cached INFO output *&#x2F;</span><br><span class="line">&#125; sentinelRedisInstance;</span><br></pre></td></tr></table></figure></li>
<li><p>其中的 addr 属性是一个指向 sentinel.c/sentinelAddr 结构的指针，这个结构保存实例的IP地址和端口号:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">typedef struct sentinelAddr&#123;</span><br><span class="line">	char *p;</span><br><span class="line">	int port;</span><br><span class="line">&#125;sentinelAddr;</span><br></pre></td></tr></table></figure></li>
<li><p>对Sentinel 状态的初始化将引发对 masters 字典的初始化,而 masters 字典的初始化是根据被载入的Sentinel配置文件来进行的。<strong>假设我们有master1和master2，由如下图1的配置文件导入</strong>：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-63050f2a3d66283638dc1c17d2f1ec19778.png" alt=""></li>
</ul>
</li>
<li><p>那么我们得到两个sentinelRedisInstance：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-f7d42df36db19bd7fa4c53b9e289381dc62.png" alt=""></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-238ac368f60e323211e08ebaeb8e7308450.png" alt=""></li>
</ul>
</li>
<li><p>最终sentinelRedisInstance为：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-235ef5d9525c74626220b099acbff598f27.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li><p>创建连向主服务器的网络连接</p>
<ul>
<li>这是最后一步啦，这一步是创建连向被监视主服务器的网络连接，<strong>Sentinel将成为主服务器的客户端</strong>，可以向主服务器发送命令，并从命令回复中获取相关的信息。</li>
<li>每个被Sentinel监视的主服务器，Sentinel会创建两个连向主服务器的异步网络连接：<ol>
<li>命令连接，用于向主服务器发送命令，并接收命令回复</li>
<li>订阅连接，用于订阅主服务器的<code>__sentinel__:hello</code>频道</li>
</ol>
</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-4dd23054ec9ad51b2c753001abd3bbe46a5.png" alt=""><h2 id="3-2-Sentinel与服务器的交互"><a href="#3-2-Sentinel与服务器的交互" class="headerlink" title="3.2 Sentinel与服务器的交互"></a>3.2 Sentinel与服务器的交互</h2></li>
</ul>
</li>
</ol>
<p>Sentinel作为一个监视Redis服务器的监控系统，必然需要有如下的权利或者义务：</p>
<ol>
<li><p>要能掌握被自己监视的主服务器和其从服务器的状态信息</p>
<ul>
<li><strong>INFO命令</strong>：每十秒一次，通过<strong>命令链接</strong>向被监视的主服务和从服务器发送<strong>INFO命令</strong>。分析主服务器的应答得到主服务器的状态信息。</li>
</ul>
</li>
<li><p>要有为“与自己监视了相同服务器的其他Sentinel”感知到自己提供便利的义务。</p>
<ul>
<li><strong>广播频道消息</strong>：Sentinel每两秒一次，通过<strong>命令链接</strong>向所有被自己监视的主服务器和从服务器发送<strong>PUBLISH命令</strong>，发布自己的一些状态信息到对应主服务器的<strong>sentinel</strong>:hello频道，以便让其他监视了同一服务器的Sentinel（当然这些Sentinel也订阅了该服务器的<strong>sentinel</strong>:hello频道）感知到自己的存在，宣誓主权。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-5cc7e6782bf95df108607d7a9179b94f625.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li><p>要能感知到“与自己监视了同一服务器的其他Sentinel”的状态信息。</p>
<ul>
<li><strong>接收频道消息</strong>：Sentinel在与主服务器创建订阅链接后就会通过订阅命令来订阅主服务器的<strong>sentinel</strong>:hello频道。通过<strong>订阅链接</strong>，Sentinel能接收到该频道上其他Sentinel发布的他们各自的状态信息。从而感知到他们的存在。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-5b9e81f3a2d2692d744f2dd17340e377a4a.png" alt=""></li>
</ul>
</li>
<li><strong>创建Sentinel之间的链接</strong>：Sentinel A 感知到另一个Sentinel B 时，如果是第一次感知到，那么A会创建连向B的命令链接。当然B也会有一个发现A的过程，所以对于监视相同服务器的Sentinel来说，他们是这样相互关联的。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-e15a80cc3eaec80234386903b967ca94f1d.png" alt=""></li>
</ul>
</li>
</ul>
</li>
</ol>
<p>归纳完毕，现在我们来一一展开介绍：</p>
<h3 id="3-2-1-INFO命令"><a href="#3-2-1-INFO命令" class="headerlink" title="3.2.1 INFO命令"></a>3.2.1 INFO命令</h3><p>假设有个主服务器和三个从服务器。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cc3509fe121399c911c2c76c9141eae43f0.png" alt=""></p>
<p>Sentinel 默认每十秒一次，通过命令连接向被监视的主服务器发送 INFO 命令，得到如下信息：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-bc6314d42194e83e8c3024d39401f1ba78e.png" alt=""></p>
<ul>
<li>关于服务器本身的信息<ul>
<li>包括 run_id 域记录的服务器运行ID，以及 role 域记录的服务器角色</li>
</ul>
</li>
<li>关于主服务器属下的所有从服务器信息<ul>
<li>每个从服务器都由一个“slave”字符串开头的行记录，每行的 ip= 域记录了从服务器的IP地址, port= 域记录了从服务器的端口号。根据这些IP地址和端口号，Sentinel无须用户提供从服务器的地址信息，就可以自动发现从服务器。</li>
</ul>
</li>
</ul>
<p>根据 run_id 域和 role 域的信息，Sentinel将对主服务器的实例结构（sentinelRedisInstance）进行更新。而主服务器返回的从服务器信息，将会被用于更新主服务器实例结构（sentinelRedisInstance）的 slaves 字典(记录了属下从服务器的名单，key为ip:port格式，值指向从服务器的sentinelRedisInstance实例)。</p>
<p>Sentinel 分析 INFO 命令中包含的从服务器信息时，会检查这个从服务器实例结构(sentinelRedisInstance）是否已经存在于主服务器的 slaves 字典： 如果存在，就对从服务器的实例结构进行更新，如果不存在(表明这个从服务器是新发现的从服务器)，Sentinel会在 slaves 字典中为这个从服务器创建一个新的实例结构。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-39a3a3f5b3381711f3063c1719f4ab03f89.png" alt=""></p>
<p>当Sentinel发现主服务器有新的服务器出现时，除了会为这个新从服务器创建相应的实例结构之外，<strong>还会创建连接到从服务器的命令连接和订阅连接</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0301ec71756c260aaae4f67a696c939939c.png" alt=""></p>
<p>创建了命令连接之后，每10秒一次向从服务器发送 INFO 命令，依次来维护从服务器的实例结构(sentinelRedisInstance）的状态。</p>
<blockquote>
<p>主服务器实例结构的 flags 值为 SRI_MASTER,从服务器是 SRI_SLAVE</p>
</blockquote>
<h3 id="3-2-2-广播频道消息"><a href="#3-2-2-广播频道消息" class="headerlink" title="3.2.2 广播频道消息"></a>3.2.2 广播频道消息</h3><p>Sentinel会<strong>每两秒一次</strong>，通过<strong>命令连接</strong>向所有被监视的主服务器和从服务器发送以下格式的命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PUBLISH __sentinel__:hello &quot;&lt;s_ip&gt;,&lt;s_port&gt;,&lt;s_runid&gt;,&lt;s_epoch&gt;,</span><br><span class="line">	&lt;m_name&gt;,&lt;m_ip&gt;,&lt;m_port&gt;,&lt;m_epoch&gt;&quot;</span><br></pre></td></tr></table></figure>

<p>这条命令就表示向服务器的 __sentinel__:hello 频道发送一条信息，信息由一下部分组成：</p>
<ul>
<li>以 s_ 开头的参数记录Sentinel本身的信息</li>
<li>以 m_ 开头的参数则是该频道所属的主服务器的信息，当然如果监视的是从服务器，这个信息表示的就是所属的从服务器的信息</li>
<li>具体含义如下图</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-0554962e101651acacc73f8c04897f3d7ef.png" alt=""></li>
</ul>
<h3 id="3-2-3-接收频道消息"><a href="#3-2-3-接收频道消息" class="headerlink" title="3.2.3 接收频道消息"></a>3.2.3 接收频道消息</h3><p>在建立起订阅连接之后，Sentinel会通过这个连接，向服务器发送<code>SUBSCRIBE __sentinel__:hello</code>命令，也就是订阅这个频道，这个订阅关系会一直持续到Sentinel与服务器的连接断开之后。</p>
<p>对于监视同一服务器的多个Sentinel来说，一个Sentinel发送的信息会被其他的Sentinel接收到，并用于更新其他Sentinel对发送信息Sentinel的认知，和被用于更新其他Sentinel对被监视服务器的认知。</p>
<p>假如该<strong>Sentinel A</strong>从其监控的<strong>主服务器M</strong>的 <code>__sentinel__:hello</code>频道中，接收到其他<strong>Sentinel B</strong>发来的<code>&lt;s_ip&gt;,&lt;s_port&gt;,&lt;s_runid&gt;,&lt;s_epoch&gt;,&lt;m_name&gt;,&lt;m_ip&gt;,&lt;m_port&gt;,&lt;m_epoch&gt;</code>格式的信息后，Sentinel A会从信息中分析出以下信息：</p>
<ul>
<li>与Sentinel相关的参数：Sentinel B的IP、port、run_id、配置纪元</li>
<li>与主服务器相关参数：Sentinel B 正在监视的这个主服务器（也就是主服务器M）的名字、IP、port、配置纪元</li>
</ul>
<p>服务器实例结构（sentinelRedisInstance）中除了slave字典外，还有一个sentinels字典，存放着其他共同监控着这个主服务器的sentinels的状态信息。<strong>这个字典的键是Sentinel的名字，格式：ip:port。值是对应Sentinel的实例结构(还是sentinelRedisInstance结构)。</strong></p>
<p>根据之前那些主服务器参数，Sentinel A 会在自己的Sentinel状态（sentinelState）的 masters 字典中查找相应的主服务器实例结构（sentinelRedisInstance），然后根据Sentinel参数，检查主服务器实例结构的 sentinels 字典中，Sentinel B的实例结构是否存在：</p>
<ul>
<li>存在，就对Sentinel B的实例结构进行更新</li>
<li>存在，说明Sentinel B是才开始监视主服务器的新Sentinel，Sentinel A 会为Sentinel B创建一个新的实例结构，并将这个结构添加到 sentinels 字典里面</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-084760de95dd05ca210595633b1328d141f.png" alt=""></p>
<h3 id="3-2-4-创建Sentinel之间的链接"><a href="#3-2-4-创建Sentinel之间的链接" class="headerlink" title="3.2.4 创建Sentinel之间的链接"></a>3.2.4 创建Sentinel之间的链接</h3><p>当Sentinel通过频道信息发现了一个新的Sentinel时，它不仅会为新的Sentinel在 sentinels 字典中创建相应的实例结构，还会创建一个连向新Sentinel的命令连接。</p>
<p>新的Sentinel同样会创建连向这个Sentinel的命令连接，最终监视同一主服务器的多个Sentinel将形成相互连接的网络：SentinelA有连向SentinelB的命令连接，SentinelB也有连向SentinelA的命令连接。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e15a80cc3eaec80234386903b967ca94f1d.png" alt=""></p>
<blockquote>
<p>Sentinel之间不会创建订阅连接</p>
</blockquote>
<h2 id="3-3-监控下线和故障转移"><a href="#3-3-监控下线和故障转移" class="headerlink" title="3.3 监控下线和故障转移"></a>3.3 监控下线和故障转移</h2><p>了解了Sentinel与服务器/其他Sentinel的交互方式后，就可以来着手解决实际问题了，Sentinel的使命主要有两点：</p>
<ul>
<li>监控下线</li>
<li>选举领头sentinel</li>
<li>故障转移</li>
</ul>
<h3 id="3-3-1-监控下线"><a href="#3-3-1-监控下线" class="headerlink" title="3.3.1 监控下线"></a>3.3.1 监控下线</h3><h4 id="3-3-1-1-检测主观下线状态"><a href="#3-3-1-1-检测主观下线状态" class="headerlink" title="3.3.1.1 检测主观下线状态"></a>3.3.1.1 检测主观下线状态</h4><p>主观下线状态，即单个sentinel认为某个<strong>主服务器/从服务器/sentinel</strong>下线了，至于是不是真的已经下线，则不一定。</p>
<ul>
<li>默认情况下，Sentinel会以<strong>每秒一次</strong>的频率向所有与它创建了<strong>命令连接</strong>的实例(包括主服务器、从服务器、其他Sentinel在内)发送 <code>PING</code> 命令，并通过实例返回的 <code>PING</code> 命令回复来判断实例是否在线。</li>
<li>对 <code>PING</code> 命令的回复，Redis只认两种含义：<ul>
<li>有效回复：实例返回 +PONG 、 -LOADING 、-MASTERDOWN 三种其中一种</li>
<li>无效回复，除了上面三种之外的其它回复，或者在指定时限内没有返回任何回复</li>
</ul>
</li>
<li>Sentinel配置文件中的 down-after-millseconds 选项指定了Sentinel判断实例进入主观下线所需的时间长度：如果一个实例在 down-after-millseconds 毫秒内，连续向Sentinel返回无效回复，那么Sentinel会修改这个实例所对应的实例结构，在结构的 flags 属性中打上 <code>SRI_S_DOWN</code> 标识，用于表示这个实例已经进入主观下线状态。（也就是我认为你已经下线了）</li>
</ul>
<blockquote>
<p>主观下线时长选项，即 down-after-millseconds 的值，不仅会被Sentinel用于判断其监控的主服务器的主观下线状态，还会被用于判断该主服务器属下的所有从服务器，以及所有同样监视这个主服务器的其他Sentinel的主观下线状态。</p>
</blockquote>
<blockquote>
<p>多个Sentinel设置的主观下线时长可能不同，对于监视同一个主服务器的多个Sentinel来说，这些Sentinel设置的 down-after-milliseconds 选项的值可能不同，因此，当一个Sentinel将主服务器判断为主观下线时，其它Sentinel可能任然会认为主服务器处于在线状态。</p>
</blockquote>
<h4 id="3-3-1-2-检测客观下线状态"><a href="#3-3-1-2-检测客观下线状态" class="headerlink" title="3.3.1.2 检测客观下线状态"></a>3.3.1.2 检测客观下线状态</h4><p>客观下线状态，即经过确认后，可断定为事实上确实下线了。</p>
<p>当Sentinel将一个主服务器判断为主观下线之后，为确定这个服务器是否真的下线，它会<strong>向同样监视这个主服务器的其它Sentinel进行询问</strong>，当接收到足够数量的已下线判断之后，Sentinel就会将从服务器判定为客观下线，并对主服务器进行故障转移操作。</p>
<ul>
<li>发送 <code>SENTINEL is-master-down-by-addr</code> 命令<ul>
<li>entinel会发送下面的命令询问其它Sentinel是否同意主服务器下线：</li>
<li><code>SENTINEL is-master-down-by-addr &lt;ip&gt; &lt;port&gt; &lt;current_epoch&gt; &lt;runid&gt;</code></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-1bff3ef7742eb8463677f3e0c00fb30240d.png" alt=""></li>
</ul>
</li>
<li>接收 <code>SENTINEL is-master-down-by-addr</code> 命令<ul>
<li>当一个Sentinel(目标Sentinel)接收到另外一个Sentinel(源Sentinel)发来的 <code>SENTINEL is-master-by-addr</code>命令时，目标Sentinel会分析并取出命令请求中包含的各个参数，并根据其中的IP和port，判断主服务器是否已经下线，然后向源Sentinel返回一个包含三个参数的 Multi Bulk 回复作为这个命令的回复。这三个参数分别是：<ol>
<li><strong><down_state></strong>：返回目标Sentinel对主服务器的检查结果，1表示主服务器已下线，0表示主服务器未下线</li>
<li><strong><leader_runid></strong>：可以是 * 符号或者目标Sentinel的局部领头Sentinel的运行ID，*表示命令仅仅用于检测主服务器的下线状态，而局部领头Sentinel的运行ID则用于选举领头Sentinel</li>
<li><strong><leader_epoch></strong>：目标Sentinel的局部领头Sentinel的配置纪元，用于选举领头Sentinel。仅在 leader_runid 值不为 * 时有效，如果其值为 * ,这个参数总为0</li>
</ol>
</li>
</ul>
</li>
<li>接收 <code>SENTINEL is-master-down-by-addr</code> 命令之后<ul>
<li>根据其他Sentinel发回的 <code>SENTINEL is-master-down-by-addr</code>回复，Sentinel会统计反馈了“同意这个主服务器已经下线”这个信息的sentinel数量。</li>
<li>当这个值达到配置指定的判断客观下线所需的数量时(即 quorum 属性的值)，Sentinel会将主服务器实例结构中（sentinelRedisInstance） flags 属性的 SRI_O_DOWN 标识打开，标识主服务器已经进入客观下线状态。</li>
</ul>
</li>
</ul>
<h3 id="3-3-2-选举领头sentinel"><a href="#3-3-2-选举领头sentinel" class="headerlink" title="3.3.2 选举领头sentinel"></a>3.3.2 选举领头sentinel</h3><p>当一个Master服务器客观下线后，<strong>监控这个Master服务器的所有Sentinel</strong>将会选举出一个领头Sentinel。并由领头Sentinel对客观下线的Master进行故障转移。</p>
<p>选举领头Sentinel的规则和方法:</p>
<ol>
<li><p>所有监控客观下线Master的Sentinel都有可能成为领头Sentinel。每次进行领头Sentinel选举之后，不论是否选举成功，<strong>所有Sentinel的配置纪元（configuration epoch）的值都会自动增加一次</strong>。</p>
</li>
<li><p>在一个配置纪元里面，所有Sentinel都有一次将某个Sentinel设置为局部领头Sentinel的机会，并且局部领头Sentinel一旦设置，<strong>在这个配置纪元里面将不能再更改</strong>。</p>
</li>
<li><p>监视Master客观下线的所有在线Sentinel都有要求其它Sentinel将自己设置为局部领头Sentinel的机会。</p>
</li>
<li><p>当一个Sentinel（源Sentinel）向另一个Sentinel（目标Sentinel）发送<code>SENTINEL is-master-down-by-addr</code>命令，<strong>并且命令中的runid参数不是“*”符号而是当前Sentinel的运行ID时，这表示当前Sentinel要求目标Sentinel将自己设置为领头Sentinel</strong>。</p>
</li>
<li><p>Sentinel设置局部领头Sentinel的规则是<strong>先到先得</strong>。即最先向目标Sentinel发送设置要求的Sentinel将会成为局部领头Sentinel，之后<strong>接受到的请求都会被拒绝</strong>。</p>
</li>
<li><p>目标Sentinel接收到SENTINEL is-master-down-by-addr命令后，将向源Sentinel返回一条命令回复，<strong>回复中的leader_runid参数和leader_epoch参数分别记录了目标Sentinel的局部领头Sentinel的运行ID和配置纪元</strong>。</p>
</li>
<li><p>源Sentinel在接收到目标Sentinel返回的命令回复之后，会检查回复中leader_epoch参数的值和自己的配置纪元是否相同，如果相同的话，那么源Sentinel继续取出回复中的leader_runid参数，如果leader_runid参数的值和源Sentinel的运行ID一直，<strong>那么表示目标Sentinel将源Sentinel设置成了局部领头Sentinel，记录下来</strong>。</p>
</li>
<li><p>记录之后，如果有某个Sentinel发现自己已经被半数以上的Sentinel设置成了局部领头Sentinel，那么这个Sentinel就会成为领头Sentinel。</p>
</li>
<li><p>领头Sentinel的产生需要半数以上的Sentinel支持，并且每个Sentinel在每个配置纪元里面只能设置一次局部Sentinel，所以在一个配置纪元里面，只会出现一个领头Sentinel。</p>
</li>
<li><p>如果在给定时限内，没有一个Sentinel被选举为领头Sentinel，那么各个Sentinel将在一段时间之后<strong>再次进行选举</strong>，直到选出领头Sentinel为止，（所以建议哨兵设置奇数个，且数量不小于3）。</p>
</li>
</ol>
<h3 id="3-3-3-故障转移"><a href="#3-3-3-故障转移" class="headerlink" title="3.3.3 故障转移"></a>3.3.3 故障转移</h3><p>接收到<code>SENTINEL is-master-down-by-addr</code>命令回复的源Sentinel可以统计出有多少个Sentinel将自己设置成局部领头Sentinel。如果超过半数，则当前Sentinel就会被选为领头Sentinel并进行故障转移。</p>
<p>故障转移包括以下三步：</p>
<ol>
<li>在已下线的Master主机下面挑选一个他的Slave服务器，并将其转换为主服务器。</li>
<li>让<strong>其余</strong>所有Slave服务器复制新的Master服务器。</li>
<li>让已下线的Master服务器变成新的Master服务器的Slave。当已下线的服务器再次上线后将复新的Master的数据。</li>
</ol>
<h4 id="3-3-3-1-选举新的主服务器的过程"><a href="#3-3-3-1-选举新的主服务器的过程" class="headerlink" title="3.3.3.1 选举新的主服务器的过程"></a>3.3.3.1 选举新的主服务器的过程</h4><p>领头Sentinel会在所有Slave中选出新的Master，发送<strong>SLAVEOF no one</strong>命令，将这个服务器确定为主服务器。</p>
<p>领头Sentinel会将已下线Master的所有从服务器保存在一个列表中，按照以下规则，一项一项进行<strong>过滤</strong>。</p>
<ol>
<li><p>删除列表中所有处于下线或者短线状态的Slave。（保证剩下都是在线的）</p>
</li>
<li><p>删除列表中所有最近5s内没有回复过领头Sentinel的INFO命令的Slave。（保证剩下都是近期成功通信过的）</p>
</li>
<li><p>删除所有与<strong>下线Master</strong>连接断开超过down-after-milliseconds * 10毫秒的Slave。（过滤掉过早的和下线Master断开连接的，这样可以保证剩下的Slave，数据都比较新）</p>
</li>
<li><p>领头Sentinel将根据Slave优先级，对列表中剩余的Slave进行排序，并选出其中优先级最高的Slave。</p>
</li>
<li><p>如果有多个具有相同优先级的Slave，那么领头Sentinel将按照Slave复制偏移量，选出其中偏移量最大的Slave。（复制偏移量的slave就是保存的最新数据的slave）</p>
</li>
<li><p>如果有多个优先级最高，偏移量最大的Slave，那么根据运行ID最小原则选出新的Master。</p>
</li>
</ol>
<p>确定新的Master之后，领头Sentinel会以<strong>每秒一次</strong>的频率向新的Master发送INFO命令，当得到确切的回复：role由slave变为master之后，当前服务器顺利升级为Master服务器。</p>
<h4 id="3-3-3-2-修改从服务器的复制目标"><a href="#3-3-3-2-修改从服务器的复制目标" class="headerlink" title="3.3.3.2 修改从服务器的复制目标"></a>3.3.3.2 修改从服务器的复制目标</h4><p>选出新的Master服务器后，领头Sentinel会向<strong>下线Master的剩余Slave</strong>发送SLAVEOF命令，让它们复制新的Master。</p>
<h4 id="3-3-3-3-将旧的Master变成Slave"><a href="#3-3-3-3-将旧的Master变成Slave" class="headerlink" title="3.3.3.3 将旧的Master变成Slave"></a>3.3.3.3 将旧的Master变成Slave</h4><p>当已下线的Master重新上线后，领头Sentinel会向此服务器发送SLAVEOF命令，将当前服务器变成新的Master的Slave。</p>
<h1 id="4-集群模式"><a href="#4-集群模式" class="headerlink" title="4. 集群模式"></a>4. 集群模式</h1><p>Redis集群是Redis的分布式数据库方案，通过分片来进行数据共享，并提供复制和故障转移功能。集群为Redis提供了更加便利的水平拓展能力，是现代企业级Redis实现高吞吐高并发的重要实现。</p>
<ul>
<li>集群模式和主从模式的区别：<ul>
<li>主从模式<ul>
<li>指的是针对多台redis实例时候，只存在一台主服务器master，提供读写的功能，同时存在依附在这台主服务器的从服务器slaver，只提供读服务。</li>
<li>主从作用是：读写分离，分散访问量，提高访问可读性，同时保证数据的冗余和备份。</li>
</ul>
</li>
<li>集群模式<ul>
<li>指的是针对多个redis实例，去中心化，去中间件，集群中的每个节点都是平等的关系，都是对等的。</li>
<li>集群的作用是：实现扩容、分摊压力、无中心配置相对简单。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="4-1-节点"><a href="#4-1-节点" class="headerlink" title="4.1 节点"></a>4.1 节点</h2><p>节点，<strong>指的就是我们之前说的Redis服务器</strong>。</p>
<p>一个Redis 集群通常由多个节点组成，在刚开始的时候，每个节点都是独立的，只处于只包含自己的集群中（也就是之前我们说到的单机模式），当要组成一个真正可工作的集群时，就需要将这些独立的节点连接起来，构建成一个包含多个节点的集群。</p>
<p>如何连接各个节点？使用<code>CLUSTER MEET</code>命令</p>
<p><code>CLUSTER MEET &lt;ip&gt; &lt;port&gt;</code></p>
<p>向一个节点发送<code>CLUSTER MEET</code>命令，可以让节点与ip和port所指定的节点进行握手，握手成功，节点就会将ip和port指定的节点添加到当前的集群中。</p>
<blockquote>
<p>节点A向节点B发送<code>CLUSTER MEET</code>命令，那么B将会加入A的集群中。反之，A加入B的集群中。</p>
</blockquote>
<p>在启动时，服务器会根据 <code>cluster-enabled</code> 配置选项来决定是否开启集群模式。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6885d13841ad33d7783816ac2e8c63736dd.png" alt=""></p>
<h3 id="4-2-集群数据结构"><a href="#4-2-集群数据结构" class="headerlink" title="4.2  集群数据结构"></a>4.2  集群数据结构</h3><p>Redis使用clusterNode结构来保存一个节点的状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;一个节点的当前状态</span><br><span class="line">struct clusterNode&#123;    </span><br><span class="line">    &#x2F;&#x2F; 创建节点的时间    </span><br><span class="line">    mstime_t ctime;    </span><br><span class="line">    &#x2F;&#x2F; 节点的名字，由40个16进制字符组成    </span><br><span class="line">    char name[REDIS_CLUSTER_NAMELEN];    </span><br><span class="line">    &#x2F;&#x2F; 节点标识    </span><br><span class="line">    int flags;    </span><br><span class="line">    &#x2F;&#x2F; 节点当前的配置纪元，用于实现故障转移    </span><br><span class="line">    uint64_t configEpoch;    </span><br><span class="line">    &#x2F;&#x2F; 节点的ip地址    </span><br><span class="line">    char ip[REDIS_IP_STR_LEN];    </span><br><span class="line">    &#x2F;&#x2F; 节点的端口号    </span><br><span class="line">    int port；    </span><br><span class="line">    &#x2F;&#x2F; 保存连接节点所需的有关信息   </span><br><span class="line">    clusterLink *link；    </span><br><span class="line">    &#x2F;&#x2F;……</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>clusterNode 结构的 link 属性：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterLink &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 连接的创建时间</span><br><span class="line">    mstime_t ctime;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; TCP 套接字描述符</span><br><span class="line">    int fd;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 输出缓冲区，保存着等待发送给其他节点的消息（message）。</span><br><span class="line">    sds sndbuf;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 输入缓冲区，保存着从其他节点接收到的消息。</span><br><span class="line">    sds rcvbuf;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 与这个连接相关联的节点，如果没有的话就为 NULL</span><br><span class="line">    struct clusterNode *node;</span><br><span class="line"></span><br><span class="line">&#125; clusterLink;</span><br></pre></td></tr></table></figure>
<p>最后，每个节点都保存着一个clusterState结构，这个结构记录了<strong>在当前节点的视角下集群目前所处的状态</strong>，比如集群是在线还是下线，包含多少个节点，当前的配置纪元等：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 指向当前节点的指针</span><br><span class="line">    clusterNode *myself;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群当前的配置纪元，用于实现故障转移</span><br><span class="line">    uint64_t currentEpoch;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群当前的状态：是在线还是下线</span><br><span class="line">    int state;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群中至少处理着一个槽的节点的数量</span><br><span class="line">    int size;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群节点名单（包括 myself 节点）</span><br><span class="line">    &#x2F;&#x2F; 字典的键为节点的名字，字典的值为节点对应的 clusterNode 结构</span><br><span class="line">    dict *nodes;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">&#125; clusterState;</span><br></pre></td></tr></table></figure>
<p><img src="https://oscimg.oschina.net/oscnet/up-cb0413dac3d1923097cdf136316e96c8f4f.png" alt=""></p>
<h3 id="4-2-1-CLUSTER-MEET-命令的实现"><a href="#4-2-1-CLUSTER-MEET-命令的实现" class="headerlink" title="4.2.1 CLUSTER MEET 命令的实现"></a>4.2.1 CLUSTER MEET 命令的实现</h3><p>向节点A发送 CLUSTER MEET 命令，能让接收命令的节点A将另一个节点B（ip和port指向的节点）添加到节点A当前所处的集群里。</p>
<p>收到命令的节点A 和节点B进行握手，以此来确认彼此的存在，并为将来的进一步通信打好基础：</p>
<ol>
<li><p>节点A为节点B创建一个clusterNode结构，并将该结构添加到节点A自己的clusterState.nodes字典中。</p>
</li>
<li><p>节点A根据ip和port发送meet消息给节点B。</p>
</li>
<li><p>如果一切顺利，节点B收到meet消息，为节点A创建一个clusterNode结构，并将该结构添加到节点B自己的clusterState.nodes字典中。</p>
</li>
<li><p>如果一切顺利，节点B向节点A发送PONG消息</p>
</li>
<li><p>如果一切顺利，节点A向节点B返回PING消息</p>
</li>
<li><p>如果一切顺利，至此，握手完成</p>
</li>
<li><p>最后节点A会向自己处于的集群内的其他节点发送信息，让其他节点也和B节点握手，最终达到集群内的所有节点都相互认识彼此。至此，B节点加入进集群。</p>
</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-40fa2846f5067087ba601c5ba8b0658df00.png" alt=""></p>
<h2 id="4-3-redis负载均衡算法——hash-slot"><a href="#4-3-redis负载均衡算法——hash-slot" class="headerlink" title="4.3 redis负载均衡算法——hash slot"></a>4.3 redis负载均衡算法——hash slot</h2><p>Redis使用分片的方式来保存数据库中的键值对：整个集群被分为16384个槽(slot)，数据库中的每个键都位于这其中的某个槽上，集群中的节点，最少可以处理0个槽，最多可以处理16384个槽。</p>
<p><strong>当数据库中的 16384 个槽都有节点在处理时，集群处于上线状态，否则，处于下线状态。</strong></p>
<p>我们可以使用CLUSTER ADDSLOTS命令来给某个节点指派要处理的槽：</p>
<p><code>CLUSTER ADDSLOTS [slot ...]</code></p>
<p>这个命令接受一个或多个槽的编号作为参数，并将所有输入的槽指派给接收该命令的节点负责。</p>
<p>如<code>CLUSTER ADDSLOTS 0 1 2 3 ... 1000</code></p>
<p>表示将槽0到槽1000指派给接收到命令的整个节点负责。</p>
<h3 id="4-3-1-记录节点的槽指派信息"><a href="#4-3-1-记录节点的槽指派信息" class="headerlink" title="4.3.1 记录节点的槽指派信息"></a>4.3.1 记录节点的槽指派信息</h3><p>clusterNode结构中的slots数组和numslots字段记录了该节点负责处理的槽。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 一个节点的当前状态</span><br><span class="line">struct clusterNode&#123;</span><br><span class="line">    &#x2F;&#x2F;……</span><br><span class="line">    &#x2F;&#x2F; 记录处理那些槽</span><br><span class="line">    &#x2F;&#x2F; 二进制位数组，长度为 2048 个字节，包含 16384 个二进制位</span><br><span class="line">    &#x2F;&#x2F; 如果slots数组在索引i上的二进制位的值为1，那么表示节点负责处理槽i；否则表示节点不负责处理槽i</span><br><span class="line">    unsigned char slots[16384&#x2F;8];</span><br><span class="line">    &#x2F;&#x2F;记录自己负责处理的槽的数量</span><br><span class="line">    int numslots;</span><br><span class="line">    &#x2F;&#x2F;……</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>slots数组有16384个二进制位，<strong>第i项上的二进制值如果为1，则表示槽i由自己负责。为0则表示槽i不是由自己负责</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-08c2162c6cae22ff35c3fd9c53e0ec5bf8c.png" alt=""></p>
<p>数组的定位时间复杂度是O(1)，这样的设计可以让节点非常快速的知道某个槽到底是不是由自己负责。</p>
<h3 id="4-3-2-传播节点的槽指派信息"><a href="#4-3-2-传播节点的槽指派信息" class="headerlink" title="4.3.2 传播节点的槽指派信息"></a>4.3.2 传播节点的槽指派信息</h3><p>一个节点除了会将自己负责处理的槽记录在clusterNode结构的slots属性和numslots属性之外，它还会<strong>将自己的slots数组通过消息发送给集群中其他的节点</strong>，以此来告知其他节点自己目前负责处理哪些槽。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4068617fde399f6fe494c764ff1e330620c.png" alt=""></p>
<p>当节点A通过消息从节点B那里接收到节点B的slots数组时，节点A会在<strong>自己的clusterState.nodes字典中</strong>查找<strong>节点B对应的clusterNode结构</strong>，并对该clusterNode结构中的slots数组进行保存或者更新。</p>
<p>每个节点都相互分享自己的槽指派信息，每个节点又在自己的clusterState.nodes字典中保存其他节点的槽指派信息，因此，集群中的每个节点都会知道整个集群数据库的全部槽，都分别被分派给了哪些节点。</p>
<h3 id="4-3-3-记录集群所有槽的指派信息"><a href="#4-3-3-记录集群所有槽的指派信息" class="headerlink" title="4.3.3 记录集群所有槽的指派信息"></a>4.3.3 记录集群所有槽的指派信息</h3><p>我们知道，每个节点都保存着一个clusterState结构，这个结构，<strong>我们可以看做节点自己对整个集群所描绘的详细概念地图</strong>。</p>
<p>节点除了会在clusterState.nodes字典中维护每个节点的槽分派信息外，还会在clusterState结构结构中维护一个clusterNode *slots[16384]数组。</p>
<p>clusterState.slots数组有16384项，每个数组项都是一个指向clusterNode的指针：</p>
<ul>
<li>如果slots[i]指向NULL，那么表示槽i尚未指派给任何节点。</li>
<li>如果slots[i]指向一个clusterNode，那么表示槽i已经指派给了这个clusterNode所对应的节点</li>
</ul>
<p>假设槽被指派给了集群中的三个节点，那么slots数组结构如下图：<br><img src="https://oscimg.oschina.net/oscnet/up-ef32357ce2410db6cf95670fec70e865b75.png" alt=""></p>
<ul>
<li>clusterState.nodes[i].slots<ul>
<li>节点A在自己的clusterState.nodes字典中的某个clusterNode结构（假设对应节点B）中保存的槽分派信息，是以单节点（节点B）为视角的槽分派信息，即——<strong>我这个节点负责如下这些槽</strong>。</li>
</ul>
</li>
<li>clusterState.slots</li>
<li>节点A在自己的clusterState.slots数组中保存的槽分派信息，是以每个槽为视角的槽分派信息。即——<strong>我这个槽被某个节点负责</strong>。</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-d08d4389ea5a796d227eed8522533cc9bf9.png" alt=""></p>
<h2 id="4-4-集群处理命令"><a href="#4-4-集群处理命令" class="headerlink" title="4.4 集群处理命令"></a>4.4 集群处理命令</h2><p>当集群中的所有槽都被指派之后，集群就会进入上线状态，这是客户端就可以向集群中的节点发送命令了。</p>
<p>一张图解释如下过程：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1cfff66398d714cab3142e3825989d4f9d0.png" alt=""></p>
<h3 id="4-4-1-计算键属于哪个槽"><a href="#4-4-1-计算键属于哪个槽" class="headerlink" title="4.4.1 计算键属于哪个槽"></a>4.4.1 计算键属于哪个槽</h3><p>节点用以下算法计算给定键 key 属于哪个槽：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def slot_number(key):</span><br><span class="line">	return CRC16(key) &amp; 16383 &#x2F;&#x2F;CRC16(key) 计算key的CRC-16校验和，然后和16383与出一个0-16383的序号来。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 用于查看一个给定键属于哪个槽</span><br><span class="line">CLUSTER KETSLOT &lt;key&gt;</span><br></pre></td></tr></table></figure>
<h3 id="4-4-2-判断某个槽是否由当前节点负责"><a href="#4-4-2-判断某个槽是否由当前节点负责" class="headerlink" title="4.4.2 判断某个槽是否由当前节点负责"></a>4.4.2 判断某个槽是否由当前节点负责</h3><p>当节点计算出键所属槽 i 之后，节点会检查自己在 clusterState.slots 数组中的项 i ，判断键所处的槽是否由自己负责：</p>
<ul>
<li>如果 <code>clusterState.slots[i]</code> 等于 <code>clusterState.myself</code> ，那么说明槽 i 由当前节点负责，节点可以执行客户端发送的命令；</li>
<li>否则，槽 i 不由当前节点负责,节点会根据 <code>clusterState.slots[i]</code> 所指向的 clusterNode 结构所记录的节点IP和端口号，向客户端返回 MOVED 错误并指引客户端转向正在处理槽i的节点，格式如下：<ul>
<li><code>MOVED &lt;slot&gt; &lt;ip&gt;:&lt;port&gt;</code></li>
<li>客户端接收到 MOVED 命令之后，根据其提供的IP和端口，转向负责处理槽 slot 的节点，并向节点<strong>重新发送之前想要执行的命令</strong>。</li>
<li>客户端会和每个节点创建套接字连接，所谓的转向，其实就是换一个套接字来发送命令。</li>
</ul>
</li>
</ul>
<h2 id="4-5-节点数据库的实现"><a href="#4-5-节点数据库的实现" class="headerlink" title="4.5 节点数据库的实现"></a>4.5 节点数据库的实现</h2><p>我们在文章<a href="https://my.oschina.net/lscherish/blog/3147447" target="_blank" rel="noopener" title="Redis数据库结构/键空间/过期字典/事务/锁/持久化">Redis数据库结构/键空间/过期字典/事务/锁/持久化</a>中讨论过Redis服务器的键空间（即如何存储键值对）redisDb结构的dict字典数组，保存了所有的键值对。redisDb结构的expires字典数组，保存了所有的过期字典。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6d3519de440528a8af1eded3347c9337236.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-dbb09c36a7db3dcb13c5f538cb3ccc80092.png" alt=""></p>
<p><strong>单机服务器和集群服务器（节点）的保存键值对以及键值对过期时间，实现都是一样的</strong>。只不过节点只能使用 0 号数据库，单机服务器没有限制。</p>
<p>和单机服务器不同的是，除了键值对之外，节点还需要维护<strong>槽和键的关系</strong>，节点会用 clusterState 结构中的 <code>slots_to_keys</code> 跳跃表来保存槽和键之间的关系：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState&#123;</span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">    zskiolist *slots_to_keys;</span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">&#125; clusterState;</span><br></pre></td></tr></table></figure>
<p>这个跳跃表每个节点的分值( score )都是一个槽号，节点的成员( member )都是一个数据库键：</p>
<ul>
<li><p>每当节点往数据库中添加一个新的键值对时，节点就会将这个键以及键的槽号关联到 slots_to_key s跳跃表</p>
</li>
<li><p>当节点删除数据库中的某个键值对时，节点就会在slots_to_keys跳跃表解除被删除键与槽号的关联</p>
</li>
</ul>
<p>图例：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0bc955e758a048378d24a0e10ca3a39540a.png" alt=""></p>
<p>该图表示：</p>
<ul>
<li>键”book”所在跳跃表节点的分值为1337.0，这表示键”book”所在的槽为1337</li>
<li>键”date”所在跳跃表节点的分值为2022.0，这表示键”date”所在的槽为2022</li>
<li>键”lst”所在跳跃表节点的分值为3347.0，这表示键”lst”所在的槽为3347</li>
</ul>
<blockquote>
<p>slots_to_keys 的存在是为了使节点可以很方便的对属于某个或者某些槽的所有键做批量操作。例如命令<code>CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;</code>命令可以返回最多count个属于槽slot的数据库键，而这个命令就是通过遍历 slots_to_keys跳跃表来实现的</p>
</blockquote>
<h2 id="4-6-重新分片"><a href="#4-6-重新分片" class="headerlink" title="4.6 重新分片"></a>4.6 重新分片</h2><p>Redis集群的重新分片操作可以将<strong>任意数量已经指派给某个节点（源节点）的槽改为指派给另一个节点（目标节点，并且相关槽所属的键值对也会从源节点移动到目标节点。</strong> 重新分片可以在线进行，在这过程中，集群不用下线，且源节点和目标节点都可以继续处理命令。</p>
<p>重新分片由Redis的集群管理软件 redis-trib 负责执行，redis-trib 通过向源节点和目标节点发送命令来进行重新分片：</p>
<ul>
<li><p>redis-trib对集群的单个槽 slot 进行重新分片的步骤如下：</p>
<ol>
<li><p>redis-trib 对目标节点发送 <code>CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_id&gt;</code> 命令，让目标节点<strong>准备好</strong>从源节点导入槽 slot 的键值对</p>
</li>
<li><p>redis-trib 对源节点发送 <code>CLUSTER SETSLOT &lt;slot&gt; MIGRATING &lt;source_id&gt;</code>命令，让源节点<strong>准备好</strong>将属于槽 slot的键值对迁移至目标节点</p>
</li>
<li><p>redis-trib 对源节点发送 <code>CLUSTER GETKEYSINSLOT&lt;slot&gt; &lt;count&gt;</code> 命令，获得最多 count 个属于槽 slot 的键值对的键名。</p>
</li>
<li><p>对于步骤三获得的每个键名，redis-trib 都向源节点发送一个<code>MIGRATE &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout&gt;</code> 命令，<strong>将被选中的键原子的从源节点迁移至目标节点</strong>。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-ee9006a45f14bd9001e3118803ba0f3e6a8.png" alt=""></li>
</ul>
<ol start="5">
<li>重复步骤3和4，直到源节点保存的所有属于槽slot的键值对都被迁移到目标节点为止。</li>
<li>redis-trib向集群中的任意一个节点发送 <code>CLUSTER SETSLOT &lt;slot&gt; NODE &lt;target_id&gt;</code> 命令，将槽slot指派给目标节点的信息发送给整个集群。</li>
</ol>
</li>
</ol>
</li>
<li><p>如果重新分片涉及多个槽，那么 redis-trib 将对<strong>每个给定的槽</strong>  <strong>分别</strong>执行上面给出的步骤。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-0e420042cc4a84d00d7ef383c8c9a540889.png" alt=""></li>
</ul>
</li>
</ul>
<p>重新分片的实战操作，可以参考该篇文章：<a href="http://weizijun.cn/2016/01/08/redis%20cluster%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7redis-trib-rb%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener" title="redis cluster管理工具redis-trib.rb详解">redis cluster管理工具redis-trib.rb详解</a></p>
<h2 id="4-6-ASK-错误"><a href="#4-6-ASK-错误" class="headerlink" title="4.6 ASK 错误"></a>4.6 ASK 错误</h2><p>在重新分片期间，源节点向目标节点迁移一个槽的过程中，可能会出现这样一种中间状态：属于被迁移槽的一部分键值对保存在源节点里面，而另一部分键值对保存在目标节点中。</p>
<p>这时候如果客户端向源节点发送了一个key的操作请求，就可能会触发ASK 错误。</p>
<p>当客户端向源节点发送关于键key的命令，源节点先在自己的数据库里查找这个键，如果找到就直接返回执行客户端命令，如果没找到，这个键可能已经被迁移到了目标节点，源节点向客户端返回一个 ASK 错误，指引客户端转向正在导入槽的目标节点，并再次发送之前要执行的命令。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1b3f9629997cc535ef543380112d098d3e0.png" alt=""></p>
<p>接到ASK 错误的客户端会根据错误提供的IP地址和端口号，转向至正在导入槽的目标节点，然后向目标节点发送一个 ASKING 命令， 之后再重新发送原本想要执行的命令。</p>
<h3 id="4-6-1-ASKING-命令的实现"><a href="#4-6-1-ASKING-命令的实现" class="headerlink" title="4.6.1 ASKING 命令的实现"></a>4.6.1 ASKING 命令的实现</h3><p>在重新分片过程中，我们对目标节点执行了 <code>CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_id&gt;</code>命令，这会使得clusterState状态的importing_slots_from数组会记录当前节点的哪些槽正在从哪些节点导入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState&#123;</span><br><span class="line">	&#x2F;&#x2F; ……</span><br><span class="line">    &#x2F;&#x2F; 如果importing_slots_from[i]的值不为NULL，而是指向一个clusterNode结构，表示当前节点正在从</span><br><span class="line">    &#x2F;&#x2F; clusterNode所代表的节点导入槽i</span><br><span class="line">    clusterNode *importing_slots_from[16384];</span><br><span class="line">     &#x2F;&#x2F; ……</span><br><span class="line">&#125;clusterState;</span><br></pre></td></tr></table></figure>

<p>在重新分片过程中，我们对源节点执行了<code>CLUSTER SETSLOT &lt;slot&gt; MIGRATING &lt;source_id&gt;</code>命令，这会使得clusterState状态的migrating_slots_to数组会记录当前节点正在迁移至其他节点的槽：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState&#123;</span><br><span class="line">    &#x2F;&#x2F; ……</span><br><span class="line">    &#x2F;&#x2F; 如果migrating_slots_to[i]的值不为NULL，而是指向一个clusterNode结构，表示当前节点正在将</span><br><span class="line">    &#x2F;&#x2F; 槽i迁移至clusterNode所代表的节点</span><br><span class="line">    clusterNode *migrating_slots_to[16384];</span><br><span class="line">    &#x2F;&#x2F; ……</span><br><span class="line">&#125;clusterState;</span><br></pre></td></tr></table></figure>
<p>接到ASK 错误的客户端会根据错误提供的IP地址和端口号，转向至正在导入槽的目标节点，然后向目标节点发送一个 ASKING 命令， 之后再重新发送原本想要执行的命令。</p>
<p><strong>ASKING命令要做的就是打开发送该命令的客户端的 REDIS_ASKING 标识。</strong></p>
<p>如果该客户端的 REDIS_ASKING 标识未打开，直接发送请求，由于槽的迁移过程还未完成，请求的键还属于源节点，此时直接请求目标节点，目标节点会返回一个MOVED错误。(因为迁移未完成，所以虽然部分的键已经迁移至目标节点了，但这部分键的归属，还是记在源节点上)</p>
<p>但是，如果节点的<code>clusterState.importing_slots_from[i]</code>显示节点正在导入槽 i ,并且发送命令的客户端带有 REDIS_ASKING 标识，<strong>那么节点将破例执行这个关于槽 i 的命令一次</strong>。</p>
<blockquote>
<p>客户端的 REDIS_ASKING 标识是一个一次性标识，当节点执行了一个带有 REDIS_ASKING 标识的客户单发送的命令之后，客户端的这个表示就会被移除。</p>
</blockquote>
<blockquote>
<p>ASK错误和MOVED错误的区别:<br>    MOVED错误代表槽的负责全已经从一个结点转移到了另一个节点<br>    ASK错误只是两个节点在迁移槽的过程中使用的一种临时措施</p>
</blockquote>
<h2 id="4-7-节点的复制与故障转移"><a href="#4-7-节点的复制与故障转移" class="headerlink" title="4.7 节点的复制与故障转移"></a>4.7 节点的复制与故障转移</h2><p>集群中的节点分为主节点和从节点，主节点负责处理槽，而从节点负责复制某个主节点，并在被复制的主节点下线时，替代下线主节点继续处理命令请求。</p>
<h3 id="4-7-1-设置从节点"><a href="#4-7-1-设置从节点" class="headerlink" title="4.7.1 设置从节点"></a>4.7.1 设置从节点</h3><p>向一个节点发送命令：<code>CLUSTER REPLICATE &lt;node_id&gt;</code></p>
<p>这个命令可以让接收命令的节点成为 node_id 所指定的从节点，并开始对主节点进行复制：</p>
<ul>
<li><p>这个节点会先在自己的 clusterState.nodes 字典中找到 node_id 所对应节点的 clusterNode 结构，并将自己的 <code>clusterState.myself.slaveof</code>指针指向这个结构，以此来记录这个节点正在复制的主节点</p>
</li>
<li><p>然后节点修改自己在 clusterState.myself.flags 中的属性，关闭原本的 <code>REDIS_NODE_MASTER</code>标识，打开 <code>REDIS_NODE_SLAVE</code>标识，表示这个节点由原来的主节点变成了从节点</p>
</li>
<li><p>最后，节点调用复制代码，并跟据 clusterState.myself.slaveof 指向的 clusterNode 结构所保存的IP地址和端口号，对主节点进行复制。就是相当于向从节点发送命令 <code>SLAVEOF &lt;master_ip&gt; &lt;maste_port&gt;</code></p>
</li>
</ul>
<p>一个节点开始成为从节点的时候，会向集群广播这一事实，以便集群中的其他节点更新从节点和主节点的关系。</p>
<h3 id="4-7-2-故障检测"><a href="#4-7-2-故障检测" class="headerlink" title="4.7.2 故障检测"></a>4.7.2 故障检测</h3><p>集群中的每个节点都会定期地向集群中的其他节点发送 PING 消息，以此来检测对方是否在线</p>
<p>如果接受 PING 消息的节点没有在规定时间内返回 PONG ，那么发送 PING 的节点就会将该节点标记为<strong>疑似下线</strong>(PFAIL)。</p>
<p>当一个主节点A通过消息得知主节点B认为主节点C进入疑似下线状态，主节点A会在自己的 <code>clusterState.nodes</code> 字典中找到主节点C所对应的 clusterNode 结构，并将主节点B的下线报告添加到这个结构的 fail_reports 链表里面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">struct clusterNode&#123;</span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">    &#x2F;&#x2F; 一个链表，记录了所有其他节点对该节点的下线报告</span><br><span class="line">    list *fail_reports;</span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果一个集群里，半数以上负责处理槽的主节点都将某个主节点X报告为疑似下线，那么这个主节点X将被标记为已下线(FAIL)，将主节点X标记为已下线的节点会向集群广播一条关于主节点X的FAIL消息，所有收到这条FAIL消息的节点都会立即将主节点X标记为已下线。</p>
<p>比较绕，我们来举例：假设一个集群有ABCD四个节点，A和B节点都认为D节点进入了疑似下线状态，这时刚好半数的主节点认为D疑似下线。然后，C节点通过消息交换，也将D节点标记为疑似下线状态。这时候数量就超过了半数了，于是C节点会将D节点标记为<strong>已下线</strong>，并向整个集群广播一条D节点已下线的消息。这时A和B接到消息，会将D节点标记为<strong>已下线</strong>。</p>
<h3 id="4-7-3-故障转移"><a href="#4-7-3-故障转移" class="headerlink" title="4.7.3 故障转移"></a>4.7.3 故障转移</h3><p>当一个从节点发现自己正在复制的主节点进入了已下线状态，<strong>从节点将开始对下线主节点进行故障转移</strong>:</p>
<ol>
<li>复制下线主节点的所有从节点里面，会有一个<strong>从节点</strong>被选中</li>
<li>被选中的从节点将执行 slaveof no one 命令，成为新的主节点</li>
<li>新的主节点撤销已下线主节点对指派槽的管理，并将这些槽全部指派给自己</li>
<li>新的主节点向集群广播一条PONG消息，告诉集群中的其他节点自己成为了新的主节点。</li>
<li>新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。</li>
</ol>
<p>这里面涉及到新的主节点的选举：</p>
<ol>
<li><p>集群的配置纪元是一个自增计数器，初始值为0</p>
</li>
<li><p>当集群里的某个节点开始一次故障转移操作时，集群配置纪元的值就会加一</p>
</li>
<li><p>对于每个配置纪元，集群中的每个负责处理槽的主节点都有一次投票机会，而第一个向主节点要求投票的从节点将获得主节点的投票</p>
</li>
<li><p>当从节点发现自己正在复制的主节点进入已下线状态时，从节点会向集群广播一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 消息，要求所有收到这条消息、并具有投票权的主节点向这个从节点投票</p>
</li>
<li><p>如果一个主节点具有投票权(它正在负责处理槽),并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，表示这个主节点支持从节点成为新的主节点</p>
</li>
<li><p>每个参与选举的从节点都会接受 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，并根据自己受到了多少条这种消息来统计自己获得了多少主节点 的支持</p>
</li>
<li><p>如果集群库有N个具有投票权的朱及诶单，那么当一个从节点收集到大于等于N/2+1张支持票，这个从节点当选为新的主节点</p>
</li>
<li><p>因为在每个配置纪元里面，每个具有投票权的主节点只能投一次票，所以如果有N个节点进行投票，那么具有大于等于N/2+1张支持票的从节点只会有一个，这确保了新的主节点只会有一个</p>
</li>
<li><p>如果在一个配置纪元里没有从节点能搜集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行选举，直到选出新的主节点为止。</p>
</li>
</ol>
<blockquote>
<p>和选举领头sentinel的算法一样，都是基于raft算法。</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-hand-o-left" aria-label="accessibility.prev_page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-hand-o-right" aria-label="accessibility.next_page"></i></a>
  </nav>

          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png"
                alt="cherish-ls" />
            
              <p class="site-author-name" itemprop="name">cherish-ls</p>
              <p class="site-description motion-element" itemprop="description">纸上得来终觉浅</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">61</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">26</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">98</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="git@github.com:cherish-ls/cherish-ls.github.io.git" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">cherish-ls</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">417.5k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"cherish"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  
















  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: 'TQhjcmooFXWGQ3qgqUroDKsD-gzGzoHsz',
        appKey: 'zjA9PvG5eljY1JErig8WVQQD',
        placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  

  
  

  

  

  

</body>
</html>
