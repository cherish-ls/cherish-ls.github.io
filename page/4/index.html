<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="纸上得来终觉浅，绝知此事要躬行" />










<meta name="description" content="纸上得来终觉浅">
<meta property="og:type" content="website">
<meta property="og:title" content="cherish">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="cherish">
<meta property="og:description" content="纸上得来终觉浅">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="cherish-ls">
<meta property="article:tag" content="纸上得来终觉浅，绝知此事要躬行">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/"/>





  <title>cherish</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">cherish</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">返朴归真</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/18/ElasticSearch-Master%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6%E6%B5%85%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/18/ElasticSearch-Master%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6%E6%B5%85%E6%9E%90/" itemprop="url">ElasticSearch Master选举机制浅析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-02-18T22:59:20+08:00">
                2020-02-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index">
                    <span itemprop="name">中间件</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/ElasticSearch/" itemprop="url" rel="index">
                    <span itemprop="name">ElasticSearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/02/18/ElasticSearch-Master%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6%E6%B5%85%E6%9E%90/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/02/18/ElasticSearch-Master选举机制浅析/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  8
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在ElasticSearch集群中，master负责处理集群层面配置的变更和同步工作，所有yml文件配置<code>node.master: true</code>的节点都有资格经过选举成为master节点</p>
<p><strong>es集群的master选举采用Bully算法</strong></p>
<h1 id="Bully算法"><a href="#Bully算法" class="headerlink" title="Bully算法"></a>Bully算法</h1><p>Leader选举的基本算法之一。</p>
<p>它假定所有节点都有一个惟一的ID，该ID对节点进行排序。 任何时候的当前Leader都是参与集群的最高id节点。</p>
<p>具体来说，Bully算法要求每个节点都投票给ID最高的那个节点，通过这一强制性的条件，让集群非常简单的协调一致。</p>
<p>该算法的优点是易于实现，但是，当拥有最大ID的节点处于不稳定状态的场景下会有问题，例如Master负载过重而假死，集群拥有第二大ID的节点被选为新主，这时原来的Master恢复，再次被选为新主，然后又假死…</p>
<p>而且该算法会有脑裂的问题。</p>
<p>elasticsearch通过<strong>控制触发时机来解决反复去世的问题，即当前的Master失效才会触发选举。</strong></p>
<p>同时es又<strong>要求法定得票人数过半</strong>才能选出master，以此来解决脑裂。</p>
<blockquote>
<p>es实际上是从具有master资格的节点中选id最小的节点作为master，而不是id最大的节点</p>
</blockquote>
<h1 id="选举触发时机"><a href="#选举触发时机" class="headerlink" title="选举触发时机"></a>选举触发时机</h1><ol>
<li>集群启动：<ul>
<li>后台启动线程去ping集群中的节点，按照上述策略从具有master资格的节点中选举出master</li>
</ul>
</li>
<li>Master失效<ul>
<li>非Master节点运行的MasterFaultDetection检测到Master失效，在其注册的listener中执行handleMasterGone，执行rejoin操作，重新选主。注意，即使一个节点认为Master失效，也会进入选主流程。</li>
</ul>
</li>
</ol>
<p>我们需要在候选集群中的节点的配置文件中设置参数 <code>discovery.zen.munimum_master_nodes</code>的值，这个参数表示<strong>在选举主节点时需要参与选举的候选主节点的节点数</strong>，默认值是1，官方建议取值 <code>(master_eligibel_nodes/2)+1</code>，其中 <code>master_eligibel_nodes</code>为候选主节点的个数。</p>
<p>这样做既能防止脑裂现象的发生，也能最大限度地提升集群的高可用性，因为只要不少于discovery.zen.munimum_master_nodes个候选节点存活，选举工作就能正常进行。当小于这个值的时候，无法触发选举行为，集群无法使用，不会造成分片混乱的情况。</p>
<h1 id="选举过程"><a href="#选举过程" class="headerlink" title="选举过程"></a>选举过程</h1><p>Master选举主要逻辑在<code>ZenDiscovery.findMaster（基于es 5.2版本）</code>中：</p>
<ol>
<li><p><strong>开始</strong></p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> DiscoveryNode <span class="title">findMaster</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	logger.trace(<span class="string">"starting to ping"</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>每个节点ping集群下的其他节点，等待所有节点的返回。</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//pingAndWait用于获取其他节点的状态，这里只介绍下大致实现，不再展开具体源码：</span></span><br><span class="line"><span class="comment">//pingAndWait主要是使用上面介绍的ZenPing去ping配置中的所有host</span></span><br><span class="line"><span class="comment">//通过函数名称可以知道这是个同步调用，同步的具体实现和ElasticSearch大部分需要等待</span></span><br><span class="line"><span class="comment">//远程通信返回的行为类似，采用计数器记录发送的请求个数，每次有请求响应时递减计数器，</span></span><br><span class="line"><span class="comment">//当计数器递减为0时表示所有请求都得到了响应。</span></span><br><span class="line">List&lt;ZenPing.PingResponse&gt; fullPingResponses = pingAndWait(pingTimeout).toList();</span><br><span class="line"><span class="keyword">if</span> (fullPingResponses == <span class="keyword">null</span>) &#123;</span><br><span class="line">	logger.trace(<span class="string">"No full ping responses"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (logger.isTraceEnabled()) &#123;</span><br><span class="line">	StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">	<span class="keyword">if</span> (fullPingResponses.size() == <span class="number">0</span>) &#123;</span><br><span class="line">		sb.append(<span class="string">" &#123;none&#125;"</span>);</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">for</span> (ZenPing.PingResponse pingResponse : fullPingResponses) &#123;</span><br><span class="line">			sb.append(<span class="string">"\n\t--&gt; "</span>).append(pingResponse);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	logger.trace(<span class="string">"full ping responses:&#123;&#125;"</span>, sb);</span><br><span class="line">&#125;</span><br><span class="line">	</span><br><span class="line"><span class="keyword">final</span> DiscoveryNode localNode = clusterService.localNode();</span><br><span class="line">	</span><br><span class="line"><span class="comment">// add our selves</span></span><br><span class="line"><span class="keyword">assert</span> fullPingResponses.stream().map(ZenPing.PingResponse::node)</span><br><span class="line">	.filter(n -&gt; n.equals(localNode)).findAny().isPresent() == <span class="keyword">false</span>;</span><br><span class="line"><span class="comment">//在获取的装填集中加入当前节点自己的状态，因为自己也需要加入选举，也可能被选举为主节点</span></span><br><span class="line">fullPingResponses.add(<span class="keyword">new</span> ZenPing.PingResponse(localNode, <span class="keyword">null</span>, clusterService.state()));</span><br></pre></td></tr></table></figure></li>
<li><p><strong>根据其他节点的返回，过滤掉没有资格参加选举的节点</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// filter responses</span></span><br><span class="line"><span class="comment">// 过滤PingResponse, 排除掉client节点，单纯的data节点</span></span><br><span class="line"><span class="keyword">final</span> List&lt;ZenPing.PingResponse&gt; pingResponses = filterPingResponses(fullPingResponses, masterElectionIgnoreNonMasters, logger);</span><br></pre></td></tr></table></figure></li>
<li><p><strong>根据反馈，收集当前集群已经存在的master塞入activeMasters</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//activeMasters用来记录当前已经存在的主节点</span></span><br><span class="line">List&lt;DiscoveryNode&gt; activeMasters = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span> (ZenPing.PingResponse pingResponse : pingResponses) &#123;</span><br><span class="line">	<span class="comment">// We can't include the local node in pingMasters list, otherwise we may up electing ourselves without</span></span><br><span class="line">	<span class="comment">// any check / verifications from other nodes in ZenDiscover#innerJoinCluster()</span></span><br><span class="line">	<span class="comment">//如果返回的信息表明自己当前已经是主节点，那么不会把自己加入到activeMasters中去</span></span><br><span class="line">	<span class="keyword">if</span> (pingResponse.master() != <span class="keyword">null</span> &amp;&amp; !localNode.equals(pingResponse.master())) &#123;</span><br><span class="line">		activeMasters.add(pingResponse.master());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>根据反馈，收集当前集群已经存在的具有选举资格的node塞入masterCandidates</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">	</span><br><span class="line"><span class="comment">// nodes discovered during pinging</span></span><br><span class="line"><span class="comment">//masterCandidates用来记录配置为可以成为主节点的候选节点</span></span><br><span class="line">List&lt;ElectMasterService.MasterCandidate&gt; masterCandidates = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"><span class="comment">//这里将返回节点中配置为可以作为主节点的节点加入候选节点中</span></span><br><span class="line"><span class="keyword">for</span> (ZenPing.PingResponse pingResponse : pingResponses) &#123;</span><br><span class="line">	<span class="comment">//这里要注意isMasterNode并不是说明该节点是不是主节点，而是表明该节点能不能成为主节点</span></span><br><span class="line">	<span class="keyword">if</span> (pingResponse.node().isMasterNode()) &#123;</span><br><span class="line">		masterCandidates.add(<span class="keyword">new</span> ElectMasterService.MasterCandidate(pingResponse.node(), pingResponse.getClusterStateVersion()));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>如果集群中已经有master，那么加入它，否则，开始选举</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//如果当前存在的主节点列表activeMasters为空，则从候选节点列表masterCandidates中选取主节点</span></span><br><span class="line"><span class="keyword">if</span> (activeMasters.isEmpty()) &#123;</span><br><span class="line">	<span class="comment">//判断是否有足够的候选节点</span></span><br><span class="line">	<span class="keyword">if</span> (electMaster.hasEnoughCandidates(masterCandidates)) &#123;</span><br><span class="line">		<span class="comment">//进行节点选举</span></span><br><span class="line">		<span class="keyword">final</span> ElectMasterService.MasterCandidate winner = electMaster.electMaster(masterCandidates);</span><br><span class="line">		logger.trace(<span class="string">"candidate &#123;&#125; won election"</span>, winner);</span><br><span class="line">		<span class="keyword">return</span> winner.getNode();</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">// if we don't have enough master nodes, we bail, because there are not enough master to elect from</span></span><br><span class="line">		logger.trace(<span class="string">"not enough master nodes [&#123;&#125;]"</span>, masterCandidates);</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;<span class="comment">//activeMasters不为空，表示当前集群已经有master了</span></span><br><span class="line">	<span class="keyword">assert</span> !activeMasters.contains(localNode) : <span class="string">"local node should never be elected as master when other nodes indicate an active master"</span>;</span><br><span class="line">	<span class="comment">//如果当前存在的主节点列表activeMasters不为空，则从中选取主节点</span></span><br><span class="line">	<span class="comment">// lets tie break between discovered nodes</span></span><br><span class="line">	<span class="keyword">return</span> electMaster.tieBreakActiveMasters(activeMasters);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>如果集群中现在没有master，那么选出master</strong></p>
<ul>
<li><p>选举主要算法集中在electMaster.electMaster()方法中，我们来看下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Elects a new master out of the possible nodes, returning it. Returns &lt;tt&gt;null&lt;/tt&gt;</span></span><br><span class="line"><span class="comment"> * if no master has been elected.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> MasterCandidate <span class="title">electMaster</span><span class="params">(Collection&lt;MasterCandidate&gt; candidates)</span> </span>&#123;</span><br><span class="line">	<span class="comment">//保证有足够的候选者，逻辑是判断有资格参选的node数量大于yml配置的minimumMasterNodes</span></span><br><span class="line">	<span class="function"><span class="keyword">assert</span> <span class="title">hasEnoughCandidates</span><span class="params">(candidates)</span></span>;</span><br><span class="line">	List&lt;MasterCandidate&gt; sortedCandidates = <span class="keyword">new</span> ArrayList&lt;&gt;(candidates);</span><br><span class="line">	<span class="comment">//对候选者进行排序，</span></span><br><span class="line">	sortedCandidates.sort(MasterCandidate::compare);</span><br><span class="line">	<span class="comment">//取队首的node即为master</span></span><br><span class="line">	<span class="keyword">return</span> sortedCandidates.get(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * compares two candidates to indicate which the a better master.</span><br><span class="line"> * A higher cluster state version is better</span><br><span class="line"> *</span><br><span class="line"> * @return -1 if c1 is a batter candidate, 1 if c2.</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static int compare(MasterCandidate c1, MasterCandidate c2) &#123;</span><br><span class="line">	&#x2F;&#x2F; we explicitly swap c1 and c2 here. the code expects &quot;better&quot; is lower in a sorted</span><br><span class="line">	&#x2F;&#x2F; list, so if c2 has a higher cluster state version, it needs to come first.</span><br><span class="line">	&#x2F;&#x2F;先根据节点的clusterStateVersion比较，clusterStateVersion越大，优先级越高。</span><br><span class="line">	&#x2F;&#x2F;这是为了保证新Master拥有最新的clusterState(即集群的meta)，避免已经commit的meta变更丢失。</span><br><span class="line">	&#x2F;&#x2F;因为Master当选后，就会以这个版本的clusterState为基础进行更新。</span><br><span class="line">	int ret &#x3D; Long.compare(c2.clusterStateVersion, c1.clusterStateVersion);</span><br><span class="line">	if (ret &#x3D;&#x3D; 0) &#123;</span><br><span class="line">		&#x2F;&#x2F;clusterStateVersion相同时，进入compareNodes，其内部按照节点的Id比较(Id为节点第一次启动时随机生成)</span><br><span class="line">		ret &#x3D; compareNodes(c1.getNode(), c2.getNode());</span><br><span class="line">	&#125;</span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">	</span><br><span class="line">&#x2F;** master nodes go before other nodes, with a secondary sort by id **&#x2F;</span><br><span class="line"> private static int compareNodes(DiscoveryNode o1, DiscoveryNode o2) &#123;</span><br><span class="line"> 	&#x2F;&#x2F;isMasterNode方法是判断该节点yml文件是否配置了data.master&#x3D;true，即是否有资格参选</span><br><span class="line">	&#x2F;&#x2F;有资格参选的优先（其实从findMaster进入这里，所有的node都是有资格的）</span><br><span class="line">	if (o1.isMasterNode() &amp;&amp; !o2.isMasterNode()) &#123;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	if (!o1.isMasterNode() &amp;&amp; o2.isMasterNode()) &#123;</span><br><span class="line">		return 1;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;根据id排序升序排序</span><br><span class="line">	return o1.getId().compareTo(o2.getId());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>如果集群中已经有master，找到这个master</strong></p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** selects the best active master to join, where multiple are discovered */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> DiscoveryNode <span class="title">tieBreakActiveMasters</span><span class="params">(Collection&lt;DiscoveryNode&gt; activeMasters)</span> </span>&#123;</span><br><span class="line">	<span class="comment">//同理，也是默认id最小的node就是master</span></span><br><span class="line">	<span class="keyword">return</span> activeMasters.stream().min(ElectMasterService::compareNodes).get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h1 id="选举过程简图"><a href="#选举过程简图" class="headerlink" title="选举过程简图"></a>选举过程简图</h1><p><img src="https://oscimg.oschina.net/oscnet/up-47d023a3bf701279690cbff187a131b0e4d.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/21/Raft%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/21/Raft%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/" itemprop="url">Raft算法分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-01-21T22:52:18+08:00">
                2020-01-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95-%E7%90%86%E8%AE%BA/" itemprop="url" rel="index">
                    <span itemprop="name">分布式算法&理论</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95-%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%92%8C%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/" itemprop="url" rel="index">
                    <span itemprop="name">分布式事务和数据一致性</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/01/21/Raft%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/01/21/Raft算法分析/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  4.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  17
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在了解Ratf算法前，我们需要了解如下的一些概念名词：</p>
<ol>
<li><p>状态机复制 (State Machine Replication)</p>
<ul>
<li>在分布式系统设计中，需要遵循CAP理论，如果我们要让一个服务具有容错能力，那么会让一个服务的多个副本同时运行在不同的节点上。此时，<strong>状态的改变</strong>就需要在各个副本之间做同步，实现这种同步方法就是所谓的状态机复制（State Machine Replication）。</li>
<li>状态机复制的理论基础是：如果集群里的每一个节点上都运行着相同的确定性状态机S，并且所有的状态机刚开始都处于同样的初始状态s0，那么给予这些状态机相同的输入序列: {i1, i2, i3, i4, i5, i6, …, in}, 这些状态机必然会经过相同的状态转换路径: s0-&gt;s1-&gt;s2-&gt;s3-&gt;…-&gt;sn最终达到相同的状态sn, 同时生成相同的输出序列 {o1(s1), o2(s2), o3(s3), …, on(sn)}。（典型的例子就是Redis的AOF和MySQL集群的binlog）</li>
<li>在执行输入序列I的过程中，根据同步方式的不同，系统就有了强一致性和最终一致性。如果我们要求对于序列I中的每一个in, <strong>都需要所有的服务副本确认执行了in，才能执行in+1</strong>，那么这个系统就是强一致性的系统。如果我们取消掉这个限制，仅仅要求所有的服务副本执行相同的输入序列I，但是完全各自独立执行，而不需要在中间同步，那么就有了最终一致性（各服务都会达到相同的最终状态，但是达到的时间不确定）。</li>
</ul>
</li>
<li><p>拜占庭将军问题</p>
<ul>
<li>问题很简单，拜占庭帝国要攻打一个城池，兵分多路，城池很难攻下，要多路军队同时进攻才能攻下，为了完成目标，各路的将军需要通过信使来约定一个攻打的时间，而信使有可能死亡或者叛变（传递假消息）。</li>
<li>基于以上的问题，我们需要在行动时达成共识。互联网上，每台计算机都是一个个完全相等的节点，只能靠通信来协调，没有权威背书或信任，是一个急需解决的问题。</li>
</ul>
</li>
</ol>
<blockquote>
<p>拜占庭将军问题的本质：如何让众多完全平等的节点针对某一状态达成共识。</p>
</blockquote>
<h1 id="Raft算法"><a href="#Raft算法" class="headerlink" title="Raft算法"></a>Raft算法</h1><p>拜占庭将军问题是分布式领域最复杂、最严格的容错模型。但在日常工作中使用的分布式系统面对的问题不会那么复杂，更多的是计算机故障挂掉了，或者网络通信问题而没法传递信息，这种情况不考虑计算机之间互相发送恶意信息，极大简化了系统对容错的要求，最主要的是达到一致性。</p>
<p>所以将拜占庭将军问题根据常见的工作上的问题进行简化：<strong>假设将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成一致性决定？</strong></p>
<p>对于这个简化后的问题，有许多解决方案，第一个被证明的共识算法是 Paxos，由拜占庭将军问题的作者 Leslie Lamport 在1990年提出，最初以论文难懂而出名，后来这哥们在2001重新发了一篇简单版的论文 <a href="https://link.jianshu.com?t=%255Bhttps%3A%2F%2Flamport.azurewebsites.net%2Fpubs%2Fpaxos-simple.pdf%255D%28https%3A%2F%2Flamport.azurewebsites.net%2Fpubs%2Fpaxos-simple.pdf%29" target="_blank" rel="noopener">Paxos Made Simple</a>，然而还是挺难懂的。</p>
<p>因为 Paxos 难懂，难实现，所以斯坦福大学的教授在2014年发表了新的分布式协议 Raft。与 Paxos 相比，Raft 有着基本相同运行效率，但是更容易理解，也更容易被用在系统开发上。paxos见我的另一篇文章<a href="https://my.oschina.net/lscherish/blog/3086518" target="_blank" rel="noopener" title="分布式一致性理论和paxos算法">分布式一致性理论和paxos算法</a></p>
<p>Raft算法主要分为如下几个关键步骤：</p>
<ul>
<li><strong>leader选举</strong>：<ul>
<li>Raft开始时在集群中选举出Leader负责日志复制的管理；</li>
</ul>
</li>
<li><strong>日志复制</strong>：<ul>
<li>Leader接受来自客户端的事务请求（日志），并将它们复制给集群的其他节点，然后负责通知集群中其他节点提交日志，Leader负责保证其他节点与他的日志同步。</li>
</ul>
</li>
<li><strong>故障转移</strong>：<ul>
<li>当Leader宕掉后集群其他节点会发起选举选出新的Leader；</li>
</ul>
</li>
</ul>
<p>raft算法有如下特点：</p>
<ul>
<li>强leader语义：<ul>
<li>相比其他一致性算法，Raft使用增强形式的leader语义。举个例子，日志只能由leader复制给其它节点。这简化了日志复制需要的管理工作，使得Raft易于理解。</li>
</ul>
</li>
<li>leader的选择：<ul>
<li>Raft使用随机计时器来选择leader，它的实现只是在心跳机制(任何一致性算法中都必须实现)上多做了一点“文章”，不会增加延迟和复杂性。</li>
</ul>
</li>
<li>关系改变：<ul>
<li>Raft使用了一个新机制joint consensus允许集群动态在线扩容，保障Raft的可持续服务能力。</li>
</ul>
</li>
</ul>
<h2 id="1-Ratf名词速览"><a href="#1-Ratf名词速览" class="headerlink" title="1 Ratf名词速览"></a>1 Ratf名词速览</h2><h3 id="1-1-Raft节点状态"><a href="#1-1-Raft节点状态" class="headerlink" title="1.1 Raft节点状态"></a>1.1 Raft节点状态</h3><p>从拜占庭将军的故事映射到分布式系统上，每个将军相当于一个分布式网络节点，每个节点有<strong>三种状态：Follower（跟随者），Candidate（候选者），Leader（领导者）</strong>，状态之间是互相转换的，可以参考下图，具体的后面说。</p>
<p><img src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=2542550312,1610670251&fm=26&gp=0.jpg" alt=""></p>
<h3 id="1-2-term任期"><a href="#1-2-term任期" class="headerlink" title="1.2 term任期"></a>1.2 term任期</h3><p>从上面可以看出，哪个节点做leader是大家投票选举出来的，每个leader工作一段时间，然后选出新的leader继续负责。这和民选社会的选举很像，每一届新的履职期称之为一届任期，在raft协议中，也是这样的，对应的术语叫<strong>term</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-fcbf54411bab45c59179187008e2b0bb6d3.png" alt=""></p>
<p>上图蓝色表示选举期，绿色表示履职期。</p>
<p>每个任期都有一个对应的整数与之关联，称为“任期号”，任期号用单词“Term”表示，这个值是一个严格递增的整数值。</p>
<p>如果一个candidate在一次选举中赢得leader，那么这个节点将在这个任期中担任leader的角色。但并不是每个任期都一定对应有一个leader的，比如上面的t3中，可能在选举超时到来之前都没有产生一个新的leader，那么此时将递增任期号开始一次新的选举。</p>
<h2 id="2-Raft算法流程"><a href="#2-Raft算法流程" class="headerlink" title="2. Raft算法流程"></a>2. Raft算法流程</h2><h3 id="2-1-leader选举"><a href="#2-1-leader选举" class="headerlink" title="2.1 leader选举"></a>2.1 leader选举</h3><h4 id="2-1-1-心跳机制"><a href="#2-1-1-心跳机制" class="headerlink" title="2.1.1 心跳机制"></a>2.1.1 心跳机制</h4><p>raft算法是使用<strong>心跳机制</strong>来触发leader选举的。</p>
<p>在节点刚开始启动时，初始状态是follower状态。一个follower状态的节点，只要一直收到来自leader或者candidate的正确RPC消息的话，将一直保持在follower状态。</p>
<p>leader节点通过周期性的发送心跳请求（一般使用带有空数据的AppendEntries RPC来进行心跳）来维持着leader节点状态。</p>
<h4 id="2-1-2-选举超时（election-timeout）"><a href="#2-1-2-选举超时（election-timeout）" class="headerlink" title="2.1.2 选举超时（election timeout）"></a>2.1.2 选举超时（election timeout）</h4><p>每个follower有一个选举超时（election timeout）定时器，这个定时器的值，对于每个节点都是不同的，<strong>其值在150ms到300ms之前随机</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-016776da4a64b5dd9d1153b7f5092d46aa8.png" alt=""></p>
<p>如果某个节点在这个定时器超时之前都没有收到来自leader的心跳请求，那么该follower将认为当前集群中没有leader了，<strong>它会改变自己的状态为candidate</strong>，如下图Node A。然后开启一个新的term，节点本地的任期号term+1。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3031d5fce27f4dfa56678ec53d1996b1948.png" alt=""></p>
<h4 id="2-1-3-请求投票（RequestVote）"><a href="#2-1-3-请求投票（RequestVote）" class="headerlink" title="2.1.3 请求投票（RequestVote）"></a>2.1.3 请求投票（RequestVote）</h4><p>成为candidate的节点，会先投自己一票，然后并行给其他节点发送请求投票的消息RequestVote RPCs</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-00e140d80ed7a32d3b2c37a2e9f81aee907.png" alt=""></p>
<p>那么一个节点在接收到RequestVote RPCs时，它会遵循以下约束来决定是否将票投给请求的发送者。</p>
<ol>
<li>在任一任期内，单个节点最多只能投一票</li>
<li>候选人知道的信息不能比自己的少（这一部分，后面介绍log replication和safety的时候会详细介绍）</li>
<li>first-come-first-served 先来先得</li>
</ol>
<p>如果一个节点在接收到RequestVote RPCs时，上述约束都满足，<strong>那么他将投发送者一票，重置自己的election timeout，并给予响应。</strong></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-582e3bffc1f4b8d9559d2fc6b91e21bab71.png" alt=""></p>
<h4 id="2-1-4-票仓分布"><a href="#2-1-4-票仓分布" class="headerlink" title="2.1.4 票仓分布"></a>2.1.4 票仓分布</h4><p>对于一个candidate而言，它发出了请求RequestVote RPCs后，就开始等待其他节点的回复，这时可能会有三种结果：</p>
<ol>
<li><p>全局就它一个candidate，其他的节点election timeout还没结束就接到了它的RequestVote RPCs，那么这时，这个candidate无疑会获得大多数票，成为新的leader。</p>
<p> <img src="https://oscimg.oschina.net/oscnet/up-5935fb3ed30c681c368121b30b33d0c37ca.png" alt=""></p>
</li>
<li><p>有多个节点<strong>或先后或同时</strong>成为了candidate，但基于“每个节点一个任期内只能投一票”和“先到先得”的约束，以及请求的通信时间的随机性，还是有一个candidate运气好，获得了超过半数的票。</p>
</li>
</ol>
<ul>
<li>那么这个新的leader胜选后，会广播心跳，其他candidate发现心跳中携带的term信息不低于自己，知道有已经有leader被选举出来了，于是放弃选举，转换成follower。</li>
</ul>
<ol start="3">
<li>有多个节点<strong>或先后或同时</strong>成为了candidate，但票数分布均匀，没有任何节点获得超过半数的票（这种情况称作split vote）。<ul>
<li><img src="https://img2018.cnblogs.com/blog/1089769/201812/1089769-20181216202546810-1327167758.png" alt=""></li>
<li>此时所有的candidate都在等待能使自己选票超过半数的响应，等啊等，直到超时后重新发起选举。</li>
<li>如果出现split vote的情况，那么就延长了系统不可用的时间（没有leader是不能处理客户端写请求的），因此raft才引入randomized election timeouts来尽量避免平票情况。同时，leader-based 共识算法中，节点的数目都是奇数个，尽量保证majority的出现。</li>
</ul>
</li>
</ol>
<h4 id="2-1-5-诞生leader"><a href="#2-1-5-诞生leader" class="headerlink" title="2.1.5 诞生leader"></a>2.1.5 诞生leader</h4><p>一个leader诞生以后，就像我们在前文<em>2.1.1 心跳机制</em>所述的那样，<strong>在这个新的任期内每隔heartBeat timeout时间，不停的向follower发送心跳请求（append entries）</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-737045f80305af36b81c50bfdc6952cd71c.png" alt=""></p>
<p>而每个follower则维持着自己的election timeout计时器，如果election timeout时间内没有收到来自leader的心跳，那么说明leader故障。将自己变成candidate，并开始下次选举。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9c878faedc64dd14284548e3b6b739f6f5e.png" alt=""></p>
<h3 id="2-2-日志复制（Log-Replication）"><a href="#2-2-日志复制（Log-Replication）" class="headerlink" title="2.2 日志复制（Log Replication）"></a>2.2 日志复制（Log Replication）</h3><p>前文我们说过了<strong>状态机复制(State Machine Replication)</strong>，状态机复制有多种实现，在Raft中，也有一套基于Append-Only Log的状态机复制实现。</p>
<p>Raft 是分布式一致性算法，保证的实际上是多台机器上数据的一致性。前面讨论的 leader 选举，其实都是为了保证日志复制的一致性而做的前提。Raft的状态机复制实现，我们称作日志复制（Log Replication）。</p>
<blockquote>
<p>Leader 选举只是为了保证日志相同的辅助工作。实际上，在更为学术的 Paxos 里面，是没有 leader 的概念的（大部分 Paxos 的实现通常会加入 leader 机制提高性能）。</p>
</blockquote>
<p>这里的日志，指的是命令日志，对于客户端发来的命令请求，leader会将其封装成一个Log Entry作为传输的载体。</p>
<p>在 Raft 中，leader会接收客户端的所有需求（follower会将写请求转发给leader），leader会将数据以Log Entry的方式通过AppendEntries RPC同步给所有followers</p>
<p>只要超过半数以上的follower反馈成功（返回ack），这条日志就成功提交了。如果RPC请求超时，leader就不停的进行AppendEntries RPC重试。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3d5c64ec78bb30781abc5d3932c1013c62b.png" alt=""></p>
<p><strong>简单来说，保证复制日志相同，才是分布式一致性算法的最终任务</strong>。</p>
<h4 id="2-2-1-Log和Log-Entry"><a href="#2-2-1-Log和Log-Entry" class="headerlink" title="2.2.1 Log和Log Entry"></a>2.2.1 Log和Log Entry</h4><p>Raft中每个节点，都会维护一个本地Log数组，其数据结构如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-bcaab5cd935fc5a5dd0834e80980e3cea12.png" alt=""></p>
<p>其构成有：</p>
<ul>
<li>创建日志时的任期号（用来检查节点日志是否出现不一致的情况）</li>
<li>状态机需要执行的指令（真正的内容）</li>
<li>索引：整数索引，表示日志条目在日志数组中位置</li>
</ul>
<p>上图显示，共有 8 条日志，提交了 7 条。提交的日志都将通过状态机持久化到磁盘中，防止宕机。</p>
<h4 id="2-2-2-一致性校验"><a href="#2-2-2-一致性校验" class="headerlink" title="2.2.2 一致性校验"></a>2.2.2 一致性校验</h4><p>然后谈谈主从日志的一致性问题，这个是分布式一致性算法要解决的根本问题。</p>
<p>Raft 主从日志的一致性，这个最终的目标，可以分解成<strong>一个假设</strong>和一个<strong>充分条件</strong>。</p>
<ul>
<li><p><strong>我们可以假设</strong>：如果在不同的日志中的两个日志条目的<code>任期号</code> 和 <code>索引下标</code> 相同，那么他们的指令就是相同的。</p>
<blockquote>
<p>leader 最多在一个任期里的一个日志索引位置创建一条日志条目，而所有follower的日志来源都是leader，日志条目在日志的位置从来不会改变，所以基本上可以用任期号和索引下标当做Log Entry的主键</p>
</blockquote>
</li>
<li><p><strong>那么，主从日志一致性的充分条件可以是</strong>：如果在不同节点的日志里， 任意2个拥有相同的任期号和索引的日志条目，他们之前的日志项都是相同的，那么这些节点的日志就都是一致的。</p>
</li>
</ul>
<p>达成了上述的这个充分条件，就达成了主从日志一致的最终条件，那如何达成这个充分条件呢？Raft引入了一种<strong>一致性校验</strong>约束。</p>
<p><strong>每次 RPC 发送附加日志时，leader 会把当前这条日志Entry的前一个日志Entry的下标和任期号一起发送给 follower，如果 follower 发现发来前一个日志Entry的下标和任期号和自己队尾的日志Entry不匹配，那么就拒绝接受这条日志，这个称之为一致性校验</strong></p>
<p>如果每一步都严格遵守该校验，就达成了主从日志一致的最终条件。</p>
<h4 id="2-2-3-日志复制过程"><a href="#2-2-3-日志复制过程" class="headerlink" title="2.2.3 日志复制过程"></a>2.2.3 日志复制过程</h4><p>有了这个一致性校验，我们再反过头来看下日志复制的过程。</p>
<p>在Raft协议中有两个主要的消息，一个是在第二节讲到的RequestVote RPC，用于选主投票时leader发出的消息。一个就是AppendEntries RPC，用于心跳和日志复制。对于心跳，只需要发送空内容的AppendEntries RPC就可以了，我们主要关注日志复制的消息，看看Raft是怎么操作的。</p>
<ol>
<li><p>leader接受客户端的操作请求，如“将X赋值为3”。</p>
<ul>
<li>假如leader当前的任期为term1，那么leader就会向自己本地log的最后添加一个entry，比如索引为K，内容为“term1：X赋值为3”。</li>
</ul>
</li>
<li><p>leader向集群中其他follower并行发送AppendEntries RPC消息。这个消息里面包含：</p>
<ol>
<li>这个新的entry和索引，即“term1：X赋值为3”和K。</li>
<li>前一个entry的内容和索引，比如“term1：Y赋值为2”和K-1。</li>
</ol>
</li>
<li><p>当一个follower收到一个AppendEntries RPC消息时，会查看自己本地的log中的K-1位置的entry的内容。（一致性校验）</p>
<ul>
<li><p>假如本地log中K-1位置的entry内容与接收到的来自leader的K-1的entry内容一致（下标和任期号一致），那么就将leader发来的K位置的entry保存在自己的K位置（当然要做并发控制），并返回true，告诉leader保存成功了</p>
</li>
<li><p>假如本地log中K-1位置的entry内容与接收到的来自leader的K-1的entry内容不一致（下标和任期号不一致），那么就返回false，告诉leader不一致。</p>
</li>
</ul>
</li>
<li><p>leader收到消息。</p>
<ul>
<li>如果得到的反馈为true，即某个follower保存成功了，那么这个Log Entry的复制完成。</li>
<li>否则，见下文2.2.4 特殊情况的日志复制过程。</li>
</ul>
</li>
<li><p>leader得到了超过半数的follower反馈的true消息，leader会执行这条Log Entry中的命令，并反馈客户端该命令已经提交，同时向其他follower广播这条Log Entry被commit的消息。</p>
</li>
<li><p>follower接收到Log Entry被commit的消息，执行该Log Entry中的命令。在当前日志被提交的过程中，如果leader先前的某些日志还没有被提交，则将会一同提交。</p>
</li>
</ol>
<blockquote>
<p>在Raft中，一切以leader为主。因此本地日志不是最新的话，就不能成为leader。因此在选主的时候，会进行日志比较。假如在投票阶段，一个follower收到的选主请求中，包含的日志信息比自己的要旧，那么也会拒绝给这个请求投赞成票。如何比较新旧呢？一是看任期term，一是看最后一个entry的索引号。任期大的新，任期相同的索引大的新。</p>
</blockquote>
<h4 id="2-2-4-特殊情况的日志复制过程"><a href="#2-2-4-特殊情况的日志复制过程" class="headerlink" title="2.2.4 特殊情况的日志复制过程"></a>2.2.4 特殊情况的日志复制过程</h4><p>上面说的都是日志在正常情况下的表现，没有考虑到一些异常情况。</p>
<p>即，正常情况下，leader和follower的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。但如果我们将leader或者follower崩溃的情况考虑进来，那么将可能会出现三种情况：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-49a8f26aa515f308e4feaba3cf7109e118a.png" alt=""></p>
<ol>
<li>follower缺失当前leader上存在的日志条目。如a，b</li>
<li>follower存在当前leader不存在的日志条目。如c，d(比如旧的leader仅仅将AppendEntries RPC消息发送到一部分follower就崩溃掉，然后新的当选leader的服务器恰好是没有收到该AppendEntries RPC消息的服务器)</li>
<li>或者follower即缺失当前leader上存在的日志条目，也存在当前leader不存在的日志条目。如e，f</li>
</ol>
<p>这种情况如何处理呢？</p>
<p>Raft 给出了一个方案（补丁）</p>
<blockquote>
<p>强制follower直接复制leader的日志（意味着follower中的和leader冲突的日志将被覆盖）。</p>
</blockquote>
<p>要使得follower的日志和leader进入一致状态，<strong>leader必须找到follower最后一条和leader匹配的日志，然后从这条日志开始，用leader的日志条目，覆盖follower的日志条目</strong></p>
<p>依据这个方案，上图中的 a follower和b follower从队尾直接复制即可。c follower最后一个条目将被覆盖，d follower最后2个任期为7的条目将被覆盖，e最后2个任期为4的条目将被覆盖，f 则比较厉害，需要覆盖下标为3之后的所有条目。</p>
<p>实现逻辑如下：</p>
<ul>
<li><p>leader向集群中的follower发送AppendEntries RPC，内容为最新的Log Entry和其索引K，以及前一个Log Entry及其索引K-1，这里不再赘述。</p>
</li>
<li><p>一致性检验失败，follower向leader反馈false。</p>
</li>
<li><p>leader会将K自减1，然后再次重新发AppendEntries RPC给失败的follower，直到follower返回true。那么此时的K，<strong>就是follower最后一条和leader匹配的日志的下标</strong>。</p>
</li>
</ul>
<blockquote>
<p>最坏的情况是K=0时才得到true回复，这表示follower的Log和leader完全不一致。K=0得到的回复一定是true，因为没有K-1了</p>
</blockquote>
<ul>
<li>此时leader将<strong>匹配的位置和最新的位置中间的内容</strong>都发送给follower，follower会将接收到的内容，并<strong>覆盖</strong>到对应的位置。</li>
</ul>
<blockquote>
<p>实际上leader对每个follower都维护了一个nextIndex字段，来存上述过程中一直递减的K值，描述中我没有引入nextIndex字段的概念，力求精简，以便理解。</p>
</blockquote>
<hr>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/software444/article/details/89787410" target="_blank" rel="noopener" title="状态机复制 (State Machine Replication)">状态机复制 (State Machine Replication)</a><br><a href="https://www.cnblogs.com/aibabel/p/10973585.html" target="_blank" rel="noopener" title="Raft算法详解">Raft算法详解</a></p>
<p><a href="https://blog.csdn.net/shangsongwww/article/details/90287565" target="_blank" rel="noopener" title="Raft算法原理">Raft算法原理</a><br><a href="https://www.cnblogs.com/cbkj-xd/p/12152222.html" target="_blank" rel="noopener" title="Raft算法之日志复制">Raft算法之日志复制</a></p>
<p><a href="https://blog.csdn.net/snail_ren/article/details/80588370" target="_blank" rel="noopener" title="Raft协议详解（一）前言：子问题分解">Raft协议详解（一）前言：子问题分解</a></p>
<p><a href="https://www.jianshu.com/p/b28e73eefa88" target="_blank" rel="noopener" title="Raft 日志复制 Log replication">Raft 日志复制 Log replication</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/08/Redis%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%9E%8B-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/08/Redis%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%9E%8B-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/" itemprop="url">Redis事件模型/主从复制/哨兵模型/集群模式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-01-08T22:48:41+08:00">
                2020-01-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index">
                    <span itemprop="name">中间件</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/01/08/Redis%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%9E%8B-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/01/08/Redis事件模型-主从复制-哨兵模型-集群模式/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  15.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  57
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-Redis的事件模型"><a href="#1-Redis的事件模型" class="headerlink" title="1. Redis的事件模型"></a>1. Redis的事件模型</h1><p>Redis服务器需要处理两类事件：文件事件和时间事件。</p>
<h2 id="1-1-文件事件"><a href="#1-1-文件事件" class="headerlink" title="1.1 文件事件"></a>1.1 文件事件</h2><p>Redis服务器通过<strong>套接字</strong>与客户端进行连接，<strong>而文件事件就是服务器对套接字操作的抽象</strong>。</p>
<p>Redis基于Reactor模式开发了网络事件处理器，由四部分组成：<strong>套接字、I/O多路复用程序、文件事件分派器以及事件处理器</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4f1ecfb38834ecc1e56da223851c70253d1.png" alt=""></p>
<ul>
<li><p>套接字：当有一个套接字准备好执行连接应答、写入、读取、关闭等操作时，就会产生一个文件事件（多个套接字就会有多个文件事件产生；</p>
<ul>
<li>事件类型有AE_READABLE和AE_WRITABLE<ul>
<li>如果客户端对套接字执行write或close操作，或者客户端对服务端的监听套接字执行connect操作，那么产生一个AE_READABLE事件。</li>
<li>如果客户端对套接字执行read操作，那么产生一个AE_WRITABLE事件。</li>
<li>如果一个事件既可读又可写，则先处理AE_READABLE事件，再处理AE_WRITABLE事件。</li>
</ul>
</li>
</ul>
</li>
<li><p>I/O多路复用程序：负责监听多个套接字，并向文件事件分派器传送产生事件的套接字。</p>
<ul>
<li>I/O多路复用程序会将产生的所有事件的套接字放在一个队列中，以有序（sequentially）、同步（synchronously）、每次一个的方式向文件事件分派器传送套接字，只有一个套接字的事件处理完成后才会再发下一个：<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-63c1d7f685fe82c9b6de8a1db0cf63425b1.png" alt=""></li>
</ul>
</li>
<li>I/O多路复用的功能是<strong>evport、epoll、kqueue和select这些常见的I/O多路复用函数</strong>的包装。Redis会在编译时自动选择系统中性能最高的I/O多路复用函数。<strong>默认实现是epoll</strong>。关于I/O多路复用可见本博客文章《详解IO多路复用和其三种模式——select/poll/epoll》<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-9e0589e377a8ff80d66c0ddef54da95b6d9.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li><p>文件事件分派器</p>
<ul>
<li>接收I/O多路复用程序传来的套接字，根据套接字产生的事件类型，调用相应事件处理器</li>
</ul>
</li>
<li><p>文件事件处理器</p>
<ul>
<li>连接应答处理器：acceptTCPhandler<ul>
<li>对连接服务器的各个客户端进行应答</li>
<li>Redis初始化时，将监听套接字的AE_READABLE事件与该处理器关联</li>
<li>客户端连接服务器时，监听套接字产生AE_READABLE事件，触发该处理器执行。</li>
<li>服务器将会创建一个redisClient结构的实例，并添加进自身的RedisServer结构的clients链表中。</li>
<li>处理器对客户端请求进行应答，并创建客户端套接字，将客户端套接字的AE_READABLE事件与命令请求处理器关联。</li>
</ul>
</li>
<li>命令请求处理器：readQueryFromClient<ul>
<li>接收客户端传来的命令请求</li>
<li>客户端成功连接服务器后，连接应答处理器将该客户端套接字的AE_READABLE事件与命令请求处理器关联</li>
<li>客户端向服务器发送命令请求时，客户端套接字产生AE_READABLE事件</li>
<li>命令请求处理器读取命令内容，传给相关程序执行。</li>
</ul>
</li>
<li>命令回复处理器：sendReplyToClient<ul>
<li>向客户端返回命令执行结果</li>
<li>服务器有命令执行结果要传送给客户端时，将客户端套接字的AE_WRITABLE事件始终与该处理器关联</li>
<li>客户端准备好接收命令执行结果时，客户端套接字产生AE_WRITABLE事件，触发命令回复处理器执行。</li>
<li>将全部回复写入套接字后，关联解除</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-e1c7b32c5ca809d372507522a169da2effa.png" alt=""></p>
<h2 id="1-2-时间事件"><a href="#1-2-时间事件" class="headerlink" title="1.2 时间事件"></a>1.2 时间事件</h2><p>一个时间事件包括三要素：</p>
<ul>
<li>id<ul>
<li>时间时间的全局唯一表示，新事件id大于旧事件。</li>
</ul>
</li>
<li>when<ul>
<li>毫秒精度的unix时间戳，记录了时间事件的到达时间。</li>
</ul>
</li>
<li>timeproc（时间事件处理器）<ul>
<li>时间事件处理器，一个函数，时间事件到达时，服务器调用对应处理器来执行。</li>
</ul>
</li>
</ul>
<p>时间事件分为两类：</p>
<ul>
<li><p>定时事件：让一段程序在指定时间后执行一次。</p>
<ul>
<li>定时事件的处理器返回值是固定的数值，存在ae.h/AE_NOMORE中，如果一个事件的返回为该值，那么该事件在到达一次后，就会被删除</li>
</ul>
</li>
<li><p>周期事件：让一段程序每隔一段指定时间就执行一次。</p>
<ul>
<li>周期事件的处理器返回值是非ae.h/AE_NOMORE的值，这时，返回值会覆写when值。让这个时间过一段时间再次到达，以此类推。</li>
</ul>
</li>
</ul>
<p>服务器将时间事件都放在一个无序链表中（不是按时间顺序排序，而是按照ID排序，新产生的时间事件放在链表的表头），每次时间事件执行器运行时，processTimeEvents函数遍历整个链表，查找所有已经到达的时间事件，并调用相应的事件处理器。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a1b2a265b2286571ce9313c80598511599a.png" alt=""></p>
<h3 id="1-2-1-serverCron函数"><a href="#1-2-1-serverCron函数" class="headerlink" title="1.2.1 serverCron函数"></a>1.2.1 serverCron函数</h3><p>时间时间最典型的实例就是serverCron函数，它平均100毫秒执行一次，负责Redis定期对自身资源和状态的调整，包括：</p>
<ul>
<li>更新服务器的统计信息：时间，内存，数据库占用情况</li>
<li>清理过期键值对</li>
<li>关闭失效的连接</li>
<li>尝试进行aof\rdb持久化操作</li>
<li>对从服务器进行定期同步</li>
<li>集群模式下的定期同步，连接测试</li>
</ul>
<h2 id="1-3-事件调度与执行"><a href="#1-3-事件调度与执行" class="headerlink" title="1.3 事件调度与执行"></a>1.3 事件调度与执行</h2><p>aeProcessEvents函数负责何时处理文件事件、何时处理时间事件，以及花费多久的时间<br><img src="https://oscimg.oschina.net/oscnet/up-afd39c7736ceb3cb769fdfd7d588e8943d6.png" alt=""></p>
<p>将aeProcessEvents函数放置在循环中，加上初始化、清理函数，就构成了redis服务器的主函数</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-39f2148ba5785661a77fbdecd5375a765a6.png" alt=""></p>
<blockquote>
<p>文件事件和时间事件是合作关系，服务器会轮流处理这两种事件，并且处理过程中也不会抢占线程。因此时间事件的实际处理时间要比设定的时间晚一些。</p>
</blockquote>
<h1 id="2-Redis主从复制"><a href="#2-Redis主从复制" class="headerlink" title="2. Redis主从复制"></a>2. Redis主从复制</h1><p>关系数据库通常会使用一个主服务器向多个从服务器发送更新，并使用从服务器来处理所有的读请求，Redis采用了同样方法来实现自己的复制特性。</p>
<h2 id="2-1-旧版复制功能"><a href="#2-1-旧版复制功能" class="headerlink" title="2.1 旧版复制功能"></a>2.1 旧版复制功能</h2><p><strong>Redis 2.8以前采用的复制都为旧版复制，主要使用SYNC命令同步复制</strong>，SYNC存在很大的缺陷严重消耗主服务器的资源以及大量的网络连接资源。Redis 2.8之后采用PSYNC命令替代SYNC，解决完善这些缺陷，但在介绍新版复制功能之前，必须先介绍旧版复制过程，这样才能更好地形成对比。</p>
<p>复制功能有两种模式，分为<strong>同步sync</strong>与<strong>命令传播（command propagate）</strong>，两个过程配合执行才能实现Redis复制。</p>
<ul>
<li>SYNC命令同步操作<ul>
<li>通过从服务器发送到SYNC命令给 <em>主服务器</em></li>
<li><em>主服务器</em> 执行BGSAVE命令，在后台生成RDB文件，并从现在开始将所有写命令记录进缓冲区</li>
<li>并发送给 <em>从服务器</em>，同时发送缓冲区保存的所有写命令给 <em>从服务器</em>。</li>
<li><em>从服务器</em> 清空之前数据并执行解释RDB文件，然后执行缓冲区的写命令。</li>
<li>保持数据基本一致（还需要命令传播过程才能保持一致）</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-cfd59b02030b3f463de3d8e6ee7d4fa1e63.png" alt=""></li>
</ul>
</li>
<li>命令传播操作：<ul>
<li>在同步之后，<em>主服务器</em> 仍然在不断的接受写命令，这会导致好不容易一致的主从状态再次不一致。</li>
<li>通过发送让主从服务器不一致的命令（主服务器接收到的新写命令）给从服务器并执行，让主从服务器的数据库重新回到一致状态。</li>
</ul>
</li>
</ul>
<blockquote>
<p>SYNC命令的缺陷：如果因为网络问题，导致主从断开链接一段时间，那么重新同步的时候， SYNC无法做到断点继续，而是仍要清空之前数据，并重新开始复制操作。</p>
</blockquote>
<p>SYNC命令非常消耗资源，原因有三点：</p>
<ol>
<li><p>主服务器执行BGSAVE命令生成RDB文件，这个生成过程会大量消耗主服务器资源（CPU、内存和磁盘I/O资源）</p>
</li>
<li><p>主服务器需要将自己生成的RBD文件发送给从从服务器，这个发送操作会消耗主从服务器大量的网络资源（带宽与流量）</p>
</li>
<li><p>接收到RDB文件你的从服务器需要载入RDB文件，载入期间从服务器会因为阻塞而导致没办法处理命令请求。</p>
</li>
</ol>
<h2 id="2-2-新版复制功能"><a href="#2-2-新版复制功能" class="headerlink" title="2.2 新版复制功能"></a>2.2 新版复制功能</h2><p>为了解决旧版本中断线情况下SYNC低效问题，在Redis 2.8之后使用PSYNC命令代替SYNC命令执行复制同步操作，自然PSYNC具备完整重同步和部分重同步模式</p>
<ul>
<li>完整重同步：跟旧版复制基本是一致的，可以理解为“全量”复制。</li>
<li>部分重同步：在命令传播阶段，<strong>断线重复制</strong>只需要发送主服务器<strong>在断开期间执行的写命令</strong>给从服务器即可，可以理解为“增量”复制。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-6b85f71f0d739997ec61cae37975871ef3b.png" alt=""></li>
</ul>
</li>
</ul>
<h2 id="2-3-复制的实现"><a href="#2-3-复制的实现" class="headerlink" title="2.3 复制的实现"></a>2.3 复制的实现</h2><p>Redis不管是旧版还是新版，复制的实现都可以分为七个步骤，流程图如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9844df2ae892d6aa2f0eb9bbfe8e2dc0a94.png" alt=""></p>
<ol>
<li>设置主服务的地址与端口<ul>
<li>当客户端向从服务器发送一下命令时或者在配置文件中配置slaveof选项</li>
<li><code>127.0.0.1:12345&gt; SLAVEOF 127.0.0.1 6379</code></li>
</ul>
</li>
<li>建立套接字连接<ul>
<li>从服务器根据设置的套接字创建连向主服务器的套接字连接<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-cea89403237d39529cf8fe68b1aac463c01.png" alt=""></li>
</ul>
</li>
<li>主服务器接收从服务器的套接字连接之后，为该套接字创建响应的客户端状态，并将此时的从服务器看做是主服务器的客户端，也就是该从服务器同时具备服务器与客户端两个身份。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-6c6228d79603ed7e8091349805b818b0477.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>发送PING命令<ul>
<li>从服务器成为主服务器的客户端之后，做的第一件事就是向主服务器发送PING命令。PING命令主要有两种作用：<ol>
<li>虽然建立了套接字连接，但是还未使用过，通过发送PING命令检查套接字的读写状态是否正常</li>
<li>通过发送PING命令检查主服务器能否正常处理命令请求</li>
</ol>
</li>
<li>从服务器在发送PING命令之后将遇到以下三种情况的其中一种：<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-d8186e4f60ecb5a5f4a3d94a6953b0c0f69.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>身份验证<ul>
<li>从服务器接收到主服务器返回的“PONG”回复，接下来就需要考虑身份验证的事。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-693b46071c249bb5a9ec8795a47317135ac.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>发送端口信息<ul>
<li>在身份验证步骤之后，从服务器将执行命令<code>REPLCONF listening-port &lt;port&gt;</code>，向主服务器发送从服务器的监听端口号。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-cca80560a551e9d92bb2561bc4beac8b8f7.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>同步<ul>
<li>就是上述所指的同步操作，从服务器向主服务器发送PSYNC命令，执行同步操作，值得注意的是开始只有从服务器是主服务器的客户端，但是执行同步操作之后，主服务器也会成为从服务器的客户端。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-7297be982c2757e9849b1d018d7e14a69a4.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>命令传播<ul>
<li>主从服务器就会进入命令传播阶段，主服务器只要将自己执行的写命令发送给从服务器，而从服务器只要一直执行并接收主服务器发来的写命令（上述已经介绍过，这里不过多介绍）</li>
</ul>
</li>
</ol>
<h1 id="3-Redis哨兵模型"><a href="#3-Redis哨兵模型" class="headerlink" title="3. Redis哨兵模型"></a>3. Redis哨兵模型</h1><p><strong>Sentinel(哨兵、哨岗)是Redis 的高可用性的解决方案</strong>：有一个或多个Sentinel实例组成的Sentinel系统可以<strong>监视任意多个主服务器，以及这些主服务器属下的所有从服务器</strong>，并在被监视的主服务器进入下线状态时，<strong>自动将下线主服务器属下的某个从服务器升级为主服务器</strong>，然后由新的主服务器代替已下线的主服务器继续处理命令请求。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-74b74416d8986d2bc2260d9848302bd26c5.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2e8b33cdecf632546ed70b2a91e16901f44.png" alt=""></p>
<blockquote>
<p>在替换了新的主服务器之后，如果之前下线的主服务器上线了，就会被降为新的主服务器的从服务器。</p>
</blockquote>
<h2 id="3-1-Sentinel的启动"><a href="#3-1-Sentinel的启动" class="headerlink" title="3.1 Sentinel的启动"></a>3.1 Sentinel的启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ redis-sentinel &#x2F;path&#x2F;to&#x2F;your&#x2F;sentinel.conf</span><br><span class="line">或者</span><br><span class="line">$ redis-sentinel &#x2F;path&#x2F;to&#x2F;your&#x2F;sentinel.conf --sentinel</span><br></pre></td></tr></table></figure>

<p>这两个命令都能启动Sentinel，效果都是一样的。</p>
<p>Sentinel启动后，会有五个步骤：</p>
<ol>
<li><p><strong>初始化服务器</strong></p>
<ul>
<li><strong>Sentinel的本质是一个运行在特殊模式下的Redis服务器</strong>，因此启动时必须对其进行初始化，但是由于Sentinel与普通的服务器不同，<strong>它的初始化需要执行的操作也不同</strong>。</li>
<li>下表是Sentinel 模式下Redis服务器的主要功能的使用情况</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-d17c827a40ef959aa665c9f24c9b1bbe054.png" alt=""></li>
</ul>
</li>
<li><p><strong>使用Sentinel专用代码</strong></p>
<ul>
<li>启动Sentinel的第二步，就是将普通Redis服务器使用的代码替换成Sentinel专用的代码。</li>
<li>比如 普通Redis服务器使用 redis.h/REDIS_SERVERPORT常量作为服务端口(#define REDIS_SERVERPORT 6379),使用 redis.h/redisCommandTable 作为服务器的命令表。</li>
<li>而Sentinel使用 reids.h/REDIS_SENTINEL_PORT 常量作为服务器端口，默认26379，使用 redis.h/sentinelcmds 作为服务器的命令表</li>
</ul>
</li>
<li><p><strong>初始化Sentinel状态</strong></p>
<ul>
<li>接下来，服务器会初始化一个 sentinel.c/sentinelState 结构(简称“Sentinel状态”)，这个结构保存了服务器所有和Sentinel功能有关的状态，服务器的一般状态仍然由 redis.h/redisServer 结构保存：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">typedef struct sentinelState&#123;</span><br><span class="line">	&#x2F;&#x2F; 当前纪元，用于实现故障转移</span><br><span class="line">	uint64_t current_epoch;</span><br><span class="line">	&#x2F;&#x2F; 保存了所有被这个 Sentinel监视的主服务器</span><br><span class="line">	&#x2F;&#x2F; 字典的键是主服务器的名字</span><br><span class="line">	&#x2F;&#x2F; 字典的值是一个指向 sentinelRedisInstance 结构的指针</span><br><span class="line">	dict *masters;</span><br><span class="line">	&#x2F;&#x2F; 是否进入了 TILT 模式</span><br><span class="line">	int tilt;</span><br><span class="line">	&#x2F;&#x2F; 目前正在执行的脚本数量</span><br><span class="line">	int running_scripts;</span><br><span class="line">	&#x2F;&#x2F; 进入 TILT 模式的时间</span><br><span class="line">	mstime_t tilt_start_time;</span><br><span class="line">	&#x2F;&#x2F; 最后一次执行事件处理器的时间</span><br><span class="line">	mstime_t previous_time;</span><br><span class="line">	&#x2F;&#x2F; 一个 FIFO 队列，包含了所有需要执行的用户脚本</span><br><span class="line">	list *scripts_queue;</span><br><span class="line">&#125;sentinel;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p><strong>初始化Sentinel状态的 masters 属性</strong></p>
<ul>
<li><p>接下来要做的是将sentinel状态的 masters 属性进行初始化，上面已经说过了，masters 里面保存的是所有被监视的主服务器的信息。master属性是字典，键是主服务器的名字，值是一个指向 sentinelRedisInstance 结构的指针。</p>
</li>
<li><p>我们先介绍一下 sentinelRedisInstance 结构(简称“实例结构”)，这个结构代表着一个被Sentinel监视的Redis服务器实例，可以是主服务器、从服务器或者另外一个Sentinel.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line">ypedef struct sentinelRedisInstance &#123;</span><br><span class="line">	&#x2F;&#x2F; 标识值，记录了当前Redis实例的类型和状态</span><br><span class="line">	int flags;      &#x2F;* See SRI_... defines *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 实例的名字</span><br><span class="line">	&#x2F;&#x2F; 主节点的名字由用户在配置文件中设置</span><br><span class="line">	&#x2F;&#x2F; 从节点以及Sentinel节点的名字由Sentinel自动设置，格式为：ip:port</span><br><span class="line">	char *name;     &#x2F;* Master name from the point of view of this sentinel. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F;实例的运行 ID</span><br><span class="line">	char *runid;    &#x2F;* Run ID of this instance, or unique ID if is a Sentinel.*&#x2F;</span><br><span class="line">	&#x2F;&#x2F;配置纪元，用于实现故障转移</span><br><span class="line">	uint64_t config_epoch;  &#x2F;* Configuration epoch. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F;实例的地址:ip和port</span><br><span class="line">	sentinelAddr *addr; &#x2F;* Master host. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F;实例的连接，有可能是被Sentinel共享的</span><br><span class="line">	instanceLink *link; &#x2F;* Link to the instance, may be shared for Sentinels. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 最近一次通过 Pub&#x2F;Sub 发送信息的时间</span><br><span class="line">	mstime_t last_pub_time;   &#x2F;* Last time we sent hello via Pub&#x2F;Sub. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 只有被Sentinel实例使用</span><br><span class="line">	&#x2F;&#x2F; 最近一次接收到从Sentinel发送来hello的时间</span><br><span class="line">	mstime_t last_hello_time; &#x2F;* Only used if SRI_SENTINEL is set. Last time</span><br><span class="line">								 we received a hello from this Sentinel</span><br><span class="line">								 via Pub&#x2F;Sub. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 最近一次回复SENTINEL is-master-down的时间                             </span><br><span class="line">	mstime_t last_master_down_reply_time; &#x2F;* Time of last reply to</span><br><span class="line">											 SENTINEL is-master-down command. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 实例被判断为主观下线的时间                                         </span><br><span class="line">	mstime_t s_down_since_time; &#x2F;* Subjectively down since time. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 实例被判断为客观下线的时间</span><br><span class="line">	mstime_t o_down_since_time; &#x2F;* Objectively down since time. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 实例无响应多少毫秒之后才会被判断为主观下线（subjectively down）</span><br><span class="line">	mstime_t down_after_period; &#x2F;* Consider it down after that period. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 从实例获取INFO命令回复的时间</span><br><span class="line">	mstime_t info_refresh;  &#x2F;* Time at which we received INFO output from it. *&#x2F;</span><br><span class="line"></span><br><span class="line">	&#x2F;* Role and the first time we observed it.</span><br><span class="line">	 * This is useful in order to delay replacing what the instance reports</span><br><span class="line">	 * with our own configuration. We need to always wait some time in order</span><br><span class="line">	 * to give a chance to the leader to report the new configuration before</span><br><span class="line">	 * we do silly things. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 实例的角色 </span><br><span class="line">	int role_reported;</span><br><span class="line">	&#x2F;&#x2F; 角色更新的时间</span><br><span class="line">	mstime_t role_reported_time;</span><br><span class="line">	&#x2F;&#x2F; 最近一次从节点的主节点地址变更的时间</span><br><span class="line">	mstime_t slave_conf_change_time; &#x2F;* Last time slave master addr changed. *&#x2F;</span><br><span class="line"></span><br><span class="line">	&#x2F;* Master specific. *&#x2F;</span><br><span class="line">	 &#x2F;*----------------------------------主节点特有的属性----------------------------------*&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 其他监控相同主节点的Sentinel</span><br><span class="line">	dict *sentinels;    &#x2F;* Other sentinels monitoring the same master. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 如果当前实例是主节点，那么slaves保存着该主节点的所有从节点实例</span><br><span class="line">	&#x2F;&#x2F; 键是从节点命令，值是从节点服务器对应的sentinelRedisInstance</span><br><span class="line">	dict *slaves;       &#x2F;* Slaves for this master instance. *&#x2F;</span><br><span class="line">	  &#x2F;&#x2F; 判定该主节点客观下线（objectively down）的投票数</span><br><span class="line">	&#x2F;&#x2F; 由SENTINEL monitor &lt;master-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;配置</span><br><span class="line">	unsigned int quorum;&#x2F;* Number of sentinels that need to agree on failure. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; SENTINEL parallel-syncs &lt;master-name&gt; &lt;number&gt; 选项的值</span><br><span class="line">	&#x2F;&#x2F; 在执行故障转移操作时，可以同时对新的主服务器进行同步的从服务器数量</span><br><span class="line">	int parallel_syncs; &#x2F;* How many slaves to reconfigure at same time. *&#x2F;</span><br><span class="line">	  &#x2F;&#x2F; 连接主节点和从节点的认证密码</span><br><span class="line">	char *auth_pass;    &#x2F;* Password to use for AUTH against master &amp; slaves. *&#x2F;</span><br><span class="line"></span><br><span class="line">	&#x2F;* Slave specific. *&#x2F;</span><br><span class="line">	&#x2F;*----------------------------------从节点特有的属性----------------------------------*&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 从节点复制操作断开时间</span><br><span class="line">	mstime_t master_link_down_time; &#x2F;* Slave replication link down time. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 按照INFO命令输出的从节点优先级</span><br><span class="line">	int slave_priority; &#x2F;* Slave priority according to its INFO output. *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 故障转移时，从节点发送SLAVEOF &lt;new&gt;命令的时间</span><br><span class="line">	mstime_t slave_reconf_sent_time; &#x2F;* Time at which we sent SLAVE OF &lt;new&gt; *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; 如果当前实例是从节点，那么保存该从节点连接的主节点实例</span><br><span class="line">	struct sentinelRedisInstance *master; &#x2F;* Master instance if it&#39;s slave. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; INFO命令的回复中记录的主节点的IP</span><br><span class="line">	char *slave_master_host;    &#x2F;* Master host as reported by INFO *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; INFO命令的回复中记录的主节点的port</span><br><span class="line">	int slave_master_port;      &#x2F;* Master port as reported by INFO *&#x2F;</span><br><span class="line">	 &#x2F;&#x2F; INFO命令的回复中记录的主从服务器连接的状态</span><br><span class="line">	int slave_master_link_status; &#x2F;* Master link status as reported by INFO *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 从节点复制偏移量</span><br><span class="line">	unsigned long long slave_repl_offset; &#x2F;* Slave replication offset. *&#x2F;</span><br><span class="line"></span><br><span class="line">	&#x2F;* Failover *&#x2F;</span><br><span class="line">	 &#x2F;*----------------------------------故障转移的属性----------------------------------*&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 如果这是一个主节点实例，那么leader保存的是执行故障转移的Sentinel的runid</span><br><span class="line">	&#x2F;&#x2F; 如果这是一个Sentinel实例，那么leader保存的是当前这个Sentinel实例选举出来的领头的runid</span><br><span class="line">	char *leader;       &#x2F;* If this is a master instance, this is the runid of</span><br><span class="line">						   the Sentinel that should perform the failover. If</span><br><span class="line">						   this is a Sentinel, this is the runid of the Sentinel</span><br><span class="line">						   that this Sentinel voted as leader. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; leader字段的纪元                       </span><br><span class="line">	uint64_t leader_epoch; &#x2F;* Epoch of the &#39;leader&#39; field. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 当前执行故障转移的纪元</span><br><span class="line">	uint64_t failover_epoch; &#x2F;* Epoch of the currently started failover. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 故障转移操作的状态</span><br><span class="line">	int failover_state; &#x2F;* See SENTINEL_FAILOVER_STATE_* defines. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 故障转移操作状态改变的时间</span><br><span class="line">	mstime_t failover_state_change_time;</span><br><span class="line">	&#x2F;&#x2F; 最近一次故障转移尝试开始的时间</span><br><span class="line">	mstime_t failover_start_time;   &#x2F;* Last failover attempt start time. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F;  更新故障转移状态的最大超时时间</span><br><span class="line">	mstime_t failover_timeout;      &#x2F;* Max time to refresh failover state. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 记录故障转移延迟的时间</span><br><span class="line">	mstime_t failover_delay_logged; &#x2F;* For what failover_start_time value we</span><br><span class="line">									   logged the failover delay. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 晋升为新主节点的从节点实例                                   </span><br><span class="line">	struct sentinelRedisInstance *promoted_slave; &#x2F;* Promoted slave instance. *&#x2F;</span><br><span class="line">	&#x2F;* Scripts executed to notify admin or reconfigure clients: when they</span><br><span class="line">	 * are set to NULL no script is executed. *&#x2F;</span><br><span class="line">	&#x2F;&#x2F; 通知admin的可执行脚本的地址，如果设置为空，则没有执行的脚本 </span><br><span class="line">	char *notification_script;</span><br><span class="line">	 &#x2F;&#x2F; 通知配置的client的可执行脚本的地址，如果设置为空，则没有执行的脚本</span><br><span class="line">	char *client_reconfig_script;</span><br><span class="line">	&#x2F;&#x2F; 缓存INFO命令的输出 </span><br><span class="line">	sds info; &#x2F;* cached INFO output *&#x2F;</span><br><span class="line">&#125; sentinelRedisInstance;</span><br></pre></td></tr></table></figure></li>
<li><p>其中的 addr 属性是一个指向 sentinel.c/sentinelAddr 结构的指针，这个结构保存实例的IP地址和端口号:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">typedef struct sentinelAddr&#123;</span><br><span class="line">	char *p;</span><br><span class="line">	int port;</span><br><span class="line">&#125;sentinelAddr;</span><br></pre></td></tr></table></figure></li>
<li><p>对Sentinel 状态的初始化将引发对 masters 字典的初始化,而 masters 字典的初始化是根据被载入的Sentinel配置文件来进行的。<strong>假设我们有master1和master2，由如下图1的配置文件导入</strong>：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-63050f2a3d66283638dc1c17d2f1ec19778.png" alt=""></li>
</ul>
</li>
<li><p>那么我们得到两个sentinelRedisInstance：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-f7d42df36db19bd7fa4c53b9e289381dc62.png" alt=""></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-238ac368f60e323211e08ebaeb8e7308450.png" alt=""></li>
</ul>
</li>
<li><p>最终sentinelRedisInstance为：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-235ef5d9525c74626220b099acbff598f27.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li><p>创建连向主服务器的网络连接</p>
<ul>
<li>这是最后一步啦，这一步是创建连向被监视主服务器的网络连接，<strong>Sentinel将成为主服务器的客户端</strong>，可以向主服务器发送命令，并从命令回复中获取相关的信息。</li>
<li>每个被Sentinel监视的主服务器，Sentinel会创建两个连向主服务器的异步网络连接：<ol>
<li>命令连接，用于向主服务器发送命令，并接收命令回复</li>
<li>订阅连接，用于订阅主服务器的<code>__sentinel__:hello</code>频道</li>
</ol>
</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-4dd23054ec9ad51b2c753001abd3bbe46a5.png" alt=""><h2 id="3-2-Sentinel与服务器的交互"><a href="#3-2-Sentinel与服务器的交互" class="headerlink" title="3.2 Sentinel与服务器的交互"></a>3.2 Sentinel与服务器的交互</h2></li>
</ul>
</li>
</ol>
<p>Sentinel作为一个监视Redis服务器的监控系统，必然需要有如下的权利或者义务：</p>
<ol>
<li><p>要能掌握被自己监视的主服务器和其从服务器的状态信息</p>
<ul>
<li><strong>INFO命令</strong>：每十秒一次，通过<strong>命令链接</strong>向被监视的主服务和从服务器发送<strong>INFO命令</strong>。分析主服务器的应答得到主服务器的状态信息。</li>
</ul>
</li>
<li><p>要有为“与自己监视了相同服务器的其他Sentinel”感知到自己提供便利的义务。</p>
<ul>
<li><strong>广播频道消息</strong>：Sentinel每两秒一次，通过<strong>命令链接</strong>向所有被自己监视的主服务器和从服务器发送<strong>PUBLISH命令</strong>，发布自己的一些状态信息到对应主服务器的<strong>sentinel</strong>:hello频道，以便让其他监视了同一服务器的Sentinel（当然这些Sentinel也订阅了该服务器的<strong>sentinel</strong>:hello频道）感知到自己的存在，宣誓主权。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-5cc7e6782bf95df108607d7a9179b94f625.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li><p>要能感知到“与自己监视了同一服务器的其他Sentinel”的状态信息。</p>
<ul>
<li><strong>接收频道消息</strong>：Sentinel在与主服务器创建订阅链接后就会通过订阅命令来订阅主服务器的<strong>sentinel</strong>:hello频道。通过<strong>订阅链接</strong>，Sentinel能接收到该频道上其他Sentinel发布的他们各自的状态信息。从而感知到他们的存在。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-5b9e81f3a2d2692d744f2dd17340e377a4a.png" alt=""></li>
</ul>
</li>
<li><strong>创建Sentinel之间的链接</strong>：Sentinel A 感知到另一个Sentinel B 时，如果是第一次感知到，那么A会创建连向B的命令链接。当然B也会有一个发现A的过程，所以对于监视相同服务器的Sentinel来说，他们是这样相互关联的。<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-e15a80cc3eaec80234386903b967ca94f1d.png" alt=""></li>
</ul>
</li>
</ul>
</li>
</ol>
<p>归纳完毕，现在我们来一一展开介绍：</p>
<h3 id="3-2-1-INFO命令"><a href="#3-2-1-INFO命令" class="headerlink" title="3.2.1 INFO命令"></a>3.2.1 INFO命令</h3><p>假设有个主服务器和三个从服务器。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cc3509fe121399c911c2c76c9141eae43f0.png" alt=""></p>
<p>Sentinel 默认每十秒一次，通过命令连接向被监视的主服务器发送 INFO 命令，得到如下信息：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-bc6314d42194e83e8c3024d39401f1ba78e.png" alt=""></p>
<ul>
<li>关于服务器本身的信息<ul>
<li>包括 run_id 域记录的服务器运行ID，以及 role 域记录的服务器角色</li>
</ul>
</li>
<li>关于主服务器属下的所有从服务器信息<ul>
<li>每个从服务器都由一个“slave”字符串开头的行记录，每行的 ip= 域记录了从服务器的IP地址, port= 域记录了从服务器的端口号。根据这些IP地址和端口号，Sentinel无须用户提供从服务器的地址信息，就可以自动发现从服务器。</li>
</ul>
</li>
</ul>
<p>根据 run_id 域和 role 域的信息，Sentinel将对主服务器的实例结构（sentinelRedisInstance）进行更新。而主服务器返回的从服务器信息，将会被用于更新主服务器实例结构（sentinelRedisInstance）的 slaves 字典(记录了属下从服务器的名单，key为ip:port格式，值指向从服务器的sentinelRedisInstance实例)。</p>
<p>Sentinel 分析 INFO 命令中包含的从服务器信息时，会检查这个从服务器实例结构(sentinelRedisInstance）是否已经存在于主服务器的 slaves 字典： 如果存在，就对从服务器的实例结构进行更新，如果不存在(表明这个从服务器是新发现的从服务器)，Sentinel会在 slaves 字典中为这个从服务器创建一个新的实例结构。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-39a3a3f5b3381711f3063c1719f4ab03f89.png" alt=""></p>
<p>当Sentinel发现主服务器有新的服务器出现时，除了会为这个新从服务器创建相应的实例结构之外，<strong>还会创建连接到从服务器的命令连接和订阅连接</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0301ec71756c260aaae4f67a696c939939c.png" alt=""></p>
<p>创建了命令连接之后，每10秒一次向从服务器发送 INFO 命令，依次来维护从服务器的实例结构(sentinelRedisInstance）的状态。</p>
<blockquote>
<p>主服务器实例结构的 flags 值为 SRI_MASTER,从服务器是 SRI_SLAVE</p>
</blockquote>
<h3 id="3-2-2-广播频道消息"><a href="#3-2-2-广播频道消息" class="headerlink" title="3.2.2 广播频道消息"></a>3.2.2 广播频道消息</h3><p>Sentinel会<strong>每两秒一次</strong>，通过<strong>命令连接</strong>向所有被监视的主服务器和从服务器发送以下格式的命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PUBLISH __sentinel__:hello &quot;&lt;s_ip&gt;,&lt;s_port&gt;,&lt;s_runid&gt;,&lt;s_epoch&gt;,</span><br><span class="line">	&lt;m_name&gt;,&lt;m_ip&gt;,&lt;m_port&gt;,&lt;m_epoch&gt;&quot;</span><br></pre></td></tr></table></figure>

<p>这条命令就表示向服务器的 __sentinel__:hello 频道发送一条信息，信息由一下部分组成：</p>
<ul>
<li>以 s_ 开头的参数记录Sentinel本身的信息</li>
<li>以 m_ 开头的参数则是该频道所属的主服务器的信息，当然如果监视的是从服务器，这个信息表示的就是所属的从服务器的信息</li>
<li>具体含义如下图</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-0554962e101651acacc73f8c04897f3d7ef.png" alt=""></li>
</ul>
<h3 id="3-2-3-接收频道消息"><a href="#3-2-3-接收频道消息" class="headerlink" title="3.2.3 接收频道消息"></a>3.2.3 接收频道消息</h3><p>在建立起订阅连接之后，Sentinel会通过这个连接，向服务器发送<code>SUBSCRIBE __sentinel__:hello</code>命令，也就是订阅这个频道，这个订阅关系会一直持续到Sentinel与服务器的连接断开之后。</p>
<p>对于监视同一服务器的多个Sentinel来说，一个Sentinel发送的信息会被其他的Sentinel接收到，并用于更新其他Sentinel对发送信息Sentinel的认知，和被用于更新其他Sentinel对被监视服务器的认知。</p>
<p>假如该<strong>Sentinel A</strong>从其监控的<strong>主服务器M</strong>的 <code>__sentinel__:hello</code>频道中，接收到其他<strong>Sentinel B</strong>发来的<code>&lt;s_ip&gt;,&lt;s_port&gt;,&lt;s_runid&gt;,&lt;s_epoch&gt;,&lt;m_name&gt;,&lt;m_ip&gt;,&lt;m_port&gt;,&lt;m_epoch&gt;</code>格式的信息后，Sentinel A会从信息中分析出以下信息：</p>
<ul>
<li>与Sentinel相关的参数：Sentinel B的IP、port、run_id、配置纪元</li>
<li>与主服务器相关参数：Sentinel B 正在监视的这个主服务器（也就是主服务器M）的名字、IP、port、配置纪元</li>
</ul>
<p>服务器实例结构（sentinelRedisInstance）中除了slave字典外，还有一个sentinels字典，存放着其他共同监控着这个主服务器的sentinels的状态信息。<strong>这个字典的键是Sentinel的名字，格式：ip:port。值是对应Sentinel的实例结构(还是sentinelRedisInstance结构)。</strong></p>
<p>根据之前那些主服务器参数，Sentinel A 会在自己的Sentinel状态（sentinelState）的 masters 字典中查找相应的主服务器实例结构（sentinelRedisInstance），然后根据Sentinel参数，检查主服务器实例结构的 sentinels 字典中，Sentinel B的实例结构是否存在：</p>
<ul>
<li>存在，就对Sentinel B的实例结构进行更新</li>
<li>存在，说明Sentinel B是才开始监视主服务器的新Sentinel，Sentinel A 会为Sentinel B创建一个新的实例结构，并将这个结构添加到 sentinels 字典里面</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-084760de95dd05ca210595633b1328d141f.png" alt=""></p>
<h3 id="3-2-4-创建Sentinel之间的链接"><a href="#3-2-4-创建Sentinel之间的链接" class="headerlink" title="3.2.4 创建Sentinel之间的链接"></a>3.2.4 创建Sentinel之间的链接</h3><p>当Sentinel通过频道信息发现了一个新的Sentinel时，它不仅会为新的Sentinel在 sentinels 字典中创建相应的实例结构，还会创建一个连向新Sentinel的命令连接。</p>
<p>新的Sentinel同样会创建连向这个Sentinel的命令连接，最终监视同一主服务器的多个Sentinel将形成相互连接的网络：SentinelA有连向SentinelB的命令连接，SentinelB也有连向SentinelA的命令连接。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e15a80cc3eaec80234386903b967ca94f1d.png" alt=""></p>
<blockquote>
<p>Sentinel之间不会创建订阅连接</p>
</blockquote>
<h2 id="3-3-监控下线和故障转移"><a href="#3-3-监控下线和故障转移" class="headerlink" title="3.3 监控下线和故障转移"></a>3.3 监控下线和故障转移</h2><p>了解了Sentinel与服务器/其他Sentinel的交互方式后，就可以来着手解决实际问题了，Sentinel的使命主要有两点：</p>
<ul>
<li>监控下线</li>
<li>选举领头sentinel</li>
<li>故障转移</li>
</ul>
<h3 id="3-3-1-监控下线"><a href="#3-3-1-监控下线" class="headerlink" title="3.3.1 监控下线"></a>3.3.1 监控下线</h3><h4 id="3-3-1-1-检测主观下线状态"><a href="#3-3-1-1-检测主观下线状态" class="headerlink" title="3.3.1.1 检测主观下线状态"></a>3.3.1.1 检测主观下线状态</h4><p>主观下线状态，即单个sentinel认为某个<strong>主服务器/从服务器/sentinel</strong>下线了，至于是不是真的已经下线，则不一定。</p>
<ul>
<li>默认情况下，Sentinel会以<strong>每秒一次</strong>的频率向所有与它创建了<strong>命令连接</strong>的实例(包括主服务器、从服务器、其他Sentinel在内)发送 <code>PING</code> 命令，并通过实例返回的 <code>PING</code> 命令回复来判断实例是否在线。</li>
<li>对 <code>PING</code> 命令的回复，Redis只认两种含义：<ul>
<li>有效回复：实例返回 +PONG 、 -LOADING 、-MASTERDOWN 三种其中一种</li>
<li>无效回复，除了上面三种之外的其它回复，或者在指定时限内没有返回任何回复</li>
</ul>
</li>
<li>Sentinel配置文件中的 down-after-millseconds 选项指定了Sentinel判断实例进入主观下线所需的时间长度：如果一个实例在 down-after-millseconds 毫秒内，连续向Sentinel返回无效回复，那么Sentinel会修改这个实例所对应的实例结构，在结构的 flags 属性中打上 <code>SRI_S_DOWN</code> 标识，用于表示这个实例已经进入主观下线状态。（也就是我认为你已经下线了）</li>
</ul>
<blockquote>
<p>主观下线时长选项，即 down-after-millseconds 的值，不仅会被Sentinel用于判断其监控的主服务器的主观下线状态，还会被用于判断该主服务器属下的所有从服务器，以及所有同样监视这个主服务器的其他Sentinel的主观下线状态。</p>
</blockquote>
<blockquote>
<p>多个Sentinel设置的主观下线时长可能不同，对于监视同一个主服务器的多个Sentinel来说，这些Sentinel设置的 down-after-milliseconds 选项的值可能不同，因此，当一个Sentinel将主服务器判断为主观下线时，其它Sentinel可能任然会认为主服务器处于在线状态。</p>
</blockquote>
<h4 id="3-3-1-2-检测客观下线状态"><a href="#3-3-1-2-检测客观下线状态" class="headerlink" title="3.3.1.2 检测客观下线状态"></a>3.3.1.2 检测客观下线状态</h4><p>客观下线状态，即经过确认后，可断定为事实上确实下线了。</p>
<p>当Sentinel将一个主服务器判断为主观下线之后，为确定这个服务器是否真的下线，它会<strong>向同样监视这个主服务器的其它Sentinel进行询问</strong>，当接收到足够数量的已下线判断之后，Sentinel就会将从服务器判定为客观下线，并对主服务器进行故障转移操作。</p>
<ul>
<li>发送 <code>SENTINEL is-master-down-by-addr</code> 命令<ul>
<li>entinel会发送下面的命令询问其它Sentinel是否同意主服务器下线：</li>
<li><code>SENTINEL is-master-down-by-addr &lt;ip&gt; &lt;port&gt; &lt;current_epoch&gt; &lt;runid&gt;</code></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-1bff3ef7742eb8463677f3e0c00fb30240d.png" alt=""></li>
</ul>
</li>
<li>接收 <code>SENTINEL is-master-down-by-addr</code> 命令<ul>
<li>当一个Sentinel(目标Sentinel)接收到另外一个Sentinel(源Sentinel)发来的 <code>SENTINEL is-master-by-addr</code>命令时，目标Sentinel会分析并取出命令请求中包含的各个参数，并根据其中的IP和port，判断主服务器是否已经下线，然后向源Sentinel返回一个包含三个参数的 Multi Bulk 回复作为这个命令的回复。这三个参数分别是：<ol>
<li><strong><down_state></strong>：返回目标Sentinel对主服务器的检查结果，1表示主服务器已下线，0表示主服务器未下线</li>
<li><strong><leader_runid></strong>：可以是 * 符号或者目标Sentinel的局部领头Sentinel的运行ID，*表示命令仅仅用于检测主服务器的下线状态，而局部领头Sentinel的运行ID则用于选举领头Sentinel</li>
<li><strong><leader_epoch></strong>：目标Sentinel的局部领头Sentinel的配置纪元，用于选举领头Sentinel。仅在 leader_runid 值不为 * 时有效，如果其值为 * ,这个参数总为0</li>
</ol>
</li>
</ul>
</li>
<li>接收 <code>SENTINEL is-master-down-by-addr</code> 命令之后<ul>
<li>根据其他Sentinel发回的 <code>SENTINEL is-master-down-by-addr</code>回复，Sentinel会统计反馈了“同意这个主服务器已经下线”这个信息的sentinel数量。</li>
<li>当这个值达到配置指定的判断客观下线所需的数量时(即 quorum 属性的值)，Sentinel会将主服务器实例结构中（sentinelRedisInstance） flags 属性的 SRI_O_DOWN 标识打开，标识主服务器已经进入客观下线状态。</li>
</ul>
</li>
</ul>
<h3 id="3-3-2-选举领头sentinel"><a href="#3-3-2-选举领头sentinel" class="headerlink" title="3.3.2 选举领头sentinel"></a>3.3.2 选举领头sentinel</h3><p>当一个Master服务器客观下线后，<strong>监控这个Master服务器的所有Sentinel</strong>将会选举出一个领头Sentinel。并由领头Sentinel对客观下线的Master进行故障转移。</p>
<p>选举领头Sentinel的规则和方法:</p>
<ol>
<li><p>所有监控客观下线Master的Sentinel都有可能成为领头Sentinel。每次进行领头Sentinel选举之后，不论是否选举成功，<strong>所有Sentinel的配置纪元（configuration epoch）的值都会自动增加一次</strong>。</p>
</li>
<li><p>在一个配置纪元里面，所有Sentinel都有一次将某个Sentinel设置为局部领头Sentinel的机会，并且局部领头Sentinel一旦设置，<strong>在这个配置纪元里面将不能再更改</strong>。</p>
</li>
<li><p>监视Master客观下线的所有在线Sentinel都有要求其它Sentinel将自己设置为局部领头Sentinel的机会。</p>
</li>
<li><p>当一个Sentinel（源Sentinel）向另一个Sentinel（目标Sentinel）发送<code>SENTINEL is-master-down-by-addr</code>命令，<strong>并且命令中的runid参数不是“*”符号而是当前Sentinel的运行ID时，这表示当前Sentinel要求目标Sentinel将自己设置为领头Sentinel</strong>。</p>
</li>
<li><p>Sentinel设置局部领头Sentinel的规则是<strong>先到先得</strong>。即最先向目标Sentinel发送设置要求的Sentinel将会成为局部领头Sentinel，之后<strong>接受到的请求都会被拒绝</strong>。</p>
</li>
<li><p>目标Sentinel接收到SENTINEL is-master-down-by-addr命令后，将向源Sentinel返回一条命令回复，<strong>回复中的leader_runid参数和leader_epoch参数分别记录了目标Sentinel的局部领头Sentinel的运行ID和配置纪元</strong>。</p>
</li>
<li><p>源Sentinel在接收到目标Sentinel返回的命令回复之后，会检查回复中leader_epoch参数的值和自己的配置纪元是否相同，如果相同的话，那么源Sentinel继续取出回复中的leader_runid参数，如果leader_runid参数的值和源Sentinel的运行ID一直，<strong>那么表示目标Sentinel将源Sentinel设置成了局部领头Sentinel，记录下来</strong>。</p>
</li>
<li><p>记录之后，如果有某个Sentinel发现自己已经被半数以上的Sentinel设置成了局部领头Sentinel，那么这个Sentinel就会成为领头Sentinel。</p>
</li>
<li><p>领头Sentinel的产生需要半数以上的Sentinel支持，并且每个Sentinel在每个配置纪元里面只能设置一次局部Sentinel，所以在一个配置纪元里面，只会出现一个领头Sentinel。</p>
</li>
<li><p>如果在给定时限内，没有一个Sentinel被选举为领头Sentinel，那么各个Sentinel将在一段时间之后<strong>再次进行选举</strong>，直到选出领头Sentinel为止，（所以建议哨兵设置奇数个，且数量不小于3）。</p>
</li>
</ol>
<h3 id="3-3-3-故障转移"><a href="#3-3-3-故障转移" class="headerlink" title="3.3.3 故障转移"></a>3.3.3 故障转移</h3><p>接收到<code>SENTINEL is-master-down-by-addr</code>命令回复的源Sentinel可以统计出有多少个Sentinel将自己设置成局部领头Sentinel。如果超过半数，则当前Sentinel就会被选为领头Sentinel并进行故障转移。</p>
<p>故障转移包括以下三步：</p>
<ol>
<li>在已下线的Master主机下面挑选一个他的Slave服务器，并将其转换为主服务器。</li>
<li>让<strong>其余</strong>所有Slave服务器复制新的Master服务器。</li>
<li>让已下线的Master服务器变成新的Master服务器的Slave。当已下线的服务器再次上线后将复新的Master的数据。</li>
</ol>
<h4 id="3-3-3-1-选举新的主服务器的过程"><a href="#3-3-3-1-选举新的主服务器的过程" class="headerlink" title="3.3.3.1 选举新的主服务器的过程"></a>3.3.3.1 选举新的主服务器的过程</h4><p>领头Sentinel会在所有Slave中选出新的Master，发送<strong>SLAVEOF no one</strong>命令，将这个服务器确定为主服务器。</p>
<p>领头Sentinel会将已下线Master的所有从服务器保存在一个列表中，按照以下规则，一项一项进行<strong>过滤</strong>。</p>
<ol>
<li><p>删除列表中所有处于下线或者短线状态的Slave。（保证剩下都是在线的）</p>
</li>
<li><p>删除列表中所有最近5s内没有回复过领头Sentinel的INFO命令的Slave。（保证剩下都是近期成功通信过的）</p>
</li>
<li><p>删除所有与<strong>下线Master</strong>连接断开超过down-after-milliseconds * 10毫秒的Slave。（过滤掉过早的和下线Master断开连接的，这样可以保证剩下的Slave，数据都比较新）</p>
</li>
<li><p>领头Sentinel将根据Slave优先级，对列表中剩余的Slave进行排序，并选出其中优先级最高的Slave。</p>
</li>
<li><p>如果有多个具有相同优先级的Slave，那么领头Sentinel将按照Slave复制偏移量，选出其中偏移量最大的Slave。（复制偏移量的slave就是保存的最新数据的slave）</p>
</li>
<li><p>如果有多个优先级最高，偏移量最大的Slave，那么根据运行ID最小原则选出新的Master。</p>
</li>
</ol>
<p>确定新的Master之后，领头Sentinel会以<strong>每秒一次</strong>的频率向新的Master发送INFO命令，当得到确切的回复：role由slave变为master之后，当前服务器顺利升级为Master服务器。</p>
<h4 id="3-3-3-2-修改从服务器的复制目标"><a href="#3-3-3-2-修改从服务器的复制目标" class="headerlink" title="3.3.3.2 修改从服务器的复制目标"></a>3.3.3.2 修改从服务器的复制目标</h4><p>选出新的Master服务器后，领头Sentinel会向<strong>下线Master的剩余Slave</strong>发送SLAVEOF命令，让它们复制新的Master。</p>
<h4 id="3-3-3-3-将旧的Master变成Slave"><a href="#3-3-3-3-将旧的Master变成Slave" class="headerlink" title="3.3.3.3 将旧的Master变成Slave"></a>3.3.3.3 将旧的Master变成Slave</h4><p>当已下线的Master重新上线后，领头Sentinel会向此服务器发送SLAVEOF命令，将当前服务器变成新的Master的Slave。</p>
<h1 id="4-集群模式"><a href="#4-集群模式" class="headerlink" title="4. 集群模式"></a>4. 集群模式</h1><p>Redis集群是Redis的分布式数据库方案，通过分片来进行数据共享，并提供复制和故障转移功能。集群为Redis提供了更加便利的水平拓展能力，是现代企业级Redis实现高吞吐高并发的重要实现。</p>
<ul>
<li>集群模式和主从模式的区别：<ul>
<li>主从模式<ul>
<li>指的是针对多台redis实例时候，只存在一台主服务器master，提供读写的功能，同时存在依附在这台主服务器的从服务器slaver，只提供读服务。</li>
<li>主从作用是：读写分离，分散访问量，提高访问可读性，同时保证数据的冗余和备份。</li>
</ul>
</li>
<li>集群模式<ul>
<li>指的是针对多个redis实例，去中心化，去中间件，集群中的每个节点都是平等的关系，都是对等的。</li>
<li>集群的作用是：实现扩容、分摊压力、无中心配置相对简单。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="4-1-节点"><a href="#4-1-节点" class="headerlink" title="4.1 节点"></a>4.1 节点</h2><p>节点，<strong>指的就是我们之前说的Redis服务器</strong>。</p>
<p>一个Redis 集群通常由多个节点组成，在刚开始的时候，每个节点都是独立的，只处于只包含自己的集群中（也就是之前我们说到的单机模式），当要组成一个真正可工作的集群时，就需要将这些独立的节点连接起来，构建成一个包含多个节点的集群。</p>
<p>如何连接各个节点？使用<code>CLUSTER MEET</code>命令</p>
<p><code>CLUSTER MEET &lt;ip&gt; &lt;port&gt;</code></p>
<p>向一个节点发送<code>CLUSTER MEET</code>命令，可以让节点与ip和port所指定的节点进行握手，握手成功，节点就会将ip和port指定的节点添加到当前的集群中。</p>
<blockquote>
<p>节点A向节点B发送<code>CLUSTER MEET</code>命令，那么B将会加入A的集群中。反之，A加入B的集群中。</p>
</blockquote>
<p>在启动时，服务器会根据 <code>cluster-enabled</code> 配置选项来决定是否开启集群模式。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6885d13841ad33d7783816ac2e8c63736dd.png" alt=""></p>
<h3 id="4-2-集群数据结构"><a href="#4-2-集群数据结构" class="headerlink" title="4.2  集群数据结构"></a>4.2  集群数据结构</h3><p>Redis使用clusterNode结构来保存一个节点的状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;一个节点的当前状态</span><br><span class="line">struct clusterNode&#123;    </span><br><span class="line">    &#x2F;&#x2F; 创建节点的时间    </span><br><span class="line">    mstime_t ctime;    </span><br><span class="line">    &#x2F;&#x2F; 节点的名字，由40个16进制字符组成    </span><br><span class="line">    char name[REDIS_CLUSTER_NAMELEN];    </span><br><span class="line">    &#x2F;&#x2F; 节点标识    </span><br><span class="line">    int flags;    </span><br><span class="line">    &#x2F;&#x2F; 节点当前的配置纪元，用于实现故障转移    </span><br><span class="line">    uint64_t configEpoch;    </span><br><span class="line">    &#x2F;&#x2F; 节点的ip地址    </span><br><span class="line">    char ip[REDIS_IP_STR_LEN];    </span><br><span class="line">    &#x2F;&#x2F; 节点的端口号    </span><br><span class="line">    int port；    </span><br><span class="line">    &#x2F;&#x2F; 保存连接节点所需的有关信息   </span><br><span class="line">    clusterLink *link；    </span><br><span class="line">    &#x2F;&#x2F;……</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>clusterNode 结构的 link 属性：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterLink &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 连接的创建时间</span><br><span class="line">    mstime_t ctime;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; TCP 套接字描述符</span><br><span class="line">    int fd;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 输出缓冲区，保存着等待发送给其他节点的消息（message）。</span><br><span class="line">    sds sndbuf;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 输入缓冲区，保存着从其他节点接收到的消息。</span><br><span class="line">    sds rcvbuf;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 与这个连接相关联的节点，如果没有的话就为 NULL</span><br><span class="line">    struct clusterNode *node;</span><br><span class="line"></span><br><span class="line">&#125; clusterLink;</span><br></pre></td></tr></table></figure>
<p>最后，每个节点都保存着一个clusterState结构，这个结构记录了<strong>在当前节点的视角下集群目前所处的状态</strong>，比如集群是在线还是下线，包含多少个节点，当前的配置纪元等：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 指向当前节点的指针</span><br><span class="line">    clusterNode *myself;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群当前的配置纪元，用于实现故障转移</span><br><span class="line">    uint64_t currentEpoch;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群当前的状态：是在线还是下线</span><br><span class="line">    int state;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群中至少处理着一个槽的节点的数量</span><br><span class="line">    int size;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群节点名单（包括 myself 节点）</span><br><span class="line">    &#x2F;&#x2F; 字典的键为节点的名字，字典的值为节点对应的 clusterNode 结构</span><br><span class="line">    dict *nodes;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">&#125; clusterState;</span><br></pre></td></tr></table></figure>
<p><img src="https://oscimg.oschina.net/oscnet/up-cb0413dac3d1923097cdf136316e96c8f4f.png" alt=""></p>
<h3 id="4-2-1-CLUSTER-MEET-命令的实现"><a href="#4-2-1-CLUSTER-MEET-命令的实现" class="headerlink" title="4.2.1 CLUSTER MEET 命令的实现"></a>4.2.1 CLUSTER MEET 命令的实现</h3><p>向节点A发送 CLUSTER MEET 命令，能让接收命令的节点A将另一个节点B（ip和port指向的节点）添加到节点A当前所处的集群里。</p>
<p>收到命令的节点A 和节点B进行握手，以此来确认彼此的存在，并为将来的进一步通信打好基础：</p>
<ol>
<li><p>节点A为节点B创建一个clusterNode结构，并将该结构添加到节点A自己的clusterState.nodes字典中。</p>
</li>
<li><p>节点A根据ip和port发送meet消息给节点B。</p>
</li>
<li><p>如果一切顺利，节点B收到meet消息，为节点A创建一个clusterNode结构，并将该结构添加到节点B自己的clusterState.nodes字典中。</p>
</li>
<li><p>如果一切顺利，节点B向节点A发送PONG消息</p>
</li>
<li><p>如果一切顺利，节点A向节点B返回PING消息</p>
</li>
<li><p>如果一切顺利，至此，握手完成</p>
</li>
<li><p>最后节点A会向自己处于的集群内的其他节点发送信息，让其他节点也和B节点握手，最终达到集群内的所有节点都相互认识彼此。至此，B节点加入进集群。</p>
</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-40fa2846f5067087ba601c5ba8b0658df00.png" alt=""></p>
<h2 id="4-3-redis负载均衡算法——hash-slot"><a href="#4-3-redis负载均衡算法——hash-slot" class="headerlink" title="4.3 redis负载均衡算法——hash slot"></a>4.3 redis负载均衡算法——hash slot</h2><p>Redis使用分片的方式来保存数据库中的键值对：整个集群被分为16384个槽(slot)，数据库中的每个键都位于这其中的某个槽上，集群中的节点，最少可以处理0个槽，最多可以处理16384个槽。</p>
<p><strong>当数据库中的 16384 个槽都有节点在处理时，集群处于上线状态，否则，处于下线状态。</strong></p>
<p>我们可以使用CLUSTER ADDSLOTS命令来给某个节点指派要处理的槽：</p>
<p><code>CLUSTER ADDSLOTS [slot ...]</code></p>
<p>这个命令接受一个或多个槽的编号作为参数，并将所有输入的槽指派给接收该命令的节点负责。</p>
<p>如<code>CLUSTER ADDSLOTS 0 1 2 3 ... 1000</code></p>
<p>表示将槽0到槽1000指派给接收到命令的整个节点负责。</p>
<h3 id="4-3-1-记录节点的槽指派信息"><a href="#4-3-1-记录节点的槽指派信息" class="headerlink" title="4.3.1 记录节点的槽指派信息"></a>4.3.1 记录节点的槽指派信息</h3><p>clusterNode结构中的slots数组和numslots字段记录了该节点负责处理的槽。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 一个节点的当前状态</span><br><span class="line">struct clusterNode&#123;</span><br><span class="line">    &#x2F;&#x2F;……</span><br><span class="line">    &#x2F;&#x2F; 记录处理那些槽</span><br><span class="line">    &#x2F;&#x2F; 二进制位数组，长度为 2048 个字节，包含 16384 个二进制位</span><br><span class="line">    &#x2F;&#x2F; 如果slots数组在索引i上的二进制位的值为1，那么表示节点负责处理槽i；否则表示节点不负责处理槽i</span><br><span class="line">    unsigned char slots[16384&#x2F;8];</span><br><span class="line">    &#x2F;&#x2F;记录自己负责处理的槽的数量</span><br><span class="line">    int numslots;</span><br><span class="line">    &#x2F;&#x2F;……</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>slots数组有16384个二进制位，<strong>第i项上的二进制值如果为1，则表示槽i由自己负责。为0则表示槽i不是由自己负责</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-08c2162c6cae22ff35c3fd9c53e0ec5bf8c.png" alt=""></p>
<p>数组的定位时间复杂度是O(1)，这样的设计可以让节点非常快速的知道某个槽到底是不是由自己负责。</p>
<h3 id="4-3-2-传播节点的槽指派信息"><a href="#4-3-2-传播节点的槽指派信息" class="headerlink" title="4.3.2 传播节点的槽指派信息"></a>4.3.2 传播节点的槽指派信息</h3><p>一个节点除了会将自己负责处理的槽记录在clusterNode结构的slots属性和numslots属性之外，它还会<strong>将自己的slots数组通过消息发送给集群中其他的节点</strong>，以此来告知其他节点自己目前负责处理哪些槽。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-4068617fde399f6fe494c764ff1e330620c.png" alt=""></p>
<p>当节点A通过消息从节点B那里接收到节点B的slots数组时，节点A会在<strong>自己的clusterState.nodes字典中</strong>查找<strong>节点B对应的clusterNode结构</strong>，并对该clusterNode结构中的slots数组进行保存或者更新。</p>
<p>每个节点都相互分享自己的槽指派信息，每个节点又在自己的clusterState.nodes字典中保存其他节点的槽指派信息，因此，集群中的每个节点都会知道整个集群数据库的全部槽，都分别被分派给了哪些节点。</p>
<h3 id="4-3-3-记录集群所有槽的指派信息"><a href="#4-3-3-记录集群所有槽的指派信息" class="headerlink" title="4.3.3 记录集群所有槽的指派信息"></a>4.3.3 记录集群所有槽的指派信息</h3><p>我们知道，每个节点都保存着一个clusterState结构，这个结构，<strong>我们可以看做节点自己对整个集群所描绘的详细概念地图</strong>。</p>
<p>节点除了会在clusterState.nodes字典中维护每个节点的槽分派信息外，还会在clusterState结构结构中维护一个clusterNode *slots[16384]数组。</p>
<p>clusterState.slots数组有16384项，每个数组项都是一个指向clusterNode的指针：</p>
<ul>
<li>如果slots[i]指向NULL，那么表示槽i尚未指派给任何节点。</li>
<li>如果slots[i]指向一个clusterNode，那么表示槽i已经指派给了这个clusterNode所对应的节点</li>
</ul>
<p>假设槽被指派给了集群中的三个节点，那么slots数组结构如下图：<br><img src="https://oscimg.oschina.net/oscnet/up-ef32357ce2410db6cf95670fec70e865b75.png" alt=""></p>
<ul>
<li>clusterState.nodes[i].slots<ul>
<li>节点A在自己的clusterState.nodes字典中的某个clusterNode结构（假设对应节点B）中保存的槽分派信息，是以单节点（节点B）为视角的槽分派信息，即——<strong>我这个节点负责如下这些槽</strong>。</li>
</ul>
</li>
<li>clusterState.slots</li>
<li>节点A在自己的clusterState.slots数组中保存的槽分派信息，是以每个槽为视角的槽分派信息。即——<strong>我这个槽被某个节点负责</strong>。</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-d08d4389ea5a796d227eed8522533cc9bf9.png" alt=""></p>
<h2 id="4-4-集群处理命令"><a href="#4-4-集群处理命令" class="headerlink" title="4.4 集群处理命令"></a>4.4 集群处理命令</h2><p>当集群中的所有槽都被指派之后，集群就会进入上线状态，这是客户端就可以向集群中的节点发送命令了。</p>
<p>一张图解释如下过程：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1cfff66398d714cab3142e3825989d4f9d0.png" alt=""></p>
<h3 id="4-4-1-计算键属于哪个槽"><a href="#4-4-1-计算键属于哪个槽" class="headerlink" title="4.4.1 计算键属于哪个槽"></a>4.4.1 计算键属于哪个槽</h3><p>节点用以下算法计算给定键 key 属于哪个槽：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def slot_number(key):</span><br><span class="line">	return CRC16(key) &amp; 16383 &#x2F;&#x2F;CRC16(key) 计算key的CRC-16校验和，然后和16383与出一个0-16383的序号来。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 用于查看一个给定键属于哪个槽</span><br><span class="line">CLUSTER KETSLOT &lt;key&gt;</span><br></pre></td></tr></table></figure>
<h3 id="4-4-2-判断某个槽是否由当前节点负责"><a href="#4-4-2-判断某个槽是否由当前节点负责" class="headerlink" title="4.4.2 判断某个槽是否由当前节点负责"></a>4.4.2 判断某个槽是否由当前节点负责</h3><p>当节点计算出键所属槽 i 之后，节点会检查自己在 clusterState.slots 数组中的项 i ，判断键所处的槽是否由自己负责：</p>
<ul>
<li>如果 <code>clusterState.slots[i]</code> 等于 <code>clusterState.myself</code> ，那么说明槽 i 由当前节点负责，节点可以执行客户端发送的命令；</li>
<li>否则，槽 i 不由当前节点负责,节点会根据 <code>clusterState.slots[i]</code> 所指向的 clusterNode 结构所记录的节点IP和端口号，向客户端返回 MOVED 错误并指引客户端转向正在处理槽i的节点，格式如下：<ul>
<li><code>MOVED &lt;slot&gt; &lt;ip&gt;:&lt;port&gt;</code></li>
<li>客户端接收到 MOVED 命令之后，根据其提供的IP和端口，转向负责处理槽 slot 的节点，并向节点<strong>重新发送之前想要执行的命令</strong>。</li>
<li>客户端会和每个节点创建套接字连接，所谓的转向，其实就是换一个套接字来发送命令。</li>
</ul>
</li>
</ul>
<h2 id="4-5-节点数据库的实现"><a href="#4-5-节点数据库的实现" class="headerlink" title="4.5 节点数据库的实现"></a>4.5 节点数据库的实现</h2><p>我们在文章<a href="https://my.oschina.net/lscherish/blog/3147447" target="_blank" rel="noopener" title="Redis数据库结构/键空间/过期字典/事务/锁/持久化">Redis数据库结构/键空间/过期字典/事务/锁/持久化</a>中讨论过Redis服务器的键空间（即如何存储键值对）redisDb结构的dict字典数组，保存了所有的键值对。redisDb结构的expires字典数组，保存了所有的过期字典。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6d3519de440528a8af1eded3347c9337236.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-dbb09c36a7db3dcb13c5f538cb3ccc80092.png" alt=""></p>
<p><strong>单机服务器和集群服务器（节点）的保存键值对以及键值对过期时间，实现都是一样的</strong>。只不过节点只能使用 0 号数据库，单机服务器没有限制。</p>
<p>和单机服务器不同的是，除了键值对之外，节点还需要维护<strong>槽和键的关系</strong>，节点会用 clusterState 结构中的 <code>slots_to_keys</code> 跳跃表来保存槽和键之间的关系：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState&#123;</span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">    zskiolist *slots_to_keys;</span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">&#125; clusterState;</span><br></pre></td></tr></table></figure>
<p>这个跳跃表每个节点的分值( score )都是一个槽号，节点的成员( member )都是一个数据库键：</p>
<ul>
<li><p>每当节点往数据库中添加一个新的键值对时，节点就会将这个键以及键的槽号关联到 slots_to_key s跳跃表</p>
</li>
<li><p>当节点删除数据库中的某个键值对时，节点就会在slots_to_keys跳跃表解除被删除键与槽号的关联</p>
</li>
</ul>
<p>图例：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0bc955e758a048378d24a0e10ca3a39540a.png" alt=""></p>
<p>该图表示：</p>
<ul>
<li>键”book”所在跳跃表节点的分值为1337.0，这表示键”book”所在的槽为1337</li>
<li>键”date”所在跳跃表节点的分值为2022.0，这表示键”date”所在的槽为2022</li>
<li>键”lst”所在跳跃表节点的分值为3347.0，这表示键”lst”所在的槽为3347</li>
</ul>
<blockquote>
<p>slots_to_keys 的存在是为了使节点可以很方便的对属于某个或者某些槽的所有键做批量操作。例如命令<code>CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;</code>命令可以返回最多count个属于槽slot的数据库键，而这个命令就是通过遍历 slots_to_keys跳跃表来实现的</p>
</blockquote>
<h2 id="4-6-重新分片"><a href="#4-6-重新分片" class="headerlink" title="4.6 重新分片"></a>4.6 重新分片</h2><p>Redis集群的重新分片操作可以将<strong>任意数量已经指派给某个节点（源节点）的槽改为指派给另一个节点（目标节点，并且相关槽所属的键值对也会从源节点移动到目标节点。</strong> 重新分片可以在线进行，在这过程中，集群不用下线，且源节点和目标节点都可以继续处理命令。</p>
<p>重新分片由Redis的集群管理软件 redis-trib 负责执行，redis-trib 通过向源节点和目标节点发送命令来进行重新分片：</p>
<ul>
<li><p>redis-trib对集群的单个槽 slot 进行重新分片的步骤如下：</p>
<ol>
<li><p>redis-trib 对目标节点发送 <code>CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_id&gt;</code> 命令，让目标节点<strong>准备好</strong>从源节点导入槽 slot 的键值对</p>
</li>
<li><p>redis-trib 对源节点发送 <code>CLUSTER SETSLOT &lt;slot&gt; MIGRATING &lt;source_id&gt;</code>命令，让源节点<strong>准备好</strong>将属于槽 slot的键值对迁移至目标节点</p>
</li>
<li><p>redis-trib 对源节点发送 <code>CLUSTER GETKEYSINSLOT&lt;slot&gt; &lt;count&gt;</code> 命令，获得最多 count 个属于槽 slot 的键值对的键名。</p>
</li>
<li><p>对于步骤三获得的每个键名，redis-trib 都向源节点发送一个<code>MIGRATE &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout&gt;</code> 命令，<strong>将被选中的键原子的从源节点迁移至目标节点</strong>。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-ee9006a45f14bd9001e3118803ba0f3e6a8.png" alt=""></li>
</ul>
<ol start="5">
<li>重复步骤3和4，直到源节点保存的所有属于槽slot的键值对都被迁移到目标节点为止。</li>
<li>redis-trib向集群中的任意一个节点发送 <code>CLUSTER SETSLOT &lt;slot&gt; NODE &lt;target_id&gt;</code> 命令，将槽slot指派给目标节点的信息发送给整个集群。</li>
</ol>
</li>
</ol>
</li>
<li><p>如果重新分片涉及多个槽，那么 redis-trib 将对<strong>每个给定的槽</strong>  <strong>分别</strong>执行上面给出的步骤。</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-0e420042cc4a84d00d7ef383c8c9a540889.png" alt=""></li>
</ul>
</li>
</ul>
<p>重新分片的实战操作，可以参考该篇文章：<a href="http://weizijun.cn/2016/01/08/redis%20cluster%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7redis-trib-rb%E8%AF%A6%E8%A7%A3/" target="_blank" rel="noopener" title="redis cluster管理工具redis-trib.rb详解">redis cluster管理工具redis-trib.rb详解</a></p>
<h2 id="4-6-ASK-错误"><a href="#4-6-ASK-错误" class="headerlink" title="4.6 ASK 错误"></a>4.6 ASK 错误</h2><p>在重新分片期间，源节点向目标节点迁移一个槽的过程中，可能会出现这样一种中间状态：属于被迁移槽的一部分键值对保存在源节点里面，而另一部分键值对保存在目标节点中。</p>
<p>这时候如果客户端向源节点发送了一个key的操作请求，就可能会触发ASK 错误。</p>
<p>当客户端向源节点发送关于键key的命令，源节点先在自己的数据库里查找这个键，如果找到就直接返回执行客户端命令，如果没找到，这个键可能已经被迁移到了目标节点，源节点向客户端返回一个 ASK 错误，指引客户端转向正在导入槽的目标节点，并再次发送之前要执行的命令。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-1b3f9629997cc535ef543380112d098d3e0.png" alt=""></p>
<p>接到ASK 错误的客户端会根据错误提供的IP地址和端口号，转向至正在导入槽的目标节点，然后向目标节点发送一个 ASKING 命令， 之后再重新发送原本想要执行的命令。</p>
<h3 id="4-6-1-ASKING-命令的实现"><a href="#4-6-1-ASKING-命令的实现" class="headerlink" title="4.6.1 ASKING 命令的实现"></a>4.6.1 ASKING 命令的实现</h3><p>在重新分片过程中，我们对目标节点执行了 <code>CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_id&gt;</code>命令，这会使得clusterState状态的importing_slots_from数组会记录当前节点的哪些槽正在从哪些节点导入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState&#123;</span><br><span class="line">	&#x2F;&#x2F; ……</span><br><span class="line">    &#x2F;&#x2F; 如果importing_slots_from[i]的值不为NULL，而是指向一个clusterNode结构，表示当前节点正在从</span><br><span class="line">    &#x2F;&#x2F; clusterNode所代表的节点导入槽i</span><br><span class="line">    clusterNode *importing_slots_from[16384];</span><br><span class="line">     &#x2F;&#x2F; ……</span><br><span class="line">&#125;clusterState;</span><br></pre></td></tr></table></figure>

<p>在重新分片过程中，我们对源节点执行了<code>CLUSTER SETSLOT &lt;slot&gt; MIGRATING &lt;source_id&gt;</code>命令，这会使得clusterState状态的migrating_slots_to数组会记录当前节点正在迁移至其他节点的槽：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState&#123;</span><br><span class="line">    &#x2F;&#x2F; ……</span><br><span class="line">    &#x2F;&#x2F; 如果migrating_slots_to[i]的值不为NULL，而是指向一个clusterNode结构，表示当前节点正在将</span><br><span class="line">    &#x2F;&#x2F; 槽i迁移至clusterNode所代表的节点</span><br><span class="line">    clusterNode *migrating_slots_to[16384];</span><br><span class="line">    &#x2F;&#x2F; ……</span><br><span class="line">&#125;clusterState;</span><br></pre></td></tr></table></figure>
<p>接到ASK 错误的客户端会根据错误提供的IP地址和端口号，转向至正在导入槽的目标节点，然后向目标节点发送一个 ASKING 命令， 之后再重新发送原本想要执行的命令。</p>
<p><strong>ASKING命令要做的就是打开发送该命令的客户端的 REDIS_ASKING 标识。</strong></p>
<p>如果该客户端的 REDIS_ASKING 标识未打开，直接发送请求，由于槽的迁移过程还未完成，请求的键还属于源节点，此时直接请求目标节点，目标节点会返回一个MOVED错误。(因为迁移未完成，所以虽然部分的键已经迁移至目标节点了，但这部分键的归属，还是记在源节点上)</p>
<p>但是，如果节点的<code>clusterState.importing_slots_from[i]</code>显示节点正在导入槽 i ,并且发送命令的客户端带有 REDIS_ASKING 标识，<strong>那么节点将破例执行这个关于槽 i 的命令一次</strong>。</p>
<blockquote>
<p>客户端的 REDIS_ASKING 标识是一个一次性标识，当节点执行了一个带有 REDIS_ASKING 标识的客户单发送的命令之后，客户端的这个表示就会被移除。</p>
</blockquote>
<blockquote>
<p>ASK错误和MOVED错误的区别:<br>    MOVED错误代表槽的负责全已经从一个结点转移到了另一个节点<br>    ASK错误只是两个节点在迁移槽的过程中使用的一种临时措施</p>
</blockquote>
<h2 id="4-7-节点的复制与故障转移"><a href="#4-7-节点的复制与故障转移" class="headerlink" title="4.7 节点的复制与故障转移"></a>4.7 节点的复制与故障转移</h2><p>集群中的节点分为主节点和从节点，主节点负责处理槽，而从节点负责复制某个主节点，并在被复制的主节点下线时，替代下线主节点继续处理命令请求。</p>
<h3 id="4-7-1-设置从节点"><a href="#4-7-1-设置从节点" class="headerlink" title="4.7.1 设置从节点"></a>4.7.1 设置从节点</h3><p>向一个节点发送命令：<code>CLUSTER REPLICATE &lt;node_id&gt;</code></p>
<p>这个命令可以让接收命令的节点成为 node_id 所指定的从节点，并开始对主节点进行复制：</p>
<ul>
<li><p>这个节点会先在自己的 clusterState.nodes 字典中找到 node_id 所对应节点的 clusterNode 结构，并将自己的 <code>clusterState.myself.slaveof</code>指针指向这个结构，以此来记录这个节点正在复制的主节点</p>
</li>
<li><p>然后节点修改自己在 clusterState.myself.flags 中的属性，关闭原本的 <code>REDIS_NODE_MASTER</code>标识，打开 <code>REDIS_NODE_SLAVE</code>标识，表示这个节点由原来的主节点变成了从节点</p>
</li>
<li><p>最后，节点调用复制代码，并跟据 clusterState.myself.slaveof 指向的 clusterNode 结构所保存的IP地址和端口号，对主节点进行复制。就是相当于向从节点发送命令 <code>SLAVEOF &lt;master_ip&gt; &lt;maste_port&gt;</code></p>
</li>
</ul>
<p>一个节点开始成为从节点的时候，会向集群广播这一事实，以便集群中的其他节点更新从节点和主节点的关系。</p>
<h3 id="4-7-2-故障检测"><a href="#4-7-2-故障检测" class="headerlink" title="4.7.2 故障检测"></a>4.7.2 故障检测</h3><p>集群中的每个节点都会定期地向集群中的其他节点发送 PING 消息，以此来检测对方是否在线</p>
<p>如果接受 PING 消息的节点没有在规定时间内返回 PONG ，那么发送 PING 的节点就会将该节点标记为<strong>疑似下线</strong>(PFAIL)。</p>
<p>当一个主节点A通过消息得知主节点B认为主节点C进入疑似下线状态，主节点A会在自己的 <code>clusterState.nodes</code> 字典中找到主节点C所对应的 clusterNode 结构，并将主节点B的下线报告添加到这个结构的 fail_reports 链表里面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">struct clusterNode&#123;</span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">    &#x2F;&#x2F; 一个链表，记录了所有其他节点对该节点的下线报告</span><br><span class="line">    list *fail_reports;</span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果一个集群里，半数以上负责处理槽的主节点都将某个主节点X报告为疑似下线，那么这个主节点X将被标记为已下线(FAIL)，将主节点X标记为已下线的节点会向集群广播一条关于主节点X的FAIL消息，所有收到这条FAIL消息的节点都会立即将主节点X标记为已下线。</p>
<p>比较绕，我们来举例：假设一个集群有ABCD四个节点，A和B节点都认为D节点进入了疑似下线状态，这时刚好半数的主节点认为D疑似下线。然后，C节点通过消息交换，也将D节点标记为疑似下线状态。这时候数量就超过了半数了，于是C节点会将D节点标记为<strong>已下线</strong>，并向整个集群广播一条D节点已下线的消息。这时A和B接到消息，会将D节点标记为<strong>已下线</strong>。</p>
<h3 id="4-7-3-故障转移"><a href="#4-7-3-故障转移" class="headerlink" title="4.7.3 故障转移"></a>4.7.3 故障转移</h3><p>当一个从节点发现自己正在复制的主节点进入了已下线状态，<strong>从节点将开始对下线主节点进行故障转移</strong>:</p>
<ol>
<li>复制下线主节点的所有从节点里面，会有一个<strong>从节点</strong>被选中</li>
<li>被选中的从节点将执行 slaveof no one 命令，成为新的主节点</li>
<li>新的主节点撤销已下线主节点对指派槽的管理，并将这些槽全部指派给自己</li>
<li>新的主节点向集群广播一条PONG消息，告诉集群中的其他节点自己成为了新的主节点。</li>
<li>新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。</li>
</ol>
<p>这里面涉及到新的主节点的选举：</p>
<ol>
<li><p>集群的配置纪元是一个自增计数器，初始值为0</p>
</li>
<li><p>当集群里的某个节点开始一次故障转移操作时，集群配置纪元的值就会加一</p>
</li>
<li><p>对于每个配置纪元，集群中的每个负责处理槽的主节点都有一次投票机会，而第一个向主节点要求投票的从节点将获得主节点的投票</p>
</li>
<li><p>当从节点发现自己正在复制的主节点进入已下线状态时，从节点会向集群广播一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 消息，要求所有收到这条消息、并具有投票权的主节点向这个从节点投票</p>
</li>
<li><p>如果一个主节点具有投票权(它正在负责处理槽),并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，表示这个主节点支持从节点成为新的主节点</p>
</li>
<li><p>每个参与选举的从节点都会接受 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，并根据自己受到了多少条这种消息来统计自己获得了多少主节点 的支持</p>
</li>
<li><p>如果集群库有N个具有投票权的朱及诶单，那么当一个从节点收集到大于等于N/2+1张支持票，这个从节点当选为新的主节点</p>
</li>
<li><p>因为在每个配置纪元里面，每个具有投票权的主节点只能投一次票，所以如果有N个节点进行投票，那么具有大于等于N/2+1张支持票的从节点只会有一个，这确保了新的主节点只会有一个</p>
</li>
<li><p>如果在一个配置纪元里没有从节点能搜集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行选举，直到选出新的主节点为止。</p>
</li>
</ol>
<blockquote>
<p>和选举领头sentinel的算法一样，都是基于raft算法。</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%93%E6%9E%84-%E9%94%AE%E7%A9%BA%E9%97%B4-%E8%BF%87%E6%9C%9F%E5%AD%97%E5%85%B8-%E4%BA%8B%E5%8A%A1-%E9%94%81-%E6%8C%81%E4%B9%85%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%93%E6%9E%84-%E9%94%AE%E7%A9%BA%E9%97%B4-%E8%BF%87%E6%9C%9F%E5%AD%97%E5%85%B8-%E4%BA%8B%E5%8A%A1-%E9%94%81-%E6%8C%81%E4%B9%85%E5%8C%96/" itemprop="url">Redis数据库结构/键空间/过期字典/事务/锁/持久化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-12-25T22:45:55+08:00">
                2019-12-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index">
                    <span itemprop="name">中间件</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/12/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%93%E6%9E%84-%E9%94%AE%E7%A9%BA%E9%97%B4-%E8%BF%87%E6%9C%9F%E5%AD%97%E5%85%B8-%E4%BA%8B%E5%8A%A1-%E9%94%81-%E6%8C%81%E4%B9%85%E5%8C%96/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/12/25/Redis数据库结构-键空间-过期字典-事务-锁-持久化/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  3.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  12
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-Redis服务器结构"><a href="#1-Redis服务器结构" class="headerlink" title="1 Redis服务器结构"></a>1 Redis服务器结构</h1><p>Redis服务器将所有数据库都保存在redis.h/redisServer结构中，这里面最重要的一个结构是 <strong>redisDb *db</strong>，这是一个数组，保存着服务器中的所有数据库。<br>在redis初始化的时候，程序会根据dbnum属性来决定创建多少个数据库，这个属性由配置文件里的database选项来决定，默认是16，故而redis服务器默认创建16个数据库。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-dd2a29153e71b63cd5bfd49ea2758169ebb.png" alt=""></p>
<h2 id="1-1-目标数据库"><a href="#1-1-目标数据库" class="headerlink" title="1.1 目标数据库"></a>1.1 目标数据库</h2><p>每个redis客户端都有自己的目标数据库，redis的读写操作都是针对目标数据库的。</p>
<p>默认情况下，redis的目标数据库是0号数据库，用户可以使用select命令来切换目标数据库。<code>SELECT 1</code>命令即为使目标数据库为1号数据库。</p>
<p>用来存储客户端状态的redisClient对象中的db属性记录了客户端当前的目标数据库，这个指针指向了redisDb数组的某个节点。</p>
<p>Select就是通过改变db属性的指针而切换目标数据库的。</p>
<h2 id="1-2-数据库键空间"><a href="#1-2-数据库键空间" class="headerlink" title="1.2 数据库键空间"></a>1.2 数据库键空间</h2><p><img src="https://oscimg.oschina.net/oscnet/up-d6e14f11d52889dd33329a8330c815e5b10.png" alt=""></p>
<p>上文说过redisDb结构表示一个数据库，其中的dict字典保存了数据库中的所有键值对，我们将这个字典称为键空间。我们对键值对的增删改查，都是对这个键空间的操作。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-edc492565847bfab632cc7203a17fb62736.png" alt=""></p>
<p>使用字典的好处是，随着数据量的增大，定位到某个键值对的时间复杂度并不会增加太厉害。很适合redis数据库的情况。</p>
<h2 id="1-3-过期字典"><a href="#1-3-过期字典" class="headerlink" title="1.3 过期字典"></a>1.3 过期字典</h2><p>要理解过期字典，先知道生存时间这一概念：</p>
<h3 id="1-3-1-设置过期时间"><a href="#1-3-1-设置过期时间" class="headerlink" title="1.3.1 设置过期时间"></a>1.3.1 设置过期时间</h3><p>Redis可以设置键的生存时间或过期时间：</p>
<ul>
<li>expire命令或者pexpire命令，客户端可以以秒（前者）或者毫秒（后者）精度，为数据库中某个键设置生存时间。</li>
</ul>
<blockquote>
<p>expire命令或者pexpire命令为一个key设置生存时间，注意，这个生存时间设置在<strong>key上</strong>，除非是用新的k-v来取代这个k-v，否则，只改变其value（可能是链表，集合，哈希等等）的结构，或者只是重命名这个key，或者对key进行自增自减操作，本质上都不会改变key上的生存时间。</p>
</blockquote>
<ul>
<li>Persist命令可以移除一个键的生存时间设置。</li>
<li>TTL 命令可以查看一个带有生存时间限制的键的剩余时间，以秒为单位，底层实现是以过期时间戳减去当前时间。（PTTL以毫秒为单位）</li>
</ul>
<h3 id="1-3-2-过期字典空间"><a href="#1-3-2-过期字典空间" class="headerlink" title="1.3.2 过期字典空间"></a>1.3.2 过期字典空间</h3><p>回到我们的redisDb结构，我们可以看到一个dict数组叫做expires</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-6d3519de440528a8af1eded3347c9337236.png" alt=""></p>
<p>Expires字典保存了数据库中<strong>所有键的过期时间</strong>，这个键就是过期字典。</p>
<ul>
<li><strong>过期字典的键是一个指针，指向了键空间中的某个键对象</strong>（所以才说生存时间是针对key的）</li>
<li><strong>过期字典的值是一个long long 类型的整数</strong>，这个整数保存了键所指向的键对象的过期时间——以毫秒为精度的一个时间戳（所以底层其实都是用PEXPIREAT命令）</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-dbb09c36a7db3dcb13c5f538cb3ccc80092.png" alt=""></p>
<h3 id="1-3-3-过期键删除策略"><a href="#1-3-3-过期键删除策略" class="headerlink" title="1.3.3 过期键删除策略"></a>1.3.3 过期键删除策略</h3><p>Redis使用了<strong>惰性删除（在使用到键时才去判断是否过期以及删除）和定期删除（每隔一段时间删除库中的过期键）两种结合的删除策略</strong></p>
<ul>
<li>db.c/expireIfNeeded函数负责惰性删除，</li>
<li>redis.c/activeExpireCycle函数实现定期删除，它在规定的时间内，分多次遍历服务器中的各个数据库，从过期字典中随机检查一部分键的过期时间，并删除过期键。</li>
</ul>
<h1 id="2-Redis的事务"><a href="#2-Redis的事务" class="headerlink" title="2 Redis的事务"></a>2 Redis的事务</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;我们首先使用MULTI命令告诉Redis：</span><br><span class="line">&#x2F;&#x2F;“下面我发给你的命令属于同一个事务，你先不要执行，而是把它们暂时存起来。”Redis回答：“OK。</span><br><span class="line"></span><br><span class="line">redis &gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;而后我们发送了两个SADD命令来实现关注和被关注操作.</span><br><span class="line">&#x2F;&#x2F;可以看到Redis遵守了承诺，没有执行这些命令，</span><br><span class="line">&#x2F;&#x2F;而是 返回QUEUED表示这两条命令已经进入等待执行的事务队列中了。</span><br><span class="line">redis &gt; 命令1</span><br><span class="line">QUEUED</span><br><span class="line">redis &gt; 命令2</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;当把所有要在同一个事务中执行的命令都发给Redis后，</span><br><span class="line">&#x2F;&#x2F;我们 使用EXEC命令告诉Redis将等待执行的事务队列中的所有命令（即刚才所有返回QUEUED的命令）</span><br><span class="line">&#x2F;&#x2F;按照发送顺序依次执行。</span><br><span class="line">&#x2F;&#x2F;EXEC命令的返回值就是这些命令的返回值组成的列表，返回值顺序和命令的顺序相同。</span><br><span class="line"></span><br><span class="line">redis &gt; EXEC</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Redis的事务和其他的事务一样保证最基本的原子性，只要执行exec命令，事务就会执行，执行过程中，一个命令失败，事务中的命令就全部取消。</p>
</blockquote>
<blockquote>
<p>redis没有类似关系型数据库的回滚功能，烂摊子只能自己收拾。</p>
</blockquote>
<h1 id="3-Redis的锁"><a href="#3-Redis的锁" class="headerlink" title="3 Redis的锁"></a>3 Redis的锁</h1><p>Redis的Watch命令具有乐观锁的功能，WATCH命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行。</p>
<p>监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，所以在MULTI命令后可以修改WATCH监控的键值）</p>
<blockquote>
<p>WATCH只负责  当被监控的键值被修改后 阻止紧随其后的一个事务的执行，而不能保证其他客户端不修改这一键值。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">redis &gt; SET key 1</span><br><span class="line">OK</span><br><span class="line">redis &gt; WATCH key</span><br><span class="line">OK</span><br><span class="line">redis &gt; SET key 2</span><br><span class="line">OK</span><br><span class="line">redis &gt; MULTI</span><br><span class="line">OK</span><br><span class="line">redis &gt; SET key 3</span><br><span class="line">QUEUED</span><br><span class="line">redis &gt; EXEC</span><br><span class="line">(nil)</span><br><span class="line">redis &gt; GET key   &#x2F;&#x2F;得到2，说明SET key 3命令没有实现，事务被取消了</span><br><span class="line">&quot;2&quot;</span><br></pre></td></tr></table></figure>

<h1 id="4-Redis的持久化"><a href="#4-Redis的持久化" class="headerlink" title="4 Redis的持久化"></a>4 Redis的持久化</h1><p>为了防止因为突发情况，导致Redis数据库的数据丢失，我们需要对Redis做持久化。Redis如何做持久化呢？有两种方式：</p>
<ul>
<li>RDB（快照）持久化</li>
<li>AOF</li>
</ul>
<h2 id="4-1-RDF"><a href="#4-1-RDF" class="headerlink" title="4.1 RDF"></a>4.1 RDF</h2><p>RDB（快照）持久化：保存某个时间点的全量数据快照，生成RDB文件在磁盘中。RDB文件是一个压缩过的二进制文件，可以还原为Redis的数据。</p>
<h3 id="4-1-1-触发和载入方式"><a href="#4-1-1-触发和载入方式" class="headerlink" title="4.1.1 触发和载入方式"></a>4.1.1 触发和载入方式</h3><ul>
<li><p>手动触发方式</p>
<ul>
<li>SAVE命令：阻塞Redis的服务器进程，直到RDB文件被创建完毕，阻塞期间服务器不能处理任何命令请求。</li>
<li>BGSAVE命令：Fork出一个子进程来创建RDB文件，不阻塞服务器进程。lastsave 指令可以查看最近的备份时间。</li>
</ul>
</li>
<li><p>载入方式</p>
<ul>
<li>Redis没有主动载入RDB文件的命令，RDB文件是在服务器启动时自动载入，只要Redis服务器检测到RDB文件的存在，即会载入。<strong>且载入过程，服务器也会是阻塞状态</strong>。</li>
</ul>
</li>
<li><p><strong>自动触发方式</strong></p>
<ul>
<li><p>根据redis.conf配置里的save m n定时触发（用的是BGSAVE），m表示多少时间内，n表示修改次数。<strong>save可以设置多个条件，任意条件达到即会执行BGSAVE命令</strong>。</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1  &#x2F;&#x2F;设置条件1，即服务器在900秒内，对数据库进行了至少1次修改，即会触发BGSAVE</span><br><span class="line">save 300 10 &#x2F;&#x2F;设置条件2，即服务器在300秒内，对数据库进行了至少10次修改，即会触发BGSAVE</span><br><span class="line">save 60 1000  &#x2F;&#x2F;设置条件3，即服务器在0秒内，对数据库进行了至少1000次修改，即会触发BGSAVE</span><br></pre></td></tr></table></figure></li>
<li><p><strong>redis如何保存自动触发方式的save配置呢</strong>？</p>
<ul>
<li>redisServer结构中维护了一个saveParam的数组，数组每个saveParam都存储着一个save条件，如下图：<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-a92236652f39715c887c21cc25185375914.png" alt=""></li>
<li><img src="https://oscimg.oschina.net/oscnet/up-5a64963f2ac3b06d5b7420e21fbee878300.png" alt=""></li>
</ul>
</li>
<li>前文所述三个save，其saveParam的数组将会是下图的样子<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-049e2745bfb3bde016408e3504b8d04e19f.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>自动触发方式如何实现的呢</strong>？</p>
<ul>
<li>redisServer结构维护了一个dirty计数器和lastsave属性。</li>
<li><strong>dirty计数器记录了上次SAVE或者BGSAVE之后，数据库执行了多少次的增删改</strong>，当服务器成功执行一个修改命令后，程序就会对该值+1，（对集合操作n个元素，dirty+n）。SAVE或者BGSAVE命令执行后，dirty计数器清零。</li>
<li>lastsave属性是一个unix时间戳，记录了服务器上次成功执行SAVE或者BGSAVE命令的时间。</li>
<li>Redis服务器有个周期性操作函数serverCron，默认每100毫秒执行一次，它其中一项工作就是检查saveParam保存的条件，并根据dirty和lastsave字段判断是否有哪一条条件已经被满足。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="4-1-2-RDB文件的结构"><a href="#4-1-2-RDB文件的结构" class="headerlink" title="4.1.2 RDB文件的结构"></a>4.1.2 RDB文件的结构</h3><p><img src="https://oscimg.oschina.net/oscnet/up-bf5e7bf3f501d299a65899d125c4490ea9c.png" alt=""></p>
<p>不加赘述，详见<a href="https://www.cnblogs.com/huangxincheng/p/5074998.html" target="_blank" rel="noopener" title="让你彻底了解RDB存储结构">让你彻底了解RDB存储结构</a></p>
<h2 id="4-2-AOF"><a href="#4-2-AOF" class="headerlink" title="4.2 AOF"></a>4.2 AOF</h2><p>除了RDB持久化以外，Redis还提供了AOF（append only file）持久化功能，和RDB通过保存数据库的键值对来记录状态不同，AOF持久化是通过保存Reids服务器所执行的写命令来记录数据库状态的。</p>
<h3 id="4-2-1-AOF持久化的实现"><a href="#4-2-1-AOF持久化的实现" class="headerlink" title="4.2.1  AOF持久化的实现"></a>4.2.1  AOF持久化的实现</h3><p>AOF持久化功能的实现可以分为命令追加（append）、文件写入、文件同步（sync）三个步骤。</p>
<ul>
<li>命令追加<ul>
<li>当AOF持久化功能处于打开状态时，服务器在执行完一个写命令后，会以协议格式将被执行的写命令追加到服务器状态的 aof_buf缓存区的末尾。</li>
</ul>
</li>
<li>AOF文件的写入和同步<ul>
<li>Redis的服务器进程就是一个事件循环。</li>
<li>每次结束一个事件循环之前，都会调用flushAppendOnlyFile函数，考虑是否将缓冲区的内容写入和保存到AOF文件里面。</li>
<li>flushAppendOnlyFile函数根据配置项appendsync的不同选值有不同的同步策略。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-53aa39c4281edee37463b23c40a0ca46eb7.png" alt=""></li>
</ul>
</li>
</ul>
<h3 id="4-2-2-AOF文件的载入"><a href="#4-2-2-AOF文件的载入" class="headerlink" title="4.2.2 AOF文件的载入"></a>4.2.2 AOF文件的载入</h3><p>Redis读取AOF文件并还原数据库状态的详细步骤如下：</p>
<ul>
<li>服务器创建一个不带网络连接的伪客户端（fake client）（因为Redis的命令只能在客户端上下文中执行）；</li>
<li>从AOF文件中分析并读取出一条写命令。</li>
<li>从AOF文件中分析并读取出一条写命令。</li>
<li>一直执行步骤2和步骤3，直到AOF文件中的所有写命令都被处理完毕为止。</li>
</ul>
<h3 id="4-2-3-AOF重写"><a href="#4-2-3-AOF重写" class="headerlink" title="4.2.3 AOF重写"></a>4.2.3 AOF重写</h3><p>体积过大的AOF文件很可能对Redis服务器、甚至整个宿主计算机造成影响，并且AOF文件的体积越大，使用AOF文件来进行数据还原所需的时间就越多。</p>
<p>为了解决AOF文件体积膨胀的问题，Redis提供了AOF文件重写（rewrite）功能。</p>
<p>通过该功能，Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个AOF文件所保存的数据库状态相同，但新AOF文件不会包含任何浪费空间的冗余命令，所以新AOF文件的体积通常会比旧AOF文件的体积要小得多。</p>
<p>我们称新的AOF文件为<strong>AOF重写文件</strong>，AOF重写文件不是像AOF一样记录每一条的写命令，也不是对AOF文件的简单复制和压缩。<strong>AOF重写是通过读取当前Redis数据库状态来实现的</strong>。</p>
<p>比如一个animals键，我们有如下操作：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-dd5c6d3f849ab2c7e4028ae3b8ae976c920.png" alt=""></p>
<p>在AOF中，我们要保存四条写命令，而在AOF重写文件中，我们使用一条<code>SADD animals &quot;Dog&quot; &quot;Panda&quot; &quot;Tiger&quot; &quot;Lion&quot; &quot;Cat&quot;</code>来替代四条命令。</p>
<blockquote>
<p>从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令，这就是AOF重写功能的实现原理。（比如连续6条RPUSH命令会被整合成1条）</p>
</blockquote>
<blockquote>
<p>在实际中，为了避免在执行命令时造成客户端输入缓冲区溢出，重写程序在处理列表、哈希表、集合、有序集合这四种可能会带有多个元素的键时，会先检查键所包含的元素数量，如果元素的数量超过了redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD常量(默认为64)的值，那么重写程序将使用多条命令来记录键的值，而不单单使用一条命令。例如如果SADD后面加入的元素为90条，那么会分成两天SADD，第一条SADD 64个元素，第二条SADD 36个元素。</p>
</blockquote>
<h3 id="4-2-3-AOF后台重写"><a href="#4-2-3-AOF后台重写" class="headerlink" title="4.2.3 AOF后台重写"></a>4.2.3 AOF后台重写</h3><p>Redis服务器是单线程，如果由服务器发起AOF重写，那么服务器将阻塞。为了防止这个情况，Redis使用子进程进行AOF重写，在这同时主进程仍然在接受并处理客户端的请求。</p>
<p>因为在子线程重写的过程中，主线程也在处理请求导致数据库状态变化，为了解决数据不一致问题，Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用。</p>
<p>在子线程重写的过程中，当Redis服务器执行完一个写命令之后，它会同时将这个写命令发送给<strong>AOF缓冲区</strong>和<strong>AOF重写缓冲区</strong>。</p>
<p>这样一来可以保证： </p>
<ol>
<li>AOF缓冲区的内容会定期被写入和同步到AOF文件，对现有AOF文件的处理工作会如常进行。</li>
<li>从创建子进程开始，服务器执行的所有写命令都会被记录到AOF重写缓冲区里面。</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/up-6a4615d0c2484006b568327f6ad06b36bfb.png" alt=""></p>
<p>当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接到该信号之后，会调用一个信号处理函数，并执行以下工作：</p>
<ol>
<li><p>将AOF重写缓冲区中的所有内容写入到AOF重写文件中，这时AOF重写文件所保存的数据库状态将和服务器当前的数据库状态一致。</p>
</li>
<li><p>对新的AOF文件进行改名，原子地（atomic）覆盖现有的AOF文件，完成新旧两个AOF文件的替换。</p>
</li>
</ol>
<p>在整个AOF后台重写过程中，只有信号处理函数执行时会对服务器进程（父进程）造成阻塞，在其他时候，AOF后台重写都不会阻塞父进程，这将AOF重写对服务器性能造成的影响降到了最低。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/19/Redis%E7%9A%845%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/19/Redis%E7%9A%845%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/" itemprop="url">Redis的5种数据类型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-12-19T22:42:07+08:00">
                2019-12-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index">
                    <span itemprop="name">中间件</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/12/19/Redis%E7%9A%845%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/12/19/Redis的5种数据类型/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  9
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Redis是一个key-value存储系统，由C语言编写。</p>
<p>Redis使用对象来表示数据库中的键和值，每次当我们在Redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键(key对象)，另一个对象用作键值对的值(value对象)。</p>
<p>Redis的每种数据类型全都是套用一种结构的对象(redisObject)。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d95d7fe428cfe258965098d3c8425942dba.png" alt=""></p>
<p><strong>Redis支持5种对象类型</strong>，分别是字符串(string)、列表(list)、哈希(hash)、集合(set)、有序集合(zset)，redisObject使用type字段记录自身属于哪种类型。</p>
<p>而每种对象类型至少使用了两种底层数据结构来实现，redisObject使用编码字段（encoding字段）记录了自己使用的是哪种底层数据结构实现。<strong>而*ptr指针则会直接指向这个对应的底层数据结构</strong>。</p>
<p>每个对象会用到的编码以及对应的数据结构详见下表，即共8种底层数据结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9e9d4aadc7f129e331c74b52b7db9d6d7d2.png" alt=""></p>
<blockquote>
<p>Redis中的键，都是用字符串对象来存储的，即对于Redis数据库中的键值对来说，键总是一个字符串对象，而值可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象中的其中一种。</p>
</blockquote>
<p>Redis的8种数据结构，我们已经在<a href="https://my.oschina.net/lscherish/blog/3145142" target="_blank" rel="noopener" title="Redis的8种底层数据结构">Redis的8种底层数据结构</a>一文中有过介绍，本文我们来讲Redis支持的5种对象类型</p>
<h1 id="统一的对象——redisObject"><a href="#统一的对象——redisObject" class="headerlink" title="统一的对象——redisObject"></a>统一的对象——redisObject</h1><p>Redis的五种数据类型全都是套用一种结构的对象 ：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e3635d29856355ba1d30a58c82b4632d3c0.png" alt=""></p>
<p>redisObject对象实现了基于引用计数技术的内存回收机制和对象共享机制。</p>
<p>因为redis是k-v键值对的缓存数据库，所以每一次我们新建一个k-v键值对时，redis都会创建两个redisObject对象，<strong>键总是字符串对象</strong>。</p>
<p>这几个属性我们拆开一个个讲：</p>
<ul>
<li><p><strong>Type</strong></p>
<ul>
<li>redisObject对象根据type的不同会有五种类型，这个字段就是用来标记<strong>不同类型的对象</strong>的。</li>
<li>命令TYPE keyname 可以得到这个type属性。</li>
<li>具体值见下表：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-9d87b66548de4d735b77d81f7b5e9e12e32.png" alt=""></li>
<li>Redis基于类型的多态就是根据type字段来判断的，如DEL,EXPIRE等命令可以针对任何类型的键操作，而SET/GET只能针对字符串键操作，HDEL,HSET只能针对哈希键操作等，这种针对特定类型的命令实现，其实就是在执行命令前先检查一下这个type值。</li>
</ul>
</li>
<li><p><strong>Ptr内存指针</strong></p>
<ul>
<li>Ptr是一个指针，用来指向对象的底层数据结构。</li>
</ul>
</li>
<li><p><strong>Encoding</strong></p>
<ul>
<li>对象ptr指针指向对象的<strong>底层实现数据结构</strong>，而到底取用哪个数据结构，则在encoding中标记。</li>
<li>后续Redis命令在针对对象进行操作时，也会根据encoding自动选择合适的函数，这是Redis命令的多态。</li>
<li>下面是encoding的字面值和各种数据结构的对应：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-698fd8d4d8dc2a1676a2b8422c71a99ab0d.png" alt=""></li>
<li>上图中值得注意的是 “跳跃表和字典”。其实在redis中，在使用跳跃表时（其实也就用于有序集合），总会辅助一个字典来提升效率的。这时字典的k-v会分别保存一个元素的<strong>成员地址</strong>和<strong>分值地址</strong>。跳跃表和字典的指针共同指向一个数据，这样既不会占用内存，也能利用字典实现 <strong>常数级的</strong> 定位查找。</li>
</ul>
</li>
<li><p><strong>Refcount</strong></p>
<ul>
<li><p>Refcount是redisObject对象的引用计数器，redis的内存回收是引用计数法，规则如下：</p>
<ul>
<li>当一个新对象创建时，refcount被设置为1。</li>
<li>当对象被一个程序引用时，refcount +1</li>
<li>不再被某个对象引用时，refcount – 1</li>
<li>Refcount为0时，对象被释放</li>
</ul>
</li>
<li><p>Refcount的功能为redis的对象共享提供了可能性，为了节约内存，Redis中大量使用了指针，前面就说过，跳跃表和字典的结合中就大量用到了内存共享。他们相互对应的节点中，指针被指向了同一个对象。</p>
</li>
<li><p>比如为键A新创建了一个整数值为100的字符串对象C，如果键B的值也是100，那么value指针就会指向C，C对象的refcount+1</p>
</li>
<li><p>限于cpu时间的限制，redis只对包含整数值的字符串对象进行共享。</p>
</li>
</ul>
</li>
<li><p><strong>Lru</strong></p>
<ul>
<li>Lru属性记录了该对象最后一次被命令访问的时间</li>
<li>通过它，Redis可以得到这个对象的闲置时间，从而在服务器被占用的内存大小超过maxmenmory时，空转时间长的对象会被优先释放。</li>
</ul>
</li>
</ul>
<h2 id="1-字符串对象"><a href="#1-字符串对象" class="headerlink" title="1 字符串对象"></a>1 字符串对象</h2><p>字符串对象的编码可以是int、raw或者embstr。或者说，字符串对象的encoding只能是<strong>REDIS_ENCODING_INT，REDIS_ENCODING_EMBSTR和REDIS_ENCODING_RAW</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-34c77b394832476e0bbeedef031129d1d08.png" alt=""></p>
<table>
<thead>
<tr>
<th align="center">场景</th>
<th align="center">prt和encoding的值</th>
</tr>
</thead>
<tbody><tr>
<td align="center">如果保存的字符串是整数值，并且这个整数值可以用long类型来表示</td>
<td align="center">Ptr属性中，void*会转化成long，encoding改为REDIS_ENCODING_INT</td>
</tr>
<tr>
<td align="center">保存的字符串不是整数值，且长度<strong>大于39字节</strong>（包含可以用long double 类型保存的浮点数）</td>
<td align="center">Ptr属性中，void*会转化成SDS，encoding为REDIS_ENCODING_RAW</td>
</tr>
<tr>
<td align="center">保存的字符串保存的字符串不是整数值，且长度<strong>小于等于39字节</strong></td>
<td align="center">Ptr属性中，void*会转化成embstr，encoding为REDIS_ENCODING_EMBSTR</td>
</tr>
</tbody></table>
<p>下图展示了一个当ptr指向SDS时的字符串对象的结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-0f49a84c13fabc614b44f2bb095baef5f9a.png" alt=""></p>
<blockquote>
<p>注意：当字符串改变，直到不满足上述各自条件时，embstr和int会被转换为raw类型。</p>
</blockquote>
<blockquote>
<p>注意：Embstr实际上是只读的，因为redis没有为它编写任何的修改函数，所以对它进行任何操作，它都会先转换为raw，然后再执行命令，且不会变回来。</p>
</blockquote>
<h2 id="2-列表对象"><a href="#2-列表对象" class="headerlink" title="2 列表对象"></a>2 列表对象</h2><p>列表对象的编码可以是压缩链表ziplist或者双端链表linkedlist，encoding取值<strong>REDIS_ENCODING_ZIPLIST或者REDIS_ENCODING_LINKEDLIST</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9bd3b4fd6b03622da176ffcb6dbe8759400.png" alt=""></p>
<table>
<thead>
<tr>
<th align="center">场景</th>
<th align="center">prt和encoding的值</th>
</tr>
</thead>
<tbody><tr>
<td align="center">当列表保存的<strong>所有</strong>字符串元素的长度<strong>都小于</strong>64字节，且元素的数量<strong>小于512</strong></td>
<td align="center">Ptr指向一个ziplist，encoding改为REDIS_ENCODING_ZIPLIST</td>
</tr>
<tr>
<td align="center">否则</td>
<td align="center">Ptr指向一个linkedlist，encoding改为REDIS_ENCODING_LINKEDLIST</td>
</tr>
</tbody></table>
<blockquote>
<p>当列表对象被改变，使其无法满足上述条件时，ziplist会向linkedlist迁移</p>
</blockquote>
<h3 id="2-1-列表对象中的Ziplist"><a href="#2-1-列表对象中的Ziplist" class="headerlink" title="2.1 列表对象中的Ziplist"></a>2.1 列表对象中的Ziplist</h3><ul>
<li><p>Ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。</p>
</li>
<li><p>当列表对象元素不大，每个元素也不大的时候，就采用Ziplist存储。</p>
</li>
<li><p>但当数据量过大时就ziplist就不是那么好用了。因为为了保证他存储内容在内存中的连续性，插入的复杂度是O(N)，即每次插入都会重新进行realloc。</p>
</li>
<li><p>如下图所示，对象结构中ptr所指向的就是一个Ziplist。整个Ziplist只需要malloc一次，它们在内存中是一块连续的区域。</p>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-c482fdbc263e1449b8228a94a380c173d1b.png" alt=""></p>
<h3 id="2-2-列表对象中的Linkedlist"><a href="#2-2-列表对象中的Linkedlist" class="headerlink" title="2.2 列表对象中的Linkedlist"></a>2.2 列表对象中的Linkedlist</h3><ul>
<li><p>linkedlist是一种双向链表。它的结构比较简单，节点中存放pre和next两个指针，还有节点相关的信息。</p>
</li>
<li><p>当每增加一个node的时候，就需要重新malloc一块内存。</p>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-9f827f3c5c40fcdf61d8b61cf780f0eeb8d.png" alt=""></p>
<h2 id="3-哈希对象"><a href="#3-哈希对象" class="headerlink" title="3 哈希对象"></a>3 哈希对象</h2><p>哈希对象的底层实现可以是ziplist或者dict。Encoding的值可以是压缩链表REDIS_ENCODING_ZIPLIST或者字典REDIS_ENCODING_HT</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5d9f5a97ffdf3ff8f60580807c38ad7b2b3.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-cc2b0b5bb5247b99b76742c3ebf1ce28ced.png" alt=""></p>
<table>
<thead>
<tr>
<th align="center">场景</th>
<th align="center">prt和encoding的值</th>
</tr>
</thead>
<tbody><tr>
<td align="center">对象保存的<strong>所有键值对的键和值</strong>的字符串长度<strong>都小于64字节</strong>，且键值对<strong>数量小于512</strong></td>
<td align="center">Ptr指向一个ziplist，encoding改为REDIS_ENCODING_ZIPLIST</td>
</tr>
<tr>
<td align="center">否则</td>
<td align="center">Ptr指向一个dict，encoding改为REDIS_ENCODING_HT</td>
</tr>
</tbody></table>
<h3 id="3-1-哈希对象中的ziplist"><a href="#3-1-哈希对象中的ziplist" class="headerlink" title="3.1 哈希对象中的ziplist"></a>3.1 哈希对象中的ziplist</h3><ul>
<li><p>ziplist中的哈希对象是按照key1,value1,key2,value2这样的顺序存放来存储的。</p>
</li>
<li><p>新的键值插入表尾，先是key节点，紧接着value节点。因此同一键值对的两个节点总是紧挨在一起，key在前，value在后。</p>
</li>
<li><p>先添加的k-v靠近表头，后添加的靠近表尾，当对象数目不多且内容不大时，这种方式效率是很高的。</p>
</li>
</ul>
<h3 id="3-2-哈希对象中的dict"><a href="#3-2-哈希对象中的dict" class="headerlink" title="3.2 哈希对象中的dict"></a>3.2 哈希对象中的dict</h3><p>之前已经介绍过dict了，字典中，dicht[0] 是用于真正存放数据，dicht[1]一般在哈希表元素过多进行rehash的时候用于中转数据。</p>
<p>dictht中的table用于真正存放元素，每个key/value对用一个dictEntry表示，放在dictEntry数组中。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e7e180d88c04aecf2ab4f03230acffcc1e6.png" alt=""></p>
<h2 id="4-集合对象"><a href="#4-集合对象" class="headerlink" title="4 集合对象"></a>4 集合对象</h2><p>集合对象的编码可以是intset或者dict。Encoding可以是整数集合REDIS_ENCODING_INTSET或者字典REDIS_ENCODING_HT。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5d9f5a97ffdf3ff8f60580807c38ad7b2b3.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-43dad25f3a597386f766d258daddc45f7b9.png" alt=""></p>
<table>
<thead>
<tr>
<th align="center">场景</th>
<th align="center">prt和encoding的值</th>
</tr>
</thead>
<tbody><tr>
<td align="center">当集合对象保存的<strong>所有元素</strong>都是<strong>整数值</strong>，且元素数量<strong>不超过512个</strong></td>
<td align="center">Ptr指向一个intset，encoding改为REDIS_ENCODING_ZIPLIST</td>
</tr>
<tr>
<td align="center">否则</td>
<td align="center">Ptr指向一个dict，encoding改为REDIS_ENCODING_HT</td>
</tr>
</tbody></table>
<blockquote>
<p>注意：当使用哈希表作为集合对象的底层实现时，字典的每一个键都是一个字符串对象，用来保存集合元素，而<strong>字段的值都被设置为null</strong>。联想一下JAVA的keySet，这方式跟set和hashmap的关系是一样的。</p>
</blockquote>
<h2 id="5-有序集合对象"><a href="#5-有序集合对象" class="headerlink" title="5 有序集合对象"></a>5 有序集合对象</h2><p>有序集合的编码可能两种，一种是ziplist，<strong>另一种是skiplist与dict的结合</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-cc2b0b5bb5247b99b76742c3ebf1ce28ced.png" alt=""><br><img src="https://oscimg.oschina.net/oscnet/up-d234e8da671c9d487dd5ca5470753fc75a1.png" alt=""></p>
<table>
<thead>
<tr>
<th align="center">场景</th>
<th align="center">prt和encoding的值</th>
</tr>
</thead>
<tbody><tr>
<td align="center">有序集合保存的元素<strong>数量小于128</strong>，且所有成员的长度都<strong>小于64字节</strong></td>
<td align="center">Ptr指向一个ziplist，encoding改为REDIS_ENCODING_ZIPLIST</td>
</tr>
<tr>
<td align="center">否则</td>
<td align="center">Ptr指向一个skiplist和dict的结合体，encoding改为REDIS_ENCODING_SKIPLIST</td>
</tr>
</tbody></table>
<h3 id="4-1-有序集合对象中的ziplist"><a href="#4-1-有序集合对象中的ziplist" class="headerlink" title="4.1 有序集合对象中的ziplist"></a>4.1 有序集合对象中的ziplist</h3><ul>
<li>ziplist作为集合和作为哈希对象是一样的，member和score顺序紧凑的存放。</li>
<li>按照score从小到大顺序排列。它的结构不再复述。</li>
</ul>
<h3 id="4-2-有序集合对象中的跳跃表和字典合用"><a href="#4-2-有序集合对象中的跳跃表和字典合用" class="headerlink" title="4.2 有序集合对象中的跳跃表和字典合用"></a>4.2 有序集合对象中的跳跃表和字典合用</h3><p>前面讲过：<br>在使用跳跃表时（其实也就用于有序集合），总会辅助一个字典来提升效率的。这时字典的k-v会分别保存一个元素的成员地址和分值地址。跳跃表和字典的指针共同指向一个数据，这样既不会占用内存，也能利用字典实现** 常数级的** 定位查找。</p>
<p>例如：</p>
<ul>
<li><p>如果我们只使用字典，那么虽然我们可以以O(1)复杂度查找成员的分值，但是因为字典以无序的方式存储，所以在执行注入zrank之类的范围型命令时，还需要重排序。至少需要O（NlogN）的时间复杂度和O（N）的空间复杂度。</p>
</li>
<li><p>反之，我们查找分值这一操作，将需要O（logN）的复杂度。</p>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-e4c2cc27528e959f2850a4732f53d8b308b.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/19/Redis%E7%9A%848%E7%A7%8D%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/19/Redis%E7%9A%848%E7%A7%8D%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" itemprop="url">Redis的8种底层数据结构</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-12-19T22:38:18+08:00">
                2019-12-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index">
                    <span itemprop="name">中间件</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/12/19/Redis%E7%9A%848%E7%A7%8D%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/12/19/Redis的8种底层数据结构/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  10.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  40
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><ul>
<li><p>Redis是一个key-value存储系统，由C语言编写。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型），这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。</p>
</li>
<li><p>在此基础上，Redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。</p>
</li>
</ul>
<ul>
<li><p>Redis 是一个高性能的key-value数据库。 Redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。它提供了Java，C/C++，C#，PHP，JavaScript，Perl，Object-C，Python，Ruby，Erlang等客户端，使用很方便。</p>
</li>
<li><p>Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。存盘可以有意无意的对数据进行写操作。由于完全实现了发布/订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助。</p>
</li>
</ul>
<blockquote>
<p>Redis的作者叫Salvatore Sanfilippo，来自意大利的西西里岛，现在居住在卡塔尼亚。目前供职于Pivotal公司。他使用的网名是antirez。</p>
</blockquote>
<h1 id="Redis的5种对象与8种数据结构"><a href="#Redis的5种对象与8种数据结构" class="headerlink" title="Redis的5种对象与8种数据结构"></a>Redis的5种对象与8种数据结构</h1><p>Redis使用对象来表示数据库中的键和值，每次当我们在Redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键(key对象)，另一个对象用作键值对的值(value对象)。</p>
<p>Redis的每种数据类型全都是套用一种结构的对象(redisObject)。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d95d7fe428cfe258965098d3c8425942dba.png" alt=""></p>
<p><strong>Redis支持5种对象类型</strong>，分别是字符串(string)、列表(list)、哈希(hash)、集合(set)、有序集合(zset)，redisObject使用type字段记录自身属于哪种类型。</p>
<p>而每种对象类型至少使用了两种底层数据结构来实现，redisObject使用编码字段（encoding字段）记录了自己使用的是哪种底层数据结构实现。<strong>而*ptr指针则会直接指向这个对应的底层数据结构</strong>。</p>
<p>每个对象会用到的编码以及对应的数据结构详见下表，即共8种底层数据结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9e9d4aadc7f129e331c74b52b7db9d6d7d2.png" alt=""></p>
<blockquote>
<p>Redis中的键，都是用字符串对象来存储的，即对于Redis数据库中的键值对来说，键总是一个字符串对象，而值可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象中的其中一种。</p>
</blockquote>
<p>那么，我们首先先从底层开始，了解一下Redis的8种数据结构。</p>
<h1 id="Reids的8种底层数据结构"><a href="#Reids的8种底层数据结构" class="headerlink" title="Reids的8种底层数据结构"></a>Reids的8种底层数据结构</h1><h2 id="1-整数"><a href="#1-整数" class="headerlink" title="1 整数"></a>1 整数</h2><p>如果保存的字符串是整数值，并且这个整数值可以用long类型来表示，那么ptr指针的void*则转化为C语言源生的long类型，这个无须多言。</p>
<h2 id="2-简单动态字符串-SDS"><a href="#2-简单动态字符串-SDS" class="headerlink" title="2 简单动态字符串 SDS"></a>2 简单动态字符串 SDS</h2><p>在Redis中，只有在使用到不会被修改的字符串字面量时（比如打印日志），Redis才会采用c语言传统的字符串（以空字符结尾的字符数组），<strong>而在Redis数据库中，所有的字符串在底层都由SDS来实现的</strong>。</p>
<h3 id="2-1-SDS数据结构"><a href="#2-1-SDS数据结构" class="headerlink" title="2.1 SDS数据结构"></a>2.1 SDS数据结构</h3><p>被重新定义过的字符串对象（SDS）是Redis的基本存储类型，一个SDS字符串的完整结构，由在内存地址上前后相邻的<strong>两部分</strong>组成（header和char数组）。如下图，SDS字符串有多种类型，<strong>不同类型的SDS字符串是为了保存不同长度的内容</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5a36209c6053a1edbd5881ba7aeeb0f018e.png" alt=""></p>
<ul>
<li><p>header——我们把上图中非char数组（变量名为buf）的部分都统称为header，其成员有：</p>
<ul>
<li><p>第一个成员变量len记录的是为buf分配的<strong>内存空间已使用的长度，即我们看见的，有效的字符串</strong>；</p>
</li>
<li><p>第二个成员变量alloc记录的是为buf分配的内存空间的<strong>总长度</strong>，alloc – len 就是未使用的空间，当然<strong>这长度不包括SDS字符串头和结尾NULL</strong>。</p>
</li>
<li><p>第三个字符flags只使用了<strong>低三位表示类型</strong>，高五位没有用处，目的是根据字符串的长度的不同选择不同的sds结构体。</p>
<ul>
<li><p><strong><em>为何要定义不同的结构体</em></strong>： 结构体的主要区别是len和alloc的类型（uint8，uint16等等），定义不同的结构体是为了存储不同长度的字符串，根据不同长度定义不同的类型是为了节省一部分空间大小，毕竟在Redis字符串非常多，哪怕一点点优化积累起来都很可观。</p>
</li>
<li><p><strong><em>flags字段的用处</em></strong>：由于SDS字符串结构的设计，在我们需要访问header中成员变量时，需要通过sds指针向前回溯一个头结构体的长度，然后通过这个地址去访问。至于回溯多长，则要视该SDS字符串的类型而定，而这个信息就保存在sds指针前一个unsigned char长度的空间中——即flags。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>char数组</p>
<ul>
<li><p>这是一个没有指明长度的字符数组，这是C语言中定义字符数组的一种特殊写法，称为<strong>柔性数组</strong>（flexible array member），只能定义在一个结构体的最后一个字段上。它在这里只是起到一个标记的作用，表示在flags字段后面就是一个字符数组，或者说，它指明了紧跟在flags字段后面的这个字符数组在结构体中的偏移位置。而程序在分配内存的时候，一开始它并不占用内存空间。</p>
</li>
<li><p>这个字符数组的长度等于最大容量+1。之所以字符数组的长度比最大容量多1个字节，就是为了在字符串长度达到最大容量时仍然<strong>有1个字节NULL结束符</strong>，即ASCII码为0的’\0’字符，这样字符串可以和c语言源生的字符串兼容。</p>
</li>
<li><p>与其他的结构体不同，<strong>sdshdr5没有定义char数组和alloc字段</strong>，他的值存储在flag没有被使用的高五位中，所以sdshdr5对应的SDS_TYPE_5类型字符串只能保存原串长度小于等于2^5 = 32，因此，它不能为字符串分配空余空间。如果字符串需要动态增长，那么它就必然要重新分配内存才行。所以说，这种类型的sds字符串更适合存储静态的短字符串</p>
</li>
</ul>
</li>
</ul>
<h3 id="2-2-使用sds结构的优点"><a href="#2-2-使用sds结构的优点" class="headerlink" title="2.2 使用sds结构的优点"></a>2.2 使用sds结构的优点</h3><ul>
<li><p>1.有利于减少内存碎片，提高存储效率</p>
<ul>
<li>在各个header的定义中使用了<strong>attribute</strong> ((packed))，是为了让编译器以<strong>紧凑模式</strong>来分配内存。如果没有这个属性，编译器可能会为struct的字段做优化对齐，在其中填充空字节。那样的话，就不能保证header和sds的数据部分紧紧前后相邻，也不能按照固定向低地址方向偏移1个字节的方式来获取flags字段了。<strong>这样利于获取header字段，提高性能</strong>。</li>
</ul>
</li>
<li><p>2.常数复杂度获取字符串长度</p>
<ul>
<li>C语言源生的获取字符串长度的方式是遍历整个char数组，因此复杂度为O(N)，SDS采用len字段记录长度，且header和char数组紧凑排列，获取的复杂度为O(1)。设置和更新SDS长度的工作是由SDS的api在执行时<strong>自动完成</strong>的。</li>
</ul>
</li>
<li><p>3.杜绝缓冲区溢出</p>
<ul>
<li>C语言字符串不记录自身长度，也容易造成缓冲区溢出。而当SDS对自身字符串进行修改时，API会先检查SDS的剩余空间是否满足需要（获取alloc减len），如果不满足，则会先拓展空间，再执行API。</li>
</ul>
</li>
<li><p>4.空间预分配</p>
<ul>
<li><p>SDS在重新分配空间的时候，会预分配一些空间来作为冗余。当SDS的len属性长度小于1MB时，Redis会分配和len相同长度的free空间。至于为什么这样分配呢，上次用了len长度的空间，那么下次程序可能也会用len长度的空间，所以Redis就为你预分配这么多的空间。</p>
</li>
<li><p>但是当SDS的len属性长度大于1MB时，程序将多分配1M的未使用空间。这个时候我在根据这种惯性预测来分配的话就有点得不偿失了。所以Redis是将1MB设为一个风险值，没过风险值你用多少我就给你多少，过了的话那这个风险值就是我能给你临界值。</p>
</li>
</ul>
</li>
<li><p>5.惰性空间释放</p>
<ul>
<li>Redis的内存回收采用惰性回收，即你把字符串变短了，那么多余的内存空间也不会立刻还给操作系统，先留着，用header的字段将其记录下来，以防接下来又要被使用呢。</li>
</ul>
</li>
<li><p>6.二进制安全</p>
<ul>
<li>因为’\0’字符串在SDS中没有意义，他作为结束符的任务已经被header字段给替代了，所以与c语言不一样的，SDS是二进制安全的。<h2 id="3-embstr"><a href="#3-embstr" class="headerlink" title="3 embstr"></a>3 embstr</h2></li>
</ul>
</li>
</ul>
<p>embstr编码是专门用来保存短字符串的一种优化编码方式，其实他和raw编码一样，底层都会使用SDS，只不过raw编码是调用两次内存分配函数分别创建redisObject和SDS，而embstr只调用一次内存分配函数来分配一块连续的空间，embstr编码的的redisObject和SDS是紧凑在一起的。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-2adb57eb7edab3562f560151c3c38894cef.png" alt=""></p>
<p>其优势是：</p>
<ul>
<li><p>embstr的创建只需分配一次内存，而raw为两次（一次为sds分配对象，另一次为objet分配对象，embstr省去了第一次）。</p>
</li>
<li><p>相对地，释放内存的次数也由两次变为一次。</p>
</li>
<li><p>embstr的objet和sds放在一起，更好地利用缓存带来的优势。</p>
</li>
</ul>
<p>不过很显然，紧凑型的方式只适合短字符串，长字符串占用空间太大，就没有优势了。</p>
<blockquote>
<p>如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度小于等于 39 字节， 那么字符串对象将使用 embstr 编码的方式来保存这个字符串值。否则采用raw编码的SDS来存储。这在3.0以上版本的Redis出现。</p>
</blockquote>
<blockquote>
<p>至于为什么是39?<br>embstr是一块连续的内存区域，由redisObject和sdshdr组成。其中redisObject占16个字节，当buf内的字符串长度是39时，sdshdr的大小为8+8+39+1=56，那一个字节是’\0’。加起来刚好64。 </p>
</blockquote>
<blockquote>
<p>从2.4版本开始，Redis开始使用jemalloc内存分配器。在这里可以简单理解，jemalloc会分配8，16，32，64等字节的内存。embstr中即便sdshdr的buf为空，最小空间占用也为16+8+8+1=33，所以jemalloc低三档的分配粒度无法满足embstr，最少也要分配64字节。故而当字符数小于39时，都会分配64字节。<strong>默认39就是这么来的</strong>。</p>
</blockquote>
<h2 id="4-双端链表-linkedlist"><a href="#4-双端链表-linkedlist" class="headerlink" title="4 双端链表 linkedlist"></a>4 双端链表 linkedlist</h2><p>C语言中没有内置链表结构，Redis构建了自己的链表实现。list的容量是2的32次方减1个元素，即最多有4294967295个元素数量。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d670404ad3811655092266b0d0c830362ac.png" alt=""></p>
<h3 id="4-1-链表的数据结构"><a href="#4-1-链表的数据结构" class="headerlink" title="4.1 链表的数据结构"></a>4.1 链表的数据结构</h3><p><img src="https://oscimg.oschina.net/oscnet/up-2f435501df72b60b23103eae103efddce78.png" alt=""></p>
<p><strong>列表的节点</strong>（注意不是列表的定义）定义如上，除了双向链表必须的前后指针外，为了实现通用性，支持不同类型数据的存储，Redis将节点类型的数据域定义为void *类型，从而模拟了“泛型”。<br>整个列表定义如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a1fe34a95b7cb4b1ece1b7719b9dd4c1086.png" alt=""></p>
<p>在链表结构中，Redis定义了三个字段和三个函数：</p>
<ul>
<li>字段：<ul>
<li>listNode *head;  // 指向链表的头结点</li>
<li>listNode *tail;    //  指向链表的尾节点</li>
<li>unsigned long len;  //  链表长度</li>
</ul>
</li>
<li>函数：<ul>
<li>void *(*dup)(void *ptr);    //  节点值复制函数，用于复制某个节点的值</li>
<li>void (*free)(void *ptr);    //  节点值释放函数，用于释放某个节点的值</li>
<li>int (*match)(void *ptr, void *key); // 节点值对比函数，用于对比节点的值和另一个输入值是否相等</li>
</ul>
</li>
</ul>
<h2 id="5-字典-dict"><a href="#5-字典-dict" class="headerlink" title="5 字典 dict"></a>5 字典 dict</h2><p>在Redis中，字典的结构可以简单归纳如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3f6ae07f99f50b0510198ece877358ec0d4.png" alt=""></p>
<h3 id="5-1-Dict的数据结构"><a href="#5-1-Dict的数据结构" class="headerlink" title="5.1 Dict的数据结构"></a>5.1 Dict的数据结构</h3><p>Redis定义了dictEntry、dictType、dictht和dict四个结构体来实现哈希表的功能。它们具体定义如下：</p>
<h4 id="5-1-1-dictEntry结构体"><a href="#5-1-1-dictEntry结构体" class="headerlink" title="5.1.1 dictEntry结构体"></a>5.1.1 dictEntry结构体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* 保存键值（key - value）对的结构体，类似于STL的pair。*&#x2F;</span><br><span class="line">typedef struct dictEntry &#123;</span><br><span class="line">    &#x2F;&#x2F; 关键字key定义</span><br><span class="line">    void *key;  </span><br><span class="line">    &#x2F;&#x2F; 值value定义，只能存放一个被选中的成员</span><br><span class="line">    union &#123;</span><br><span class="line">        void *val;      </span><br><span class="line">        uint64_t u64;   </span><br><span class="line">        int64_t s64;    </span><br><span class="line">        double d;       </span><br><span class="line">    &#125; v;</span><br><span class="line">    &#x2F;&#x2F; 指向下一个键值对节点</span><br><span class="line">    struct dictEntry *next;</span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure>

<h4 id="5-1-2-dictType结构体"><a href="#5-1-2-dictType结构体" class="headerlink" title="5.1.2 dictType结构体"></a>5.1.2 dictType结构体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* 定义了字典操作的公共方法，类似于adlist.h文件中list的定义，将对节点的公共操作方法统一定义。搞不明白为什么要命名为dictType *&#x2F;</span><br><span class="line">typedef struct dictType &#123;</span><br><span class="line">    &#x2F;* hash方法，根据关键字计算哈希值 *&#x2F;</span><br><span class="line">    unsigned int (*hashFunction)(const void *key);</span><br><span class="line">    &#x2F;* 复制key *&#x2F;</span><br><span class="line">    void *(*keyDup)(void *privdata, const void *key);</span><br><span class="line">    &#x2F;* 复制value *&#x2F;</span><br><span class="line">    void *(*valDup)(void *privdata, const void *obj);</span><br><span class="line">    &#x2F;* 关键字比较方法 *&#x2F;</span><br><span class="line">    int (*keyCompare)(void *privdata, const void *key1, const void *key2);</span><br><span class="line">    &#x2F;* 销毁key *&#x2F;</span><br><span class="line">    void (*keyDestructor)(void *privdata, void *key);</span><br><span class="line">    &#x2F;* 销毁value *&#x2F;</span><br><span class="line">    void (*valDestructor)(void *privdata, void *obj);</span><br><span class="line">&#125; dictType;</span><br></pre></td></tr></table></figure>
<h4 id="5-1-3-dictht结构体"><a href="#5-1-3-dictht结构体" class="headerlink" title="5.1.3 dictht结构体"></a>5.1.3 dictht结构体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* 哈希表结构 *&#x2F;</span><br><span class="line">typedef struct dictht &#123;</span><br><span class="line">    &#x2F;&#x2F; 散列数组。</span><br><span class="line">    dictEntry **table;</span><br><span class="line">    &#x2F;&#x2F; 散列数组的长度</span><br><span class="line">    unsigned long size;</span><br><span class="line">    &#x2F;&#x2F; sizemask等于size减1</span><br><span class="line">    unsigned long sizemask;</span><br><span class="line">    &#x2F;&#x2F; 散列数组中已经被使用的节点数量</span><br><span class="line">    unsigned long used;</span><br><span class="line">&#125; dictht;</span><br></pre></td></tr></table></figure>
<h4 id="5-1-4-dict结构体"><a href="#5-1-4-dict结构体" class="headerlink" title="5.1.4 dict结构体"></a>5.1.4 dict结构体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* 字典的主操作类，对dictht结构再次包装  *&#x2F;</span><br><span class="line">typedef struct dict &#123;</span><br><span class="line">    &#x2F;&#x2F; 字典类型</span><br><span class="line">    dictType *type;</span><br><span class="line">    &#x2F;&#x2F; 私有数据</span><br><span class="line">    void *privdata;</span><br><span class="line">    &#x2F;&#x2F; 一个字典中有两个哈希表</span><br><span class="line">    dictht ht[2];</span><br><span class="line">    &#x2F;&#x2F;rehash的标记，rehashidx&#x3D;&#x3D;-1，表示没在进行rehash</span><br><span class="line">    long rehashidx; </span><br><span class="line">    &#x2F;&#x2F; 当前正在使用的迭代器的数量</span><br><span class="line">    int iterators; </span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure>
<h4 id="5-1-5-dict结构总结"><a href="#5-1-5-dict结构总结" class="headerlink" title="5.1.5 dict结构总结"></a>5.1.5 dict结构总结</h4><p>上面的结构体如果看得你头昏脑胀，没有关系，下面两张图让你理清他们的关系：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-713ec9ca17f9f0c789e9b94986d7ee907a0.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-53481663c1f1a2a56aebcc0edb1c2aa0daa.png" alt=""></p>
<blockquote>
<p>可以很清楚的看到，通过“拉链法”来解决冲突问题的，dictEntry结构体的*next指针指向了其拉链列表的下一个节点。</p>
</blockquote>
<ul>
<li><p>上图中，dict是字典的包装对象，居于最外层。</p>
</li>
<li><p>ht[2]是包含两个项的哈希表的数组，一般情况下，只使用h[0]，h[1]只有在rehash的时候才会使用</p>
</li>
</ul>
<ul>
<li><p>dictht是哈希表的结构，他除了一个数组table用来存放键值对以外，还有used字段表示目前已有键值对，size表示数组大小，sizemark=size-1，用来hash索引。</p>
</li>
<li><p>dictType是类型特定函数，上图中从上到下，依次是：</p>
<ol>
<li>HashFunction  计算哈希值的函数</li>
<li>KeyDup       复制键的函数</li>
<li>ValDup          复制值的函数</li>
<li>KeyCompare    对比键的函数</li>
<li>KeyDestructor   销毁键的函数</li>
<li>ValDestructor    销毁值的函数</li>
</ol>
</li>
</ul>
<h3 id="5-2-dict的哈希算法"><a href="#5-2-dict的哈希算法" class="headerlink" title="5.2 dict的哈希算法"></a>5.2 dict的哈希算法</h3><p>Redis提供了三种不同的散列函数，分别是：</p>
<ul>
<li>使用Thomas Wang’s 32 bit Mix哈希算法，对一个整型进行哈希，该方法在dictIntHashFunction函数中实现。  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">unsigned int dictIntHashFunction(unsigned int key)      &#x2F;&#x2F;用于计算int整型哈希值的哈希函数</span><br><span class="line">&#123;</span><br><span class="line">	key +&#x3D; ~(key &lt;&lt; 15);</span><br><span class="line">	key ^&#x3D;  (key &gt;&gt; 10);</span><br><span class="line">	key +&#x3D;  (key &lt;&lt; 3);</span><br><span class="line">	key ^&#x3D;  (key &gt;&gt; 6);</span><br><span class="line">	key +&#x3D; ~(key &lt;&lt; 11);</span><br><span class="line">	key ^&#x3D;  (key &gt;&gt; 16);</span><br><span class="line">	return key;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>使用MurmurHash2哈希算法对字符串进行哈希，该方法在dictGenHashFunction函数中实现。(当字典被用作数据库的底层实现，或者哈希键的底层实现时，Redis用MurmurHash2算法来计算哈希值，能产生32-bit或64-bit哈希值。)  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">unsigned int dictGenHashFunction(const void *key, int len) &#123;  &#x2F;&#x2F;用于计算字符串的哈希值的哈希函数</span><br><span class="line">	&#x2F;&#x2F;m和r这两个值用于计算哈希值，只是因为效果好。</span><br><span class="line">	uint32_t seed &#x3D; dict_hash_function_seed;</span><br><span class="line">	const uint32_t m &#x3D; 0x5bd1e995;</span><br><span class="line">	const int r &#x3D; 24;</span><br><span class="line">	&#x2F;* Initialize the hash to a &#39;random&#39; value *&#x2F;</span><br><span class="line">	uint32_t h &#x3D; seed ^ len;    &#x2F;&#x2F;初始化</span><br><span class="line">	&#x2F;* Mix 4 bytes at a time into the hash *&#x2F;</span><br><span class="line">	const unsigned char *data &#x3D; (const unsigned char *)key;</span><br><span class="line">	&#x2F;&#x2F;将字符串key每四个一组看成uint32_t类型，进行运算的到h</span><br><span class="line">	while(len &gt;&#x3D; 4) &#123;</span><br><span class="line">		uint32_t k &#x3D; *(uint32_t*)data;</span><br><span class="line">		k *&#x3D; m;</span><br><span class="line">		k ^&#x3D; k &gt;&gt; r;</span><br><span class="line">		k *&#x3D; m;</span><br><span class="line">		h *&#x3D; m;</span><br><span class="line">		h ^&#x3D; k;</span><br><span class="line">		data +&#x3D; 4;</span><br><span class="line">		len -&#x3D; 4;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;* Handle the last few bytes of the input array  *&#x2F;</span><br><span class="line">	switch(len) &#123;</span><br><span class="line">	case 3: h ^&#x3D; data[2] &lt;&lt; 16;</span><br><span class="line">	case 2: h ^&#x3D; data[1] &lt;&lt; 8;</span><br><span class="line">	case 1: h ^&#x3D; data[0]; h *&#x3D; m;</span><br><span class="line">	&#125;;</span><br><span class="line">	&#x2F;* Do a few final mixes of the hash to ensure the last few</span><br><span class="line">	 * bytes are well-incorporated. *&#x2F;</span><br><span class="line">	h ^&#x3D; h &gt;&gt; 13;</span><br><span class="line">	h *&#x3D; m;</span><br><span class="line">	h ^&#x3D; h &gt;&gt; 15;</span><br><span class="line">	return (unsigned int)h;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>在dictGenCaseHashFunction函数中提供了一种比较简单的djb哈希算法，对字符串进行哈希。（djb哈希算法，算法的思想是利用字符串中的ascii码值与一个随机seed，通过len次变换，得到最后的hash值。）  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">unsigned int dictGenCaseHashFunction(const unsigned char *buf, int len) &#123;   &#x2F;&#x2F;用于计算字符串的哈希值的哈希函数</span><br><span class="line">	unsigned int hash &#x3D; (unsigned int)dict_hash_function_seed;</span><br><span class="line"></span><br><span class="line">	while (len--)</span><br><span class="line">		hash &#x3D; ((hash &lt;&lt; 5) + hash) + (tolower(*buf++)); &#x2F;* hash * 33 + c *&#x2F;</span><br><span class="line">	return hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="5-3-dict的rehash"><a href="#5-3-dict的rehash" class="headerlink" title="5.3 dict的rehash"></a>5.3 dict的rehash</h3><p>当哈希表的大小不能满足需求，就可能会有两个或者以上数量的键被分配到了哈希表数组上的同一个索引上，于是就发生冲突（collision），在Redis中解决冲突的办法我们提到过是拉链法（separate chaining）。</p>
<p>但是我们仍然需要尽可能避免冲突，希望哈希表的负载因子（load factor），维持在一个合理的范围之内，就需要对哈希表进行扩展或收缩。</p>
<p>Rehsh会根据负载因子（load_factor = ht[0].used/ht[0].size）调整，当满足如下任意条件时，哈希表会rehash拓展：</p>
<ol>
<li>在服务器没有执行BGSAVE或BGREWRITEAOF，即没有持久化数据的时候，如果负载因子大于等于1</li>
<li>在服务器正在执行BGSAVE或BGREWRITEAOF时，如果负载因子大于等于5</li>
</ol>
<p>Rehash扩展有三个步骤:</p>
<ol>
<li>扩展备用的ht[1]，将它的容量扩张到<strong>第一个大于ht[0].used*2的 2的n次方</strong></li>
<li>将ht[0]的值重新经过hash索引之后迁移到ht[1]上。</li>
<li>释放ht[0]，将ht[1]设为ht[0]，创建新的空表ht[1]。<blockquote>
<p>注意：当负载因子小于0.1时，进行收缩操作，步骤将上述三步中的<strong>大于</strong>变为<strong>小于</strong>就是</p>
</blockquote>
</li>
</ol>
<h4 id="5-3-1-Rehash是渐进式的"><a href="#5-3-1-Rehash是渐进式的" class="headerlink" title="5.3.1 Rehash是渐进式的"></a>5.3.1 Rehash是渐进式的</h4><p> Rehash不是一步完成的，而是在操作过程中渐进式的。字典维持一个<strong>索引计数器rehashidx</strong>用来记录当前正在操作的索引，从ht[0]的0号索引上开始，<strong>一个项一个项的迁移到ht[1]</strong>，直到完成所有迁移，rehashidx变成-1。</p>
<p> 在rehash期间，所有新增字段添加在ht[1]中，而删除，更新操作会在两个表上同时进行。查找时先找ht[0]，再找ht[1]。</p>
<h2 id="6-跳跃表-skiplist"><a href="#6-跳跃表-skiplist" class="headerlink" title="6 跳跃表 skiplist"></a>6 跳跃表 skiplist</h2><p>跳跃表是有序集合zset的底层实现之一（另一个是压缩列表），当元素数量比较多，或者元素成员是比较长的字符串时，底层实现采用跳跃表。</p>
<p>跳跃表是一种<strong>有序数据结构</strong>，他在一个节点中维持多个指向其他节点的指针</p>
<p>跳跃表的<strong>平均复杂度为O(logN)，最坏为O(N)</strong>，其效率可以和平衡树相媲美，而且跟<strong>平衡树</strong>相比，<strong>实现简单</strong>；</p>
<h3 id="6-1-平衡的跳跃表"><a href="#6-1-平衡的跳跃表" class="headerlink" title="6.1 平衡的跳跃表"></a>6.1 平衡的跳跃表</h3><p><img src="https://oscimg.oschina.net/oscnet/up-417f68c4ab9f1d7ceb35303dee800dc5c89.png" alt=""></p>
<p>如图：<strong>每一个竖列其实是一个节点</strong>。如果能通过在节点中维持多个指向不同节点的指针（比如node4（值为21）就有三个指针，分别指向node5（33），node6（37），node8（55）），那么就会得到一个平衡的跳跃表。</p>
<p>在平衡的跳跃表中是左右对称的，node2两层，node4三层，node8四层。这样查到某一个节点的复杂度都为O(logN)：</p>
<ul>
<li>比如要查46，可以走L4到55，再用55的后退指针得到46。</li>
<li>比如要查37，先走L2层到21，再前进一步得到33。</li>
</ul>
<p>可以看到，上述表中，找到任何一个节点，时间复杂度<strong>不超过两次跳跃</strong>。</p>
<p><strong>但是，跳跃表最难的，就是保持平衡，维持平衡的跳跃表难度要大于维持平衡的二叉树。故而易于实现的，是实现<em>概率平衡<em>，而不是</em>强制平衡</em></strong></p>
<h4 id="6-1-1-跳跃表的查询"><a href="#6-1-1-跳跃表的查询" class="headerlink" title="6.1.1 跳跃表的查询"></a>6.1.1 跳跃表的查询</h4><p>跳跃表的查询是从顶层往下找，那么会先从第顶层开始找，方式就是循环比较，如过顶层节点的下一个节点为空说明到达末尾，会跳到第二层，继续遍历，直到找到对应节点。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f87590f2742d68eabeebbcd26f5c44fe8f8.png" alt=""></p>
<p>例子：查找元素 117</p>
<ol>
<li>比较 21， 比 21 大，且21有后继，向后面找</li>
<li>比较 37, 比 37大，且37节点同层没有后继了，则从 37 的下面一层开始找</li>
<li>比较 71, 比 71 大，且71节点同层没有后继了，则从 71 的下面一层开始找</li>
<li>比较 85， 比 85 大，且85有后继，向后面找</li>
<li>比较 117， 等于 117， 找到了节点。</li>
</ol>
<h4 id="6-1-2-跳表的删除"><a href="#6-1-2-跳表的删除" class="headerlink" title="6.1.2 跳表的删除"></a>6.1.2 跳表的删除</h4><p>使用标准的 delete from list 方法删除该节点。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-3b0a0c32dfd79ae06682a776c19c90234d3.png" alt=""></p>
<h3 id="6-2-Redis中的跳跃表的实现"><a href="#6-2-Redis中的跳跃表的实现" class="headerlink" title="6.2 Redis中的跳跃表的实现"></a>6.2 Redis中的跳跃表的实现</h3><p>为了尽可能的维持理想的跳跃表，Redis根据<strong>幂次定律</strong>来使跳跃表尽可能的平衡，我们先看Redis中跳跃表和跳跃表<strong>节点</strong>的结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-70e4d2aeab504a37e26ac2fcbe36f60faa1.png" alt=""></p>
<p>我们逐个分析</p>
<ul>
<li><p>zskiplistNode 表示跳跃表节点结构</p>
<ul>
<li>ele是个SDS，是有序集合的值element。</li>
<li>Score是double结构，存储分数值。</li>
<li>Backward，后退指针，指向列表前一个node。</li>
<li>Level [ ]数组，表示一个节点可以有多个层。<ul>
<li>数组里面的项是zskiplistLevel结构，可以看到，每一层都有一个跳跃指针forward。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-4b6dcf80fa31562f83545c064df02e16302.png" alt=""></li>
<li>跨度span，顾名思义，就是用来记录跨度的，相邻的节点跨度为1。</li>
<li>注意：跨度的用处是用来计算某个节点在跳跃表中的排位的，zset的排序按score从小到大排序。比如我查找到node7，通过将沿途的<strong>所有跨度累加</strong>，我们可以得到其排在列表中的序列。</li>
</ul>
</li>
</ul>
</li>
<li><p>zskiplist 表示跳跃表结构</p>
<ul>
<li>zskiplist中有指向整个跳跃表两端的head指针和tail指针</li>
<li>记录跳跃表长度的leng字段。</li>
<li><strong>Int型的level用来记录目前整个跳跃表中最高的层数</strong>。</li>
</ul>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-7aa4b36237430d0296ff16d8d80d656494a.png" alt=""></p>
<h3 id="6-3-一般情况下维持平衡跳跃表的实现"><a href="#6-3-一般情况下维持平衡跳跃表的实现" class="headerlink" title="6.3 一般情况下维持平衡跳跃表的实现"></a>6.3 一般情况下维持平衡跳跃表的实现</h3><ol>
<li>在跳跃表中插入一个新的节点时，程序需要确定两个要素：该节点的位置，以及层数</li>
<li>因为有序集合按照score排序，故而位置可以按照score比出，确定位置。</li>
<li>确定了位置后，再确定node的层数，可以采用抛硬币的方式，一次正面，层数+1，直到反面出现为止。因为抛硬币会使层数L的值满足参数为 p = 1/2 的几何分布，在数量足够大时，可以近似平衡。</li>
<li>用抛硬币的方式，可以使level+1的概率为2分之一，也就是说，k层节点的数量是k+1层的1/2 ，你可以把它看成是一个二叉树。</li>
</ol>
<h3 id="6-4-Redis维持平衡跳跃表的实现"><a href="#6-4-Redis维持平衡跳跃表的实现" class="headerlink" title="6.4 Redis维持平衡跳跃表的实现"></a>6.4 Redis维持平衡跳跃表的实现</h3><p>与上述抛硬币的方式不同，Redis尽可能去掉不确定性，根据幂次定律维持一个尽可能理想的跳跃表（即节点数尽可能大时，整个链表尽可能平衡。）</p>
<h4 id="6-4-1-幂次定律"><a href="#6-4-1-幂次定律" class="headerlink" title="6.4.1 幂次定律"></a>6.4.1 幂次定律</h4><ul>
<li>含义是：如果某件事的发生频率和它的某个属性成幂关系，那么这个频率就可以称之为符合幂次定律。</li>
<li>表现是：少数几个事件的发生频率占了整个发生频率的大部分， 而其余的大多数事件只占整个发生频率的一个小部分。</li>
<li>说人话版：<strong>越大的数，出现的概率越小</strong>。</li>
</ul>
<h4 id="6-4-2-实现算法"><a href="#6-4-2-实现算法" class="headerlink" title="6.4.2 实现算法"></a>6.4.2 实现算法</h4><ul>
<li><p>当Redis在跳跃表中插入一个新的节点时，程序需要确定两个要素：该节点的位置，以及层数</p>
</li>
<li><p>Redis的实现与一般维持平衡跳跃表的实现大同小异，Redis中跳跃表的层数也是在插入的时候确定，按照分数找好位置后，Redis会生成一个1-32的数作为层数。</p>
</li>
<li><p>Redis的level+1的概率是1/4,所以Redis的跳跃表是一个四叉树。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">level &#x3D; zslRandomLevel();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;下面是 zslRandomLevel() 函数的具体实现：</span><br><span class="line">&#x2F;* Returns a random level for the new skiplist node we are going to create.</span><br><span class="line"> * The return value of this function is between 1 and ZSKIPLIST_MAXLEVEL</span><br><span class="line"> * (both inclusive), with a powerlaw-alike distribution where higher</span><br><span class="line"> * levels are less likely to be returned. *&#x2F;</span><br><span class="line"> &#x2F;&#x2F;这个函数返回一个随机值，范围在：1 到 ZSKIPLIST_MAXLEVEL 之间，最小值为 1。</span><br><span class="line">int zslRandomLevel(void) &#123;</span><br><span class="line">    int level &#x3D; 1;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;(random()&amp;0xFFFF 得到 &lt;&#x3D; 0xFFFF的随机数，这个随机数比ZSKIPLIST_P * 0xFFFF小的概率为ZSKIPLIST_P。</span><br><span class="line">    while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF))</span><br><span class="line">        level +&#x3D; 1;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;最大不会超过ZSKIPLIST_MAXLEVEL</span><br><span class="line">    return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;每一次while为true的概率都为ZSKIPLIST_P，换个角度想就是level n的概率为 ZSKIPLIST_P ^ (n-1)。</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ZSKIPLIST_P=0.25，所以Redis的跳跃表是一个四叉树。</p>
<h2 id="7-整数集合-intset"><a href="#7-整数集合-intset" class="headerlink" title="7 整数集合 intset"></a>7 整数集合 intset</h2><p>整数集合是set的底层实现之一，当一个集合中只包含整数值，并且元素数量不多时，redis使用整数集合作为set的底层实现。</p>
<h3 id="7-1-数据结构"><a href="#7-1-数据结构" class="headerlink" title="7.1 数据结构"></a>7.1 数据结构</h3><p><img src="https://oscimg.oschina.net/oscnet/up-504f3c5be7d45452af037a4ff1fa3a0087e.png" alt=""></p>
<ul>
<li>Encoding 存储编码方式</li>
<li>Length  inset的长度，即元素数量</li>
<li>Content   Int数组，用来保存元素，各个项在数组中按数值从小到大排序，不包含重复项</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-197396aea88a0d869af62e1fa24fc0b068f.png" alt=""></p>
<blockquote>
<p>注意：虽然content数组的结构是int8_t，但其实他不会存储任何int8_t类型的值，当encoding=INTSET_ENC_INT16，那么他存的就是int16_t。以此类推，还有int32和int64。</p>
</blockquote>
<h3 id="7-2-整数集合的升级"><a href="#7-2-整数集合的升级" class="headerlink" title="7.2 整数集合的升级"></a>7.2 整数集合的升级</h3><p>当在一个int16类型的整数集合中插入一个int32类型的值，整个集合的所有元素都会转换成32类型。<br>整个过程有三步：</p>
<ol>
<li><p>根据新元素的类型（比如int32），扩展整数集合底层数组的空间大小，并为新元素分配空间。</p>
</li>
<li><p>将底层数组现有的所有元素都转换成与新元素相同的类型， 并将类型转换后的元素放置到正确的位上， 而且在放置元素的过程中， 需要继续维持底层数组的有序性质不变。</p>
</li>
<li><p>最后改变encoding的值，length+1。</p>
</li>
</ol>
<p>举个例子， 假设现在有一个<code>INTSET_ENC_INT16</code>编码的整数集合， 集合中包含三个 int16_t 类型的元素。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-527a9df97126e409ffd78f281302358fe4a.png" alt=""></p>
<p>因为每个元素都占用 16 位空间， 所以整数集合底层数组的大小为 3 * 16 = 48 位， 图 6-4 展示了整数集合的三个元素在这 48 位里的位置。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-5337e299b492cee7a39513cf3672b48cd7d.png" alt=""></p>
<p>现在， 假设我们要将类型为 int32_t 的整数值 65535 添加到整数集合里面， 因为 65535 的类型 int32_t 比整数集合当前所有元素的类型都要长， 所以在将 65535 添加到整数集合之前， 程序需要先对整数集合进行升级。</p>
<p>升级首先要做的是， 根据新类型的长度， 以及集合元素的数量（包括要添加的新元素在内）， 对底层数组进行空间重分配。</p>
<p>整数集合目前有三个元素， 再加上新元素 65535 ， 整数集合需要分配四个元素的空间， 因为每个 int32_t 整数值需要占用 32 位空间， 所以在空间重分配之后， 底层数组的大小将是 32 * 4 = 128 位， 如图 6-5 所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-d39ad394e9c97feee8c766d2ec7bf53685a.png" alt=""></p>
<p>虽然程序对底层数组进行了空间重分配， 但数组原有的三个元素 1 、 2 、 3 仍然是 int16_t 类型， 这些元素还保存在数组的前 48 位里面， 所以程序接下来要做的就是将这三个元素转换成 int32_t 类型， 并将转换后的元素放置到正确的位上面， 而且在放置元素的过程中， 需要维持底层数组的有序性质不变。</p>
<p>首先， 因为元素 3 在 1 、 2 、 3 、 65535 四个元素中排名第三， 所以它将被移动到 contents 数组的索引 2 位置上， 也即是数组 64 位至 95位的空间内。因为元素 2 在 1 、 2 、 3 、 65535 四个元素中排名第二， 所以它将被移动到 contents 数组的索引 1 位置上， 也即是数组的 32 位至 63 位的空间内， 如图 6-7 所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7b54a434071d7d0d42a3e926621cdb02b88.png" alt=""></p>
<p>之后， 因为元素 1 在 1 、 2 、 3 、 65535 四个元素中排名第一， 所以它将被移动到 contents 数组的索引 0 位置上， 也即是数组的 0 位至 31位的空间内， 如图 6-8 所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-726879c870feb95bbdf5ff302348de545a3.png" alt=""></p>
<p>然后， 因为元素 65535 在 1 、 2 、 3 、 65535 四个元素中排名第四， 所以它将被添加到 contents 数组的索引 3 位置上， 也即是数组的 96 位至 127 位的空间内， 如图 6-9 所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-dc660d12146cd03ff50fc5c1c6ff08083e6.png" alt=""></p>
<p>最后， 程序将整数集合 encoding 属性的值从 INTSET_ENC_INT16 改为 INTSET_ENC_INT32 ， 并将 length 属性的值从 3 改为 4 ， 设置完成之后的整数集合如图 6-10 所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-7b1384f5a3986181d02c59a30c8b1ab2be6.png" alt=""></p>
<blockquote>
<p>因为每次向整数集合添加新元素都可能会引起升级， 而每次升级都需要对底层数组中已有的所有元素进行类型转换， 所以向整数集合添加新元素的时间复杂度为 O(N) 。</p>
</blockquote>
<blockquote>
<p>注意，整数集合只支持升级操作，不支持<strong>降级操作</strong></p>
</blockquote>
<blockquote>
<p>升级之后新元素的摆放位置如何确定？因为引发升级的新元素的长度总是比整数集合现有所有元素的长度都大， 所以这个新元素的值要么就大于所有现有元素， 要么就小于所有现有元素：</p>
<ul>
<li>在新元素小于所有现有元素的情况下， 新元素会被放置在底层数组的最开头（索引 0 ）；</li>
<li>在新元素大于所有现有元素的情况下， 新元素会被放置在底层数组的最末尾（索引 length-1 ）。</li>
</ul>
</blockquote>
<h2 id="8-压缩列表-ziplist"><a href="#8-压缩列表-ziplist" class="headerlink" title="8 压缩列表 ziplist"></a>8 压缩列表 ziplist</h2><p>压缩列表是list和hash的底层实现之一，当一个列表只包含少量元素，并且每个元素要么就是小整数值，要么就是长度比较短的字符串，那么Redis使用ziplist作为列表实现。</p>
<p>压缩表是为了节约内存而开发的，压缩表可以包含任意个节点，每个节点保存一个字节数组（字符串）或一个整数值。</p>
<h3 id="8-1-压缩表数据结构"><a href="#8-1-压缩表数据结构" class="headerlink" title="8.1 压缩表数据结构"></a>8.1 压缩表数据结构</h3><p><img src="https://oscimg.oschina.net/oscnet/up-dcf94c09f6de184765b374036918756b9e1.png" alt=""></p>
<ul>
<li>Zlbytes 类型：uint32_t   记录整个压缩表占用的内存字节数，对压缩表进行内存重分配和或者计算zlend位置时被使用</li>
<li>Zltail_offset   类型：uint32_t    记录压缩列表尾节点entryN距离压缩列表的起始地址的字节数。用来快速确定表尾节点的地址。</li>
<li>Zllength   类型：uint16_t    若不超过uint16的极值65535，就是<strong>记录着压缩表节点的数量</strong>。否则，真实的节点数量需要遍历压缩表才能得出</li>
<li>Zlend   类型：uint8_t    特殊值0xFF（十进制255），用于标记表的末端。</li>
<li>Entry    char[]或uint     长度不定，节点的长度随保存的内容而改变。</li>
</ul>
<h3 id="8-2-压缩表节点的结构"><a href="#8-2-压缩表节点的结构" class="headerlink" title="8.2 压缩表节点的结构"></a>8.2 压缩表<strong>节点</strong>的结构</h3><p><img src="https://oscimg.oschina.net/oscnet/up-3c3b0793d2b96c8ea61d178eccfe64c1ec8.png" alt=""></p>
<ul>
<li>prevrawlen：前置节点的长度（以字节为单位）</li>
<li>prevrawlensize：存储 prevrawlen 的值所需的字节大小</li>
<li>len：当前节点的长度</li>
<li>lensize：存储 len 的值所需的字节大小</li>
<li>headersize：当前节点 header 的大小，等于 prevrawlensize + lensize</li>
<li>encoding：当前节点值所使用的编码类型</li>
<li>p：指向当前节点的指针</li>
</ul>
<p>虽然定义了这个结构体，但是Redis<strong>根本就没有使用</strong>zlentry结构来作为压缩列表中用来存储数据节点中的结构，这个结构总共在32位机占用了28个字节(32位机)，在64位机占用了32个字节。这不符合压缩列表的设计目的：提高内存的利用率。</p>
<p>ziplist在存储节点信息时，并没有将zlentry数据结构所有属性保存，而是做了简化。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-ab3f09a0f2c6679b6087075e4f9ad585ec2.png" alt=""></p>
<p><strong>虽然在压缩列表中使用的是”压缩版”的zlentry结构，但是在对节点操作时，还是要将”压缩版” “翻译”到zlentry结构中，因为我们无法对着一串字符直接进行操作。</strong></p>
<p>因此，就有了下面的函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* Return a struct with all information about an entry. *&#x2F;</span><br><span class="line">&#x2F;&#x2F; 将p指向的列表节点信息全部保存到zlentry中，并返回该结构</span><br><span class="line">static zlentry zipEntry(unsigned char *p) &#123;</span><br><span class="line">    zlentry e;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; e.prevrawlensize 保存着编码前一个节点的长度所需的字节数</span><br><span class="line">    &#x2F;&#x2F; prevrawlen 保存着前一个节点的长度</span><br><span class="line">    ZIP_DECODE_PREVLEN(p, e.prevrawlensize, e.prevrawlen);  &#x2F;&#x2F;恢复前驱节点的信息</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; p + e.prevrawlensize将指针移动到当前节点信息的起始地址</span><br><span class="line">    &#x2F;&#x2F; encoding保存当前节点的编码格式</span><br><span class="line">    &#x2F;&#x2F; lensize保存编码节点值长度所需的字节数</span><br><span class="line">    &#x2F;&#x2F; len保存这节点值的长度</span><br><span class="line">    ZIP_DECODE_LENGTH(p + e.prevrawlensize, e.encoding, e.lensize, e.len);  &#x2F;&#x2F;恢复当前节点的信息</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;当前节点header的大小 &#x3D; lensize + prevrawlensize</span><br><span class="line">    e.headersize &#x3D; e.prevrawlensize + e.lensize;    </span><br><span class="line">    e.p &#x3D; p;    &#x2F;&#x2F;保存指针</span><br><span class="line">    return e;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;ZIP_DECODE_PREVLEN和ZIP_DECODE_LENGTH都是定义的两个宏，在ziplist.c文件中</span><br></pre></td></tr></table></figure>


<h4 id="8-2-1-prev-entry-len"><a href="#8-2-1-prev-entry-len" class="headerlink" title="8.2.1 prev_entry_len"></a>8.2.1 prev_entry_len</h4><p>prev_entry_len成员实际上就是zlentry结构中prevrawlensize(记录存储prevrawlen值的所需的字节个数)和prevrawlen(记录着上一个节点的长度)这两个成员的压缩版。</p>
<ul>
<li>如果前一节点的长度小于254（即2^8-1）字节，则pre_entry_len用一个字节记录其长度。</li>
<li>当前驱节点的长度大于等于255（即2^8-1）字节，那么prev_entry_len使用5个字节表示。<ul>
<li>并且用5个字节中的最高8位(最高1个字节)用 0xFE来标志prev_entry_len占用了5个字节，后四个字节才是真正保存前驱节点的长度值。</li>
</ul>
</li>
<li>pre_entry_len最大的用处是用来从后向前遍历，因为前一个节点的指针c = 当前节点指针p –pre_entry_len，可以快速往前上溯。</li>
</ul>
<blockquote>
<p>因为，对于访问的指针都是char 类型，它能访问的范围为1个字节，如果这个字节的大小等于0xFE，那么就会继续向后访问四个字节来获取前驱节点的长度，如果该字节的大小小于0xFE，那么该字节就是要获取的前驱节点的长度。因此这样就使prev_entry_len同时具有了prevrawlen和prevrawlensize的功能，而且更加节约内存。</p>
</blockquote>
<h4 id="8-2-2-encoding"><a href="#8-2-2-encoding" class="headerlink" title="8.2.2 encoding"></a>8.2.2 encoding</h4><p>prev_entry_len一样，encoding成员同样可以看做成zlentry结构中lensize（记录存储 len 所需的字节大小）和len（当前节点的长度）的压缩版。</p>
<p>Encoding记录了节点内容（value）的<strong>类型和长度</strong>。value可存的类型有两种，<strong>整数和字符串（字节数组）</strong>。Redis对字节数组和整数编码提供了一组宏定义，定义在ziplist.c中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* Different encoding&#x2F;length possibilities *&#x2F;</span><br><span class="line">#define ZIP_STR_MASK 0xc0               &#x2F;&#x2F;1100 0000     字节数组的掩码</span><br><span class="line">#define ZIP_STR_06B (0 &lt;&lt; 6)            &#x2F;&#x2F;0000 0000</span><br><span class="line">#define ZIP_STR_14B (1 &lt;&lt; 6)            &#x2F;&#x2F;0100 0000</span><br><span class="line">#define ZIP_STR_32B (2 &lt;&lt; 6)            &#x2F;&#x2F;1000 0000</span><br><span class="line"></span><br><span class="line">#define ZIP_INT_MASK 0x30               &#x2F;&#x2F;0011 0000     整数的掩码</span><br><span class="line">#define ZIP_INT_16B (0xc0 | 0&lt;&lt;4)       &#x2F;&#x2F;1100 0000</span><br><span class="line">#define ZIP_INT_32B (0xc0 | 1&lt;&lt;4)       &#x2F;&#x2F;1101 0000</span><br><span class="line">#define ZIP_INT_64B (0xc0 | 2&lt;&lt;4)       &#x2F;&#x2F;1110 0000</span><br><span class="line">#define ZIP_INT_24B (0xc0 | 3&lt;&lt;4)       &#x2F;&#x2F;1111 0000</span><br><span class="line">#define ZIP_INT_8B 0xfe                 &#x2F;&#x2F;1111 1110</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;掩码个功能就是区分一个encoding是字节数组编码还是整数编码</span><br><span class="line">&#x2F;&#x2F;如果这个宏返回 1 就代表该enc是字节数组，如果是 0 就代表是整数的编码</span><br><span class="line">#define ZIP_IS_STR(enc) (((enc) &amp; ZIP_STR_MASK) &lt; ZIP_STR_MASK)</span><br></pre></td></tr></table></figure>

<p>上面这些常量被如下代码使用：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;从ptr中取出节点信息，并将其保存在encoding、lensize和len中</span><br><span class="line">#define ZIP_DECODE_LENGTH(ptr, encoding, lensize, len) do &#123;                         \</span><br><span class="line">    &#x2F;*从ptr数组中取出节点的编码格式并将其赋值给encoding*&#x2F;                                  \</span><br><span class="line">    ZIP_ENTRY_ENCODING((ptr), (encoding));                                          \</span><br><span class="line">    &#x2F;*如果是字符串编码格式*&#x2F;                                                            \</span><br><span class="line">    if ((encoding) &lt; ZIP_STR_MASK) &#123;                                                 \</span><br><span class="line">        if ((encoding) &#x3D;&#x3D; ZIP_STR_06B) &#123;   &#x2F;*6位字符串编码格式*&#x2F;                        \</span><br><span class="line">            (lensize) &#x3D; 1;                 &#x2F;*编码长度需要1个字节*&#x2F;                      \</span><br><span class="line">            (len) &#x3D; (ptr)[0] &amp; 0x3f;       &#x2F;*当前字节长度保存到len中*&#x2F;                  \</span><br><span class="line">        &#125; else if ((encoding) &#x3D;&#x3D; ZIP_STR_14B) &#123;    &#x2F;*14位字符串编码格式*&#x2F;               \</span><br><span class="line">            (lensize) &#x3D; 2;                 &#x2F;*编码长度需要2个字节*&#x2F;                      \</span><br><span class="line">            (len) &#x3D; (((ptr)[0] &amp; 0x3f) &lt;&lt; 8) | (ptr)[1]; &#x2F;*当前字节长度保存到len中*&#x2F;    \</span><br><span class="line">        &#125; else if (encoding &#x3D;&#x3D; ZIP_STR_32B) &#123;   &#x2F;*32串编码格式*&#x2F;                       \</span><br><span class="line">            (lensize) &#x3D; 5;                   &#x2F;*编码长度需要5节*&#x2F;                        \</span><br><span class="line">            (len) &#x3D; ((ptr)[1] &lt;&lt; 24) |         &#x2F;*当前字节长度保存到len中*&#x2F;               \</span><br><span class="line">                    ((ptr)[2] &lt;&lt; 16) |                                                \</span><br><span class="line">                    ((ptr)[3] &lt;&lt;  8) |                                                \</span><br><span class="line">                    ((ptr)[4]);                                                       \</span><br><span class="line">        &#125; else &#123;                                                                      \</span><br><span class="line">            assert(NULL);                                                             \</span><br><span class="line">        &#125;                                                                             \</span><br><span class="line">    &#125; else &#123;    &#x2F;*整数编码格式*&#x2F;                                                        \</span><br><span class="line">        (lensize) &#x3D; 1;            &#x2F;*需要1个字节*&#x2F;                                      \</span><br><span class="line">        (len) &#x3D; zipIntSize(encoding);                                                 \</span><br><span class="line">    &#125;                                                                                 \</span><br><span class="line">&#125; while(0);</span><br></pre></td></tr></table></figure>

<p>看不懂没关系，简单归纳就是：</p>
<table>
<thead>
<tr>
<th align="center">编码格式</th>
<th align="center">value类型</th>
<th align="center">encoding长度</th>
<th align="center">value保存的值长度</th>
<th align="center">解释</th>
</tr>
</thead>
<tbody><tr>
<td align="center">00xxxxxx</td>
<td align="center">字节数组</td>
<td align="center">1字节</td>
<td align="center">长度小于等于 2^6−1 字节</td>
<td align="center">encoding长8bit，后6个bit，最多承载数量2^6−1的数字，说明其最多能为长度为2^6−1的字节数组计数</td>
</tr>
<tr>
<td align="center">01xxxxxx xxxxxxxx</td>
<td align="center">字节数组</td>
<td align="center">2字节</td>
<td align="center">长度小于等于2^14−1字节</td>
<td align="center">encoding长16bit，后14个bit，最多承载数量2^14−1的数字，说明其最多能为长度为2^14−1的字节数组计数</td>
</tr>
<tr>
<td align="center">10—— xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx</td>
<td align="center">字节数组</td>
<td align="center">5字节</td>
<td align="center">长度小于等于2^32−1字节</td>
<td align="center">encoding长40bit，前两位bit10表示该encoding5字节，然后6bit留空，最后32个bit，最多承载数量2^32−1的数字，说明其最多能为长度为2^32−1的字节数组计数</td>
</tr>
<tr>
<td align="center">1100 0000</td>
<td align="center">整数</td>
<td align="center">1字节</td>
<td align="center">int16_t类型整数</td>
<td align="center">—–</td>
</tr>
<tr>
<td align="center">1101 0000</td>
<td align="center">整数</td>
<td align="center">1字节</td>
<td align="center">int32_t类型整数</td>
<td align="center">—–</td>
</tr>
<tr>
<td align="center">1110 0000</td>
<td align="center">整数</td>
<td align="center">1字节</td>
<td align="center">int64_t类型整数</td>
<td align="center">—–</td>
</tr>
<tr>
<td align="center">1111 0000</td>
<td align="center">整数</td>
<td align="center">1字节</td>
<td align="center">24 bit 有符号整数</td>
<td align="center">—–</td>
</tr>
<tr>
<td align="center">1111 1110</td>
<td align="center">整数</td>
<td align="center">1字节</td>
<td align="center">8 bit 有符号整数</td>
<td align="center">—–</td>
</tr>
<tr>
<td align="center">1111 xxxx</td>
<td align="center">整数</td>
<td align="center">1字节</td>
<td align="center">4 bit 无符号整数,[0,12]</td>
<td align="center">encoding为该值的节点是没有value的，因为xxxx已经足够存储0-12的值了，<strong>value直接存在encoding中</strong>。xxxx首先最小值应该是0001（0000已经被占用），最大值应该是1101（1110与1111均已经被占用），因此，可被编码的值实际上只能是 1 至 13，由于还需要减1，所以实际只能编码[0,12]，至于减1的理由，我的理解是方便编码0。</td>
</tr>
</tbody></table>
<h4 id="8-2-3-value"><a href="#8-2-3-value" class="headerlink" title="8.2.3 value"></a>8.2.3 value</h4><p>根据encoding来保存字节数组或整数。我们举例说明：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-460ea93659f8a9216f91160daf7b0d2ee92.png" alt=""></p>
<p>假设这是一个压缩列表的头两个节点，因此：</p>
<ul>
<li>第一个节点信息：<ul>
<li>prev_entry_len成员值为0，占1字节空间，因为前驱节点长度为0，小于254。</li>
<li>encoding成员值为0000 0101，最高两位为00，因此encoding占1个字节且可以算出value为字符数组，根据剩下的6位00 0101，可以算出value长度为5字节。</li>
<li>value成员根据encoding成员算出长度为5字节，因此，会读5个字节的字节数组，值为”Redis”。</li>
</ul>
</li>
<li>第二个节点信息：<ul>
<li>prev_entry_len成员值为0x07，占一个字节，因为前驱节点长度为7，小于254。<br>encoding成员编码值为1101 0000，最高两位为11，因此encoding占1个字节且可以算出value为整数，在根据encoding编码可以得出value值为占32位，4个字节int32_t类型的有符号整数。</li>
<li>value成员根据encoding编码，读出4个字节的整数，值为 1234。</li>
</ul>
</li>
<li>压缩列表的表头信息：<ul>
<li>zlbytes为整个压缩列表所占字节数24。</li>
<li>zltail_offset为从压缩列表的首地址到最后一个entry节点的偏移量17。</li>
<li>zlength为节点个数2。</li>
<li>zlend为常数255(0xFF)。</li>
</ul>
</li>
</ul>
<h3 id="8-3-连锁更新"><a href="#8-3-连锁更新" class="headerlink" title="8.3 连锁更新"></a>8.3 连锁更新</h3><p>因为有如下的前提，所以才会出现连锁更新的场景：</p>
<ul>
<li><p>如果前驱节点的长度小于254（2^8-1），那么prev_entry_len成员需要用1字节长度来保存这个长度值。</p>
</li>
<li><p>如果前驱节点的长度大于等于254（2^8-1），那么prev_entry_len成员需要用5字节长度来保存这个长度值。</p>
</li>
</ul>
<p>如果在一个压缩列表中，有<strong>多个连续、长度介于250字节到253字节之间的节点</strong>，因此记录这些节点只需要1个字节的prev_entry_len，如果要插入一个长度<strong>大于等于254的新节点e0</strong>到压缩列表的头部，然而原来的头节点e1的prev_entry_len成员长度仅仅为1个字节，无法保存新节点的长度，这会使得e1的prev_entry_len必须扩容到5个节点。e1的长度本来就在[250,254]之间，一扩容又大于了254，使得e2又要扩容，以此类推，引发连锁扩展。</p>
<p>反之，也会引发连锁收缩。</p>
<blockquote>
<p>因为ziplist是链表，他们节点之间不是紧挨着的，所以重分配的代价并不是特别大。</p>
</blockquote>
<hr>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.zhihu.com/question/25624589/answer/61382148" target="_blank" rel="noopener" title="为什么redis小等于39字节的字符串是embstr编码，大于39是raw编码？">为什么redis小等于39字节的字符串是embstr编码，大于39是raw编码？</a></p>
<p><a href="https://blog.csdn.net/xiejingfa/article/details/51018337" target="_blank" rel="noopener" title="【Redis源码剖析】 - Redis内置数据结构之字典dict">【Redis源码剖析】 - Redis内置数据结构之字典dict</a></p>
<p><a href="https://blog.csdn.net/kisimple/article/details/38706729" target="_blank" rel="noopener" title="SkipList 浅析">SkipList 浅析</a></p>
<p><a href="https://www.jianshu.com/p/c21a1d51a33b" target="_blank" rel="noopener" title="整数集合">整数集合</a></p>
<p><a href="http://blog.csdn.net/men_wen/article/details/70176753" target="_blank" rel="noopener" title="Redis源码剖析和注释（六）--- 压缩列表(ziplist)">Redis源码剖析和注释（六）— 压缩列表(ziplist)</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/03/Class%E6%96%87%E4%BB%B6%E5%92%8C%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/03/Class%E6%96%87%E4%BB%B6%E5%92%8C%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/" itemprop="url">Class文件和类加载机制</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-12-03T22:59:01+08:00">
                2019-12-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/JAVA-JVM/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA JVM</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/12/03/Class%E6%96%87%E4%BB%B6%E5%92%8C%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/12/03/Class文件和类加载机制/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  11.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  40
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-class文件结构"><a href="#1-class文件结构" class="headerlink" title="1 class文件结构"></a>1 class文件结构</h1><ul>
<li><p>Class文件结构是了解虚拟机的重要基础之一，如果想深入的了解虚拟机，Class文件结构是不能不了解的。</p>
</li>
<li><p>Class文件是一组以8位字节为基础单位的二进制流，各项数据项目严格按照顺序紧凑地排列在Class文件之中，中间没有添加任何分隔符，如果是超过8位字节以上空间的数据项，则会按照高位在前的方式（Big-Endian）分割成若干个8位字节进行存储。（Big-Endian模式具体可见<a href="https://blog.csdn.net/zhangpinghao/article/details/14031857" target="_blank" rel="noopener" title="详解大端模式和小端模式">详解大端模式和小端模式</a>）</p>
</li>
<li><p>Class文件中包含了Java虚拟机指令集和符号表以及若干其他辅助信息。</p>
</li>
<li><p>Class文件格式只有两种数据类型：无符号数和表。</p>
<ul>
<li>无符号数属于基本的数据类型，以u1,u2,u4,u8来分别代表1个字节，2个字节，4个字节和8个字节的无符号数；可用来描述数字，索引引用，数量值或者按照UTF-8编码构成的字符串值。</li>
<li>表是由<strong>多个无符号数或者其他表作为数据项构成的复合数据类型</strong>，所有表都习惯性地以“_info”结尾。表用于描述由层次关系的复合结构的数据。</li>
</ul>
</li>
<li><p>整个Class文件本质上就是一张表</p>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/up-4ba7398c95ae3265cf9332d9761b6160b9a.png" alt=""></p>
<blockquote>
<p>class文件的内容中没有任何的分隔符号，所以在上表中的数据项，无论是顺序还是数量，都是被严格限定的，哪个字节代表什么含义，长度多少，先后顺序如何，都不允许改变。</p>
</blockquote>
<h2 id="1-1-魔数和class文件的版本"><a href="#1-1-魔数和class文件的版本" class="headerlink" title="1.1 魔数和class文件的版本"></a>1.1 魔数和class文件的版本</h2><ul>
<li><p>Class文件的头4个字节成为魔数（Magic Number），它唯一的作用是确定这个文件是否为一个能被虚拟机接受的Class文件，他是一个固定的值： 0XCAFEBABE（咖啡宝贝）。如果开头四个字节不是0XCAFEBABE， 那么就说明它不是class文件， 不能被JVM识别</p>
<ul>
<li>文件存储标准中都使用魔数来进行身份识别，比如图片格式，gif和JPEG等文件头中都存有魔数。使用魔数而非拓展名来识别身份，主要是基于安全方面的考虑，因为文件拓展名可以随意修改。</li>
</ul>
</li>
<li><p>紧接着魔数的4个字节是Class文件的版本号：第5,6字节是<strong>次版本号</strong>（Minor Version）,第7,8字节是<strong>主版本号</strong>（Major Version）。</p>
<ul>
<li>java版本号从45开始，jdk1.1以后每个jdk大版本发布，<strong>主版本</strong>号向上加1。（jdk1.0<del>1.1使用了45.0</del>45.3的版本号）</li>
<li>一般情况下， 高版本的JVM能识别低版本的javac编译器编译的class文件， 而低版本的JVM不能识别高版本的javac编译器编译的class文件。 如果使用低版本的JVM执行高版本的class文件， JVM会抛出java.lang.UnsupportedClassVersionError 。</li>
<li>下图为jdk1.1到jdk1.7，主流jdk编译器输出的默认和可支持的class文件版本号：</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-30ad9cf600f13a0f540843512252923e335.png" alt=""></li>
</ul>
</li>
</ul>
<h2 id="1-2-常量池"><a href="#1-2-常量池" class="headerlink" title="1.2 常量池"></a>1.2 常量池</h2><ul>
<li>紧接着主次版本号之后是常量池入口，由于常量池中<strong>常量的数量</strong>是不固定的，所以在常量池的入口需要放置一个常量池容量计数值（constant_pool_count）,这个容量计数是从1而不是0开始的，设计者这样设计的目的是为了满足后面某些指向常量池的索引值的数据在特殊情况下需要表达“不引用任何一个常量池项目”的含义。（所以上表中常量的数量为（constant_pool_count-1），因为第一项是计数器不，不是常量项）</li>
</ul>
<ul>
<li><p>常量池中主要存放两大类常量：字面量（Literal）和符号引用。</p>
<ul>
<li>字面量接近Java语言层面的常量概念，如文本字符串、声明为final的常量值等。</li>
<li>符号引用属于编译原理的概念，包括三类常量：<ol>
<li>类和接口的全限定名；</li>
<li>字段的名称和描述符；</li>
<li>方法的名称和描述符。</li>
</ol>
</li>
<li><blockquote>
<p>符号引用 ：符号引用以一组符号来描述所引用的目标。符号引用可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可，符号引用和虚拟机的布局无关。可以理解为：在编译的时候虚拟机并不知道引用对象的直接地址，多以就用符号引用来代替，而在解析阶段，就是为了把这个符号引用转化成为真正的地址的阶段。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>常量池中每一项常量都是一个表，在JDK1.7之后共有14种表结构（有14种不代表每个类的常量池都有全部的14种）。它们有一个共同的特点，就是表开始的第一位是一个u1类型的标志位（tag，取值见下表），代表当前这个常量属于哪种常量类型。</p>
</li>
<li><p><img src="https://oscimg.oschina.net/oscnet/up-5a1dc07d76e9c0a28e062301b28727fe654.png" alt=""></p>
</li>
<li><p>这14种常量类型各自有自己的结构，下面列出每个常量项的结构及含义</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-49edc6b667c3b7b848c539852736ab72b9c.png" alt=""></li>
</ul>
</li>
</ul>
<h2 id="1-3-访问标志"><a href="#1-3-访问标志" class="headerlink" title="1.3 访问标志"></a>1.3 访问标志</h2><ul>
<li><p>紧接着常量池之后的2个字节代表访问标志（access_flags），用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口、是否为public类型、是否为abstract类型、类是否声明为final等。标志位及其含义如下表</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-578f90a99345cf296903932a1c26223202d.png" alt=""></li>
</ul>
</li>
<li><p>假设一个类为普通java类，不是接口，不是枚举或者注解，被public修士但没有被声明为final和abstract，那么它的ACC_PUBLIC标志应该为真（即为1），而ACC_FINAL、ACC_INTERFACE、ACC_ABSTRACT等标志位都应该为假。</p>
</li>
<li><p>access_flags中一共有16个标志位可以使用，当前只定义了其中8个，没用使用到的标志位要求一律为0。</p>
</li>
</ul>
<h2 id="1-4-类索引、父类索引与接口索引集合"><a href="#1-4-类索引、父类索引与接口索引集合" class="headerlink" title="1.4 类索引、父类索引与接口索引集合"></a>1.4 类索引、父类索引与接口索引集合</h2><ul>
<li><p>Class文件中由 索引、父类索引与接口索引集合 这三项数据来确定这个类的继承关系。</p>
</li>
<li><p>访问标志之后顺序排列类索引、父类索引、接口索引集合。</p>
</li>
<li><p>类索引两个字节，用于确定这个类的全限定名。</p>
</li>
<li><p>父类索引两个字节，用于确定这个类的父类的全限定名。因为java不允许多继承，所以只有一个父类索引，除了Object类以外，所有的类都有父类索引。Object的父类索引值为0；</p>
</li>
<li><p>类索引和父类索引的值都指向了一个类型为CONSTANT_Class_info的类描述符常量，通过前文我们知道通过CONSTANT_Class_info类型中的index值可以定位到一个CONSTANT_Utf8_info类型的常量，该常量中有全限定名字符串。下图展示了其索引过程：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-cf8c4d9d9963e0af80de6ec7f744e3a6cc3.png" alt=""></li>
</ul>
</li>
<li><p>接口索引集合大小不确定，用来描述这个类实现了哪些接口。接口索引集合入口第一项是u2类型的接口计数器（interfaces_count）表示索引表的容量（即实现了几个接口）。如果该类没用实现任何接口，则计数器值为0，后面的接口索引表不再占用任何字节。否则，接口索引集合的内容也是为指向CONSTANT_Class_info类型的索引值。</p>
</li>
</ul>
<h2 id="1-5-字段表集合"><a href="#1-5-字段表集合" class="headerlink" title="1.5 字段表集合"></a>1.5 字段表集合</h2><p>排在接口索引集合后边的是字段计数器：用于标识有多少个字段；</p>
<p>接着就是字段表集合。字段表（field_info）用于描述接口或者类中声明的变量。字段包括类级变量以及实例级变量(不包括方法内声明的局部变量)。可以包括的信息有：</p>
<ol>
<li>字段的作用域（public、private、protected修饰符）</li>
<li>实例变量还是类变量（static修饰符）</li>
<li>可变性（final）</li>
<li>并发可见性（volatile）</li>
<li>可否被序列化（transient）</li>
<li>字段数据类型（基本类型，对象，数组）</li>
<li>字段名称</li>
</ol>
<p>我们来看下字段表集合的结构：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9df277841bf95f2056917158b5becf38812.png" alt=""></p>
<ul>
<li><p>access_flags：其中public、private、protected、static、final、volatile、transient这些修饰符都是用access_flags字段来表示的，和上面讲述的类的access_flags类似，即如果一个字段是public的，那么public对应的标志位应该为真（1），以此类推，这些修饰符对应的标志位如下图：</p>
<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-6bc20666d6f49db2c6069a6a040fb8899e9.png" alt=""></li>
</ul>
</li>
<li><p>name_index和descriptor_index:这两个index都是<strong>对常量池的引用</strong>，分别代表着字段的“简单名称”和“字段和方法的描述符”；</p>
<ul>
<li>全限定名：就是类名全称,例如:org/xxx/class/testClass，为了使连续的多个全限定名之间不产生混淆，在使用时最后一般会加入一个“;”表示全限定名结束。</li>
<li>简单名称：即没有类型和参数修饰的字段或者方法名称，例如方法test()的简单名称就是test，m字段的简单名称就是m。</li>
<li>描述符：描述符的作用是描述字段的数据类型、方法的参数列表（包括数量、类型及顺序）和返回值。根据描述符的规则，基本数据类型以及代表无返回值的void类型都用一个大写字符来表示，而对象类型则用字符L加对象的全限定名表示，见下表<ul>
<li><img src="https://oscimg.oschina.net/oscnet/up-b35f5e3bca8690a449ea15aaad29418860d.png" alt=""></li>
<li>对于数组类型，每一维度将使用一个前置的“[”字符来描述，如“String[][]”,会被记录为”[[Ljava/lang/String”，”int[]”被记录为“[I”。</li>
<li>描述符描述方法时，按照先参数列表，后返回值的顺序描述。参数列表按照参数的严格顺序放置一组小括号“()”内，如<ul>
<li>“void inc()” 的描述符为“()V”</li>
<li>“viod main(String[] args)” 的描述符为“([Ljava/lang/String;)V”</li>
<li>“int indexOf(char[] source,int sourceOffset,int sourceCount,char[] target,int targetOffset,int targetCount,int fromIndex)” 的描述符为“([CII[CIII)I”。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>字段表集合中不会列出从超类或者父类接口中继承而来的字段，但有可能列出原本Java代码之中不存在的字段。</p>
</li>
<li><p>在descriptor_index之后跟随着一个属性表集合用于存储一些额外的信息，字段都可以在属性表中描述零至多项的额外信息。对于本例中的字段m，他的属性表计数器为0，也就是说没有需要额外描述的信息，但是，如果将字段m的声明改为“int m=123”，那就可能会存在一项名称为ConstantValue的属性，其值指向常量123。</p>
</li>
</ul>
<h3 id="1-5-1-字段表集合demo"><a href="#1-5-1-字段表集合demo" class="headerlink" title="1.5.1 字段表集合demo"></a>1.5.1 字段表集合demo</h3><p>举例：假设对于一个TestClass.class文件来说，字段表集合从地址0x000000F*开始</p>
<ul>
<li>第一个u2类型的数据为容量计数器fields_count，如下图所示，其值为0x0001，说明这个类只有一个字段表数据。</li>
<li>接下来紧跟着容量计数器的是access_flags标志，值为0x0002，代表private修饰符的ACC_PRIVATE标志位为真（ACC_PRIVATE标志的值为0x0002），其他修饰符为假。</li>
<li>代表字段名称的name_index的值为0x0005，从常量表中可查的第5项常量是一个CONSTANT_UTF8_info类型的字符串，其值为“m”</li>
<li>代表字符描述符的descriptor_index的值为0x0006，指向常量池的字符串“I”，根据这些信息，我们可以推断出原代码定义的字段为：“private int m;”。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-49563d3e5f1385282014a4de040f188d14e.png" alt=""><h2 id="1-6-方法表集合"><a href="#1-6-方法表集合" class="headerlink" title="1.6 方法表集合"></a>1.6 方法表集合</h2></li>
</ul>
<p>排在后边的是方法计数器：用于标识有多少个方法；</p>
<p>Class文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方式，方法表的结构如同字段表一样，依次包括了访问标志（access_flags）、名称索引（name_index）、描述符索引（descriptor_index）、属性表结合（attributes）几项，见下表。这些数据项目的含义也非常类似，仅在访问标志和属性表集合的可选项中有所区别。<br><img src="https://oscimg.oschina.net/oscnet/up-ef3a3608c87b67b9e8a868b39fcc8c8c4bb.png" alt=""></p>
<ul>
<li><p>access_flags</p>
<ul>
<li>因为volatile关键字和transient关键字不能修饰方法，所以方法表的访问标志中没有了ACC_VOLATILE标志和ACC_TRANSIENT标志。</li>
<li>与之相对的，synchronized、native、strictfp和abstract关键字可以修饰方法，所以方法表的访问标志中增加了ACC_SYNCHRONIZED、ACC_NATIVE、ACC_STRICTFP和ACC_ABSTRACT标志。</li>
<li>对于方法表，所有标志位及其取值可参考下表。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-7a9b0f82f5daae316c14588e6ff88472bed.png" alt=""></li>
</ul>
</li>
<li><p>代码：方法的定义可以通过访问标志、名称索引、描述符索引表达清楚，但方法里面的代码去哪里了？方法里的Java代码，经过编译器编译成字节码指令后，存放在方法属性集合中一个名为“Code”的属性里面，属性表作为Class文件格式中最具扩展性的一种数据项目，我们将在下一内容进行介绍。</p>
</li>
<li><p>与字段表集合相对应的，如果父类方法在子类汇总没有被重写（Override），方法表集合中就不会出现来自父类的方法信息。但同样的，有可能会出现由编译器自动添加的方法，最典型的便是类构造器“&lt;clinit&gt;”方法和实例构造器“&lt;init&gt;”方法。</p>
<h3 id="1-6-1-方法表集合demo"><a href="#1-6-1-方法表集合demo" class="headerlink" title="1.6.1 方法表集合demo"></a>1.6.1 方法表集合demo</h3></li>
</ul>
<p>举例：假设有一个Class文件，对方法表集合进行分析。</p>
<ul>
<li>如下图所示，方法表集合的入口地址为：0x00000101，第一个u2类型的数据（即是计数器容量）的值为0x0002，代表集合中有两个方法（这两个方法为编译器添加的实例构造器&lt;int&gt;和源码中的方法inc()）。</li>
<li>第一个方法的访问标志值为0x001，也就是说只有ACC_PUBLIC标志为真，名称索引值为0x0007，查<strong>常量池</strong>得方法名为“&lt;init&gt;”，描述符索引值为0x0008，对应常量为“( ) V”。</li>
<li>属性表计数器attributes_count的值为0x0001就表示此方法的<strong>属性表集合</strong>有一项属性，属性名称索引为0x0009，对应常量为“Code”，说明此属性是方法的字节码描述。</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-fb5d03169ec70161436339635bb6852bdf2.png" alt=""></li>
</ul>
<h2 id="1-7-属性表集合"><a href="#1-7-属性表集合" class="headerlink" title="1.7 属性表集合"></a>1.7 属性表集合</h2><p>与Class文件中其他的数据项目要求严格的顺序、长度和内容不同，属性表集合的限制稍微宽松了一些，不再要求各个属性表具有严格顺序，并且只要不与已有属性名重复，任何人实现的编译器都可以向属性表具有严格顺序.</p>
<p>并且只要不与已有属性名重复，任何人实现的编译器都可以向属性表中写入自己定义的属性信息，Java虚拟机运行时会忽略掉他不认识的属性。</p>
<p>为了能正确解析Class文件，《java虚拟机规范》预定义21项虚拟机实现应当能识别的属性，具体内容见下表。下文中将对其中一些属性中的关键常用的部分进行讲解。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-aecdf06ebdaf14cd2c4aae8bf8ff82917fe.png" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/up-b2a280abbfbb65133ba325367f48302bb26.png" alt=""></p>
<p>对于单个属性来说，他的名称需要从常量池中引用一个CONSTANT_Utf8_info类型的常量来表示，而属性的结构则是完全自定义的，只需要通过一个u4的长度属性去说明属性值所占用的位数即可。一个符合规则的属性表应该满足下表所定义的结构。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-9fa65bd813bf963ab289294e91e4999f4e1.png" alt=""></p>
<p>下面我们来介绍重要的，虚拟机规范预定义的属性——code属性。</p>
<h3 id="1-7-1-code属性"><a href="#1-7-1-code属性" class="headerlink" title="1.7.1 code属性"></a>1.7.1 code属性</h3><p>Java程序方法体中的代码经过Javac编译器处理后，最终变为字节码指令存储在Code属性内。<strong>Code属性出现在方法表的属性集合之中</strong>，但并非所有的方法表都必须存在这个属性，譬如接口或者抽象类中的方法就不存在Code属性，如果方法表有Code属性存在，那么Code属性的结构将如下表所示。</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-f4bc87d6a053a2e25007351ed3086f13570.png" alt=""></p>
<ul>
<li><p>attribute_name_index是一项指向CONSTANT_Utf8_info型常量的索引，常量值固定为“Code”，他代表了该属性的属性名称，</p>
</li>
<li><p>attribute_length指示了属性值的长度，由于属性名称索引与属性长度一共为6个字节，所以属性值的内容长度固定为整个属性表长度减6个字节。</p>
</li>
<li><p>max_stack代表了操作数栈（Operand Stacks）深度的最大值。在方法执行的任意时刻，操作数栈都不会超过这个深度。虚拟机运行的时候需要根据这个值分配栈帧（Stack Frame）中的操作帧深度。</p>
</li>
<li><p>max_locals代表了局部变量表所需的存储空间。在这里，max_locals的单位是Slot，Slot是虚拟机为局部变量分配内存所使用的最小单位。</p>
<ul>
<li>对于byte、char、float、int、short、boolean和returnAddress等长度不超过32位的数据类型，每个局部变量占用1个Slot，而double和long这两种64位的数据类型则需要两个Slot来存放。</li>
<li>方法参数（包括实例方法中的隐藏参数“this”）、显式异常处理器的参数（Exception Handler Parameter，就是try-catch语句中catch块所定义的异常）、方法体中定义的局部变量都需要使用局部变量表来存放。</li>
<li>另外，并不是在方法中用到了多少个局部变量，就把这些局部变量所占Slot之和作为max_locals的值，原因是局部变量表中的Slot可以重用，当代码执行超出一个局部变量的作用域时，这个局部变量所占的Slot可以被其他局部变量所使用，Javac编译器会根据变量的作用域来分配Slot给各个变量使用，然后计算出max_locals的大小。</li>
</ul>
</li>
<li><p>code_length和code用来存储java源程序编译后生成的字节码指令。</p>
<ul>
<li>code_length代表字节码长度，code是用于存储字节码指令的一系列字节流。</li>
<li>既然叫字节码指令，那么每个指令就是一个u1类型的单字节，当虚拟机读取到code中的一个字节码时，就可以对应找出这个字节码代表的是什么指令，并且可以知道这条指令后面是否需要跟随参数，以及参数应当如何理解。我们知道一个u1数据类型的取值范围为0x00<del>0xFF，对应十进制的0</del>255，也就是一共可以表达256条指令，目前，Java虚拟机规范已经定义了其中约200条编码值对应的指令含义。</li>
<li>关于code_length，有一件值得注意的事情，虽然他是一个u4类型的长度值，理论上最大值可以达到2的32次方减1，但是虚拟机规范中明确限制了一个方法不允许超过65535条字节码指令，即他实际只使用了u2的长度，如果超过这个限制，Javac编译器也会拒绝编译。</li>
</ul>
</li>
<li><p>exception_table_length和exception_table表示这个方法的显示异常处理表（下文简称异常表）集合，异常表对于Code属性来说并不是必须存在的</p>
<ul>
<li>异常表的格式如下表所示</li>
<li><img src="https://oscimg.oschina.net/oscnet/up-18972444f8c9359ed0dfa0b2feb46ea0dda.png" alt=""></li>
<li>他包含4个字段，这些字段的含义为：如果当字节码在第start_pc行到end_pc行之间（不含第end_pc行）出现了类型为catch_type或者其子类的异常（catch_type为指向一个CONSTANT_Class_info型常量的索引），则转到第handler_pc行继续处理。<strong>当catch_type的值为0时，代表任意异常情况都需要转向到handler_pc处进行处理</strong>。</li>
</ul>
</li>
</ul>
<p>Code属性是Class文件中最重要的一个属性，如果把一个Java程序中的信息分为代码（Code，方法体里面的Java代码）和元数据（Metadata，包括类、字段、方法定义及其他信息）两部分，那么在整个Class文件中，Code属性用于描述代码，所有的其他数据项目都用于描述元数据。</p>
<h3 id="1-7-2-code属性demo"><a href="#1-7-2-code属性demo" class="headerlink" title="1.7.2 code属性demo"></a>1.7.2 code属性demo</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public class TestClass &#123;</span><br><span class="line"></span><br><span class="line">    private int m;</span><br><span class="line"></span><br><span class="line">    public int inc() &#123;</span><br><span class="line">        return m + 1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上面代码的TestClass.class文件为例</p>
<ul>
<li><p>如下图所示。这时实例构造器“&lt;init&gt;”方法的Code属性。</p>
<ul>
<li><p><img src="https://oscimg.oschina.net/oscnet/up-257e2c34636c8652be0f226ddada6202aad.png" alt=""></p>
</li>
<li><p>他的操作数栈的最大深度和本地变量表的容量都为0x0001</p>
</li>
<li><p>字节码区域所占空间的长度为0x0005。</p>
</li>
<li><p>虚拟机读取到字节码区域的长度后，按照顺序依次读入紧随的5个字节，并根据字节码指令翻译出所对应的字节码指令。翻译“2A B7 00 0A B1”的过程中：</p>
<ol>
<li>读入2A，查表得0x2A对应的指令为aload_0，这个指令的含义是将第0个Slot中为reference类型的本地变量推送到操作数栈顶。</li>
<li>读入B7，查表得0xB7对应的指令为invokespecial，这条指令的作用是以栈顶的reference类型的数据所指向的对象作为方法接收者，调用此对象的实例构造器方法、private方法或者他的父类的方法。这个方法有一个u2类型的参数说明具体调用哪一个方法，他指向常量池中的一个CONSTANT_Methodref_info类型常量，即此方法的方法符号引用。</li>
<li>读入000A，这时invokespecial的参数，查常量吃得0x000A对应的常量为实例构造器“&lt;init&gt;”方法的符号引用。</li>
<li>读入B1，查表得0xB1对应的指令为return，含义是返回此方法，并且返回值为void。这条指令执行后，当前方法结束。</li>
</ol>
</li>
</ul>
</li>
</ul>
<h1 id="2-类加载机制"><a href="#2-类加载机制" class="headerlink" title="2 类加载机制"></a>2 类加载机制</h1><p>上一节我们已经知道了类文件结构，在class文件中描述的各种信息最终都需要加载到虚拟机中之后才能运行和使用。那么虚拟机是如加载这些class文件呢？class文件中的信息进入到虚拟机后会发生什么变化？</p>
<blockquote>
<p>虚拟机把描述类的数据从class文件加载到内存，并对数据进行校验、转换解析和初始化。最终形成可以被虚拟机最直接使用的java类型的过程就是虚拟机的类加载机制。</p>
</blockquote>
<p>另外需要注意的很重要的一点是：java语言中类型的加载连接以及初始化过程都是在程序运行期间完成的，这种策略虽然会使类加载时稍微增加一些性能开销，但是会为java应用程序提供高度的灵活性。java里天生就可以动态扩展语言特性就是依赖运行期间动态加载和动态连接这个特点实现的。比如，如果编写一个面向接口的程序，可以等到运行时再指定其具体实现类。</p>
<h2 id="2-1-类的生命周期"><a href="#2-1-类的生命周期" class="headerlink" title="2.1 类的生命周期"></a>2.1 类的生命周期</h2><p>类从被加载到虚拟机内存到卸出内存为止，它的整个生命周期包括：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-e528b6e0fce95406fef545eb9d0df2282e0.png" alt=""></p>
<blockquote>
<p>加载，样子，准备，初始化和卸载五个阶段的顺序是确定的，而解析阶段则不一定，他在有些情况下可以在初始化阶段后再开始。</p>
</blockquote>
<h2 id="2-2-类加载的时机"><a href="#2-2-类加载的时机" class="headerlink" title="2.2 类加载的时机"></a>2.2 类加载的时机</h2><p>什么时候需要开始类加载的第一个阶段：加载？</p>
<p>虚拟机规范严格规定了<strong>有且只有</strong>五种情况必须立即对类进行“初始化”：</p>
<ol>
<li>使用new关键字实例化对象的时候、读取或设置一个类的静态字段的时候，已经调用一个类的静态方法的时候。</li>
<li>使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有初始化，则需要先触发其初始化。</li>
<li>当初始化一个类的时候，如果发现其父类没有被初始化就会先初始化它的父类。<ul>
<li>而对于接口，当一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口时（如引用父接口中定义的常量）才会初始化。</li>
</ul>
</li>
<li>当虚拟机启动的时候，用户需要指定一个要执行的主类（就是包含main()方法的那个类），虚拟机会先初始化这个类；</li>
<li>使用Jdk1.7动态语言支持的时候的一些情况。如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。</li>
</ol>
<p>这5种场景中的行为称为对一个类进行主动引用。还有就是被动引用：所有引用类的方式都不会触发初始化。</p>
<h3 id="2-2-1-被动引用demo"><a href="#2-2-1-被动引用demo" class="headerlink" title="2.2.1 被动引用demo"></a>2.2.1 被动引用demo</h3><p>下面是3个被动引用的例子。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 被动使用类字段演示一：</span><br><span class="line"> * 通过子类引用父类的静态字段，不会导致子类初始化</span><br><span class="line"> **&#x2F;</span><br><span class="line">public class SuperClass &#123;</span><br><span class="line">    static &#123;</span><br><span class="line">        System.out.println(&quot;SuperClass init&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    public static int value &#x3D; 123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class SubClass extends SuperClass &#123;</span><br><span class="line">    static &#123;</span><br><span class="line">        System.out.println(&quot;SubClass init&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;**</span><br><span class="line"> * 非主动使用类字段演示</span><br><span class="line"> *&#x2F;</span><br><span class="line">class NotInitialization &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        System.out.println(SubClass.value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码只会输出”SuperClass init”和”123”。对于静态字段，只有直接定义这个字段的类才会被初始化。因此通过其子类来引用父类定义的静态字段，只会触发父类的初始化。至于是否要触发子类的加载和验证，取决于虚拟机的具体实现。对于Sun HotSpot虚拟机来说，可通过-XX:+TraceClassLoading参数会导致子类的加载。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 被动使用类字段演示二：通过数组定义引用类，不会触发此类的初始化</span><br><span class="line"> *&#x2F;</span><br><span class="line">class NotInitialization &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SuperClass[] sc &#x3D; new SuperClass[10];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码没有触发初始化，但里面触发了另外一个名为”[LSuperClass”类的初始化阶段，对于用户代码来说，这并不是一个合法的类名称，它是由虚拟机自动生成的、直接继承与java.lang.Object的子类，创建动作由字节码指令newarray触发。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 被动使用类字段演示三：</span><br><span class="line"> * 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化</span><br><span class="line"> *&#x2F;</span><br><span class="line">class ConstClass &#123;</span><br><span class="line">    static &#123;</span><br><span class="line">        System.out.println(&quot;ConstClass init&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    public static final String HELLOWORLD &#x3D; &quot;hello world&quot;;</span><br><span class="line">&#125;</span><br><span class="line">class NotInitialization &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        System.out.println(ConstClass.HELLOWORLD);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码也没有输出”ConstClass init”，因为Java源码中引用了ConstClass类中的常量HELLOWORLD，但其实在编译阶段通过常量传播优化，已经将此常量的值”hello world”存储到了NotInitialization类的常量池中。所以在NotInitialization对ConstClass.HELLOWORLD的引用实际上是对自身常量池的引用。</p>
<h2 id="2-3-类加载的过程"><a href="#2-3-类加载的过程" class="headerlink" title="2.3 类加载的过程"></a>2.3 类加载的过程</h2><h3 id="2-3-1-加载"><a href="#2-3-1-加载" class="headerlink" title="2.3.1 加载"></a>2.3.1 加载</h3><p>“加载” 是 “类加载” 过程的一个阶段，切不可将二者混淆。</p>
<p>加载”是”类加载”过程的一个阶段，虚拟机需要完成3件事情：</p>
<ol>
<li><p>通过一个类的全限定名来获取定义此类的二进制字节流。</p>
<ul>
<li>没有指明从哪里获取、怎样获取，可以说一个非常开放的平台了。</li>
<li>目前可以从zip包获取，即jar，ear，war格式的基础。</li>
<li>从网络获取，即applet实现。</li>
<li>运行时计算生成，典型如动态代理。</li>
<li>由其他文件生成，典型如JSP应用，即为JSP文件生成的class类。</li>
<li>从数据库中读取，这种较少见。</li>
</ul>
</li>
<li><p>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</p>
<ul>
<li>方法区的数据存储格式由各种虚拟机实现自行定义，并无明确规范。</li>
</ul>
</li>
<li><p>在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。</p>
<ul>
<li>并没有明确存放于要在堆中，实际上它虽然是对象，但是HotSpot虚拟机仍将其存放在方法区中。</li>
</ul>
</li>
</ol>
<p>对于非数组类的加载阶段(准确的说是加载阶段中获取类的二进制字节流的动作)是开发人员可控性最强的，因为加载阶段既可以使用系统提供的引导类加载器完成，也可以由用户自定义的类加载器完成（即重写一个类加载器的loadClass（）方法）。</p>
<p>对于数组，数组类本身不通过类加载器创建，是由Java虚拟机直接创建的。但数组类与类加载器也有密切关系，因为数组类的元素类型(String[]的元素类型即为String)，最终要靠类加载器创建。</p>
<h3 id="2-3-2-验证"><a href="#2-3-2-验证" class="headerlink" title="2.3.2 验证"></a>2.3.2 验证</h3><p>验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。</p>
<p>虚拟机如果不检查输入的字节流，并对其完全信任的话，很可能会因为载入了有害的字节流而导致系统崩溃，所以验证是虚拟机对自身保护的一项重要工作。这个阶段是否严谨，直接决定了java虚拟机是否能承受恶意代码的攻击。</p>
<p>从整体上看，验证阶段大致上会完成4个阶段的校验工作：文件格式、元数据、字节码、符号引用。</p>
<ol>
<li><p>文件格式验证：验证字节流是否符合Class文件格式的规范。</p>
<ul>
<li>是否以魔数0xCAFEBABE开头。</li>
<li>主、次版本号是否在当前虚拟机处理范围之内。</li>
<li>常量池的常量是否有不被支持的常量类型(检查常量tag标志)。</li>
<li>…</li>
</ul>
</li>
<li><p>元数据验证：字节码描述的信息是否符合Java语言规范。</p>
<ul>
<li>这个类是否有父类。</li>
<li>这个类的父类是否继承了不允许被继承的类。</li>
<li>如果这个类不是抽象类，是否实现了其父类或接口中要求实现的所有方法。</li>
<li>…</li>
</ul>
</li>
<li><p>字节码验证：通过数据流和控制流分析，确定程序语义是合法、符合逻辑的。</p>
<ul>
<li>保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作，例如不会出现：在操作栈放置了int类型的数据，使用时按long类型加载入本地变量表中。</li>
<li>保证跳转指令不会跳转到方法体以外的字节码指令上。</li>
<li>保证类型转换是有效的。</li>
<li>…</li>
</ul>
</li>
<li><p>符号引用验证：对类自身以外(常量池中各种符号引用)的信息进行匹配性校验。</p>
<ul>
<li>符号引用中通过字符串描述的全限定是否能找到对应的类。</li>
<li>在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段。</li>
<li>符号引用的类、字段、方法的访问性是否可以被当前类访问。</li>
<li>…</li>
</ul>
</li>
</ol>
<h3 id="2-3-3-准备"><a href="#2-3-3-准备" class="headerlink" title="2.3.3 准备"></a>2.3.3 准备</h3><p>正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。</p>
<blockquote>
<p>注意：这时进行内存分配的仅包括类变量(static修饰)，不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中；</p>
</blockquote>
<blockquote>
<p>注意：初始值通常是数据类型的零值：对于：public static int value = 123;，那么变量value在准备阶段过后的初始值为0而不是123，这时候尚未开始执行任何java方法，把value赋值为123的动作将在初始化阶段才会被执行。</p>
</blockquote>
<blockquote>
<p>注意：对于：public static final int value = 123;编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123。</p>
</blockquote>
<p>基本数据类型的零值：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-a8fc433e06919ce8b5789af9ce6ee5c6934.png" alt=""></p>
<h3 id="2-3-4-解析"><a href="#2-3-4-解析" class="headerlink" title="2.3.4 解析"></a>2.3.4 解析</h3><p>虚拟机将常量池内的<strong>符号引用替换为直接引用</strong>的过程。（如果不理解这句话的意思，可以参考R大的答案：<a href="https://www.zhihu.com/question/30300585）" target="_blank" rel="noopener">https://www.zhihu.com/question/30300585）</a></p>
<ul>
<li><p>符号引用：上面我们介绍过符号引用，这里再重申一遍，以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存和布局无关，引用的目标并不一定已经加载到内存中了。</p>
</li>
<li><p>直接引用：直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用和虚拟机实现的内存布局有关，引用的目标必定已经在内存中了。</p>
</li>
</ul>
<p>解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。分别对应常量池的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info、CONSTANT_MethodType_info、CONSTANT_MethodHandle_info、CONSTANT_InvokeDynamic_info。(先只说前4种)</p>
<p>下面假设我们要把一个从未解析过的符号引用N解析为一个类或接口C的直接引用。</p>
<ul>
<li><p>类或接口的解析：假设当前代码所处的类为D，那么有3个步骤：</p>
<ul>
<li><p>如果目标类C不是数组类型，虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C。</p>
</li>
<li><p>如果目标类C是一个数组类型，并且数组的元素类型为对象，N的描述符会是类似”[Ljava/lang/Integer”的形式，将会按照第1点的规则加载数组元素类型。即需要加载的元素类型是”java.lang.Integer”，接着由虚拟机生成一个代表此数组维度和元素的数组对象。</p>
</li>
<li><p>如果上面没有异常，解析完成前会进行符号引用验证，确认D是否具备C的访问权限（public，private，protected这些）。如果没有权限，将抛出java.lang.IllegalAccessError异常。</p>
</li>
</ul>
</li>
<li><p>字段解析</p>
<ul>
<li>首先将字段表内class_index中索引的CONSTANT_Class_info符号引用解析(就是字段所属的类或接口的符号引用)。如果解析完成，会有以下步骤：</li>
<li>如果C已经包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个引用。</li>
<li>否则，如果C实现了接口，将会按继承关系从下往上递归搜索各个接口和它的父接口，如果找到则返回。</li>
<li>否则，如果C不是java.lang.Object的话，将会按照继承关系从下往上递归搜索其父类，如果找到则返回。</li>
<li>否则，查找失败，抛出”java.lang.NoSuchFieldError”异常。</li>
<li>如果成功返回了引用，将会对字段进行权限认证。如果发现没有权限抛出”java.lang.IllegalAccessError”异常。</li>
</ul>
</li>
<li><p>类方法解析</p>
<ul>
<li><p>先解析出类方法表的class_index项中索引的方法所属的类或接口的符号引用，解析成功后，有以下几个步骤：</p>
</li>
<li><p>类方法和接口方法符号引用的常量类型定义是分开的，如果方法表中发现class_index中索引的C是个接口，直接抛出”java.lang.IncompatibleClassChangeError”异常。</p>
</li>
<li><p>在类C查找是否有简单名称和描述符与目标匹配的方法，如果有则返回。</p>
</li>
<li><p>否则，在类C的父类中递归查找是否有与目标匹配的方法，如有有则返回。</p>
</li>
<li><p>否则，在类C实现的接口列表及它们的父接口中递归查找是否有与目标匹配的方法，如果有说明C是抽象类，查找结束，抛出”java.lang.AbstractMethodError”异常。</p>
</li>
<li><p>否则，方法查找失败，抛出”java.lang.NoSuchMethodError”异常。</p>
</li>
<li><p>如果查找成功，返回直接引用。会对这个方法进行权限认证，如果没有权限，抛出”java.lang.IllegalAccessError”异常。</p>
</li>
</ul>
</li>
<li><p>接口方法解析</p>
<ul>
<li><p>同样，解析接口方法表class_index中索引对方法所属对类或接口的符号引用，如果解析成功，会执行以下步骤：</p>
</li>
<li><p>如果接口方法表中发现class_index中的索引C是个类，直接抛出”java.lang.IncompatibleClassChangeError”异常。</p>
</li>
<li><p>否则，在接口C中查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用。</p>
</li>
<li><p>否则，在接口C的父接口中递归查找，直到java.lang.Object类，查找是否有简单名称和描述符与目标相匹配的方法，如果有则返回。</p>
</li>
<li><p>否则，方法查找失败，抛出”java.lang.NoSuchMehtodError”异常。</p>
</li>
<li><p>接口所有方法默认都是public，没有访问权限问题。</p>
</li>
</ul>
</li>
</ul>
<h3 id="2-3-5-初始化"><a href="#2-3-5-初始化" class="headerlink" title="2.3.5 初始化"></a>2.3.5 初始化</h3><p>这个阶段才真正开始执行类中定义的Java程序代码。(字节码)</p>
<p>准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通过程序的主观计划初始化类变量和其他资源。或者说，<strong>初始化阶段是执行类构造器&lt;clinit&gt;()方法的过程</strong>。</p>
<p>对于类构造器&lt;clinit&gt;()，有如下几个要点：</p>
<ul>
<li>类构造器&lt;clinit&gt;()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块(static块)中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，<strong>静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句快可以赋值，但是不能访问</strong>。（否则提示非法向前引用）</li>
</ul>
<ul>
<li><p>类构造器&lt;clinit&gt;()方法与类的构造函数(实例构造函数&lt;init&gt;()方法)不同，它不需要显式调用父类构造，虚拟机会保证在子类&lt;clinit&gt;()方法执行之前，父类的&lt;clinit&gt;()方法已经执行完毕。因此在虚拟机中的第一个执行的&lt;clinit&gt;()方法的类肯定是java.lang.Object。</p>
</li>
<li><p>由于父类的&lt;clinit&gt;()方法先执行，也就意味着父类中定义的静态语句快要优先于子类的变量赋值操作。</p>
</li>
<li><p>&lt;clinit&gt;()方法对于类或接口来说并不是必须的，如果一个类中没有静态语句，也没有变量赋值的操作，<strong>那么编译器可以不为这个类生成&lt;clinit&gt;()方法</strong>。</p>
</li>
<li><p>接口中不能使用静态语句块，但接口与类不太一样的是，<strong>执行接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法</strong>。只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，<strong>接口的实现类在初始化时也一样不会执行接口的&lt;clinit&gt;()方法</strong>。</p>
</li>
<li><p>虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确加锁和同步，如果多个线程同时去初始化一个类，那么只会有一个线程执行这个类的&lt;clinit&gt;()方法，其他线程都需要阻塞等待，直到活动线程执行&lt;clinit&gt;()方法完毕。如果一个类的&lt;clinit&gt;()方法中有耗时很长的操作，那就可能造成多个进程阻塞。</p>
</li>
</ul>
<h1 id="3-类加载器"><a href="#3-类加载器" class="headerlink" title="3 类加载器"></a>3 类加载器</h1><p>虚拟机设计团队把类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块称为“类加载器”。</p>
<p>对于任何一个类，都需要由加载它的类加载器和这个类来确立其在JVM中的<strong>唯一性</strong>。也就是说，只有两个类来源于同一个Class文件，并且被同一个类加载器加载，这两个类才相等（这里的相等包括equals方法，isAssignableFrom方法，isInstance方法等判断，包括instanceOf关键字所做出的的对象所属判断）。<strong>否则，即便是两个同名的类，甚至是来自一个class文件的类，不同的加载器加载，他们也不会是同一个类。</strong></p>
<h2 id="3-1-类加载器种类"><a href="#3-1-类加载器种类" class="headerlink" title="3.1 类加载器种类"></a>3.1 类加载器种类</h2><p>从虚拟机的角度来说，只存在两种不同的类加载器：</p>
<ul>
<li>一种是<strong>启动类加载器（Bootstrap ClassLoader）</strong>，该类加载器使用C++语言实现，属于虚拟机自身的一部分。</li>
<li>另外一种就是<strong>所有其它的类加载器</strong>，这些类加载器是由Java语言实现，独立于JVM外部，并且全部继承自抽象类java.lang.ClassLoader。</li>
</ul>
<p>从Java开发人员的角度来看，类加载器会分的更加细致，大部分Java程序一般会使用到以下三种系统提供的类加载器：</p>
<ol>
<li><p>启动类加载器（Bootstrap ClassLoader）：负责加载JAVA_HOME\lib目录中并且能被虚拟机识别的类库到JVM内存中（如rt.jar），如果名称不符合的类库即使放在lib目录中也不会被加载。该类加载器无法被Java程序直接引用。</p>
</li>
<li><p>扩展类加载器（Extension ClassLoader）：该加载器主要是负责加载JAVA_HOME\lib\ext目录中，或者被 java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器；</p>
</li>
<li><p>应用程序类加载器（Application ClassLoader）：这个类加载器由 sun.misc.Launcher$App-ClassLoader 实现。getSystemClassLoader() 方法返回的就是这个类加载器，因此也被称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库。开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。</p>
</li>
</ol>
<h2 id="3-2-双亲委派模型"><a href="#3-2-双亲委派模型" class="headerlink" title="3.2 双亲委派模型"></a>3.2 双亲委派模型</h2><p>我们的应用程序都是由上述这3种类加载器互相配合进行加载的，在必要时还可以自己定义类加载器。它们的关系如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/up-de58eeaf1c8e7d2b3a81cd80af628b1e537.png" alt=""></p>
<p><strong>上图中所呈现出的这种层次关系，称为类加载器的双亲委派模型（Parents Delegation Model）。双亲委派模型要求除了顶层的启动类加载器以外，其余的类加载器都应当有自己的父类加载器。</strong></p>
<p>双亲委派模型的工作过程是这样的：</p>
<ul>
<li>如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成。</li>
<li>每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中。</li>
<li>只有当父类加载器反馈自己无法完成这个类加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。</li>
</ul>
<blockquote>
<p>这样做的好处就是 Java 类随着它的类加载器一起具备了一种带有优先级的层次关系。例如 java.lang.Object，它放在 rt.jar中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型顶端的启动类加载器来加载，因此 Object 类在程序的各种类加载器环境中都是同一个类。<br>相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，如果用户自己编写了一个称为 java.lang.Object 的类，并放在程序的 ClassPath 中，那系统中将会出现多个不同的 Object 类，Java 类型体系中最基本的行为也就无法保证了。</p>
</blockquote>
<p>双亲委派模型对于保证 Java 程序运行的稳定性很重要，但它的实现很简单，实现双亲委派模型的代码都集中在 java.lang.ClassLoader 的 loadClass() 方法中，逻辑很清晰：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">protected Class&lt;?&gt; loadClass(String name, boolean resolve)</span><br><span class="line">        throws ClassNotFoundException &#123;</span><br><span class="line">    &#x2F;&#x2F; 首先，检查请求的类是不是已经被加载过</span><br><span class="line">    Class&lt;?&gt; c &#x3D; findLoadedClass(name);</span><br><span class="line">    if (c &#x3D;&#x3D; null) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (parent !&#x3D; null) &#123;&#x2F;&#x2F;若没有则调用父类加载器的loadClass()方法</span><br><span class="line">                c &#x3D; parent.loadClass(name, false);</span><br><span class="line">            &#125; else &#123;&#x2F;&#x2F;若父加载器为空则默认使用启动类加载器作为父加载器</span><br><span class="line">                c &#x3D; findBootstrapClassOrNull(name);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (ClassNotFoundException e) &#123;</span><br><span class="line">            &#x2F;&#x2F; 如果父类抛出ClassNotFoundException说明父类加载器无法完成加载</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (c &#x3D;&#x3D; null) &#123;</span><br><span class="line">            &#x2F;&#x2F; 如果父类加载器无法加载，则调用自己的findClass方法来进行类加载</span><br><span class="line">            c &#x3D; findClass(name);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if (resolve) &#123;</span><br><span class="line">        resolveClass(c);</span><br><span class="line">    &#125;</span><br><span class="line">    return c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/25/JAVA%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/25/JAVA%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/" itemprop="url">JAVA对象的创建和内存分配策略</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-25T22:30:12+08:00">
                2019-11-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/JAVA-JVM/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA JVM</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/25/JAVA%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/11/25/JAVA对象的创建和内存分配策略/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  4.7k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  16
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-对象的创建"><a href="#1-对象的创建" class="headerlink" title="1 对象的创建"></a>1 对象的创建</h1><h2 id="1-1-对象的创建"><a href="#1-1-对象的创建" class="headerlink" title="1.1 对象的创建"></a>1.1 对象的创建</h2><p>虚拟机遇到new指令：</p>
<ol>
<li><p>检查指令的参数是否可以在常量池中定位到一个类的符号引用，且检查这个符号引用代表的类是否已被加载。如果没有执行类加载过程。</p>
</li>
<li><p>为生成的对象分配内存</p>
<ul>
<li>对象的大小在类加载后已被确定。</li>
<li>目前主流的是两种分配方式：指针碰撞和空闲列表。具体哪种方式由堆采用的GC是否带有压缩整理功能决定。<ul>
<li>指针碰撞：已分配空间和未分配空间规整时，中间放置一个指针表示分界点，指针移动即为分配空间。使用serial/parnew等带有压缩compact过程的收集器时，系统的分配算法是指针碰撞。   </li>
<li>空闲列表：空闲列表：如果内存不规则，已分配和未分配空间犬牙交错，虚拟机必须维护一个列表，记录哪些内存块可用。使用CMS这种标记替换算法的收集器时，系统的分配算法通常用空闲列表。</li>
<li>内存分配会产生并发问题，具体详见 1.2 内存分配并发问题</li>
</ul>
</li>
</ul>
</li>
<li><p>将分配到的内存空间都初始化为零值（不代表就为0）（不包括对象头），如果使用TLAB，这一工作也可以提前至TLAB分配时进行。</p>
</li>
<li><p>填充对象的对象头，具体详见1.3 对象的内存布局</p>
</li>
<li><p>init方法还没执行，所有字段还都为零值，执行init方法，将字段初始化。</p>
</li>
<li><p>1 对象的创建 的扩展：</p>
<h2 id="1-2-内存分配并发问题"><a href="#1-2-内存分配并发问题" class="headerlink" title="1.2 内存分配并发问题"></a>1.2 内存分配并发问题</h2></li>
</ol>
<p>在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：</p>
<ul>
<li>CAS： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。</li>
<li>TLAB： 为每一个线程预先分配一块内存，JVM在给线程中的对象分配内存时，首先在TLAB分配，当对象大于TLAB中的剩余内存或TLAB的内存已用尽时，再采用上述的CAS进行内存分配。设置 -XX:UseTLAB 参数会开启TLAB。默认是开启的。</li>
</ul>
<h3 id="1-2-1-TLAB"><a href="#1-2-1-TLAB" class="headerlink" title="1.2.1 TLAB"></a>1.2.1 TLAB</h3><p>JVM在内存新生代Eden Space中开辟了一小块线程私有的区域，称作TLAB，全称是Thread Local Allocation Buffer，即线程本地分配缓存区，这是一个线程专用的内存分配区域。</p>
<p>如果设置了虚拟机参数 <code>-XX:UseTLAB</code> ，在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个空间，如果需要分配内存，就在自己的空间上分配，这样就不存在竞争的情况，可以大大提升分配效率。</p>
<p>TLAB空间的内存非常小，缺省情况下仅占有整个Eden空间的1%，也可以通过选项<code>-XX:TLABWasteTargetPercent</code> 设置TLAB空间所占用Eden空间的百分比大小。</p>
<p>TLAB的本质其实是三个指针管理的区域：start，top 和 end，每个线程都会从Eden分配一块空间，例如说100KB，作为自己的TLAB，其中 start 和 end 是占位用的，标识出 eden 里被这个 TLAB 所管理的区域，卡住eden里的一块空间不让其它线程来这里分配。</p>
<p>TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区更为合理一点</p>
<p>当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。</p>
<p>不过TLAB也有自己的缺点。因为TLAB通常很小，所以放不下大对象：</p>
<ol>
<li>TLAB空间大小是固定的，但是这时候一个大对象，我TLAB剩余的空间已经容不下它了。(比如100kb的TLAB，来了个110KB的对象)</li>
<li>TLAB空间还剩一点点没有用到，有点舍不得。(比如100kb的TLAB，装了80KB，又来了个30KB的对象)</li>
</ol>
<p>故而开发人员对于大对象的创建做了优化，最终的分配流程如下：</p>
<ol>
<li>编译器通过逃逸分析，确定对象是在栈上分配还是在堆上分配。如果是在堆上分配，则进入选项2.</li>
<li>如果top + size &lt;= end，说明TLAB还放得下，则在在TLAB上直接分配对象并增加top的值，如果现有的TLAB不足以存放当前对象则进入3.</li>
<li>重新申请一个TLAB，并再次尝试存放当前对象。如果放不下，则4.</li>
<li>在Eden区加锁（这个区是多线程共享的），如果eden_top + size &lt;= eden_end，说明Eden区放得下，则将对象存放在Eden区，增加eden_top的值，如果Eden区不足以存放，则5.</li>
<li>执行一次Young GC（minor collection）。</li>
<li>经过Young GC之后，如果Eden区任然不足以存放当前对象，则直接分配到老年代。</li>
</ol>
<h2 id="1-3-对象的内存布局"><a href="#1-3-对象的内存布局" class="headerlink" title="1.3 对象的内存布局"></a>1.3 对象的内存布局</h2><p>hotspot设计了一个OOP-Klass Model，这里的OOP指的是Ordinary Object Pointer （普通对象指针），它用来表示对象的实例信息，看起来像个指针实际上是藏在指针里的对象。而 Klass 则包含元数据和方法信息，用来描述Java类。</p>
<ul>
<li><ol>
<li>Klass : Klass简单的说是Java类在HotSpot中的c++对等体，用来描述Java类。那Klass是什么时候创建的呢？一般jvm在加载class文件时，会在方法区创建instanceKlass，表示其元数据，包括常量池、字段、方法等。</li>
</ol>
</li>
</ul>
<ul>
<li><ol start="2">
<li><p>OOP： Klass是在class文件在加载过程中创建的，OOP则是在Java程序运行过程中new对象时创建的。一个OOP对象包含以下几个部分：</p>
<ul>
<li><p>2.1 instanceOopDesc，也叫对象头</p>
<ul>
<li><p>Mark Word，主要存储对象运行时记录信息，如hashcode, GC分代年龄，锁状态标志，线程ID，时间戳等。这些字段并不是固定的，而是不断变化的，对象在不同的阶段，mark word的值不一样。 在64位的虚拟机上标记字段一般是8个字节，类型指针也是8个字节，总共就是16个字节. 可以使用<code>-XX:UseCompressedOops</code>来开启压缩指针, 以减少对象的内存使用量, 默认是开启的</p>
</li>
<li><p>元数据指针，即指向方法区的instanceKlass实例</p>
</li>
<li><p>如果对象是一个 Java 数组，那在对象头中还必须有一块用于记录数组长度的数据。因为虚拟机可以通过普通 Java 对象的元数据信息确定 Java 对象的大小，但是从数组的元数据中无法确定数组的大小。</p>
</li>
<li><p><img src="https://oscimg.oschina.net/oscnet/519b55ad729cc4eeb7072aa70e7ad75b5bf.png" alt=""></p>
</li>
</ul>
</li>
<li><p>2.2 实例数据</p>
<ul>
<li>实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。这部分的存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在 Java 源码中定义顺序的影响。</li>
<li>各字段的分配策略为longs/doubles、ints、shorts/chars、bytes/boolean、oops(ordinary object pointers)，相同宽度的字段总是被分配到一起，便于之后取数据。父类定义的变量会出现在子类定义的变量的前面</li>
</ul>
</li>
<li><p>2.3 对齐填充。仅仅起到占位符的作用，并非必须。</p>
<ul>
<li>对齐填充是最常见的优化手段，CPU一次寻址一般是2的倍数，所以一般会按照2的倍数来对齐提高CPU效率.这个似乎没什么好讲的。此外，JVM上对齐填充也方便gc, JVM能直接计算出对象的大小, 就能快速定位到对象的起始终止地址.</li>
</ul>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<pre><code>- ![](https://oscimg.oschina.net/oscnet/e6d2c492581b2287ec2f0720ebd999c3b47.png)</code></pre><h2 id="1-4-压缩指针"><a href="#1-4-压缩指针" class="headerlink" title="1.4 压缩指针"></a>1.4 压缩指针</h2><p>为了减少对象内存的使用，64位JVM引入了压缩指针的概念（虚拟机选项-XX:+UseCompressedOops，默认开启），将堆中的64位指针压缩成32位，这样以来，对象头占用的内存就从16字节下降到了12字节。</p>
<p>那么压缩指针是什么原理呢？</p>
<p>打个比方，路上停着的全是房车，而且每辆房车恰好占据两个停车位。现在，我们按照顺序给它们编号。也就是说，停在0号和1号停车位上的叫 0 号车，停在2号和3号停车位上的叫1号车，依次类推。</p>
<p>原本的内存寻址用的是车位号。比如说我有一个值为6的指针，代表第6个车位，那么沿着这个指针可以找到3号车。现在我们规定指针里存的值是车号，比如3指代3号车。当需要查找3号车时，我便可以将该指针的值乘以2，再沿着6号车位找到3号车。</p>
<p>这样一来，32位压缩指针最多可以表示2的32次方辆车，对应着2的33次方个车位。当然，房车也有大小之分。大房车占据的车位可能是三个甚至是更多。不过这并不会影响我们的寻址算法：我们只需跳过部分车号，便可以保持原本车号*2的寻址系统。</p>
<p>上述模型有一个前提，你应该已经想到了，就是每辆车都从偶数号车位停起。这个概念我们称之为内存对齐（对应虚拟机选项 <code>-XX:ObjectAlignmentInBytes</code>，默认值为 8）。</p>
<h2 id="1-5-对象大小"><a href="#1-5-对象大小" class="headerlink" title="1.5 对象大小"></a>1.5 对象大小</h2><p>JVM的数据类型分为基本数据类型和引用数据类型。基本数据类型有：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">long&#x2F;double: 8字节, 长整型和双精度浮点型</span><br><span class="line">int&#x2F;float: 4字节, 整数和浮点数</span><br><span class="line">char,short: 2字节,字符型和短整型</span><br><span class="line">byte: 1字节, 整数</span><br></pre></td></tr></table></figure>

<p>基本数据类型没啥好说的，这里我们有必要讲一下引用（reference），引用的实现主要有两种：</p>
<ol>
<li><p>句柄访问：</p>
<ul>
<li>在堆中分配一块句柄池，reference中存的就是句柄地址，而句柄中包括了实例对象和类型对象的地址，如图：</li>
<li><img src="https://oscimg.oschina.net/oscnet/7153e3dd29c3b8db7596114912f689ac913.png" alt=""></li>
</ul>
</li>
<li><p>直接指针：</p>
<ul>
<li>reference中存的直接就是对象地址：</li>
<li><img src="https://oscimg.oschina.net/oscnet/da62dfa83dc319bf81497e270073865ab32.png" alt=""></li>
</ul>
</li>
</ol>
<p>二者之间，我们可以看到，句柄方式，类型数据得到了安置，而直接指针，<strong>则需要额外安排类型数据的放置</strong>。</p>
<p><strong>HotSpot虚拟机使用的是直接指针，至于对类型数据的安排，前文我们也说过了，类型指针在对象头里</strong>。</p>
<h3 id="1-5-1-对象大小的计算"><a href="#1-5-1-对象大小的计算" class="headerlink" title="1.5.1 对象大小的计算"></a>1.5.1 对象大小的计算</h3><ul>
<li>在JDK8, 64位HotSpot上, 引用数据类型都是直接指针, 如果开了压缩指针，就是4字节，没开就是8字节。</li>
<li>对象头在64位的虚拟机上开了压缩指针就是12字节，没开就是16字节。</li>
<li>实例数据的大小依据数据类型的大小来计算, 注意要子类的对象大小要把父类的实例数据大小也计算进去。</li>
<li>对齐填充是按照对象里最宽的数据类型的大小来对齐的, 比如最大的是long 8字节, 那么就是按照8的倍数来对齐。</li>
</ul>
<p>接下来我们如果有这么一个对象</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public class ObjectByteTest &#123;</span><br><span class="line"></span><br><span class="line">    private double a;</span><br><span class="line">    private int b;</span><br><span class="line">    private String c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>按照理论，开启压缩指针后,对象头占12字节， 实例数据最长的double是8个字节, int是4字节, String是引用类型，占4字节, 按照8字节对齐。</p>
<p>总共是12+8+4+4=28字节，按照8字节对齐是32字节，要4个字节的对齐填充。</p>
<p>故而得到，Instance size=32字节。</p>
<h3 id="1-5-2-字段重排"><a href="#1-5-2-字段重排" class="headerlink" title="1.5.2 字段重排"></a>1.5.2 字段重排</h3><p>其实上面的对对象大小的计算，是jvm对对象重排之后的结果，对象重排，目的为了减少填充，节约空间，过程不多说，一张图就足以看懂：</p>
<p>对于对象：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">class A &#123;</span><br><span class="line">    long l;</span><br><span class="line">    int i；</span><br><span class="line">&#125;</span><br><span class="line">class B extends A &#123;</span><br><span class="line">    long l;</span><br><span class="line">    int i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>字段重排列前后如图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/0cda333b04b5d5426083503efaedffe18ad.png" alt=""></p>
<p>可以看到通过字段重排列，节省了空间。</p>
<h1 id="2-对象的内存的分配"><a href="#2-对象的内存的分配" class="headerlink" title="2 对象的内存的分配"></a>2 对象的内存的分配</h1><p>对象的内存分配，就是在堆上分配（如果经过JIT编译器逃逸分析，发现有些对象没有逃逸出方法，那么有可能堆内存分配会被优化成栈内存分配），对象主要分配在eden区，少数情况下也可能直接分配至老年代中，分配的规则视当前使用的垃圾收集器组合和内存参数规则决定。</p>
<h2 id="2-1-对象优先在eden分配"><a href="#2-1-对象优先在eden分配" class="headerlink" title="2.1 对象优先在eden分配"></a>2.1 对象优先在eden分配</h2><p>对象在绝大多数情况下，在新生代eden区分配，当eden区没有足够空间进行分配的时候，JVM会发起一次Minor GC。</p>
<p>相关内存参数如下：</p>
<ul>
<li><code>-Xms</code>:最小堆内存值</li>
<li><code>-Xmx</code>:最大堆内存值</li>
<li><code>-Xmn</code>:新生代内存值</li>
<li><code>-XX:SurvivorRatio</code>:新生代中eden区与一个survivor区的空间比</li>
</ul>
<p>比如，设置的参数是<code>-Xms20M、-Xmx20M、-Xmn10M、-XX:SurvivorRatio=8</code>，可得知，最小堆和最大堆内存一致，即堆内存固定为20MB，新生代为10MB，而老年代=堆内存-新生代,得知老年代为10MB，eden区与survivor区的比例是8：1，eden区=新生代 * SurvivorRatio / 10，eden区的大小为8MB，survivor区为2MB，s0和s1区都为1MB，那么新生代的总可用空间为9MB（eden区 + 1个survivor区）。</p>
<h2 id="2-2-大对象直接进入老年代"><a href="#2-2-大对象直接进入老年代" class="headerlink" title="2.2 大对象直接进入老年代"></a>2.2 大对象直接进入老年代</h2><p>大对象，即需要大量连续内存空间的对象。经常出现大对象就容易导致内存还有不少空间时就提前触发了GC，以便获取更大的连续空间来分配。大对象对虚拟机来说是个坏消息，更坏的消息是那些“朝生夕死”的大对象。</p>
<p>虚拟机提供了一个参数<code>-XX:PretenureSizeThreshold</code>，大于此设置值的对象将直接进入老年代分配内存，这样做的目的是避免在eden区和两个survivor区之间发生大量的内存复制(因为新生代采用复制算法收集)。</p>
<h2 id="2-3-长期存活的对象进入老年代"><a href="#2-3-长期存活的对象进入老年代" class="headerlink" title="2.3 长期存活的对象进入老年代"></a>2.3 长期存活的对象进入老年代</h2><p>与大对象相对应，小对象在GC过程中通常不会因为内存空间不够分配而直接进入老年代。为了确定哪些是“稳定”的对象（应该放入老年代），哪些是“朝生夕死”的对象（不应该进入老年代），jvm通过给每个对象定义一个对象年龄计数器的方式定义对象的年龄。对象在eden区出生，经过第一次Minor GC后仍然能存活，并且能被survivor区容纳，将被移动到survivor区中，并且对象的年龄设为1。对象在survivor区每经过一次Minor GC，对象的年龄就加1岁，当它的年龄增加到一定程度时（默认为15岁），就会晋升到老年代中去。</p>
<p>对象晋升老年代的年龄阈值，可通过参数<code>-XX:MaxTenuringThreshold</code>调整。</p>
<h2 id="2-4-动态对象年龄判定"><a href="#2-4-动态对象年龄判定" class="headerlink" title="2.4 动态对象年龄判定"></a>2.4 动态对象年龄判定</h2><p>为了能更好地适应不同程序的内存状况，虚拟机并不是永远的要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，而是有个机智的策略：如果在survivor区中处于某个年龄的对象内存总和大于survivor区内存的一半，那么年龄大于或等于该年龄的对象就可以直接进入老年代，无须达到MaxTenuringThreshold中要求的年龄。</p>
<h2 id="2-5-空间分配担保"><a href="#2-5-空间分配担保" class="headerlink" title="2.5 空间分配担保"></a>2.5 空间分配担保</h2><ul>
<li>在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象的空间，<ul>
<li>如果条件满足，那么Minor GC就是安全的，</li>
<li>否则继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小<ul>
<li>如果大于，则“尝试”进行一次Minor GC</li>
<li>如果小于，则要进行Full GC。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>为什么是尝试进行Minor GC呢？因为新生代采用复制收集算法，只使用其中一个survivor空间来作为轮换备份，因此出现大量对象在Minor GC后仍然存活的情况下（最极端的就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把survivor区无法容纳的对象直接移至老年代。</p>
<p>老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的空间，然而一共会有多少对象存活下来，在实际完成内存回收的过程中是无法明确知晓的，所以只好取之前每一次回收晋升到老年代的对象容量的平均大小值作为参考值，与老年代的剩余空间比较，来决定是否进行Full GC来让老年代腾出更多空间。</p>
<h2 id="2-6-总结"><a href="#2-6-总结" class="headerlink" title="2.6 总结"></a>2.6 总结</h2><ol>
<li>对象优先在eden区分配内存，如果eden没有足够的空间，则会触发Minor GC，清理空间</li>
<li>对象达到了MaxTenuringThreshold设定的年龄，或survivor区中相同年龄的所有对象大小的总和大于survivor区空间的一半时，年龄大于或等于该年龄的对象，就可以直接进入老年代</li>
<li>新生代对象的总大小或者历次晋升的平均大小大于老年代的连续空间时，就会进行Full GC，反之进行Minor GC</li>
</ol>
<h2 id="2-7-触发Full-GC的方式："><a href="#2-7-触发Full-GC的方式：" class="headerlink" title="2.7 触发Full GC的方式："></a>2.7 触发Full GC的方式：</h2><ol>
<li>Perm（永久代）空间不足；</li>
<li>CMS GC时出现promotion failed和concurrent mode failure（concurrent mode failure发生的原因一般是CMS正在进行，但是由于老年代空间不足，需要尽快回收老年代里面的不再被使用的对象，这时停止所有的线程，同时终止CMS，直接进行Serial Old GC）；</li>
<li>统计得到的Minor GC晋升到老年代的平均大小大于老年代的剩余空间；</li>
<li>主动触发Full GC（执行jmap -histo:live [pid]）来避免碎片问题。</li>
</ol>
<hr>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.jianshu.com/p/5040d62cf043" target="_blank" rel="noopener" title="java 对象的内存布局和大小计算">java 对象a内存布局和大小计算</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/21/JAVA%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/21/JAVA%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/" itemprop="url">JAVA垃圾回收器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-21T22:24:02+08:00">
                2019-11-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/JAVA-JVM/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA JVM</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/21/JAVA%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/11/21/JAVA垃圾回收器/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  16.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  57
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>java内存运行时区域的各个部分，其中的程序计数器，虚拟机栈，本地方法栈三个区域是随线程而生、随线程而亡的；</p>
<p>栈中的栈帧是随着方法的进入和退出而执行入栈和出栈的。每个栈帧中分配的内存在类结构确定下来时就是已知的，因此这几个区域的内存分配和回收都是确定的，方法结束和线程结束时，内存自然就回收了。</p>
<p>而Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序运行期间才能知道要创建哪些对象，这部分内存分配和回收是动态的，也就是说这部分内存的回收是要干预的。<strong>后续我们参与讨论的“内存”分配与回收也仅指这一部分内存</strong></p>
<h1 id="1-判断对象死亡与否"><a href="#1-判断对象死亡与否" class="headerlink" title="1.判断对象死亡与否"></a>1.判断对象死亡与否</h1><p>java堆里存放着几乎所有的对象实例，在进行GC前，我们必须要弄清楚那些对象还活着（即不可被回收），哪些对象已经死了（可以被回收了）。</p>
<p>我们有如下的方法来判断对象存活与否；</p>
<h2 id="1-1-引用计数法"><a href="#1-1-引用计数法" class="headerlink" title="1.1 引用计数法"></a>1.1 引用计数法</h2><blockquote>
<p> 给对象添加一个引用计数器，每当有一个地方引用它时，计数值就加1；当引用失效时计数器值就减1；任何时刻当一个对象的计数器值为0时就是不再被使用的，即就是要被回收的。</p>
</blockquote>
<p>这种算法实现简单，判定效率也很高，在多数情况下它是一个不错的算法，但是在java语言中没有选取这种方法来管理内存，因为它无法解决对象之间互相循环引用的问题：</p>
<ul>
<li>比如对象A和对象B都有字段instance</li>
<li>令A.instance = B及B.instance = A，除此之外这两个对象再无其他任何引用。</li>
</ul>
<p>实际上这两个对象是要被回收的对象，但是他们之间存在着互相引用，导致计数器的值不为0，引用计数算法就不能回收他们（回收条件计数器值为0）。</p>
<h2 id="1-2-可达性分析算法"><a href="#1-2-可达性分析算法" class="headerlink" title="1.2 可达性分析算法"></a>1.2 可达性分析算法</h2><p>主流的商用程序语言（JAVA/C#等）的主流实现都是通过可达性分析来判定对象是否存活。</p>
<blockquote>
<p>通过“GC Roots”的对象作为起始点，从这个起始点向下搜索，搜索所走过的路径成为引用链，当一个对象没有与任何引用链相连（即从GC Roots不可达），此时说明这个对象是不可用的。</p>
</blockquote>
<p>如下图，obj5，obj6，obj7虽然相互有关联，但是他们到GC Root是不可达的，会被判定为可回收的对象。<br><img src="https://oscimg.oschina.net/oscnet/d6249ffd6b925c4d76f9884bb9e2d1439d7.jpg" alt=""></p>
<p>在java语言中，可作为GC Roots的对象包含以下几种：</p>
<ul>
<li>虚拟机栈（栈帧中的本地变量表）中引用的对象。</li>
<li>方法区中类静态属性引用的对象。</li>
<li>方法区中的常量引用的对象</li>
<li>本地方法栈中JNI（即一般说的native方法）的引用的对象</li>
</ul>
<h1 id="2-引用"><a href="#2-引用" class="headerlink" title="2. 引用"></a>2. 引用</h1><p>传统的引用的定义（如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，那它就是引用）无法满足gc的需要。</p>
<p>在实际中我们希望能有这样的对象：当内存空间足够时保存在内存中，当内存紧张时，则可以抛弃这些对象。</p>
<p>故而在JDK1.2之后，java将引用的概念进行了扩充，将引用分为：强引用，软引用，弱引用，虚引用四种，这四种的引用强度依次逐渐减弱。</p>
<ul>
<li><p>强引用在代码中普遍存在，如Object obj = new Object() 这样的引用就是强引用，只要这个对象的引用还存在，垃圾回收器就永远不会回收它。（在通常对静态属性赋值时一定要各位注意，它的生命周期会贯穿整个app的生命周期）</p>
</li>
<li><p>软引用用来描述一些还有用，但是并非必须的对象，正常gc时不会回收它，只有在系统即将发生内存溢出之前，会将这些对象进行回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。</p>
</li>
<li><p>弱引用是用来描述非必须对象的，他比软引用更更弱一些，被弱引用关联的对象只能生存到下一次垃圾回收收集之前。当GC时无论当前内存是否足够，都会回收掉只被弱引用关联的对象（注意是只被弱引用关联的对象，如果一个对象即被强引用引用也被弱引用引用，GC时是不会回收的）</p>
</li>
<li><p>虚引用也称为幽灵引用或幻影引用，它是最弱的一种引用关系。一个对象是否有有虚引用，完全不会影响它的生存周期周期，也无法通过一个虚引用获得一个对象。为一个对象设置为虚引用关联的唯一目的就是希望能在这个对象被回收时收到一个系统通知。</p>
</li>
</ul>
<h1 id="3-finalize方法"><a href="#3-finalize方法" class="headerlink" title="3. finalize方法"></a>3. finalize方法</h1><p>即使是被可达性分析算法不可达的对象，也不是非死不可，这时候它处于“缓刑”状态，finalize()是它完成自救的最后机会</p>
<p>finalize()是Object中的方法,当垃圾回收器将要回收对象所占内存之前被调用，其过程为：</p>
<ul>
<li>某个对象被判断为不可达，被第一次标记。判断该对象是否有必要执行finalize()<ul>
<li>如果对象没有重新该方法，或者该方法已经被虚拟机调用过（所以finalize()最多只能执行一次），它将第二次被标记，基本上在劫难逃了。</li>
<li>否则，则会将该对象放置在一个叫做F-Queue的队列中，并在稍后由一条虚拟机自动建立的，低优先级的Finalizer线程去执行（调用finalize（）方法），但并不承诺会等待它运行结束<ul>
<li>finalize（）方法是对象逃离死亡的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象在finalize（）中成功拯救了自己（重新与引用链建立关联），那在第二次标记时它将被移除出即将回收的集合；</li>
<li>否则，第二次标记没躲掉，它基本上也在劫难逃了。</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>不承诺执行完finalize（）的原因是：如果一个对象的finalize（）方法执行缓慢或者发生死循环等极端情况，将会导致F-Queue队列永久处于等待zhua状态，甚至导致整个GC系统的崩溃。</p>
</blockquote>
<blockquote>
<p>在java中不建议使用finalize方法。</p>
</blockquote>
<h1 id="4-方法区的回收"><a href="#4-方法区的回收" class="headerlink" title="4. 方法区的回收"></a>4. 方法区的回收</h1><p>很多人认为方法区（或者HotSpot虚拟机中的永久代）是没有垃圾回收的，java虚拟机规范确实说过不要求虚拟机在方法区实现垃圾回收，而且在方法区进行垃圾回收的性价比比较低：在堆中，尤其是在新生代中，常规的应用进行一次垃圾回收一般能回收70%~95%的空间，而永久代代的垃圾回收效率远低于此。</p>
<p>其实永久代的垃圾回收主要回收两部分内容</p>
<ul>
<li><p>废弃常量</p>
<ul>
<li>回收废弃常量与回收java堆中的对象非常类似，比如常量池字面量‘abc’，如果此时没有一个String对象值为‘abc’，即没有任何String对象引用‘abc’常量，那么发生gc时，其将被清出常量池。常量池中的其他类、接口、方法、字段的符号引用也类似。</li>
</ul>
</li>
<li><p>无用的类</p>
<ul>
<li><p>相比判断废弃常量，判断无用的类条件比较苛刻，需要同时满足以下三个条件。</p>
<ul>
<li><p>该对象的所有实例都已经被回收，也就是堆中不存在该类的任何实例。</p>
</li>
<li><p>加载该类的ClassLoader也已经被回收</p>
</li>
<li><p>该类对应的java.lang.Class对象没有在任何地方被引用，也无法在任何地方通过反射来访问该类的方法</p>
</li>
</ul>
</li>
<li><p>虚拟机可以对这样的无用的类进行回收，但也局限于可以，而不是必然。Hotspot虚拟机提供了-Xnoclass参数进行控制。</p>
</li>
</ul>
</li>
</ul>
<h1 id="4-垃圾回收算法"><a href="#4-垃圾回收算法" class="headerlink" title="4. 垃圾回收算法"></a>4. 垃圾回收算法</h1><h2 id="4-1-标记-清除算法"><a href="#4-1-标记-清除算法" class="headerlink" title="4.1 标记-清除算法"></a>4.1 标记-清除算法</h2><p>（Mark-sweep）这是最基础的垃圾回收算法，顾名思义，分为标记和清除两个阶段。它这里的标记就是指介绍finalize方法时提到的第二次标记。</p>
<blockquote>
<p>首先标记出所有需要回收的对象，在标记完成后统一回收掉被标记的对象。它主要有两个缺点：一个是效率问题，标记和清理过程效率都不高；另一个问题是空间问题，在清除后会产生大量不连续的内存碎片，当空间碎片太多时会导致，当程序以后运行需要分配较大对象时无法找到足够的连续内存而不得不提前触发下一次GC动作。</p>
</blockquote>
<p><img src="https://oscimg.oschina.net/oscnet/307291672aaad50b723465c56a901fcdded.jpg" alt=""></p>
<h2 id="4-2-复制算法"><a href="#4-2-复制算法" class="headerlink" title="4.2 复制算法"></a>4.2 复制算法</h2><p>为了解决效率问题，复制算法应运而生。</p>
<blockquote>
<p>它将内存按容量划分为大小相等的两块，每次使用其中的一块。当这一块用完时就将还存活的对象复制到令一块上，然后将已使用过的这一块内存清理掉。这样分配时就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行效率高。</p>
</blockquote>
<p><strong>但是缺点也是显而易见的：内存利用率只有一半。</strong></p>
<p><img src="https://oscimg.oschina.net/oscnet/4f884849df9cda6a0c38b20e78d2428dc06.jpg" alt=""></p>
<h3 id="4-2-1-新生代的回收"><a href="#4-2-1-新生代的回收" class="headerlink" title="4.2.1 新生代的回收"></a>4.2.1 新生代的回收</h3><p>现在的商业虚拟机都采用这种算法来收集新生代，IBM的专门研究表明，新生代的对象98%都是朝生夕死的，所以并不需要按1：1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块SuSurvivor。</p>
<p>回收时，将Eden和刚才刚才用过的Survivor的空间中还活着的对象一次拷贝到令外一块Survivor空间上，最后清理掉Eden和刚才刚才使用过的Survivor的空间。</p>
<p>虚拟机默认Eden区和Survivor区的大小比例是8:1，也就是每次新生代中可用空间为整个新生代容量的90%。</p>
<p>当然我们没办法保证每次回收时，都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他的内存（这里指老年代）进行分配担保。（稍后详解）</p>
<h2 id="4-3-标记-整理算法"><a href="#4-3-标记-整理算法" class="headerlink" title="4.3 标记-整理算法"></a>4.3 标记-整理算法</h2><p>如果内存中对象的存活率比较高的话，那么复制算法需要执行较多的复制操作，效率会变低，更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。</p>
<p>根据老年代的特点，有人提出了“标记–整理”算法，标记过程仍与“标记–清除”算法一样，但是后续步骤不是直接对可回收的对象进行清理，而是让<strong>所有存活的对象</strong>都向一端移动，然后直接清理掉端边界以外的内存。</p>
<p><img src="https://oscimg.oschina.net/oscnet/d1f66984f417d019a3eba91276c6c0e2cb6.jpg" alt=""></p>
<h2 id="4-4-分代收集算法"><a href="#4-4-分代收集算法" class="headerlink" title="4.4 分代收集算法"></a>4.4 分代收集算法</h2><p>当前商业虚拟机的垃圾回收都是采用的“分代收集”算法，根据对象的存货周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的垃圾回收算法。在新生代中，每次垃圾每次垃圾回收都发现大批对象死去，只有少量存活，<strong>那就使用复制算法</strong>。而老年代中因为对象存活率较高，没有额外的空间对它进行分配担保，<strong>就必须使用“标记–清理‘’或者‘标记–整理’‘算法来进行回收</strong>。</p>
<h1 id="5-HotSpot虚拟机的算法实现"><a href="#5-HotSpot虚拟机的算法实现" class="headerlink" title="5 HotSpot虚拟机的算法实现"></a>5 HotSpot虚拟机的算法实现</h1><p>上述的这些对象存货判断算法和垃圾收集算法，在hotspot虚拟机上，会为了达到更高的效率，而做一些优化或者变动。这些优化有：</p>
<h2 id="5-1-枚举根节点"><a href="#5-1-枚举根节点" class="headerlink" title="5.1 枚举根节点"></a>5.1 枚举根节点</h2><p>可达性分析算法目前有两个主要的局限：</p>
<ul>
<li><p>可达性分析需要从GC root节点开始寻找引用链，而GC root主要在全局性的引用（常量和静态变量）和执行的上下文（栈帧的本地变量）中，这类数据日臻庞大，如果要逐个检查，那么必然消耗很多时间。</p>
</li>
<li><p>可达性分析需要等待GC停顿，即一个整个系统类似被冻结的时间节点（停顿所有执行线程），因为可达性分析无法在引用关系还在不断变化的情况下准确分析。</p>
</li>
</ul>
<p>目前主流的java虚拟机都采用准确式GC，所以当gc停顿后，并不需要一个不漏的检查所有上下文和全局的引用。在HotSpot的实现中，有一组成为OopMap的数据结构，类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用。这样，GC在扫描时就可以直接得知哪些地方存放着对象引用。</p>
<blockquote>
<p>准确式内存管理：即虚拟机可以知道内存中某个位置的数据具体是什么类型。譬如内存中有一个32位的整数123456，它到底是一个reference类型指向的123456的内存地址还是一个数值为123456的整数，虚拟机将有能力分辨出来，这样才能在GC的时候准确判断对上的数据是否还可能被使用。</p>
</blockquote>
<p>保守式GC,半保守式GC和准确式GC，以及OopMap，推荐可以拓展看该篇文章<a href="https://my.oschina.net/lscherish/blog/3128494" target="_blank" rel="noopener" title="JVM中的OopMap">JVM中的OopMap</a></p>
<h2 id="5-2-安全点Safe-Point"><a href="#5-2-安全点Safe-Point" class="headerlink" title="5.2 安全点Safe Point"></a>5.2 安全点Safe Point</h2><p> 有了OopMap，HotSpot可以快速准确完成GC Roots枚举。但是另一个问题来了，我们要在什么地方创建OopMap？程序运行期间，引用的变化在不断发生，如果每一条指令都生成OopMap，那占用空间就太大了。为了解决这个问题，我们引入了安全点（Safe Point）—— 只在安全点进行GC停顿，只要保证引用变化的记录完成于GC停顿之前就可以。</p>
<blockquote>
<p>可以理解为OopMap表示的是一个班级的座位表，上面记录每个同学都在xx行xx列，分别是男是女。假设班上的同学一直在不停的变换位置，如果我们每一次变换都要创建一张新的座位表，那太繁琐，占用空间也多。<br>为了解决这个问题，我们加入了一个暂停（安全点）的概念，即某个时刻，所有同学的移动停止，我们只会在暂停的时候发生gc，那么也只需要在每次暂停之前生成座位表即可。因为座位表是给gc用的，gc又只会发生在安全点，所以这样是可行的。</p>
</blockquote>
<p>安全点选定太少，GC等待时间就太长，选的太多，GC就过于频繁。选定原则是”具有让程序长时间执行的特征“，也就是在这个时刻现有的指令是可以复用的。一般选在方法调用、循环跳转、抛出异常的位置。</p>
<p>现在的问题是在Safe Point让线程们以怎样的机制中断，方案有两种：抢先式中断、主动式中断。</p>
<ul>
<li>抢先式中断：GC发生时，中断所有线程，如果发现有线程不再安全点上，就恢复线程让它运行到安全点上。现在几乎不用这种方案。</li>
<li>主动式中断：设置一个标志，和安全点重合，再加上创建对象分配内存的地方。各个线程主动轮询这个标志，发现中断标志为真就挂起自己。HotSpot使用主动式中断。</li>
</ul>
<h2 id="5-3-安全区域safe-region"><a href="#5-3-安全区域safe-region" class="headerlink" title="5.3 安全区域safe region"></a>5.3 安全区域safe region</h2><p>貌似引入安全点，再加上OopMap，就可以完美解决GC的性能问题了，但实际上，我们还考虑漏了一种情况。即有些程序此时处于无法响应jvm中断请求的状态（比如线程sleep或者block），这样程序不会走到安全点了。</p>
<blockquote>
<p>类比的话就是移动过程中，有些同学睡着了，听不到暂停的指令（中断请求），他可能睡醒后回过神来，自顾自的去下一个座位，全然不顾班上其他同学已经暂停了。</p>
</blockquote>
<p>为了解决这个问题，hotSpot还引入了安全区域的概念。</p>
<p>安全区域是指在一段代码片段中，引用关系不会发生变化，在该区域的任何地方发生GC都是安全的。当代码执行到安全区域时，首先标识自己已经进入了安全区域，那样如果在这段时间里JVM发起GC，就不用管标示自己在安全区域的那些线程了，<strong>在线程离开安全区域时，会检查系统是否正在执行GC，如果是，就等到GC完成后再离开安全区域</strong>。</p>
<blockquote>
<p>类比为：所有睡着的同学，你们睡着可以，但是要给自己做个标记，这样我暂停排座位表（OopMap）的时候，我就忽略你们了。但是为了防止你们在暂停的时候突然醒来，然后后知后觉的到处乱闯，我只好跟你们约法三章：睡醒的时候，问一下周围现在是不是在暂停中，如果是的话，你们就不要动弹，等暂停结束了再走。</p>
</blockquote>
<h1 id="6-垃圾收集器"><a href="#6-垃圾收集器" class="headerlink" title="6 垃圾收集器"></a>6 垃圾收集器</h1><p>如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。</p>
<p>以下是hotspot虚拟机中的7中作用于不同分代的垃圾收集器，连线表示垃圾收集器可以配合使用。</p>
<p><img src="https://oscimg.oschina.net/oscnet/0ffbb89b57bb4885b3ca3854536ab80a691.jpg" alt=""></p>
<blockquote>
<p>现在来说，目前并不存在一个万能的收集器，具体应用或者具体场景，都有不同的适用的收集器。</p>
</blockquote>
<blockquote>
<p>关于收集器，我们常会用到并行与并发来做描述，他们的区别是：<br>      <strong>并行（parallel）</strong>：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。<br>      <strong>并发（concurrent）</strong>：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户线程在继续运行，而垃圾手机程序运行在另一个cpu上。</p>
</blockquote>
<h2 id="6-1-serial收集器"><a href="#6-1-serial收集器" class="headerlink" title="6.1 serial收集器"></a>6.1 serial收集器</h2><p>该收集器是最基本，最悠久的收集器，曾经在jdk1.3.1之前是虚拟机新生代收集的唯一选择。</p>
<p>它是单线程的收集器，不仅意味着只会使用一个线程进行垃圾收集工作，更重要的是它在进行垃圾收集时，<strong>必须暂停所有其他工作线程，往往造成过长的等待时间</strong>。</p>
<p><strong>serial收集器的新生代采用复制算法，老年代采取标记整理算法</strong>。</p>
<p><img src="https://oscimg.oschina.net/oscnet/4d99d32625cd2bcdd3a32cd978cea4592ee.jpg" alt=""></p>
<p>虽然经过长久的发展，为了减少停顿，开发团队设计和实现了许多更优秀更复杂的收集器，但不意味着serial老而无用。它目前仍然是虚拟机运行在client模式下的默认新生代收集器。它的优点是<strong>简单高效</strong>，对于单个 CPU 环境来说，由于没有线程交互的开销，因此拥有最高的单线程收集效率。</p>
<p>在 Client 应用场景中，分配给虚拟机管理的内存一般来说不会很大，该收集器收集几十兆甚至一两百兆的新生代停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿是可以接受的。</p>
<h2 id="6-2-ParNew-收集器"><a href="#6-2-ParNew-收集器" class="headerlink" title="6.2 ParNew 收集器"></a>6.2 ParNew 收集器</h2><p><strong>它是 Serial 收集器的多线程版本。</strong>除了使用多线程进行垃圾收集之外，其余行为包括serial收集器可用的控制参数、收集算法、stop the world、对象分配规则、回收策略等都和serial收集器完全一样。实际上二者也共用了相当多的代码。</p>
<p><img src="https://oscimg.oschina.net/oscnet/13cf838ac2071b9871818127bbf7134ea75.jpg" alt=""></p>
<p>虽然并无太多创新之处，但它是许多运行在Server模式下的虚拟机首选的新生代收集器，除了性能原因外，主要是因为除了serial收集器，只有它能与CMS收集器配合工作。</p>
<p>默认开始的线程数量与 CPU 数量相同，可以使用 -XX:ParallelGCThreads 参数来设置线程数。</p>
<blockquote>
<p>CMS收集器在jdk1.5中横空出世，其并发收集的特性具有划时代意义，但它作为老年代收集器，却只能和parnew和serial配合工作。parnew因为性能原因，是在使用cms时默认的新生代收集器。</p>
</blockquote>
<h2 id="6-3-parallel-scavenge收集器"><a href="#6-3-parallel-scavenge收集器" class="headerlink" title="6.3 parallel scavenge收集器"></a>6.3 parallel scavenge收集器</h2><p>新生代收集器，<strong>复制算法</strong>，并行的多线程收集器。看起来和parnew收集器类似，但它的特点是它的关注点和其他收集器不同。CMS等收集器的关注点是尽可能的缩短垃圾收集时的停顿时间，而parallel scavenge收集器的目的是达到一个可控制的吞吐量。它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户代码的时间占总时间的比值。（比如虚拟机运行了100分钟，垃圾回收花掉1分钟，则吞吐量是99%）</p>
<blockquote>
<p>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。<br>而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。</p>
</blockquote>
<p>parallel scavenge提供了下列参数用于精确控制吞吐量:</p>
<ul>
<li>控制最大垃圾收集停顿时间 -XX:MaxGCPauseMillis 参数，值为大于0的毫秒数，收集器尽可能保证内存回收花费的时间不超过该值。</li>
<li>直接设置吞吐量大小的 -XX:GCTimeRatio 参数，值为大于 0 且小于 100 的整数，它的值是吞吐量的倒数。</li>
<li>开关参数 -XX:+UseAdaptiveSizePolicy。打开参数后，就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种方式称为 GC 自适应的调节策略（GC Ergonomics）。</li>
</ul>
<blockquote>
<p>不要以为把XX:MaxGCPauseMillis 设置得小一些就能使垃圾回收更快，GC停顿时间缩短是牺牲吞吐量和新生代空间换来的。不说别的，调小这个值，一般会导致gc触发更加频繁，吞吐量反而下降。</p>
</blockquote>
<h2 id="6-4-Serial-Old收集器"><a href="#6-4-Serial-Old收集器" class="headerlink" title="6.4 Serial Old收集器"></a>6.4 Serial Old收集器</h2><p>老年代收集器，串行的单线程收集器，使用<strong>标记整理算法</strong>。是serial收集器的老年代版本。</p>
<p>Serial Old是Serial收集器的老年代版本，是个单线程收集器，也是给Client模式下的虚拟机使用。如果用在Server模式下，它有两大用途：</p>
<ul>
<li>在JDK 1.5 以及之前版本（Parallel Old诞生以前）中与Parallel Scavenge收集器搭配使用。</li>
<li>作为 CMS 收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/b4b25c2752edb839b6b9e185e6ab3093dd4.jpg" alt=""></p>
<h2 id="6-5-Parallel-Old收集器"><a href="#6-5-Parallel-Old收集器" class="headerlink" title="6.5 Parallel Old收集器"></a>6.5 Parallel Old收集器</h2><p>老年代收集器，并行的多线程收集器，标记整理算法。是Parallel Scavenge收集器的老年代版本，吞吐量优先的垃圾回收器。</p>
<p>在注重吞吐量以及CPU资源敏感的场合（服务端应用），都可以优先考虑Parallel Scavenge加Parallel Old收集器。</p>
<p><img src="https://oscimg.oschina.net/oscnet/4e335c54c634db7a57ee286044f08f27713.jpg" alt=""></p>
<h2 id="6-6-CMS收集器（详细介绍）"><a href="#6-6-CMS收集器（详细介绍）" class="headerlink" title="6.6 CMS收集器（详细介绍）"></a>6.6 CMS收集器（详细介绍）</h2><p>老年代收集器，并行的多线程收集器，使用<strong>标记整理</strong>算法。是一种以获取最短回收停顿时间为目标的收集器。目前大部分java应用集中在互联网网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短。</p>
<p>CMS牺牲了系统的吞吐量来追求收集速度，适合追求垃圾收集速度的服务器上。</p>
<h3 id="6-6-1-优缺点"><a href="#6-6-1-优缺点" class="headerlink" title="6.6.1 优缺点"></a>6.6.1 优缺点</h3><p>特点：</p>
<ul>
<li><p>并发收集</p>
</li>
<li><p>低停顿。<br>缺点：</p>
</li>
<li><p>对CPU资源敏感。因为并发阶段虽然用户线程不停顿，但会占用CPU资源导致用户线程变慢，吞吐量降低。CMS默认启动的回收线程数是 (CPU 数量 + 3) / 4。</p>
<ul>
<li>当CPU&gt;4时，并发线程&gt;25%的CPU资源。且随CPU数量增加而下降。</li>
<li>当CPU&lt;4时（假设为2），并发线程&gt;50%的CPU资源，很影响用户体验。</li>
</ul>
</li>
<li><p>无法处理浮动垃圾。</p>
<ul>
<li>浮动垃圾：由于并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生。这一部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理掉它们，只好留到下一次 GC 时再清理掉，这一部分垃圾就被称为“浮动垃圾”。</li>
<li>也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此它不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。</li>
<li>可以使用 -XX:CMSInitiatingOccupancyFraction 的值来改变触发收集器工作的内存占用百分比，JDK 1.5默认设置下该值为68，JDK1.6默认设置下该值为92，也就是当老年代使用了68%(92%)的空间之后会触发收集器工作。</li>
<li>如果-XX:CMSInitiatingOccupancyFraction 设置的太高，导致浮动垃圾无法保存，那么就会出现Concurrent Mode Failure，此时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集。</li>
</ul>
</li>
<li><p>标记 - 标记清除算法会导致大量空间碎片，给大对象分配带来很大的麻烦，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次Full GC。</p>
</li>
</ul>
<h3 id="6-6-2-触发条件"><a href="#6-6-2-触发条件" class="headerlink" title="6.6.2 触发条件"></a>6.6.2 触发条件</h3><p>CMS垃圾收集器的触发条件有以下几个：</p>
<ol>
<li>如果没有设置-XX:+UseCMSInitiatingOccupancyOnly，虚拟机会根据收集的数据决定是否触发（建议带上这个参数）。</li>
<li>老年代使用率达到阈值 CMSInitiatingOccupancyFraction，默认68%，即当老年代的空间使用率达到 68%时，会执行一次 CMS 回收。前提是配置了第一个参数。</li>
<li>永久代的使用率达到阈值 CMSInitiatingPermOccupancyFraction，默认92%，前提是开启 CMSClassUnloadingEnabled并且配置了第一个参数。</li>
<li>新生代的晋升担保失败。老年代有足够的空间，但是由于碎片化严重，无法容纳新生代中晋升的对象，发生晋升失败。</li>
</ol>
<h3 id="6-6-3-收集过程"><a href="#6-6-3-收集过程" class="headerlink" title="6.6.3 收集过程"></a>6.6.3 收集过程</h3><p>采用“标记-清理”算法对老年代进行回收，过程可以说很简单，标记出存活对象，清理掉垃圾对象，但是为了实现整个过程的低延迟，实际算法远远没这么简单，整个过程分为如下几个部分：</p>
<ul>
<li>初始标记(CMS-initial-mark) ，仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，<strong>需要停顿</strong>。</li>
<li>并发标记(CMS-concurrent-mark)，与用户线程同时运行，进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，。</li>
<li>预清理（CMS-concurrent-preclean），与用户线程同时运行；</li>
<li>可被终止的预清理（CMS-concurrent-abortable-preclean） 与用户线程同时运行；</li>
<li>并发重新标记(CMS-remark) ，为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，<strong>需要停顿</strong>。</li>
<li>并发清除(CMS-concurrent-sweep)，与用户线程同时运行。</li>
<li>并发重置状态等待下次CMS的触发(CMS-concurrent-reset)，与用户线程同时运行；</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/a9cecff7a47d3a0d0678e22246c1e687f8c.jpg" alt=""></p>
<h4 id="6-6-3-1-初始标记"><a href="#6-6-3-1-初始标记" class="headerlink" title="6.6.3.1 初始标记"></a>6.6.3.1 初始标记</h4><p>这是CMS中两次stop-the-world事件中的第一次。该阶段的工作是：标记<strong>存活的对象</strong>，主要有两种对象：</p>
<ol>
<li>标记老年代中所有的GC Roots对象，如下图节点1；</li>
<li>标记年轻代中活着的对象（GC Roots可达）引用到的老年代的对象（指的是年轻带中还存活的引用类型对象，引用指向老年代中的对象）如下图节点2、3；</li>
</ol>
<p><img src="https://oscimg.oschina.net/oscnet/91717af3b0ca9a874a1156120718eb3bcd1.jpg" alt=""></p>
<blockquote>
<p>为了加快此阶段处理速度，减少停顿时间，可以开启初始标记并行化，-XX:+CMSParallelInitialMarkEnabled，同时调大并行标记的线程数，线程数不要超过cpu的核数。</p>
</blockquote>
<h4 id="6-6-3-2-并发标记"><a href="#6-6-3-2-并发标记" class="headerlink" title="6.6.3.2 并发标记"></a>6.6.3.2 并发标记</h4><p>该阶段的工作是：<br>    - 从”初始标记”阶段标记的对象开始找出所有存活的对象;<br>    - 有变更的对象作重新标记<br>        - 因为是并发运行的，在运行期间会发生新生代的对象晋升到老年代、或者是直接在老年代分配对象、或者更新老年代对象的引用关系等等，对于这些对象，都是需要进行重新标记的，否则有些对象就会被遗漏，发生漏标的情况。<br>        - 为了提高重新标记的效率，该阶段会把上述对象所在的Card标识为Dirty，后续只需扫描这些Dirty Card的对象，避免扫描整个老年代；</p>
<blockquote>
<p>CMS将老年代的空间分成大小为512bytes的块，并维护一个叫做card table的数组（每个位置存的是一个byte），card table中的每个元素对应着一个块。并发标记时，如果某个对象的引用发生了变化，就标记该对象所在的块为dirty card。</p>
</blockquote>
<p>如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/ca047a2e3c46111f468435d4d84ae52a966.jpg" alt=""></p>
<p>先从”初始标记”阶段标记的对象开始找出所有存活的对象，即我们从节点1、2、3找到了节点4、5。</p>
<p>但在找到4/5节点的过程中，因为我们是并发执行的，所以可能会有一些引用发生了变更，比如节点3引用了另外一个对象，如下图：<br><img src="https://oscimg.oschina.net/oscnet/c50fbe36521473afe764d707d913ab58295.jpg" alt=""></p>
<p>这个时候，jvm会将节点3所在的card标记为dirty，但只做标记，不做处理。</p>
<h4 id="6-6-3-3-预清理阶段"><a href="#6-6-3-3-预清理阶段" class="headerlink" title="6.6.3.3 预清理阶段"></a>6.6.3.3 预清理阶段</h4><p>这个阶段就是用来处理前一个阶段因为引用关系改变导致没有标记到的存活对象的，它会扫描所有标记为Dirty的Card，然后将之前没有标记到的存活对象也标记上。</p>
<p>如下图，节点3引用的节点6也被标记上了，标记完成，并且将节点3的card的dirty状态清除。</p>
<p><img src="https://oscimg.oschina.net/oscnet/8f49f16ec62cca1671507fd60ae71648bed.jpg" alt=""></p>
<blockquote>
<p>通过参数CMSPrecleaningEnabled可以选择关闭该阶段，默认启用</p>
</blockquote>
<h4 id="6-6-3-4-可中断的预清理"><a href="#6-6-3-4-可中断的预清理" class="headerlink" title="6.6.3.4 可中断的预清理"></a>6.6.3.4 可中断的预清理</h4><p>该阶段发生的前提是，新生代Eden区的内存使用量大于参数CMSScheduleRemarkEdenSizeThreshold 设置的值，默认是2M，如果新生代的对象太少，就没有必要执行该阶段，直接执行重新标记阶段。</p>
<p><strong>为什么需要这个阶段，存在的价值是什么？</strong></p>
<p>其实这个阶段，是为了后面即将进行的“并发重新标记”环节能少一些工作量而设置的，“并发重新标记”我们还没讲到，这里简单说下：“并发重新标记”会扫描并且标记整个年老代的所有的存活对象，包括<strong>被新生代中的对象引用的老年代对象，即使新生代的对象已经不可达了，也将其引用的老年代对象视为存活</strong></p>
<p>因此，如果进入“并发重新标记”时，新生代的对象有很多，那么一个个检查过去他们是否引用老年代对象的过程也必然很长（所以该阶段触发前提是新生代内存大于CMSScheduleRemarkEdenSizeThreshold的值）</p>
<p>为了进入“并发重新标记”阶段时新生代对象尽可能少，“可中断的预清理”阶段会做两件工作：</p>
<ol>
<li>处理From和To区的对象，标记可达的老年代对象</li>
<li>和上一个阶段一样，扫描处理Dirty Card中的对象</li>
</ol>
<p>然而你会发现：</p>
<ul>
<li>工作1不就是“并发重新标记”的其中一项工作么，现在做和后续做，有什么区别吗？</li>
<li>工作2与其说是“可中断的预清理”的工作，还不如说cms收集器在并发过程中就一直会在标记这些dirty card，并不是该阶段独有的工作。</li>
</ul>
<p>如此看来，“可中断的预清理”阶段岂不是形同鸡肋？</p>
<p>其实，该阶段的目的在于：<strong>期待在该阶段的过程中，能够迎来一次young gc</strong>；</p>
<p>我们知道，新生代的对象大部分朝生暮死，每次young gc都会清理大量的新生代对象，如果在进入“并发重新标记”阶段前能够执行一次young gc，那“并发重新标记”阶段的扫描岂不是会轻松很多？</p>
<p>而且本身“可中断的预清理”阶段的触发前提就是新生代内存使用量超过一定阈值，虽然gc是JVM自动调度的，什么时候进行young gc我们控制不了，但既然能够满足“新生代内存使用量超过一定阈值”的前提，并进入“可中断的预清理”阶段，那么理论上离下一次的young gc应该也不远了。</p>
<p>所以，“可中断的预清理”阶段的核心就是：一直重复 “处理From和To区的对象，标记可达的老年代对象” 和 “扫描处理Dirty Card中的对象” 这两项工作，以期待在期间引来一次young gc</p>
<p>注意，是一直重复上述两项工作，直到：</p>
<ul>
<li>可以设置最多循环的次数 CMSMaxAbortablePrecleanLoops，默认是0，意思没有循环次数的限制。</li>
<li>如果执行这个逻辑的时间达到了阈值CMSMaxAbortablePrecleanTime，默认是5s，会退出循环。</li>
<li>如果新生代Eden区的内存使用率达到了阈值CMSScheduleRemarkEdenPenetration，默认50%，会退出循环。（这个条件能够成立的前提是，在进行Precleaning时，Eden区的使用率小于十分之一）</li>
</ul>
<h4 id="6-6-3-5-并发重新标记"><a href="#6-6-3-5-并发重新标记" class="headerlink" title="6.6.3.5 并发重新标记"></a>6.6.3.5 并发重新标记</h4><p>该阶段并发执行，在之前的并行阶段（GC线程和应用线程同时执行，好比你妈在打扫房间，你还在扔纸屑），可能产生新的引用关系如下：</p>
<ol>
<li>老年代的新对象被GC Roots引用</li>
<li>老年代的未标记对象被新生代对象引用</li>
<li>老年代已标记的对象增加新引用指向老年代其它对象</li>
<li>新生代对象指向老年代引用被删除</li>
<li>也许还有其它情况..<br>上述对象中可能有一些已经在Precleaning阶段和AbortablePreclean阶段被处理过，但总存在没来得及处理的，所以还有进行如下的处理：</li>
<li>遍历新生代对象和老年代对象，并重新标记存活的老年代对象，包括前文所说的<strong>新生代对象引用的老年代对象</strong>，即便新生代对象不可达了。</li>
<li>根据GC Roots，重新标记</li>
<li>遍历老年代的Dirty Card，重新标记，这里的Dirty Card大部分已经在clean阶段处理过，这里处理最近新生成的。</li>
</ol>
<p>在第一步骤中，需要遍历新生代的全部对象，如果新生代的使用率很高，需要遍历处理的对象也很多，这对于这个阶段的总耗时来说，是个灾难（因为可能大量的对象是暂时存活的，而且这些对象也可能引用大量的老年代对象，造成很多应该回收的老年代对象而没有被回收，遍历递归的次数也增加不少），如果在“可中断的预清理”阶段中能够恰好的发生一次young gc，这样就可以避免扫描无效的对象。</p>
<p>如果在AbortablePreclean阶段没来得及执行一次young gc，怎么办？</p>
<p>CMS算法中提供了一个参数：CMSScavengeBeforeRemark，默认并没有开启，如果开启该参数，在执行该阶段之前，会强制触发一次YGC，可以减少新生代对象的遍历时间，回收的也更彻底一点。</p>
<p>不过，这种参数有利有弊，利是降低了Remark阶段的停顿时间，弊的是在新生代对象很少的情况下也多了一次YGC，最可怜的是在AbortablePreclean阶段已经发生了一次YGC，然后在该阶段又傻傻的触发一次。</p>
<p>所以利弊需要把握。</p>
<h4 id="6-6-3-6-并发清理"><a href="#6-6-3-6-并发清理" class="headerlink" title="6.6.3.6 并发清理"></a>6.6.3.6 并发清理</h4><p>通过以上5个阶段的标记，老年代所有存活的对象已经被标记并且现在要通过Garbage Collector采用清扫的方式回收那些不能用的对象了。</p>
<p><strong>这个阶段主要是清除那些没有标记的对象并且回收空间</strong>；</p>
<p>由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。</p>
<h2 id="6-7-G1收集器"><a href="#6-7-G1收集器" class="headerlink" title="6.7 G1收集器"></a>6.7 G1收集器</h2><p>G1 GC，全称Garbage-First Garbage Collector，通过-XX:+UseG1GC参数来启用，作为体验版随着JDK 6u14版本面世，在JDK 7u4版本发行时被正式推出，相信熟悉JVM的同学们都不会对它感到陌生。在JDK 9中，G1被提议设置为默认垃圾收集器（JEP 248）。</p>
<p>G1（Garbage First）垃圾收集器也是以关注延迟为目标、服务器端应用的垃圾收集器，被HotSpot团队寄予取代CMS的使命，也是一个非常具有调优潜力的垃圾收集器。</p>
<p>它是专门针对以下应用场景设计的:</p>
<ul>
<li>像CMS收集器一样，能与应用程序线程并发执行。</li>
<li>整理空闲空间更快。</li>
<li>需要GC停顿时间更好预测。</li>
<li>不希望牺牲大量的吞吐性能。</li>
</ul>
<p>它的特点有：</p>
<ol>
<li>的设计原则是”垃圾优先? 不是，是优先处理那些垃圾多的内存块(Garbage First)”。因此，G1并不会等内存耗尽(串行、并行)或者快耗尽(CMS)的时候开始垃圾收集，而是在内部采用了启发式算法，在老年代找出具有高收集收益的分区进行收集。同时G1可以根据用户设置的暂停时间目标自动调整年轻代和总堆大小，暂停目标越短年轻代空间越小、总空间就越大；</li>
<li>G1采用内存分区(Region)的思路，将内存划分为一个个相等大小的内存分区，回收时则以分区为单位进行回收，存活的对象复制到另一个空闲分区中。由于都是以相等大小的分区为单位进行操作，因此G1天然就是一种压缩方案(局部压缩)；</li>
<li>G1虽然也是分代收集器，但整个内存分区不存在物理上的年轻代与老年代的区别，也不需要完全独立的survivor(to space)堆做复制准备。G1只有逻辑上的分代概念，或者说每个分区都可能随G1的运行在不同代之间前后切换；</li>
<li>G1的收集都是STW的，但年轻代和老年代的收集界限比较模糊，采用了混合(mixed)收集的方式。即每次收集既可能只收集年轻代分区(年轻代收集)，也可能在收集年轻代的同时，包含部分老年代分区(混合收集)，这样即使堆内存很大时，也可以限制收集范围，从而降低停顿。</li>
<li>G1整体采用标记-整理算法，局部是通过是通过复制算法，不会产生很多内存碎片。</li>
</ol>
<h3 id="6-7-1-G1的内存模型"><a href="#6-7-1-G1的内存模型" class="headerlink" title="6.7.1 G1的内存模型"></a>6.7.1 G1的内存模型</h3><h4 id="6-7-1-1-region分区"><a href="#6-7-1-1-region分区" class="headerlink" title="6.7.1.1 region分区"></a>6.7.1.1 region分区</h4><p>G1将新生代，老年代的物理空间划分模糊化了。取而代之的是，G1算法将堆划分为若干个大小相等的内存区域（Region）。</p>
<ul>
<li><p>每次分配对象空间将逐段地使用内存。因此，在堆的使用上，G1并不要求对象的存储一定是物理上连续的，只要逻辑上连续即可；</p>
</li>
<li><p>启动时可以通过参数<code>-XX:G1HeapRegionSize=n</code>可指定region大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个region。</p>
</li>
<li><p>它仍然属于分代收集器，仍然会分为新生代（Eden和survivor）和老年代，只不过此时的内存单位是region，即某些region为新生代服务（如下图的E和S），某些region为老年代服务（下图的O），<strong>新生代的垃圾收集依然采用暂停所有应用线程的方式，将存活对象拷贝到老年代或者Survivor空间</strong>。</p>
</li>
<li><p>每个region也不会确定地只为某个代服务，可以按需在年轻代和老年代之间切换。（但在特定时刻，它要么为新生代服务，要么为老年代服务）。年轻代空间并不是固定不变的，当现有年轻代分区占满时，JVM会分配新的空闲region加入到年轻代空间。</p>
</li>
<li><p>整个年轻代内存会在初始空间<code>-XX:G1NewSizePercent</code>(默认整堆5%)与最大空间<code>-XX:G1MaxNewSizePercent</code>(默认60%)之间动态变化，且由参数目标暂停时间<code>-XX:MaxGCPauseMillis</code>(默认200ms)、需要扩缩容的大小以及分区的已记忆集合(RSet)计算得到。当然，G1依然可以设置固定的年轻代大小(参数<code>-XX:NewRatio、-Xmn</code>)，但同时暂停目标将失去意义。</p>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/143e8c4013e811b881e3083163b22b7980d.png" alt=""></p>
<h4 id="6-7-1-2-Card"><a href="#6-7-1-2-Card" class="headerlink" title="6.7.1.2 Card"></a>6.7.1.2 Card</h4><p>在cms收集器的介绍中我们提到过card，这里的card也类似，是比region更小的一个内存单位。</p>
<p>G1启用后，jvm会在每个分区内部分配了若干个大小为512 Byte卡片(Card)，标识堆内存最小可用粒度。所有分区的卡片都会记录在卡片表(Card Table)中。</p>
<p>分配的对象会占用物理上连续的若干个卡片，当查找对分区内对象的引用时，便可通过记录卡片来查找该引用对象(见RSet)。每次对内存的回收，都是对指定分区的卡片进行处理。</p>
<p><img src="https://oscimg.oschina.net/oscnet/9049e04d540dd52600d14c6f22b099cfb16.png" alt=""></p>
<h4 id="6-7-1-3-本地分配缓冲（LAB）"><a href="#6-7-1-3-本地分配缓冲（LAB）" class="headerlink" title="6.7.1.3 本地分配缓冲（LAB）"></a>6.7.1.3 本地分配缓冲（LAB）</h4><p>本地分配缓冲 Local allocation buffer 简称Lab</p>
<p>我们知道TLAB是在eden区分配的一个线程私有的本地缓冲，当我们启用G1收集器的时候，TLAB的内存单位，也相应的改为了region，即：</p>
<ul>
<li><p>每个线程均可以”认领”某个region用于线程本地的内存分配，而不需要顾及region是否连续。</p>
</li>
<li><p>TLAB大部分都会落入Eden区域(巨型对象或分配失败除外)，因此TLAB的分区属于Eden空间；</p>
</li>
<li><p>而每次垃圾收集时，每个GC线程同样可以独占一个本地缓冲区(GCLAB)用来转移对象，每次回收会将对象复制到Suvivor空间或老年代空间；对于从Eden/Survivor空间晋升(Promotion)到Survivor/老年代空间的对象，同样有GC独占的本地缓冲区进行操作，该部分称为晋升本地缓冲区(PLAB)。</p>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/cfc951a4c4d9dff97f49be46a44c5506500.png" alt=""></p>
<h4 id="6-7-1-4-Humongous区域"><a href="#6-7-1-4-Humongous区域" class="headerlink" title="6.7.1.4 Humongous区域"></a>6.7.1.4 Humongous区域</h4><p>在G1中，还有一种特殊的区域，叫Humongous区域。 如果一个对象占用的空间超过了region容量50%以上，G1收集器就认为这是一个巨型对象。</p>
<p>当线程为巨型分配空间时，不能简单在TLAB进行分配，因为巨型对象的移动成本很高，而且有可能一个分区不能容纳巨型对象。</p>
<p>因此这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。</p>
<p>如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。<strong>为了能找到连续的H区，有时候不得不启动Full GC</strong>。</p>
<p>巨型对象会独占一个、或多个连续分区，其中第一个分区被标记为开始巨型(StartsHumongous)，相邻连续分区被标记为连续巨型(ContinuesHumongous)。由于无法享受Lab带来的优化，并且确定一片连续的内存空间需要扫描整堆，因此确定巨型对象开始位置的成本非常高，如果可以，应用程序应避免生成巨型对象。</p>
<h4 id="6-7-1-5-Remember-Set"><a href="#6-7-1-5-Remember-Set" class="headerlink" title="6.7.1.5 Remember Set"></a>6.7.1.5 Remember Set</h4><p>在串行和并行收集器中，GC通过整堆扫描，来确定对象是否处于可达路径中（即存活）。然而G1为了避免STW式的整堆扫描，在每个region内部记录了一个已记忆集合(RSet)，这个RSet是个point-into思路（谁引用了我的对象）的产物，用来记录“引用了RSet所在region内的对象的卡片索引”。当要回收该分区时，通过扫描分区的RSet，来确定引用本分区内对象的对象是否存活，进而确定本分区内的对象存活情况。</p>
<p>事实上，并非所有的引用都需要记录在RSet中，G1 GC每次都会对年轻代进行整体收集，因此引用来源于年轻代的对象（新生代对象引用新年代对象，或者老年代引用新生代对象），也不需要在RSet中记录（即无需记录哪些老年代对象引用了我）。只需要记录新生代引用老年代对象这种跨代引用。</p>
<p>鉴于RSet是个point-into思路（谁引用了我的对象）的产物，故而最后只有老年代的region可能会有RSet记录（记录哪些新生代对象引用了我），这些分区称为拥有RSet分区(an RSet’s owning region)。</p>
<p>下图表示了RSet、Card和Region的关系</p>
<p><img src="https://oscimg.oschina.net/oscnet/b7d7d251525f0241d39159394b6e6d221c5.png" alt=""></p>
<p>上图中有三个Region，每个Region被分成了多个Card，在不同Region中的Card会相互引用，Region1中的Card中的对象引用了Region2中的Card中的对象，蓝色实线表示的就是points-out的关系，而在Region2的RSet中，记录了Region1的Card，即红色虚线表示的关系，就是points-into。</p>
<h4 id="6-7-1-6-收集集合-CSet"><a href="#6-7-1-6-收集集合-CSet" class="headerlink" title="6.7.1.6 收集集合 (CSet)"></a>6.7.1.6 收集集合 (CSet)</h4><p>收集集合(Collection Set 简称CSet)是每次G1 GC暂停时回收的目标region的集合。在任意一次收集暂停中，CSet内的所有region都会被释放，内部存活的对象都会被转移到分配的空闲region中。因此无论是年轻代收集，还是混合收集，工作的机制都是一致的。年轻代收集CSet只容纳年轻代region，而混合收集会通过启发式算法，在老年代候选回收region中，筛选出回收收益最高的region添加到CSet中。</p>
<p>哪些老年代Region会被选入CSet，由一系列参数控制，后续详解。</p>
<p>由上述可知，G1的收集都是根据CSet进行操作的，年轻代收集与混合收集没有明显的不同，最大的区别在于两种收集的触发条件。</p>
<h3 id="6-7-2-G1如何保证在并发标记的正确性"><a href="#6-7-2-G1如何保证在并发标记的正确性" class="headerlink" title="6.7.2 G1如何保证在并发标记的正确性"></a>6.7.2 G1如何保证在并发标记的正确性</h3><p>SATB的全称（Snapshot At The Beginning）字面意思是开始GC前存活对象的一个快照。SATB的作用是保证在并发标记阶段的正确性。如何理解这句话？</p>
<h4 id="6-7-2-1-三色标记法"><a href="#6-7-2-1-三色标记法" class="headerlink" title="6.7.2.1 三色标记法"></a>6.7.2.1 三色标记法</h4><p>提到并发标记，我们不得不了解并发标记的三色标记算法。它是描述追踪式回收器的一种有用的方法，利用它可以推演回收器的正确性。 首先，我们将对象分成三种类型的。</p>
<ul>
<li>黑色:根对象，或者该对象与它的子对象都被扫描</li>
<li>灰色:对象本身被扫描,但还没扫描完该对象中的子对象</li>
<li>白色:未被扫描对象，扫描完成所有对象之后，最终为白色的为不可达对象，即垃圾对象</li>
</ul>
<p>当GC开始扫描对象时，按照如下图步骤进行对象的扫描：<br>根对象被置为黑色，子对象被置为灰色。</p>
<p><img src="https://oscimg.oschina.net/oscnet/74ab428c55bb760a80c4b8bfe635d14c039.png" alt=""></p>
<p>继续由灰色遍历,将已扫描了子对象的对象置为黑色。</p>
<p><img src="https://oscimg.oschina.net/oscnet/12be353e898117fbd49072763bacd0b6693.png" alt=""></p>
<p>遍历了所有可达的对象后，所有可达的对象都变成了黑色。不可达的对象即为白色，需要被清理。</p>
<p><img src="https://oscimg.oschina.net/oscnet/8c27fb72fcfb8af79455ab653c422135cad.png" alt=""></p>
<p>这看起来很美好，但是如果在标记过程中，应用程序也在运行，那么对象的指针就有可能改变。这样的话，我们就会遇到一个问题：对象丢失问题</p>
<p>我们看下面一种情况，当垃圾收集器扫描到下面情况时：</p>
<p><img src="https://oscimg.oschina.net/oscnet/0859ebbd57f3dd299d9602d4f03ab22645d.png" alt=""></p>
<p>这时候应用程序执行了以下操作：</p>
<ol>
<li><p>c=C</p>
</li>
<li><p>c=null</p>
</li>
</ol>
<p>这样，对象的状态图变成如下情形：</p>
<p><img src="https://oscimg.oschina.net/oscnet/2e1c898dbbc8d7a5a96651d7b827ff4d9cc.png" alt=""></p>
<p>这时候垃圾收集器再标记扫描的时候就会下图成这样（因为不会扫描黑色对象的子对象，所以C不会被再标记）：</p>
<p><img src="https://oscimg.oschina.net/oscnet/037553f08aafc012c4088cd376f61b6f53e.png" alt=""></p>
<p>很显然，此时C是白色，被认为是垃圾需要清理掉，显然这是不合理的。那么我们如何保证应用程序在运行的时候，GC标记的对象不丢失呢？有如下2中可行的方式：</p>
<ul>
<li>在删除的时候记录对象</li>
<li>在插入的时候记录对象</li>
</ul>
<p>这里，就需要讲到barrier了</p>
<h4 id="6-7-2-2-barrier"><a href="#6-7-2-2-barrier" class="headerlink" title="6.7.2.2 barrier"></a>6.7.2.2 barrier</h4><p>我们首先介绍一下栅栏(Barrier)的概念。栅栏是指在原生代码片段中，当某些语句被执行时，栅栏代码也会被执行。栅栏代码分为写前栅栏(Pre-Write Barrrier)和写后栅栏(Post-Write Barrrier)。事实上，写栅栏的指令序列开销非常昂贵，应用吞吐量也会根据栅栏复杂度而降低。</p>
<p><img src="https://oscimg.oschina.net/oscnet/4b9dc302e676f69ad2eceeecb56ff856c45.png" alt=""></p>
<p><strong>写前栅栏 Pre-Write Barrrier</strong></p>
<ul>
<li>即将执行一段赋值语句a=b时，原来a所指向的对象假设为A将丢失一个引用。类比G1的场景，即a不再指向A，那么A所在region将因此丧失一个引用。</li>
<li>那么JVM就需要在赋值语句生效之前，记录丧失引用的对象在更新日志缓冲区。JVM并不会立即维护RSet，而是后面找个时机批量处理，在将来对RSet进行更新。</li>
</ul>
<p><strong>写后栅栏 Post-Write Barrrier</strong></p>
<ul>
<li>当执行一段赋值语句a=b后，等式右侧对象，即b引用指向的对象B，获取了左侧对象a的引用。类比G1的场景，那么B所在分区的RSet也应该得到更新。同样为了降低开销，写后栅栏发生后，RSet也不会立即更新，同样只是记录此次更新日志，在将来批量处理(见Concurrence Refinement Threads)。</li>
</ul>
<h4 id="6-7-2-3-SATB"><a href="#6-7-2-3-SATB" class="headerlink" title="6.7.2.3 SATB"></a>6.7.2.3 SATB</h4><p>结合我们之前说的GC标记的对象不丢失的方法</p>
<ul>
<li>在删除的时候记录对象（写前栅栏 Pre-Write Barrrier）</li>
<li>在插入的时候记录对象（写后栅栏 Post-Write Barrrier）</li>
</ul>
<p>刚好这对应CMS和G1的2种不同实现方式：</p>
<ul>
<li><p>在CMS采用的是增量更新（Incremental update），只要在写屏障（write barrier）里发现要有一个白对象的引用被赋值到一个黑对象 的字段里，那就把这个白对象变成灰色的。即插入的时候记录下来。(写后栅栏)</p>
</li>
<li><p>在G1中，使用的是STAB（snapshot-at-the-beginning）的方式，删除的时候记录所有的对象(写前栅栏)，它有如下步骤：</p>
<ol>
<li><p>在开始标记的时候生成一个快照图标记存活对象（通过可达性分析得到）</p>
</li>
<li><p>在并发标记阶段，当引用关系发生变化的时候，通过pre-write barrier函数会把这种这种变化记录下来，记录方式如下：</p>
<ul>
<li>找到该引用字段所在的位置(Card)，并设置为dirty_card</li>
<li>如果当前是应用线程，每个Java线程有一个dirty card queue，把该card插入队列</li>
<li>除了每个线程自带的dirty card queue，还有一个全局共享的queue</li>
</ul>
</li>
<li><p>接下来的RSet更新操作交由多个ConcurrentG1RefineThread（）并发完成，每当全局队列集合超过一定阈值后，ConcurrentG1RefineThread会取出若干个队列，遍历每个队列中记录的card，并进行处理，大概实现逻辑如下：</p>
<ul>
<li>根据card的地址，计算出card所在的Region</li>
<li>如果Region不存在，或者Region是Young区，或者该Region在回收集合中，则不进行处理</li>
<li>否则，更新对应的RSet</li>
</ul>
</li>
</ol>
</li>
</ul>
<blockquote>
<p>并发优化线程(Concurrence Refinement Threads)，只专注扫描日志缓冲区记录的卡片来维护更新RSet，线程最大数目可通过<code>-XX:G1ConcRefinementThreads</code>(默认等于-XX:ParellelGCThreads)设置。</p>
</blockquote>
<blockquote>
<p>并发优化线程永远是活跃的，一旦发现全局列表有记录存在，就开始并发处理。如果记录增长很快或者来不及处理，那么通过阈值<code>-X:G1ConcRefinementGreenZone/-XX:G1ConcRefinementYellowZone/-XX:G1ConcRefinementRedZone</code>，G1会用分层的方式调度，使更多的线程处理全局列表。</p>
</blockquote>
<blockquote>
<p>如果并发优化线程也不能跟上缓冲区数量，则Mutator线程(Java应用线程)会挂起应用并被加进来帮助处理，直到全部处理完。因此，必须避免此类场景出现。</p>
</blockquote>
<p>SATB的方式记录活对象，因为是快照形式，故而也就是那一时刻对象的snapshot，这时会有两类对象需要特殊处理。</p>
<ul>
<li><p>在GC过程中变成垃圾的对象，这些叫做浮动垃圾（floating garbage），浮动垃圾只能等到下一次收集回收掉。</p>
</li>
<li><p>在GC过程中新分配的对象，G1的策略是将其都当做是活的，其他不可达的对象就是死的。</p>
</li>
</ul>
<p>如何知道哪些对象是GC开始之后新分配的呢？</p>
<p>原来Region包含了5个指针，分别是bottom、previous TAMS、next TAMS、top和end。其中top是该region的当前分配指针，[bottom, top)是当前该region已用（used）的部分，[top, end)是尚未使用的可分配空间（unused）。</p>
<p><img src="https://oscimg.oschina.net/oscnet/7cc36319d43b695bd537e77d06b10923894.png" alt=""></p>
<p>其previous TAMS、next TAMS是前后两次发生并发标记时的位置，全称top-at-mark-start，他们会发生如下变动：</p>
<ol>
<li><p>假设第n轮并发标记开始，将该Region当前的top指针赋值给next TAMS，在并发标记标记期间，分配的对象都在[next TAMS, top]之间，SATB能够确保这部分的对象都会被标记，默认都是存活的</p>
</li>
<li><p>当并发标记结束时，将next TAMS所在的地址赋值给previous TAMS，SATB给 [bottom, previous TAMS] 之间的对象创建一个快照，所有垃圾对象能通过快照被识别出来</p>
</li>
<li><p>第n+1轮并发标记开始，过程和第n轮一样</p>
</li>
</ol>
<h3 id="6-7-3-停顿预测模型"><a href="#6-7-3-停顿预测模型" class="headerlink" title="6.7.3 停顿预测模型"></a>6.7.3 停顿预测模型</h3><p>G1 GC是一个响应时间优先的GC算法，它与CMS最大的不同是，用户可以设定整个GC过程的期望停顿时间，参数<code>-XX:MaxGCPauseMillis</code>指定一个G1收集过程目标停顿时间，默认值200ms，不过它不是硬性条件，只是期望值。</p>
<p>那么G1怎么满足用户的期望呢？就需要这个停顿预测模型了。G1根据这个模型统计计算出来的历史数据来预测本次收集需要选择的Region数量(即CSet大小)，从而尽量满足用户设定的目标停顿时间。</p>
<p>关于停顿时间的设置并不是越短越好。设置的时间越短意味着每次收集的CSet越小，导致垃圾逐步积累变多，最终不得不退化成Serial GC（Full GC）；停顿时间设置的过长，那么会导致每次都会产生长时间的停顿，影响了程序对外的响应时间。</p>
<h3 id="6-7-4-G1回收的过程"><a href="#6-7-4-G1回收的过程" class="headerlink" title="6.7.4 G1回收的过程"></a>6.7.4 G1回收的过程</h3><p>G1提供了两种GC模式，Young GC和Mixed GC，两种都是完全Stop The World的。</p>
<ol>
<li><p>Young GC：选定<strong>所有</strong>年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。</p>
</li>
<li><p>Mixed GC：选定<strong>所有</strong>年轻代里的Region，外加根据global concurrent marking(全局并发标记)统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。</p>
</li>
</ol>
<p>由上面的描述可知，Mixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。</p>
<h4 id="6-7-4-1-Young-GC"><a href="#6-7-4-1-Young-GC" class="headerlink" title="6.7.4.1 Young GC"></a>6.7.4.1 Young GC</h4><p>Young GC 回收的是所有年轻代的Region。当E区不能再分配新的对象时就会触发。E区的对象会移动到S区，当S区空间不够的时候，E区的对象会直接晋升到O区，同时S区的数据移动到新的S区，如果S区的部分对象到达一定年龄，会晋升到O区。</p>
<p>Yung GC过程示意图如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/e806b69f5e601a8e108870a056d005b5357.png" alt=""></p>
<h4 id="6-7-4-2-Mixed-GC"><a href="#6-7-4-2-Mixed-GC" class="headerlink" title="6.7.4.2 Mixed GC"></a>6.7.4.2 Mixed GC</h4><p>Mixed GC 翻译过来叫混合回收。之所以叫混合是因为回收<strong>所有的</strong>年轻代的Region+<strong>部分</strong>老年代的Region。</p>
<p>Mixed GC的触发也是由<code>-XX:InitiatingHeapOccupancyPercent</code>控制，这个值叫做IHOP阈值，表示老年代占整个堆大小的百分比，默认值是45%，达到该阈值就会触发一次Mixed GC。</p>
<p>Mixed GC分为两个阶段：</p>
<ol>
<li>全局并发标记阶段(Global Concurrent marking)</li>
<li>拷贝存活对象阶段(evacuation)</li>
</ol>
<h5 id="6-7-4-2-1-全局并发标记阶段"><a href="#6-7-4-2-1-全局并发标记阶段" class="headerlink" title="6.7.4.2.1 全局并发标记阶段"></a>6.7.4.2.1 全局并发标记阶段</h5><pre><code>全局并发标记阶段是基于SATB的，与CMS有些类似，但是也有不同的地方，主要的几个阶段如下：</code></pre><ul>
<li><p>初始标记 Initial Mark</p>
<ul>
<li>该阶段会STW</li>
<li>负责标记所有能被直接可达的根对象(原生栈对象、全局对象、JNI对象)，根是对象图的起点，因此初始标记需要将Mutator线程(Java应用线程)暂停掉，也就是需要一个STW的时间段。</li>
<li>事实上，当达到IHOP阈值时，G1并不会立即进入<strong>并发标记</strong>阶段，而是等待下一次年轻代收集，利用年轻代收集的STW时间段，完成初始标记，这种方式称为借道(Piggybacking)。在初始标记暂停中，分区的NTAMS都被设置到分区顶部Top，初始标记是并发执行，直到所有的分区处理完。</li>
</ul>
</li>
<li><p>根分区扫描 Root Region Scanning</p>
<ul>
<li>在初始标记暂停结束后，年轻代收集也完成将对象复制到Survivor的工作，应用线程开始活跃起来。</li>
<li>此时为了保证标记算法的正确性，所有新复制到Survivor分区的对象，都需要被扫描并标记成根，这个过程称为根分区扫描</li>
<li>同时扫描的Suvivor分区也被称为根分区(Root Region)。根分区扫描必须在下一次年轻代垃圾收集启动前完成(并发标记的过程中，可能会被若干次年轻代垃圾收集打断)，因为每次GC会产生新的存活对象集合。</li>
</ul>
</li>
</ul>
<ul>
<li><p>并发标记 Concurrent Marking</p>
<ul>
<li>和应用线程并发执行，专门司职并发标记的<strong>并发标记线程</strong>在并发标记阶段启动，可由参数<code>-XX:ConcGCThreads(默认GC线程数的1/4，即-XX:ParallelGCThreads/4)</code>控制并发标记线程启动数量。</li>
<li><strong>每个线程每次只扫描一个region分区，根据RSet收集各个Region的存活对象信息</strong>。在这一阶段会处理Previous/Next标记位图，扫描标记对象的引用字段。同时，并发标记线程还会定期检查和处理STAB全局缓冲区列表的记录（即SATB write barrier所记录下的引用），更新对象引用信息。</li>
</ul>
</li>
<li><p>最终标记 Remark</p>
<ul>
<li>该阶段会STW</li>
<li>是最后一个标记阶段。在该阶段中，G1需要一个暂停的时间，去处理剩下的SATB日志缓冲区和所有更新，找出所有未被访问的存活对象，同时安全完成存活数据计算。</li>
<li>这个阶段也是并行（注意不是并发，否则也不需要STW）执行的，通过参数<code>-XX:ParallelGCThread</code>可设置GC暂停时可用的GC线程数。</li>
<li>同时，引用处理也是重新标记阶段的一部分，所有重度使用引用对象(弱引用、软引用、虚引用、最终引用)的应用都会在引用处理上产生开销。</li>
</ul>
</li>
<li><p>清理 Cleanup</p>
<ul>
<li>该阶段会STW</li>
<li>清点和重置标记状态。这个阶段有点像mark-sweep中的sweep阶段，这个阶段并不会实际上去做垃圾的收集，只是整理堆分区，为混合收集周期识别回收收益高(基于释放空间和暂停目标)的老年代分区集合，去根据停顿模型来预测出CSet，等待evacuation（拷贝存活对象）阶段来回收。</li>
<li>preview TAMS/next TAMS 会在清除阶段交换角色</li>
<li>如果发现完全没有活对象的region就会将其整体回收到可分配region列表中。 清除空Region。</li>
</ul>
</li>
</ul>
<h5 id="6-7-4-2-2-拷贝存活对象"><a href="#6-7-4-2-2-拷贝存活对象" class="headerlink" title="6.7.4.2.2 拷贝存活对象"></a>6.7.4.2.2 拷贝存活对象</h5><p>Evacuation阶段是全暂停的。它负责把CSet里面的region里的活对象拷贝到空region里去（并行拷贝），然后回收原本的region的空间（加入空闲分区列表，清除空Region）。</p>
<p>Mixed GC的清理过程示意图如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/ca718b9f0b421c46434f7fcccf43b5a1f49.png" alt=""></p>
<p>但Evacuation是可能失败的：</p>
<p>转移失败(Evacuation Failure)是指当G1无法在堆空间中申请新的分区时，G1便会触发担保机制，执行一次STW式的、单线程的Full GC。Full GC会对整堆做标记清除和压缩，最后将只包含纯粹的存活对象。参数<code>-XX:G1ReservePercent(默认10%)</code>可以设置保留空间，来应对晋升模式下的异常情况，最大占用整堆50%，更大也无意义。</p>
<p>G1在以下场景中会触发Full GC，同时会在日志中记录to-space-exhausted以及Evacuation Failure：</p>
<ol>
<li>从年轻代分区拷贝存活对象时，无法找到可用的空闲分区</li>
<li>从老年代分区转移存活对象时，无法找到可用的空闲分区</li>
<li>分配巨型对象时在老年代无法找到足够的连续分区<br>由于G1的应用场合往往堆内存都比较大，所以Full GC的收集代价非常昂贵，应该避免Full GC的发生。</li>
</ol>
<h1 id="7-垃圾回收相关的参数"><a href="#7-垃圾回收相关的参数" class="headerlink" title="7 垃圾回收相关的参数"></a>7 垃圾回收相关的参数</h1><p><img src="https://oscimg.oschina.net/oscnet/f5894fef49569a1c2124fc8af3cd901c095.png" alt=""></p>
<h2 id=""><a href="#" class="headerlink" title=""></a><img src="https://oscimg.oschina.net/oscnet/46fa2d0f05b19bd564bb69547c375bf24c2.png" alt=""></h2><h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h1><p><a href="https://www.jianshu.com/p/870abddaba41" target="_blank" rel="noopener" title="G1垃圾收集器之RSet">G1垃圾收集器之RSet</a><br><a href="https://blog.csdn.net/coderlius/article/details/79272773" target="_blank" rel="noopener" title="详解 JVM Garbage First(G1) 垃圾收集器">详解 JVM Garbage First(G1) 垃圾收集器</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/23/JAVA%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E5%92%8C%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cherish-ls">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cherish">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/23/JAVA%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E5%92%8C%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/" itemprop="url">JAVA内存结构和内存管理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-23T23:07:25+08:00">
                2019-10-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/JAVA/JAVA-JVM/" itemprop="url" rel="index">
                    <span itemprop="name">JAVA JVM</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/23/JAVA%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E5%92%8C%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/10/23/JAVA内存结构和内存管理/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  6.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  21
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>按照官方的说法：</p>
<blockquote>
<p>“Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的。”<br>“在JVM中堆之外的内存称为非堆内存(Non-heap memory)”。</p>
</blockquote>
<p>可以看出JVM主要管理两种类型的内存：<strong>堆和非堆</strong>。</p>
<p>简单来说堆就是Java代码可及的内存，是留给开发人员使用的；非堆就是JVM留给<strong>自己</strong>用的，所以方法区、JVM内部处理或优化所需的内存(如JIT编译后的代码缓存)、每个类结构(如运行时常数池、字段和方法数据)以及方法和构造方法的代码都在非堆内存中。</p>
<h1 id="1-java内存结构简述"><a href="#1-java内存结构简述" class="headerlink" title="1. java内存结构简述"></a>1. java内存结构简述</h1><p><img src="https://oscimg.oschina.net/oscnet/995ad1c42b0ddf675bc248b8be7dee804a7.jpg" alt=""></p>
<p><img src="https://oscimg.oschina.net/oscnet/f145c250093ee3783870b09947f9354c6c4.jpg" alt=""></p>
<p>上图即为一个标准的java内存结构（也叫运行时数据区）模型图，其中：</p>
<ul>
<li><p>方法区——也称”永久代” 、“非堆”， 它用于存储虚拟机加载的类信息、常量、静态变量、是各个<strong>线程共享</strong>的内存区域。</p>
<ul>
<li>运行时常量池——是方法区的一部分，其中的主要内容来自于JVM对Class的加载。</li>
</ul>
</li>
<li><p>虚拟机栈——描述的是java 方法执行的内存模型：每个方法被执行的时候 都会创建一个“栈帧”用于存储局部变量表(包括参数)、操作栈、方法出口等信息。每个方法被调用到执行完的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。声明周期与线程相同，是<strong>线程私有的</strong>。</p>
</li>
<li><p>本地方法栈——与虚拟机栈基本类似，区别在于虚拟机栈为虚拟机执行的java方法服务，而本地方法栈则是为Native方法服务，是<strong>线程私有的</strong>。</p>
</li>
<li><p>堆——也叫做java 堆、GC堆是java虚拟机所管理的内存中最大的一块内存区域，也是被各个<strong>线程共享</strong>的内存区域，在JVM启动时创建。该内存区域存放了对象实例及数组(所有new的对象)。</p>
</li>
<li><p>程序计数器——是最小的一块内存区域，它的作用是当前线程所执行的字节码的行号指示器。<strong>线程私有</strong></p>
</li>
</ul>
<h1 id="2-内存结构分类"><a href="#2-内存结构分类" class="headerlink" title="2. 内存结构分类"></a>2. 内存结构分类</h1><h2 id="2-1-方法区"><a href="#2-1-方法区" class="headerlink" title="2.1 方法区"></a>2.1 方法区</h2><p>方法区——也称”永久代” 、“非堆”， 它用于存储虚拟机加载的类信息、常量、静态变量、是各个<strong>线程共享</strong>的内存区域。默认最小值为16MB，最大值为64MB，可以通过<code>-XX:PermSize</code> 和 <code>-XX:MaxPermSize</code>参数限制方法区的大小。</p>
<p>方法区是jvm的规范，在HotSpot中，它是PermGen space（永久代），即HotSpot的PermGen space就是HotSpot对方法区规范的实现（在JDK的HotSpot虚拟机中，可以认为方法区就是永久代，但是在其他类型的虚拟机中，没有永久代的概念）</p>
<p>至于加载的类信息、常量、静态变量，这太笼统了，具体是什么呢？</p>
<p><img src="https://oscimg.oschina.net/oscnet/e9884010a087f0638c7293b37c2ce7ef52a.jpg" alt=""></p>
<p>如上图，更加详细一点的说法是方法区里存放着被加载过的每一个类的信息（虚拟机加载的类信息（类的<strong>版本、字段、方法、接口</strong>），<strong>常量，静态变量，即时编译器编译后的代码等数据</strong>）；这些信息由类加载器在加载类的时候，从类的源文件中抽取出来；static变量信息也保存在方法区中。</p>
<blockquote>
<p>在 JDK1.2 ~ JDK6 的实现中，HotSpot 使用永久代实现方法区；  </p>
</blockquote>
<blockquote>
<p>由于 GC 分代技术的影响，使之许多优秀的内存调试工具无法在 Oracle HotSpot之上运行，必须单独处理；并且 Oracle 同时收购了 BEA 和 Sun 公司，同时拥有 JRockit 和 HotSpot，在将 JRockit 许多优秀特性移植到 HotSpot 时由于 GC 分代技术遇到了种种困难，所以从 JDK7 开始 Oracle HotSpot 开始移除永久代。<br>JDK7中符号表被移动到 Native Heap中，字符串常量和类引用被移动到 Java Heap中。</p>
</blockquote>
<blockquote>
<p>在 JDK8 中，永久代已完全被元空间(Meatspace)所取代。</p>
</blockquote>
<h3 id="2-1-1-class常量池"><a href="#2-1-1-class常量池" class="headerlink" title="2.1.1 class常量池"></a>2.1.1 class常量池</h3><p>在Class文件结构中，最头的4个字节用于存储魔数Magic Number，用于确定一个文件是否能被JVM接受，再接着4个字节用于存储版本号，前2个字节存储次版本号，后2个存储主版本号，再接着是用于存放常量的常量池，由于常量的数量是不固定的，所以常量池的入口放置一个U2类型的数据(constant_pool_count)存储常量池容量计数值。</p>
<p>如果说java的运行时数据区，那么是不包括class常量池的（即上图中的类型的常量池），class文件中除了包含类的版本、字段、方法、接口等描述信息外，还有一项信息就是<strong>常量池(constant pool table)</strong>，用于存放编译器生成的各种<strong>字面量(Literal)和符号引用(Symbolic References)</strong>。class常量池是非运行时常量池，保存虚拟机加载的class文件，其在编译阶段就已经确定；</p>
<p><img src="https://oscimg.oschina.net/oscnet/e5c0cdca043e436f4641c9bdeb7a371dc41.jpg" alt=""></p>
<ul>
<li><p>字面量就是我们所说的常量概念，如<strong>文本字符串、被声明为final的常量值</strong>等。</p>
<ul>
<li>例如String a = “aa”。其中”aa”就是字面量。</li>
</ul>
</li>
<li><p>符号引用是一组符号来描述所引用的目标，符号可以是<strong>任何形式的字面量</strong>，只要使用时能无歧义地定位到目标即可（它与直接引用区分一下，直接引用一般是指向方法区的本地指针，相对偏移量或是一个能间接定位到目标的句柄）。一般包括下面三类常量：</p>
<ol>
<li><p>类的全限定名</p>
<ul>
<li>例如对于String这个类，它的全限定名就是java/lang/String。</li>
</ul>
</li>
<li><p>字段名和属性</p>
</li>
<li><p>方法名和属性。</p>
<ul>
<li>所谓描述符就相当于方法的参数类型+返回值类型。</li>
</ul>
</li>
</ol>
</li>
</ul>
<p><img src="https://oscimg.oschina.net/oscnet/28e73b0071e9a4c8873296e9456203fb9b5.jpg" alt=""></p>
<h3 id="2-1-2-运行时常量池"><a href="#2-1-2-运行时常量池" class="headerlink" title="2.1.2 运行时常量池"></a>2.1.2 运行时常量池</h3><p>运行时常量池——是方法区的一部分，class文件中的class常量池，这部分内容在类加载后<strong>进入方法区的运行时常量池存放</strong>，符号引用有一部分是会被转变为<strong>直接引用</strong>（字节码中的方法调用指令就是以常量池中指向方法的符号引用作为参数。），比如说<strong>类的静态方法或私有方法，实例构造方法，父类方法</strong>，这是因为这些方法不能被重写其他版本，所以能在加载的时候就可以将符号引用转变为直接引用（这种转化称为静态解析）。而其他的一些方法是在这个方法被第一次调用的时候才会将符号引用转变为直接引用（这部分称为动态连接）。</p>
<p>运行时常量池相对于CLass文件常量池的另外一个重要特征是具备<strong>动态性</strong>，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入CLass文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用比较多的就是String类的intern()方法。</p>
<h2 id="2-2-虚拟机栈"><a href="#2-2-虚拟机栈" class="headerlink" title="2.2 虚拟机栈"></a>2.2 虚拟机栈</h2><p><img src="https://oscimg.oschina.net/oscnet/c8507dadf6cceaa10744e772bbcbb214fc2.jpg" alt=""></p>
<p>虚拟机栈（Java Virtual Machine Stacks）是线程隔离的，每创建一个线程时就会对应创建一个Java栈，即每个线程都有自己独立的虚拟机栈。</p>
<p>这个栈中又会对应包含多个栈帧，每调用一个方法时就会往栈中创建并压入一个栈帧，栈帧存储<strong>局部变量表、操作栈、动态链接、方法出口</strong>等信息，每一个方法从调用到最终返回结果的过程，就对应一个栈帧从<strong>入栈到出栈</strong>的过程。</p>
<p>虚拟机栈当然是一个后入先出的数据结构，线程运行过程中，只有处于栈顶的栈帧才是有效的，称为当前栈帧，与这个栈帧相关联的方法称为当前方法，当前活动帧栈始终是虚拟机栈的栈顶元素。</p>
<p>如果当前方法调用了其他方法，或者当前方法执行结束，那这个方法的栈帧就不再是当前栈帧了。当一个新的方法被调用，一个新的栈帧也会随之而创建，并且随着程序控制权移交到新的方法而成为新的当前栈帧。当方法返回的之际，当前栈帧会传回此方法的执行结果给前一个栈帧，在方法返回之后，当前栈帧就随之被丢弃，前一个栈帧就重新成为当前栈帧了。</p>
<p>栈的大小可以固定也可以动态扩展。</p>
<ul>
<li>在固定大小的情况下，JVM会为每个线程的虚拟机栈分配一定的内存大小（-Xss参数设置最大栈深度），因此虚拟机栈能够容纳的栈帧数量是有限的，若栈帧不断进栈而不出栈，最终会导致当前线程虚拟机栈的内存空间耗尽，会抛出StackOverflowError异常。</li>
<li>在动态扩展的情况下，如果虚拟机在扩展栈时无法申请到足够的内存空间，就会抛出OutOfMemoryError异常。</li>
</ul>
<h3 id="2-2-1-栈帧存放的内容"><a href="#2-2-1-栈帧存放的内容" class="headerlink" title="2.2.1 栈帧存放的内容"></a>2.2.1 栈帧存放的内容</h3><h4 id="2-2-1-1-局部变量表"><a href="#2-2-1-1-局部变量表" class="headerlink" title="2.2.1.1 局部变量表"></a>2.2.1.1 局部变量表</h4><ul>
<li>数据单元为slot，32位。一个局部变量（Slot）可以保存一个类型为boolean、byte、char、short、float、reference和returnAddress的数据，两个局部变量可以保存一个类型为long和double的数据。</li>
<li>存放了编译器可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double)、对象引用(引用指针，并非对象本身)，其中64位长度的long和double类型的数据会占用2个局部变量slot的空间，其余数据类型只占1个。</li>
<li><img src="https://oscimg.oschina.net/oscnet/bf035fb26fe0c236489ee554a070cadff88.jpg" alt=""></li>
<li>局部变量使用索引来进行定位访问，第一个局部变量的索引值为0，局部变量的索引值是从0至小于局部变量表最大容量的所有整数。<ul>
<li>long和double类型的数据占用两个连续的局部变量，这两种类型的数据值采用两个局部变量之中较小的索引值来定位。例如我们讲一个double类型的值存储在索引值为n的局部变量中，实际上的意思是索引值为n和n+1的两个局部变量都用来存储这个值。索引值为n+1的局部变量是无法直接读取的，但是可能会被写入，不过如果进行了这种操作，就将会导致局部变量n的内容失效掉。</li>
</ul>
</li>
<li><strong>Java虚拟机使用局部变量表来完成方法调用时的参数传递</strong>，当一个方法被调用的时候，它的参数将会传递至从0开始的连续的局部变量表位置上。<ul>
<li>特别地，当一个实例方法被调用的时候，<strong>第0个局部变量一定是用来存储被调用的实例方法所在的对象的引用（即Java语言中的“this”关键字）</strong>。后续的其他参数将会传递至从1开始的连续的局部变量表位置上。</li>
</ul>
</li>
<li>局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量是完全确定的，在运行期间栈帧不会改变局部变量表的大小空间。</li>
<li>通常我们所说的“栈内存”指的就是局部变量表这一部分。</li>
</ul>
<h4 id="2-2-1-2-操作栈"><a href="#2-2-1-2-操作栈" class="headerlink" title="2.2.1.2 操作栈"></a>2.2.1.2 操作栈</h4><p>操作栈也叫操作数栈（Operand Stack），</p>
<p>主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间。只支持出栈入栈操作。</p>
<p>栈帧在刚刚被创建的时候，操作数栈是空的。</p>
<p>Java虚拟机提供一些 <strong>字节码指令</strong> 来从 局部变量表 或者 对象实例的字段中 复制 常量 或 变量值 到操作数栈中，也提供了一些指令用于从操作数栈取走数据、操作数据和把操作结果重新入栈。</p>
<blockquote>
<p>举个例子，iadd字节码指令的作用是将两个int类型的数值相加，它要求在执行的之前操作数栈的栈顶已经存在两个由前面其他指令放入的int型数值。在iadd指令执行时，2个int值从操作栈中出栈，相加求和，然后将求和结果重新入栈。在操作数栈中，一项运算常由多个子运算（Subcomputations）嵌套进行，一个子运算过程的结果可以被其他外围运算所使用。</p>
</blockquote>
<blockquote>
<p>在操作数栈中的数据必须被正确地操作，这里正确操作是指对操作数栈的操作必须与操作数栈栈顶的数据类型相匹配，例如不可以入栈两个int类型的数据，然后当作long类型去操作他们，或者入栈两个float类型的数据，然后使用iadd指令去对它们进行求和。</p>
</blockquote>
<blockquote>
<p>有一小部分Java虚拟机指令（例如dup和swap指令）可以不关注操作数的具体数据类型，把所有在运行时数据区中的数据当作裸类型（Raw Type）数据来操作，这些指令不可以用来修改数据，也不可以拆散那些原本不可拆分的数据，这些操作的正确性将会通过Class文件的校验过程来强制保障。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int a &#x3D; 100;</span><br><span class="line">int b &#x3D; 98;</span><br><span class="line">int c &#x3D; a+b;</span><br></pre></td></tr></table></figure>

<p><img src="https://oscimg.oschina.net/oscnet/c68045924df8de7de842e75b719026a2665.jpg" alt=""></p>
<h4 id="2-2-1-3-动态链接"><a href="#2-2-1-3-动态链接" class="headerlink" title="2.2.1.3 动态链接"></a>2.2.1.3 动态链接</h4><p>每个栈帧都包含一个<strong>指向运行时常量池中该栈帧所属方法的引用</strong>，持有这个引用是为了支持方法调用过程中的动态连接。</p>
<h4 id="2-2-1-4-返回地址"><a href="#2-2-1-4-返回地址" class="headerlink" title="2.2.1.4 返回地址"></a>2.2.1.4 返回地址</h4><ul>
<li><p>正常完成出口</p>
<ul>
<li>当一个方法开始执行后，只会有两种方式可以退出这个方法。第一种方式是执行引擎遇到任意一个方法返回值的字节指令（return关键字）。这时候可能会有返回值传递给上层的方法调用者，是否有返回值和返回值的类型间根据遇到何种方法返回值指令来决定，这种退出方法的方式称为正常完成出口。</li>
</ul>
</li>
<li><p>异常完成出口</p>
<ul>
<li>另一种退出方式是，载方法执行过程中遇到了异常，并且这个异常没有在方法体内的得到处理，无论是虚拟机内部产生异常还是throw字节码指令产生的异常，只要在本方法异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种退出方式称为异常完成出口。</li>
</ul>
</li>
</ul>
<p>无论采用何种退出方式，在方法退出之后，都需要返回到方法被调用的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来恢复它的上层方法的执行状态。一般来说，方法正常退出时，调用者的PC计数器的值可以作为返回地址，栈帧中很可能会保存这个计数器的值。而方法异常退出时，返回地址时通过异常处理器来确定的栈帧中一般不会存储这部分信息。</p>
<p>方法退出的过程实际上就等同于把当前栈帧出栈，因为退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，<strong>把返回值（如果有的话）压入调用者栈帧的操作数栈中</strong>，调整PC计数器的值以指向方法调用指令后面的一条指令。</p>
<h2 id="2-3-本地方法栈"><a href="#2-3-本地方法栈" class="headerlink" title="2.3 本地方法栈"></a>2.3 本地方法栈</h2><ul>
<li>本地方法栈的功能和特点类似于虚拟机栈，均具有线程隔离的特点以及都能抛出StackOverflowError和OutOfMemoryError异常。</li>
<li>不同的是，本地方法栈服务的对象是JVM执行的native方法，而虚拟机栈服务的是JVM执行的java方法。</li>
<li>HotSpot虚拟机不区分虚拟机栈和本地方法栈，两者是一块的。</li>
</ul>
<h2 id="2-4-堆"><a href="#2-4-堆" class="headerlink" title="2.4 堆"></a>2.4 堆</h2><ul>
<li>堆是java虚拟机所管理的内存中最大的一块内存区域，也是被各个线程共享的内存区域，在JVM启动时创建。</li>
<li>堆是垃圾收集器管理的主要区域，因此也被称为“GC堆”。</li>
<li>该内存区域存放了对象实例及数组(所有new的对象)。</li>
<li>JAVA堆的分类： <ul>
<li>从内存回收的角度上看，可分为新生代（Eden空间，From Survivor空间、To Survivor空间）及老年代（Tenured Gen）。</li>
<li><img src="https://oscimg.oschina.net/oscnet/5895a080037fe2153317f808b2693c93cfb.jpg" alt=""></li>
<li>从内存分配的角度上看，为了解决分配内存时的线程安全性问题，线程共享的JAVA堆中可能划分出多个线程私有的分配缓冲区（TLAB）。</li>
</ul>
</li>
<li>JAVA堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。</li>
<li>其大小通过-Xms(最小值)和-Xmx(最大值)参数设置，-Xms为JVM启动时申请的最小内存，默认为操作系统物理内存的1/64但小于1G，-Xmx为JVM可申请的最大内存，默认为物理内存的1/4但小于1G。<ul>
<li>默认当空余堆内存小于40%时，JVM会增大Heap到-Xmx指定的大小，可通过<code>-XX:MinHeapFreeRation=</code>来指定这个比列；</li>
<li>当空余堆内存大于70%时，JVM会减小heap的大小到-Xms指定的大小，可通过<code>XX:MaxHeapFreeRation=</code>来指定这个比列</li>
</ul>
</li>
</ul>
<blockquote>
<p>对于运行系统，为避免在运行时频繁调整Heap的大小，通常-Xms与-Xmx的值设成一样。</p>
</blockquote>
<h3 id="2-4-1-字符串常量池"><a href="#2-4-1-字符串常量池" class="headerlink" title="2.4.1 字符串常量池"></a>2.4.1 字符串常量池</h3><p>字符串常量池存在于堆内存中的一个叫元空间（Metaspace）的区域。顾名思义，即为存放String字面量的一个常量池。String类的final修饰的，以字面量的形式创建String变量时，jvm会在编译期间就把该字面量（比如“hello”）放到字符串常量池中。这个字符串常量池的特点就是有且只有一份相同的字面量，如果有其它相同的字面量，jvm则返回这个字面量的引用，如果没有相同的字面量，则在字符串常量池创建这个字面量并返回它的引用。</p>
<ul>
<li><p>定义一个字符串的方式</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String str1 &#x3D; &quot;abcd&quot;;&#x2F;&#x2F;优先从常量池中寻找abcd这个字面量，如果有，则返回其引用赋给str1，否则，在常量池中创建该字面量，并返回创建后的引用赋给str1。</span><br><span class="line">String str2 &#x3D; new String(&quot;abcd&quot;);&#x2F;&#x2F;直接在堆中创建新的abcd对象，str2引用指向堆中该对象的地址。只要使用new方法，便需要创建新的对象。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意，虽说new String(“abcd”);直接在堆中创建新的abcd对象，但如果常量池中没有abcd这个字面量，那么其实也会在常量池中创建abcd，这并非new String()带来的，而是参数”abcd”带来的，在写下”abcd”的时候，其实就是以第一种引号的方式定义了一个String</p>
</blockquote>
</li>
<li><p>使用连接符+定义字符串</p>
<ul>
<li><strong>只有</strong>使用引号之间使用“+”连接产生的新对象才会走常量池（即优先从常量池拿，拿不到创建后再放进常量池）</li>
<li>对于所有包含new方式新建对象（包括null）的“+”连接表达式，它所产生的新对象都不会走常量池。</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">String s1 &#x3D; &quot;hello&quot;;</span><br><span class="line">String s2 &#x3D; &quot;hello&quot;;</span><br><span class="line">String s3 &#x3D; &quot;he&quot; + &quot;llo&quot;;</span><br><span class="line">String s4 &#x3D; &quot;hel&quot; + new String(&quot;lo&quot;);</span><br><span class="line">String s5 &#x3D; new String(&quot;hello&quot;);</span><br><span class="line">String s6 &#x3D; s5.intern();</span><br><span class="line">String s7 &#x3D; &quot;h&quot;;</span><br><span class="line">String s8 &#x3D; &quot;ello&quot;;</span><br><span class="line">String s9 &#x3D; s7 + s8;</span><br><span class="line">String s10 &#x3D; new String(&quot;hello&quot;) + new String(&quot;hello&quot;);</span><br><span class="line">String s11 &#x3D; &quot;hellohello&quot;;</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">　　System.out.println(s1&#x3D;&#x3D;s2);&#x2F;&#x2F;true</span><br><span class="line">　　System.out.println(s1&#x3D;&#x3D;s3);&#x2F;&#x2F;true &#x2F;&#x2F;引号之间的拼接走常量池，所以相等</span><br><span class="line">　　System.out.println(s1&#x3D;&#x3D;s4);&#x2F;&#x2F;false &#x2F;&#x2F;s4为包含new的拼接，不走常量池，所以地址不相等</span><br><span class="line">　　System.out.println(s1&#x3D;&#x3D;s9);&#x2F;&#x2F;false &#x2F;&#x2F;s9为非引号相加得来，不走常量池，它指向堆中对象</span><br><span class="line">　　System.out.println(s4&#x3D;&#x3D;s5);&#x2F;&#x2F;false &#x2F;&#x2F;s4和s5是堆中的两个对象，地址肯定不相等</span><br><span class="line">　　System.out.println(s1&#x3D;&#x3D;s6);&#x2F;&#x2F;true</span><br><span class="line">　　System.out.println(s10 &#x3D;&#x3D; s11);&#x2F;&#x2F;false</span><br></pre></td></tr></table></figure>
<blockquote>
<p>intern()方法能使一个位于堆中的字符串在运行期间动态地加入到字符串常量池中（字符串常量池的内容是程序启动的时候就已经加载好了），如果字符串常量池中有该对象对应的字面量，则返回该字面量在字符串常量池中的引用，否则，创建复制一份该字面量到字符串常量池并返回它的引用。</p>
</blockquote>
<h2 id="2-5-程序计数器"><a href="#2-5-程序计数器" class="headerlink" title="2.5 程序计数器"></a>2.5 程序计数器</h2><p>程序计数器是最小的一块内存区域，是线程独占的，每一个线程拥有自己的程序计数器。它的作用是<strong>当前线程所执行的字节码的行号指示器</strong>，在虚拟机的模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、异常处理、线程恢复等基础功能都需要依赖计数器完成。</p>
<p>其生命周期随着线程启动而产生，线程结束而消亡。</p>
<p>因为Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个时刻，一个核心只会执行一条线程的指令，因此为了线程切换以后可以恢复到正确的执行位置，每条线程都需要这个线程私有的程序计数器。</p>
<p>当线程执行java方法时，其记录的是正在执行的虚拟机字节码指令的地址，当执行native方法时，这个计数器的值为空。</p>
<h1 id="3-直接内存"><a href="#3-直接内存" class="headerlink" title="3. 直接内存"></a>3. 直接内存</h1><p>直接内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。在JDK1.4中新加入了NIO(New Input/Output)类，引入了一种基于通道(Channel)与缓冲区（Buffer）的I/O 方式，它可以使用native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。</p>
<ul>
<li>直接内存的注意事项<ul>
<li>本机直接内存的分配不会受到Java 堆大小的限制，但是受到本机总内存大小限制</li>
<li>配置虚拟机参数时，不要忽略直接内存，防止出现OutOfMemoryError异常</li>
</ul>
</li>
<li>直接内存（堆外内存）与堆内存比较</li>
<li>直接内存申请空间耗费更高的性能，当频繁申请到一定量时尤为明显</li>
<li>直接内存IO读写的性能要优于普通的堆内存，在多次读写操作的情况下差异明显</li>
</ul>
<p>其使用demo为 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;直接内存分配申请</span><br><span class="line">ByteBuffer buffer &#x3D; ByteBuffer.allocateDirect(100); &#x2F;&#x2F;ByteBuffer.allocateDirect(int capacity) 分配新的直接字节缓冲区。</span><br><span class="line">&#x2F;&#x2F; 往buffer里写入数据</span><br><span class="line">buffer.putChar(&#39;a&#39;);&#x2F;&#x2F;  putChar(char value) 用来写入 char 值的相对 put 方法</span><br><span class="line">buffer.put(10);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">buffer.flip();&#x2F;&#x2F; 将Buffer从写模式切换到读模式（必须调用这个方法）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">buffer.getChar();&#x2F;&#x2F; 读取buffer里的数据</span><br><span class="line">buffer.get()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-hand-o-left" aria-label="accessibility.prev_page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-hand-o-right" aria-label="accessibility.next_page"></i></a>
  </nav>

          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://oscimg.oschina.net/oscnet/up-c01f8b7b68770ed58c420d68072f773a30b.png"
                alt="cherish-ls" />
            
              <p class="site-author-name" itemprop="name">cherish-ls</p>
              <p class="site-description motion-element" itemprop="description">纸上得来终觉浅</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">54</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">94</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="git@github.com:cherish-ls/cherish-ls.github.io.git" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">cherish-ls</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">376.6k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"cherish"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  
















  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: 'TQhjcmooFXWGQ3qgqUroDKsD-gzGzoHsz',
        appKey: 'zjA9PvG5eljY1JErig8WVQQD',
        placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  

  
  

  

  

  

</body>
</html>
